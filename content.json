{"meta":{"title":"张慕晖的博客","subtitle":"LUX ET VERITAS","description":null,"author":"张慕晖","url":"https://zhanghuimeng.github.io"},"pages":[{"title":"《英诗金库》","date":"2018-06-26T11:56:04.000Z","updated":"2019-03-04T13:42:35.572Z","comments":true,"path":"GoldenTreasury/index.html","permalink":"https://zhanghuimeng.github.io/GoldenTreasury/index.html","excerpt":"","text":"这里收录了我已经写过的诗歌内容。 卷一 《英诗金库》I-1：Spring, the sweet spring, by T. Nashe 《英诗金库》I-2：Summons to Love, by W. Drummond 《英诗金库》I-3：When I have seen by Time’s fell hand defaced, by W. Shakespeare 《英诗金库》I-4：Since brass, nor stone, nor earth, nor boundless sea, by W. Shakespeare 《英诗金库》I-5：The Passionate Shepherd to His Love, by C. Marlowe 《英诗金库》I-6：Crabbed Age and Youth, by W. Shakespeare 《英诗金库》I-7：Under the greenwood tree, by W. Shakespeare 《英诗金库》I-8：It was a lover and his lass, by W. Shakespeare 《英诗金库》I-9：Present in Absence, by J. Donne 《英诗金库》I-10：Being your slave, what should I do but tend, by W. Shakespeare 《英诗金库》I-11：How like a winter hath my absence been, by W. Shakespeare 《英诗金库》I-12：When in disgrace with fortune and men’'s eyes, by W. Shakespeare 《英诗金库》I-13：O never say that I was false of heart, by W. Shakespeare 《英诗金库》I-14：To me, fair friend, you never can be old, by W. Shakespeare（TODO） 《英诗金库》I-15：Diaphenia, by H. Constable（TODO） 《英诗金库》I-16：Rosalynde, by T. Lodge（TODO） 《英诗金库》I-17：Beauty sat bathing by a spring, by A. Munday（TODO） 《英诗金库》I-18：Shall I compare thee to a summer’'s day, by W. Shakespeare（TODO） 《英诗金库》I-19：When in the chronicle of wasted time, by W. Shakespeare（TODO） 《英诗金库》I-20：On a day, alack the day, by W. Shakespeare（TODO） 《英诗金库》I-21：Forget not yet the tried intent, by T. Wyatt 《英诗金库》I-22：To Aurora, by W. Alexander 《英诗金库》I-23：Let me not to the marriage of true minds, by W. Shakespeare（TODO） 《英诗金库》I-24：My true-love hath my heart, by P. Sidney（TODO，因为真的很有趣） 《英诗金库》I-25：Were I as base as is the lowly plain, by J. Sylvester（TODO） 《英诗金库》I-26：O Mistress mine, where are you roaming, by W. Shakespeare（TODO） 《英诗金库》I-27：When icicles hang by the wall, by W. Shakespeare 《英诗金库》I-28：That time of year thou mayst in me behold, by W. Shakespeare（TODO） 《英诗金库》I-29：When to the sessions of sweet silent thought, by W. Shakespeare 《英诗金库》I-30：Like as the waves make towards the pebbled shore, by W. Shakespeare 《英诗金库》I-31：Farewell! thou art too dear for my possessing, by W. Shakespeare（TODO） 《英诗金库》I-32：They that have power to hurt and will do none, by W. Shakespeare（TODO） 《英诗金库》I-33：And wilt thou leave me thus, by T. Wyatt（TODO） 《英诗金库》I-34：The Nightingale, by R. Barnfield 《英诗金库》I-35：Care-charmer Sleep, by S. Daniel 《英诗金库》I-36：Madrigal, by W. Shakespeare 《英诗金库》I-37：Love’s Farewell, by D. Drayton 《英诗金库》I-38：My lute, be as thou wert when thou didst grow, by W. Drummond 《英诗金库》I-39：O me! what eyes hath Love put in my head, by W. Shakespeare 《英诗金库》I-40：The Unfaithful Shepherdess, by Anonymous 《英诗金库》I-41：If women could be fair and yet not fond, by E. Vere 《英诗金库》I-42：Blow, blow, thou winter wind, by W. Shakespeare 《英诗金库》I-43：Madrigal, by W. Drummond 《英诗金库》I-44：Come away, come away, death, by W. Shakespeare 《英诗金库》I-45：Fear no more the heat o’ the sun, by W. Shakespeare 《英诗金库》I-46：Full Fathom Five, by W. Shakespeare 《英诗金库》I-47：Call for the robin redbreast and the wren, by J. Webster 《英诗金库》I-48：If thou survive my well-contented day, by W. Shakespeare 《英诗金库》I-49：No longer mourn for me when I am dead, by W. Shakespeare 《英诗金库》I-50：Tell me where is fancy bred, by W. Shakespeare 《英诗金库》I-51：Cupid and Campaspe, by J. Lyly 《英诗金库》I-52：Pack, clouds, away, and welcome day, by T. HeyWood 《英诗金库》I-53：Prothalamion, by E. Spenser（TODO） 《英诗金库》I-54：Art thou poor, by T. Dekker 《英诗金库》I-55：This life, which seems so fair, by W. Drummond"},{"title":"操作系统","date":"2018-06-26T11:56:04.000Z","updated":"2019-03-04T13:42:35.572Z","comments":true,"path":"OS/index.html","permalink":"https://zhanghuimeng.github.io/OS/index.html","excerpt":"","text":"因为我对操作系统很感兴趣，所以下面列出了我写过的相关的文章。 OSTEP 这是操作系统课本Operating Systems: Three Easy Pieces的读书笔记和作业，这本书的作者是Remzi H. Arpaci-Dusseau和Andrea C. Arpaci-Dusseau，我很喜欢这本书。 2018.8.4 UPDATE：因为作业内容很多，所以我决定把每章的作业和实际内容总结拆分开来。 综述 OSTEP第01章总结：A Dialogue on the Book OSTEP第02章总结：Introduction to Operating Systems 虚拟化（Virtualization）部分 OSTEP第03章总结：A Dialogue on Virtualization OSTEP第04章总结：The Abstraction: The Process OSTEP第04章作业：Simulation: process-run.py OSTEP第05章总结：Interlude: Process API OSTEP第05章作业：Coding: Process APIs OSTEP第06章总结：Mechanism: Limited Direct Execution"},{"title":"USACO","date":"2019-01-06T11:56:04.000Z","updated":"2019-03-04T13:42:35.572Z","comments":true,"path":"USACO/index.html","permalink":"https://zhanghuimeng.github.io/USACO/index.html","excerpt":"","text":"USACO的题解和文章翻译合集。 Chapter 1: Getting Started Section 1.1 TEXT: Introduction（暂缺） Section 1.2: Submitting Soln, Task Types, Ad Hoc TEXT: Submitting Solutions（暂缺） PROB: Your Ride Is Here（题解：USACO 1.2.1: Your Ride Is Here） TEXT: Contest Problem Types（暂缺） TEXT: Ad Hoc Problems（暂缺） PROB: Greedy Gift Givers（题解：USACO 1.2.2: Greedy Gift Givers） PROB: Friday the Thirteenth（题解：USACO 1.2.3: Friday the Thirteenth） PROB: Broken Necklace（题解：USACO 1.2.4: Broken Necklace） Section 1.3: Complete Search TEXT: Complete Search（暂缺） PROB: Milking Cows（题解：USACO 1.2.4: Broken Necklace） PROB: Transformations（题解：USACO 1.3.2: Transformations） PROB: Name That Number（题解：USACO 1.3.3: Name That Number） PROB: Palindromic Squares（题解：USACO 1.3.4: Palindromic Squares） PROB: Dual Palindromes（题解：USACO 1.3.5: Dual Palindromes） Section 1.4: Greedy, Crafting Solutions TEXT: Greedy Algorithm（翻译：翻译：贪心算法（USACO）） PROB: Miking Milk（题解：USACO 1.4.1: Mixing Milk） PROB: Barn Repair（题解：USACO 1.4.2: Barn Repair） TEXT: Winning Solutions（翻译：翻译：编写成功的解题代码（USACO）） PROB: Prime Cryptarithm（题解：USACO 1.4.3: Prime Cryptarithm） PROB: Combination Lock（题解：USACO 1.4.4: Combination Lock） PROB: Wormholes（题解：USACO 1.4.5: Wormholes） PROB: Ski Course Design（题解：USACO 1.4.6: Ski Course Design） Section 1.5: More Search Techniques TEXT: More Search Techniques（翻译：翻译：搜索方法（USACO）） PROB: Arithmetic Progressions（题解：USACO 1.5.1: Arithmetic Progressions） PROB: Mother’s Milk（题解：USACO 1.5.2: Mother’s Milk） Section 1.6: Binary Numbers TEXT: Introduction to Binary Numbers（翻译：翻译：二进制数（USACO）） PROB: Number Triangles（题解：USACO 1.6.1: Number Triangles） PROB: Prime Palindromes（题解：USACO 1.6.2: Prime Palindromes） PROB: SuperPrime Rib（题解：USACO 1.6.3: Superprime Rib） Chapter 2: Bigger Challenges Section 2.1 TEXT: Graph Theory（翻译：翻译：图论（USACO）） TEXT: Flood Fill Algorithms（翻译：翻译：洪水填充算法（USACO）） PROB: The Castle（题解：USACO 2.1.1: The Castle） PROB: Ordered Fractions（题解：USACO 2.1.2: Ordered Fractions） PROB: Sorting A Three-Valued Sequence（题解：USACO 2.1.3: Sorting a Three-Valued Sequence） PROB: Healthy Holsteins（题解：USACO 2.1.4: Healthy Holsteins） PROB: Hamming Codes（题解：USACO 2.1.5: Hamming Codes） Section 2.2: Data Structures, Dynamic Prog. TEXT: Data Structures（翻译：翻译：数据结构（USACO）） TEXT: Dynamic Programming（翻译：翻译：动态规划（USACO）） PROB: Preface Numbering（题解：USACO 2.2.1: Preface Numbering） PROB: Subset Sums（题解：USACO 2.2.2: Subset Sums（DP）） PROB: Runaround Numbers（题解：USACO 2.2.3: Runaround Numbers） PROB: Party Lamps（题解：USACO 2.2.4: Party Lamps） Section 2.3 (All Tasks) PROB: The Longest Prefix（题解：USACO 2.3.1: Longest Prefix） PROB: Cow Pedigrees（题解：USACO 2.3.2: Cow Pedigrees） PROB: Zero Sum PROB: Money Systems PROB: Controlling Companies Section 2.4: Shortest Paths TEXT: Shortest Paths PROB: The Tamworth Two PROB: Overfencing PROB: Cow Tours PROB: Bessie Come Home PROB: Fractions to Decimals Chapter 3: Techniques more subtle Section 3.1: Spanning Trees TEXT: Minimal Spanning Trees PROB: Agri-Net PROB: Score Inflation PROB: Humble Numbers PROB: Contact PROB: Stamps Section 3.2: Knapsack TEXT: Knapsack Problems PROB: Factorials PROB: Stringobits PROB: Spinning Wheels PROB: Feed Ratios PROB: Magic Squares PROB: Sweet Butter Section 3.3: Eulerian Tours TEXT: Eulerian Tours（翻译：翻译：欧拉路（USACO）） PROB: Riding The Fences PROB: Shopping Offers PROB: Camelot PROB: Home on the Range PROB: A Game Section 3.4: Computational Geometry TEXT: Computational Geometry（翻译：翻译：计算几何（USACO）） PROB: American Heritage PROB: Electric Fence PROB: Raucous Rockers Chapter 4: Advanced algorithms and difficult drills 还没做 Chapter 5: Serious challenges 还没做 Chapter 6: Contest Practice 还没做"},{"title":"","date":"2019-03-04T13:42:36.064Z","updated":"2019-03-04T13:42:36.064Z","comments":false,"path":"categories/index.html","permalink":"https://zhanghuimeng.github.io/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2019-03-04T13:42:36.080Z","updated":"2019-03-04T13:42:36.080Z","comments":true,"path":"links/index.html","permalink":"https://zhanghuimeng.github.io/links/index.html","excerpt":"","text":""},{"title":"","date":"2019-03-04T13:42:36.080Z","updated":"2019-03-04T13:42:36.080Z","comments":false,"path":"tags/index.html","permalink":"https://zhanghuimeng.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Leetcode Weekly Contest 125总结","slug":"2019-02-26-Leetcode-Weekly-Contest-125","date":"2019-02-26T20:54:43.000Z","updated":"2019-02-27T14:41:00.000Z","comments":true,"path":"post/leetcode-weekly-contest-125-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-weekly-contest-125-summary/","excerpt":"","text":"比赛太多，题解写不过来，Leetcode题解也变成每周一份了…… 997. Find the Town Judge 标记难度：Easy 提交次数：1/2 代码效率：252ms 题意 有N个人，他们之间有一些相互信任的关系，其中可能有一个town judge，如果有则只有一个，且满足以下要求： town judge不信任别人 除了town judge之外的其他人都信任他 请找出town judge，或者返回-1。 分析 水题，随便怎么做都好。 代码 1234567891011121314151617181920class Solution &#123;public: int findJudge(int N, vector&lt;vector&lt;int&gt;&gt;&amp; trust) &#123; set&lt;int&gt; tSet[N + 1]; int trusting[N + 1]; memset(trusting, 0, sizeof(trusting)); for (int i = 0; i &lt; trust.size(); i++) &#123; tSet[trust[i][1]].insert(trust[i][0]); trusting[trust[i][0]]++; &#125; int ans = -1; for (int i = 1; i &lt;= N; i++) &#123; if (tSet[i].size() == N - 1 &amp;&amp; trusting[i] == 0) &#123; if (ans == -1) ans = i; else return -1; &#125; &#125; return ans; &#125;&#125;; 998. Maximum Binary Tree II 标记难度：Medium 提交次数：1/2 代码效率： 暴力：12ms 不暴力：8ms 题意 定义一种“最大二叉树”： 对于一个数组A，建一棵这样的树： 找出其中最大的元素A[i] 令当前结点的值为A[i]，左子结点为数组A[:i-1]建出的树，右子结点为数组A[i+1:]建出的数 现在给定一棵这样的二叉树，假设你在它对应的数组A后面加上一个值val，问得到的新树是什么样子的？ 分析 这道题还稍微有点意思。比赛的时候，鉴于这是在比赛，所以我就直接愚蠢地把整棵树序列化成数组，把val加上去，然后重造了一棵树，反正N也不大……复杂度最差O(N^2)。 不那么愚蠢的方法倒是很容易考虑。首先把val和树根比较，如果val比它大，那它就是新的树根；否则继续去右子树里面查。[1] 代码 暴力做法 真的很暴力啊。 123456789101112131415161718192021222324252627282930313233class Solution &#123;private: vector&lt;int&gt; dfs(TreeNode* root) &#123; if (root == NULL) return &#123;&#125;; vector&lt;int&gt; l = dfs(root-&gt;left); l.push_back(root-&gt;val); vector&lt;int&gt; r = dfs(root-&gt;right); l.insert(l.end(), r.begin(), r.end()); return l; &#125; TreeNode* dfs(int l, int r, vector&lt;int&gt;&amp; a) &#123; if (l &gt; r) return NULL; if (l == r) return new TreeNode(a[l]); int maxn = -1, argmax = -1; for (int i = l; i &lt;= r; i++) if (a[i] &gt; maxn) &#123; maxn = a[i]; argmax = i; &#125; TreeNode* root = new TreeNode(a[argmax]); root-&gt;left = dfs(l, argmax - 1, a); root-&gt;right = dfs(argmax + 1, r, a); return root; &#125; public: TreeNode* insertIntoMaxTree(TreeNode* root, int val) &#123; vector&lt;int&gt; a(dfs(root)); a.push_back(val); return dfs(0, a.size() - 1, a); &#125;&#125;; 不暴力的做法 12345678910111213class Solution &#123;public: TreeNode* insertIntoMaxTree(TreeNode* root, int val) &#123; if (root == NULL) return new TreeNode(val); if (val &gt; root-&gt;val) &#123; TreeNode* p = new TreeNode(val); p-&gt;left = root; return p; &#125; root-&gt;right = insertIntoMaxTree(root-&gt;right, val); return root; &#125;&#125;; 999. Available Captures for Rook 标记难度：Easy 提交次数：1/1 代码效率：4ms 题意 在一个国际象棋盘上有一个白车，几个（或没有）白主教，几个（或没有）黑卒，剩下的地方都是空格。白车可以从上下左右中选择一个方向移动，直到遇到棋盘边沿/被主教堵住/吃到黑卒。问白车一共有可能吃到多少个黑卒？ 分析 这题水到不能再水了。模拟走四次即可…… 代码 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int numRookCaptures(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; int rx, ry; int n = board.size(), m = board[0].size(); int mx[4] = &#123;0, 0, 1, -1&#125;; int my[4] = &#123;1, -1, 0, 0&#125;; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; m; j++) &#123; if (board[i][j] == 'R') &#123; rx = i; ry = j; break; &#125; &#125; int ans = 0; for (int d = 0; d &lt; 4; d++) &#123; int x = rx, y = ry; while (0 &lt;= x &amp;&amp; x &lt; n &amp;&amp; 0 &lt;= y &amp;&amp; y &lt; m) &#123; if (board[x][y] == 'p') &#123; ans++; break; &#125; else if (board[x][y] == 'B') break; x += mx[d]; y += my[d]; &#125; &#125; return ans; &#125;&#125;; 1001. Grid Illumination 标记难度：Hard 提交次数：1/1 代码效率：764ms 题意 嘿，1000题呢？ 在一个grid上有一些灯，每个灯会照亮所有和它同行、同列、同对角线的格子。我们query这个grid上的一些格子现在是不是亮的，同时，一旦进行一次query，就把和它八连通的灯都关掉（如果有这样的灯）。问每次query的结果。 分析 这道题也挺水的。记录每一行、每一列、每条对角线被多少灯照亮了，然后在query的时候进行必要的删除就行。 代码 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;private: int mx[8] = &#123;0, 0, 1, -1, 1, 1, -1, -1&#125;; int my[8] = &#123;1, -1, 0, 0, 1, -1, 1, -1&#125;;public: vector&lt;int&gt; gridIllumination(int N, vector&lt;vector&lt;int&gt;&gt;&amp; lamps, vector&lt;vector&lt;int&gt;&gt;&amp; queries) &#123; map&lt;int, int&gt; row, col, ldiag, rdiag; map&lt;pair&lt;int, int&gt;, int&gt; lampSet; for (int i = 0; i &lt; lamps.size(); i++) &#123; int x = lamps[i][0], y = lamps[i][1]; row[x]++; col[y]++; ldiag[x - y]++; rdiag[x + y]++; lampSet[&#123;x, y&#125;]++; &#125; vector&lt;int&gt; ans; for (int i = 0; i &lt; queries.size(); i++) &#123; int x = queries[i][0], y = queries[i][1]; if (row[x] &gt; 0 || col[y] &gt; 0 || ldiag[x - y] &gt; 0 || rdiag[x + y] &gt; 0) ans.push_back(1); else ans.push_back(0); for (int j = 0; j &lt; 8; j++) &#123; int nx = x + mx[j], ny = y + my[j]; if (nx &lt; 0 || nx &gt;= N || ny &lt; 0 || ny &gt;= N) continue; // 删掉可能的lamp if (lampSet.find(&#123;nx, ny&#125;) != lampSet.end() &amp;&amp; lampSet[&#123;nx, ny&#125;] &gt; 0) &#123; lampSet[&#123;nx, ny&#125;]--; row[nx]--; col[ny]--; ldiag[nx - ny]--; rdiag[nx + ny]--; &#125; &#125; &#125; return ans; &#125;&#125;; Leetcode 998 Solution - Java clean recursive solution ↩︎","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 996. Number of Squareful Arrays（DP）","slug":"2019-02-21-Leetcode-996-Number-of-Squareful-Arrays（DP）","date":"2019-02-21T00:05:00.000Z","updated":"2019-02-21T00:05:00.000Z","comments":true,"path":"post/leetcode-996-number-of-squareful-arrays/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-996-number-of-squareful-arrays/","excerpt":"","text":"题目来源：https://leetcode.com/problems/number-of-squareful-arrays/description/ 标记难度：Hard 提交次数：1/1 代码效率：36.82%（12ms） 题意 给定数组A，问有多少种A的排列，使得任意两个相邻元素的和都是平方数。认为两种排列不等当且仅当存在某个位置的元素不等（而不是把不同index的相同元素认为是不同的）。 分析 这又是一道“虽然看起来好像应该用状态DP做但因为数据量太小了所以不如直接DFS搜索”的题。既然我都写了DP了，现在实在懒得去写DFS，就这样好了。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667class Solution &#123;private: bool isSquare(int x) &#123; int s = (int) sqrt(x); if (s*s == x) return true; return false; &#125; int f[1 &lt;&lt; 12][12]; vector&lt;int&gt; A; bool ok[12][12]; int n; int calc(int state, int end) &#123; if (f[state][end] != -1) return f[state][end]; if (!(state &amp; (1 &lt;&lt; end))) &#123; f[state][end] = 0; return 0; &#125; if (__builtin_popcount(state) == 1) &#123; f[state][end] = 1; return 1; &#125; f[state][end] = 0; for (int i = 0; i &lt; n; i++) &#123; if (i == end || !ok[i][end] || !(state &amp; (1 &lt;&lt; i))) continue; f[state][end] += calc(state ^ (1 &lt;&lt; end), i); &#125; return f[state][end]; &#125; int factorial(int x) &#123; int ans = 1; while (x &gt; 0) &#123; ans *= x; x--; &#125; return ans; &#125; public: int numSquarefulPerms(vector&lt;int&gt;&amp; A) &#123; sort(A.begin(), A.end()); this-&gt;A = A; n = A.size(); for (int i = 0; i &lt; n; i++) &#123; ok[i][i] = false; for (int j = i + 1; j &lt; n; j++) &#123; if (isSquare(A[i] + A[j])) ok[i][j] = ok[j][i] = true; else ok[i][j] = ok[j][i] = false; &#125; &#125; memset(f, -1, sizeof(f)); int ans = 0; for (int i = 0; i &lt; n; i++) ans += calc((1 &lt;&lt; n) - 1, i); map&lt;int, int&gt; cnt; for (int x: A) cnt[x]++; for (auto p: cnt) ans /= factorial(p.second); return ans; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Dynamic Porgramming","slug":"alg-Dynamic-Porgramming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Porgramming/"}]},{"title":"Leetcode 995. Minimum Number of K Consecutive Bit Flips","slug":"2019-02-21-Leetcode-995-Minimum-Number-of-K-Consecutive-Bit-Flips","date":"2019-02-21T00:04:12.000Z","updated":"2019-02-22T00:30:00.000Z","comments":true,"path":"post/leetcode-995-minimum-number-of-k-consecutive-bit-flips/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-995-minimum-number-of-k-consecutive-bit-flips/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-number-of-k-consecutive-bit-flips/description/ 标记难度：Hard 提交次数：4/5 代码效率： 暴力贪心：12.68%（5152ms） 线段树：52.11%（288ms） O(n)：96.20%（84ms） 题意 有一个只包含0和1的数组A，每次可以将数组A中的恰好连续k个元素取反，问能否将A变成全1？ 分析 很容易就能想到一种贪心策略：找到左边第一个0，从它开始翻转连续k个元素（因为这个0只能在这里通过翻转而变成1，否则左边就会出现新的0），然后对于右边的0，继续进行这一操作，如果最后能成功则A可以变成全1。这个算法是O(n*k)的，或者说是O(n^2)的，可能太慢了。 很容易就能想到一种优化策略：用线段树来进行区间更新。这样复杂度就会变成O(n*log(n))，可以接受。 用线段树实在是overkill了。可以很简单地通过记录区间的开闭事件来确定当前元素是否需要取反。甚至可以不显式地记录开闭事件——如果k个元素之前的元素是0，那么现在就是一个区间的关闭。[1] 代码 暴力贪心 123456789101112131415class Solution &#123;public: int minKBitFlips(vector&lt;int&gt;&amp; A, int K) &#123; int ans = 0; for (int i = 0; i &lt; A.size(); i++) &#123; if (A[i] == 0) &#123; if (i + K - 1 &gt;= A.size()) return -1; for (int j = 0; j &lt; K; j++) A[i + j] = 1 - A[i + j]; ans++; &#125; &#125; return ans; &#125;&#125;; 线段树 当然，这是一种比较愚蠢的做法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class Solution &#123;private: struct TreeNode &#123; int l, r; bool toFlip; TreeNode(int _l = 0, int _r = 0) &#123; l = _l; r = _r; toFlip = false; &#125; &#125;; TreeNode tree[120005]; vector&lt;int&gt; a; void buildTree(int node, int l, int r) &#123; if (l &gt; r) return; if (l == r) tree[node].l = tree[node].r = l; else &#123; int m = (l + r) / 2; tree[node].l = l; tree[node].r = r; buildTree(node * 2, l, m); buildTree(node * 2 + 1, m + 1, r); &#125; &#125; void update(int node, int l, int r) &#123; if (tree[node].r &lt; l || r &lt; tree[node].l) return; if (l &lt;= tree[node].l &amp;&amp; tree[node].r &lt;= r) &#123; tree[node].toFlip = !tree[node].toFlip; return; &#125; if (tree[node].toFlip) &#123; tree[node * 2].toFlip = !tree[node * 2].toFlip; tree[node * 2 + 1].toFlip = !tree[node * 2 + 1].toFlip; tree[node].toFlip = false; &#125; update(node * 2, l, r); update(node * 2 + 1, l, r); &#125; bool query(int node, int l) &#123; if (tree[node].l == tree[node].r) &#123; if (tree[node].toFlip) return !a[l]; return a[l]; &#125; if (tree[node].toFlip) &#123; tree[node * 2].toFlip = !tree[node * 2].toFlip; tree[node * 2 + 1].toFlip = !tree[node * 2 + 1].toFlip; tree[node].toFlip = false; &#125; int m = (tree[node].l + tree[node].r) / 2; if (l &lt;= m) return query(node * 2, l); else return query(node * 2 + 1, l); &#125; public: int minKBitFlips(vector&lt;int&gt;&amp; A, int K) &#123; a = A; int n = A.size(); int ans = 0; buildTree(1, 0, n - 1); for (int i = 0; i &lt; n; i++) &#123; bool x = query(1, i); if (!x &amp;&amp; i + K &gt; n) return -1; if (!x) &#123; update(1, i, i + K - 1); ans++; &#125; &#125; return ans; &#125;&#125;; O(n) 1234567891011121314151617181920class Solution &#123;public: int minKBitFlips(vector&lt;int&gt;&amp; A, int K) &#123; int n = A.size(); int event[n + 1]; memset(event, 0, sizeof(event)); int cur = 0, ans = 0; for (int i = 0; i &lt; n; i++) &#123; cur += event[i]; int x = (A[i] + cur) % 2; if (x == 0) &#123; if (i + K - 1 &gt;= n) return -1; cur++; ans++; event[i + K]--; &#125; &#125; return ans; &#125;&#125;; les215’s solution - [Java/C++/Python] One Pass and O(1) Space ↩︎","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Codeforces Educational Codeforces Round 60 总结","slug":"2019-02-20-Codeforces-Educational-Codeforces-Round-60-总结","date":"2019-02-20T18:50:42.000Z","updated":"2019-02-21T19:32:00.000Z","comments":true,"path":"post/codeforces-educational-codeforces-round-60-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-educational-codeforces-round-60-summary/","excerpt":"","text":"这次比赛做得乱七八糟，事实上一共只做出来两道题，结果rating还涨了一点点，看来确实有点难。。 1117A 题目来源：https://codeforces.com/contest/1117/problem/A 提交次数：1/1 题意 给定一个数组，问数组中满足平均数最大的前提下长度最长的子数列。 分析 就是找到最大值然后计算最大值最多连续出现了多少次而已。水题。 代码 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int n;int a[100005];int main() &#123; int maxn = -1; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; maxn = max(maxn, a[i]); &#125; int ans = 0, l = 1; for (int i = 1; i &lt;= n; i++) &#123; if (i == n || a[i] != a[i - 1]) &#123; if (a[i - 1] == maxn) ans = max(l, ans); l = 1; &#125; else l++; &#125; cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 1117B 题目来源：https://codeforces.com/contest/1117/problem/B 提交次数：1/1 题意 给定n个emote，每个emote可以将对手的快乐值增加a[i]，你可以使用一些emote共m次，相同的emote最多连续使用k次，问最多能增加多少快乐值？ 分析 找出值最大和值次大的emote，连续用最大的emotek次，用一次次大的emote，再接着用最大的emote，以此类推，直到一共用了m次为止。水题。 代码 12345678910111213141516#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;typedef long long LL;LL n, m, k;LL a[200005];int main() &#123; cin &gt;&gt; n &gt;&gt; m &gt;&gt; k; for (int i = 0; i &lt; n; i++) cin &gt;&gt; a[i]; sort(a, a + n); LL cnt = m / (k + 1); LL ans = cnt * (a[n-1] * k + a[n-2]) + (m - (k + 1) * cnt) * a[n-1]; cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 1117C 题目来源：https://codeforces.com/contest/1117/problem/C 提交次数：1/4 题意 你在(x1, y1)处有一艘船，每天可以向上或下、左、右移动1格。每天的移动效果会和天气效果叠加，天气效果会使得船根据风向往上或下、左、右移动一格。给定m天的天气，之后的天气是循环的，问最少需要几天，船才能到达(x2, y2)处？ 分析 比赛的时候我意识到走完一个天气循环之后，能到的位置是一个菱形了（或者说是一个尖朝上的正方形）；但很可惜我没有意识到这件事的本质，还打算拿计算几何来做（？？）。显然，这件事的本质是这样的：把天气推船走的路和船自己走的路分开，可以得出一个结论：天气在一个循环内推船走的路是固定的，不妨记为(dx, dy)；船自己可以在这个点周围走出一个菱形，或者说是所有满足|x-dx|+|y-dy|&lt;=n的点。所以对天数二分查找就好了。当然，还是需要重视一下二分查找的前提：只要x天能到，那么y&gt;=x天也能到。（大不了不动）[1] 除此之外就是注意上界。显然如果能到达(x2, y2)，每个天气循环至少要向这个方向前进1格（曼哈顿距离），所以上界是(|x2-x1| + |y2-y1|)*n。如果走了这么多还没到，说明到不了了。 代码 因为long long int的使用错了好多次…… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;typedef long long LL;LL x1, y1, x2, y2;int n;char s[100005];pair&lt;LL, LL&gt; pos[100005];LL fx, fy;// U, R, D, Lint mx[4] = &#123;0, 1, 0, -1&#125;;int my[4] = &#123;1, 0, -1, 0&#125;;bool isOk(LL days) &#123; LL sx = (days / n) * fx, sy = (days / n) * fy; sx += pos[days % n].first, sy += pos[days % n].second; return abs(x2 - sx) + abs(y2 - sy) &lt;= days;&#125;int main() &#123; cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; x2 &gt;&gt; y2; x2 -= x1; y2 -= y1; cin &gt;&gt; n; cin &gt;&gt; s; for (int i = 1; i &lt;= n; i++) &#123; int d; if (s[i-1] == 'U') d = 0; else if (s[i-1] == 'R') d = 1; else if (s[i-1] == 'D') d = 2; else if (s[i-1] == 'L') d = 3; pos[i].first = pos[i-1].first + mx[d]; pos[i].second = pos[i-1].second + my[d]; &#125; fx = pos[n].first, fy = pos[n].second; LL l = 0, r = (abs(x2) + abs(y2)) * n; while (l &lt; r) &#123; LL m = (l + r) / 2; if (isOk(m)) r = m; else l = m + 1; &#125; if (!isOk(l)) cout &lt;&lt; -1 &lt;&lt; endl; else cout &lt;&lt; l &lt;&lt; endl; return 0;&#125; 1117D 题目来源：https://codeforces.com/contest/1117/problem/D 提交次数：1/1 题意 一颗魔法宝石可以分裂成M颗普通宝石，问有多少种选择魔法宝石的方法，使得分裂后总的宝石数量是N？不同的魔法宝石数量和不同index的分裂被认为是不同的方法。N&lt;=10^18，M&lt;=100。 分析 比赛的时候我努力推了一个公式出来： ∑i=0⌊N/M⌋(N−(M−1)ii)\\sum_{i=0}^{\\lfloor N/M \\rfloor} \\binom{N-(M-1)i}{i} i=0∑⌊N/M⌋​(iN−(M−1)i​) 但是肯定不能这么算，因为N太大了。我心想：用动态规划估计也不行。 事实上得用到动态规划递推的思路，看到N和M的大小，我早该想到是矩阵快速幂才对。 令f[n]表示N=n时的方法数量。显然有两种方法进行递推：一种是加上一块不分裂的宝石（f[n-1]）；另一种是加上一块分裂的宝石（f[n-M]）。（虽然第二维看起来没有什么意义……）考虑到递推的本质，不需要乘新加的宝石的位置，因此： 1f[n] = f[n-1] + f[n-M] 现在就可以造一个矩阵乘法迭代公式了： 12345| f[n-M] f[n-M+1] ... f[n-1] | * | 0 0 0 ... 0 1 | = | f[n-M+1] | | 1 0 0 ... 0 0 | | f[n-M+2] | | 0 1 0 ... 0 0 | | ... | | 0 0 1 ... 0 0 | | f[n-1] | | 0 0 0 ... 1 1 | | f[n] | 然后矩阵快速幂即可。 太久没写矩阵快速幂，手都生了…… 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;typedef long long LL;LL N;int M;const LL P = 1000000007;struct Matrix &#123; int n, m; LL a[105][105]; Matrix(int _n, int _m) &#123; memset(a, 0, sizeof(a)); n = _n; m = _m; &#125; friend Matrix operator * (const Matrix&amp; m1, const Matrix&amp; m2) &#123; Matrix m3(m1.n, m2.m); for (int i = 1; i &lt;= m1.n; i++) for (int j = 1; j &lt;= m1.m; j++) for (int k = 1; k &lt;= m2.m; k++) m3.a[i][k] = (m3.a[i][k] + m1.a[i][j] * m2.a[j][k]) % P; return m3; &#125; void print() &#123; cout &lt;&lt; n &lt;&lt; ' ' &lt;&lt; m &lt;&lt; endl; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= m; j++) cout &lt;&lt; a[i][j] &lt;&lt; ' '; cout &lt;&lt; endl; &#125; &#125;&#125;;Matrix getIdentity(int n) &#123; Matrix mat(n, n); for (int i = 1; i &lt;= n; i++) mat.a[i][i] = 1; return mat;&#125;int main() &#123; cin &gt;&gt; N &gt;&gt; M; if (N &lt; M) &#123; cout &lt;&lt; 1 &lt;&lt; endl; return 0; &#125; Matrix v(1, M); for (int i = 1; i &lt; M; i++) v.a[1][i] = 1; v.a[1][M] = 2; Matrix x(M, M); for (int i = 2; i &lt;= M; i++) x.a[i][i - 1] = 1; x.a[1][M] = x.a[M][M] = 1; LL delta = N - M; Matrix pow = x; Matrix ans = getIdentity(M); while (delta &gt; 0) &#123; if (delta &amp; 1) ans = ans * pow; delta &gt;&gt;= 1; pow = pow * pow; &#125; v = v * ans; cout &lt;&lt; v.a[1][M] &lt;&lt; endl; return 0;&#125; 1117E 题目来源：https://codeforces.com/contest/1117/problem/E 提交次数：1/1 题意 这是一道交互题。给定一个字符串，已知对它进行了&lt;=n次swap操作；你可以拿出一个新的和它长度一样的字符串，然后得到对这个字符串进行相同的swap之后的结果。你最多可以提交三次字符串。问原来的字符串是多少？ 分析 比赛的时候，我看了看这道题……觉得很有趣，但应该想半天也做不出来吧。（我从来没在比赛里做对过交互题）这道题的一种解法是这样的：既然每次提交的字符串的swap操作是一样的，不妨把提交的三次字符串看成是一个字符串，它的每个位置是由三个字符组成的一个“超字符”。这样我们就可以认为每个位置的“超字符”是两两不等的了！因为26^3 = 17576 &gt;= 1e4，这是可行的。 然后就可以立即得到每个输入位置到输出位置的映射了，倒过来对原来的字符串重新做一遍就行了。 评论区里还出现了用中国剩余定理的做法，我没细看。[2] 代码 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;char s[10005];char q[3][10005];char a[3][10005];int mapping[10005];int n;int main() &#123; cin &gt;&gt; s; n = strlen(s); int m = 0; for (int i = 0; i &lt; 26; i++) &#123; for (int j = 0; j &lt; 26; j++) &#123; for (int k = 0; k &lt; 26; k++) &#123; q[0][m] = i + 'a'; q[1][m] = j + 'a'; q[2][m] = k + 'a'; m++; if (m &gt;= n) break; &#125; if (m &gt;= n) break; &#125; if (m &gt;= n) break; &#125; for (int i = 0; i &lt; 3; i++) &#123; cout &lt;&lt; \"? \" &lt;&lt; q[i] &lt;&lt; endl; cin &gt;&gt; a[i]; &#125; for (int i = 0; i &lt; n; i++) &#123; int idx = (a[0][i] - 'a') * 26 * 26 + (a[1][i] - 'a') * 26 + (a[2][i] - 'a'); mapping[idx] = i; &#125; cout &lt;&lt; \"! \"; for (int i = 0; i &lt; n; i++) cout &lt;&lt; s[mapping[i]]; cout &lt;&lt; endl; return 0;&#125; 1117F 题目来源：https://codeforces.com/contest/1117/problem/F 提交次数：?/? 题意 还没看懂，感觉有点难度。 111G 题目来源：https://codeforces.com/contest/1117/problem/G 提交次数：?/? 题意 给定一个由1到n的全排列组成的数组，记m是[l, r]范围内的最大元素index，定义函数 12f(l, r) = (r - l + 1) + f(l, m - 1) + f(m + 1, r) (l &lt;= r)f(l, r) = 0 (l &gt; r) 给定q个询问，请给定f的值。 1 &lt;= n, q &lt;= 1e6。 分析 这道题我比赛的时候自然是不会做的。比赛完了，看看题解，发现也晦涩难懂。[1:1] 首先需要把f分解成两个函数，fl和fr： 123fl(l, r) = (m - l) + fl(l, m-1) + fl(m+1, r)fr(l, r) = (r - m) + fr(l, m-1) + fr(m+1, r)f(l, r) = (r - l + 1) + fl(l, r) + fr(l, r) 可以用数学归纳法简单地证明这个分解的正确性（虽然我可不知道为什么要这样分解……）： 12345f(l, r) = (r - l + 1) + fl(l, r) + fr(l, r) = (r - l + 1) + fl(l, m-1) + fl(m+1, r) + (m - l) + fr(l, m-1) + fr(m+1, r) + (r - m) = (r - l + 1) + f(l, m-1) - (m-1 - l + 1) + f(m+1, r) - (r - (m+1) + 1) + (r - l) = (r - l + 1) + f(l, m-1) + f(m+1, r) 然后不妨举一个例子来看看fl是怎么算出来的： （显然fl(i, i) = fr(i,i) = 0） 把这些式子全部展开，就会变成： 1234fl(1, 6) = (3-1) + fl(1, 2) + fl(4, 6) = (3-1) + (1-1) + fl(2, 2) + (4-4) + fl(5, 6) = (3-1) + (1-1) + (2-2) + (4-4) + (6-5) + fl(5, 5) = (3-1) + (1-1) + (2-2) + (4-4) + (6-5) + (5, 5) 可以看出，fl其实是由6项组成的，而且每一项都是某个l &lt;= i &lt;= r与它左边最近的比它小的元素（或者l）之间的距离。这么想其实很合理。记i左边离它最近的比它大的元素为lf[i]，可以看出，它对fl(l, r)产生贡献当且仅当它被作为最大元素选中了，且贡献大小为min(i - l, i - lf[i] - 1)。 Educational Codeforces Round 60 Editorial ↩︎ ↩︎ saeed_odak’s comment for 1117E ↩︎","categories":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/categories/Codeforces/"}],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Binary Search","slug":"alg-Binary-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search/"},{"name":"alg:Matrix","slug":"alg-Matrix","permalink":"https://zhanghuimeng.github.io/tags/alg-Matrix/"},{"name":"alg:Segmentation Tree","slug":"alg-Segmentation-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Segmentation-Tree/"}]},{"title":"Leetcode 994. Rotting Oranges（BFS）","slug":"2019-02-19-Leetcode-994-Rotting-Oranges（BFS）","date":"2019-02-19T21:38:19.000Z","updated":"2019-02-20T23:55:00.000Z","comments":true,"path":"post/leetcode-994-rotting-oranges/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-994-rotting-oranges/","excerpt":"","text":"题目来源：https://leetcode.com/problems/cousins-in-binary-tree/description/ 标记难度：Easy 提交次数：1/1 代码效率：12ms 题意 在一个四连通图上有若干个橘子，其中有一些是烂的，烂橘子每秒都会向四连通的橘子扩散，问经过多少秒，所有的橘子会烂掉？ 分析 前几天在CF上做过一道有点类似的题（1105D，也是BFS分次扩展，当时虽然过了pretest，却因为每次扩展的结点过多且queue初始化过慢超时了。所以我就学到了一个道理：在这种情况下注意到底应该扩展哪些结点。不过这道题其实没有这个必要…… 考虑到这一点，不如直接用vector代替queue。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: int orangesRotting(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; vector&lt;pair&lt;int, int&gt;&gt; q; int orangeCnt = 0; int n = grid.size(), m = grid[0].size(); int mx[4] = &#123;0, 0, 1, -1&#125;; int my[4] = &#123;1, -1, 0, 0&#125;; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (grid[i][j] != 0) orangeCnt++; if (grid[i][j] == 2) q.emplace_back(i, j); &#125; &#125; if (q.size() == orangeCnt) return 0; // 全都烂了 if (q.size() == 0) return -1; // 根本没有烂的 // [lastEnd, lastSize)这部分是本次需要扩展的 // 之前的已经扩展过了，没有再扩展一次的必要 int lastEnd = 0, lastSize = q.size(); for (int i = 1; ; i++) &#123; for (int j = lastEnd; j &lt; lastSize; j++) &#123; int x = q[j].first, y = q[j].second; for (int k = 0; k &lt; 4; k++) &#123; int nx = x + mx[k], ny = y + my[k]; if (nx &lt; 0 || nx &gt;= n || ny &lt; 0 || ny &gt;= m) continue; if (grid[nx][ny] == 1) &#123; grid[nx][ny] = 2; q.emplace_back(nx, ny); &#125; &#125; &#125; // 本次没有扩展出新的烂橘子，且还有橘子没烂，说明扩展不到那边了 if (lastSize == q.size()) return -1; // 所有橘子都烂了 if (q.size() == orangeCnt) return i; lastEnd = lastSize; lastSize = q.size(); &#125; return 0; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 993. Cousins in Binary Tree（树）","slug":"2019-02-19-Leetcode-993-Cousins-in-Binary-Tree（树）","date":"2019-02-19T02:51:51.000Z","updated":"2019-02-19T02:51:51.000Z","comments":true,"path":"post/leetcode-993-cousins-in-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-993-cousins-in-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/cousins-in-binary-tree/description/ 标记难度：Easy 提交次数：1/1 代码效率：8ms 题意 定义二叉树中的“堂兄弟”结点：两个深度相同且父结点不同的结点。给定一棵结点值互异的二叉树和两个树中的结点值x和y，问这两个结点是否为堂兄弟。 分析 只要遍历二叉树，并记录对应的两个结点的父节点和深度即可。不过为了降低复杂度，甚至可以干脆把每个结点的父节点和深度都记录下来，然后在里面查。 代码 这里遍历用的是DFS。 12345678910111213141516171819class Solution &#123;private: int father[102]; int depth[102]; void dfs(TreeNode* root, int d, int p) &#123; if (root == NULL) return; father[root-&gt;val] = p; depth[root-&gt;val] = d; dfs(root-&gt;left, d + 1, root-&gt;val); dfs(root-&gt;right, d + 1, root-&gt;val); &#125; public: bool isCousins(TreeNode* root, int x, int y) &#123; dfs(root, 0, -1); return depth[x] == depth[y] &amp;&amp; father[x] != father[y]; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"重心剖分（Centroid Decomposition）简介及例题","slug":"2019-02-16-重心剖分（Centroid-Decomposition）简介及例题","date":"2019-02-16T01:07:47.000Z","updated":"2019-02-20T18:43:00.000Z","comments":true,"path":"post/centroid-decomposition-summaary-and-example/","link":"","permalink":"https://zhanghuimeng.github.io/post/centroid-decomposition-summaary-and-example/","excerpt":"","text":"这篇文章主要参考了Centroid Decomposition和An illustrated introduction to centroid decomposition两篇文章。 问题的描述 首先给出一道例题：Codeforces 342E. Xenia and Tree。这道题的题意是这样的：有一棵结点数量为n的树，结点标号为1到n。起始时，结点1是红色的，其他结点都是蓝色的。编程处理以下两种查询： update(a)：将a更新为红色 query(a)：查询a离最近的红色点的距离 可以立刻想到两种解法： 查询时做BFS/DFS（O(N)），更新时直接更新（O(1)） 维护每个结点到最近的红色点的距离，查询时直接查询（O(1)），更新时做BFS/DFS（O(N)） 显然这两种解法都不够好。重心剖分（Centroid Decomposition，以下简写为CD）则可以在这两种方法之间取得平衡，使得查询和更新的代价都变成O(log(N))。 重心的定义 记树的总结点数为n，定义树的重心为，移除后使得留下的所有连通分量（树）的大小均不超过n/2的结点。 请注意：重心不是中心。 如何找到树的重心？ 下面给出一种计算树的重心的算法。首先任取结点a，以a为树的根结点，计算它的所有子树的大小。如果这些子树的大小均不超过n/2，则a就是重心。否则，必然存在一棵（且只能有一棵——这一点是平凡的）子树，大小超过n/2。记b为该子树的根结点，对b重复上述算法。 对b来说，以a为根的子树的大小必然不超过n/2，因此算法不会重复访问已经访问过的结点，因此算法是正确的，它的复杂度是O(n)。 在具体实现中，以a为根结点，首先用DFS求出每棵子树的大小；然后用DFS寻找重心。因为算法不需要重复访问已经访问过的结点，因此对于每个结点，考虑它的子结点对应的子树大小即可。 12345678910111213141516171819int subSize[N];set&lt;int&gt; tree[N];// 计算子树大小int dfs(int u, int p) &#123; subSize[u] = 1; for (int v: tree[u]) if (v != p) subSize[u] += dfs(v, u); return subSize[u];&#125;// 计算重心int get_centroid(int u, int p, int n) &#123; for (int v: tree[u]) if (v != p &amp;&amp; subSize[v] &gt; n/2) return get_centroid(v, u, n); return u;&#125; 练习 练习1：请证明每棵树最多只有一个重心，或者给出反例。 反例：如下图。 练习2：在什么样的树中，中心和重心是相同的？ 我感觉，计算出重心之后，以重心为根的树中，如果深度最大的两棵子树的深度相等或只相差1，那么中心等于重心。 什么是重心剖分？ 树的重心剖分是另一棵树，它递归定义为： 树根是原树的重心 树根的子结点是原树中移除重心后留下的子树的重心 实现 直接按照定义实现这棵树即可。 123456789101112131415161718192021222324252627282930313233int subSize[N];set&lt;int&gt; tree[N]; // 为了方便删除……int cd_father[N];// 计算子树大小int dfs(int u, int p) &#123; subSize[u] = 1; for (int v: tree[u]) if (v != p) subSize[u] += dfs(v, u); return subSize[u];&#125;// 计算重心int get_centroid(int u, int p, int n) &#123; for (int v: tree[u]) if (v != p &amp;&amp; subSize[v] &gt; n/2) return get_centroid(v, u, n); return u;&#125;// 重心分解void centroid_decomposition(int u, int p) &#123; int n = dfs(u, p); int centroid = get_centroid(u, p, n); cd_father[centroid] = p; for (int v: tree[centroid]) if (v != p) &#123; tree[v].erase(centroid); centroid_decomposition(v, centroid); &#125; tree[centroid].clear();&#125; 时间复杂度 建树的时间复杂度是多少？首先可以给出一个时间复杂度的上界：因为需要对每个结点都执行一次centroid_decomposition，且dfs的代价最多为O(n)，因此时间复杂度最多为O(n^2)。 不过事实上并没有那么多。对每个结点执行centroid_decomposition时，对应的连通分量大小已经大大减小了，所以dfs的代价也降低了——这是因为根据重心的性质，每个连通分量的大小最多为n/2。事实上这就类似于归并排序的分析： 因为树的高度是O(log(n))，因此总时间复杂度为O(n*log(n))。 而且实现中移除边的过程不会影响总时间复杂度，因为最多有O(n)条边需要移除，而移除每条边的代价最多是O(log(n))。（当然，你也可以不这么实现，省一点常数。） 重心剖分的性质 在CD树中，结点属于它的所有祖先对应的连通分量。 证明：在CD树中，结点a是b的子结点，仅当a属于移除b后产生的连通分量。显然这件事的前提是，a属于b对应的连通分量。（这听起来是平凡的。） 原树中结点a到结点b的最短路可以分解成结点a到lca(a, b)和lca(a, b)到b的两条路径，其中lca(a, b)是CD树中a和b的LCA。 证明：由性质1，a和b都属于lca(a, b)对应的连通分量。假定lca(a, b)并不在从a到b的最短路上，则在原树中移除lca(a, b)后，a和b仍然在同一个连通分量中，这意味着该连通分量的重心是a和b的比lca(a, b)更低的共同祖先，这显然是荒谬的。 原树中的n^2条路径（此处把退化的路径也算进去了）均可分解成两条路径，这两条路径都属于在CD树中每个结点到它的所有祖先结点的共O(n*log(n))条路径的集合。（听起来真是晦涩……） 这个性质比较难，但非常重要。以下图为例： 共有n条从结点14开始的路径。这些路径可以分成以下几类： a in {14}：从14到14，再从14到a a in {15}：从14到15，再从15到a a in {6, 9, 13}：从14到11，再从11到a a in {1, 2, 4, 5, 7, 8, 10, 12}：从14到3，再从3到a 显然14、15、11和3都是14在CD树中的祖先。这种分类方法的思路是这样的：不是选择路径的两个端点，而是选择两个结点在CD树中的LCA。 证明1：性质2说明，原树中的每条路径都可以分解成两条路径（a到lca(a, b)，以及lca(a, b)到b）。下面证明从每个结点到它的CD树中祖先结点的路径总数是O(n*log(n))。显然CD树的高度是O(log(n))，共有n个结点，所以祖先总数是O(n*log(n))。 证明2：这次考虑CD树中每个结点的后代数量。显然根结点的后代总数是n-1，而且每一层的结点的后代总数都是O(n)，因此总路径数为O(n*log(n))。 练习 练习3：给定下图中的CD树，求原树。是否有多个可能的答案？ 这棵树看起来好像很有问题，居然有重复结点，算了不管它了。。。不过显然CD树和原树不是一一对应的，举个最简单的例子，如果连通分量只剩下两个结点，那么这两个结点哪一个做重心都可以。 练习4：证明每棵CD树都是自己的CD树，或者举出反例。 证明：由CD树的构造过程可知，对于CD树的每棵子树，记其大小为n，去掉根结点后剩下的的每棵子树的大小均不超过n/2。这是因为每棵子树都是和一个联通分量对应的。因此，对CD树做重心剖分时，只需取每层的根结点为重心即可。 练习5：考虑以下陈述：“对于任意有根树，从a到b的路径都可以分解成从a到lca(a, b)的路径和从lca(a, b)到b的路径，这样我们就可以应用性质3中的方法进行处理。”如果这是真的，我们为什么需要重心剖分？ 答：这确实是真的，但对于高度没有限制的树，这么做没有意义。考虑退化成一条链的树，根结点的后代数量是n-1，深度为1的结点的后代数量是n-2，以此类推，得到的分解路径总数是n(n-1)/2，和树中所有路径总数的数量级相同，没法起到简化表示的作用。 例题 Codeforces 342E. Xenia and Tree 题意 略 分析 这道题就是上面讲解时用到的例题，应该很好理解。将树进行重心剖分之后，每两个结点之间的距离都可以分解成它们在原树中到重心剖分树中的LCA的距离。这句话听起来太绕了，不如说，对于每两个结点，它们在重心剖分树中的LCA必然会出现在它们在原树中的最短路径上。从这就可以直接推导出，原树中的每条路径都能以两个端点在重心剖分树中的LCA为终点分解成两条路径。 所以我们可以考虑用ans来维护重心剖分树中每个结点到它的子树中最近的红色结点的距离。初始时，ans[a] = inf（之后才将第一个结点涂成红色）。 对于每个update(a)操作，因为a出现在它的祖先结点对应的分量中，所以只需对它的每个祖先结点b，更新ans[b] = min(ans[b], dist(a, b))。由于树的高度为O(log(n))，计算dist(a, b)的复杂度是O(log(n))，因此更新操作的复杂度是O(log^2(n))。 对于每个query(a)操作，只需对它的所有祖先结点b，取dist(a, b) + ans[b]的最小值。如果记ans[b]对应的结点为c，则我们实际上是把从a到c的路径分解成了从a到b的路径（dist(a, b)）和从b到c的路径（ans[b]）。这意味着dist(a, b) + ans[b]是从a到b对应的连通分量中离b最近的红色结点的距离。查询操作的时间复杂度也是O(log^2(n))。 我花了特别久的时间debug。模板背错之后出现的那些问题就不说了——一背错就很可能会死循环。首先，照原文中那种删除边的写法是行不通的： 12345678910111213void build(int u, int p) &#123; int n = dfs(u, p); // find the size of each subtree int centroid = dfs(u, p, n); // find the centroid if (p == -1) p = centroid; // dad of root is the root itself dad[centroid] = p; // for each tree resulting from the removal of the centroid for (auto v : tree[centroid]) // v被删除后，指针就失效了，肯定会挂 tree[centroid].erase(v), // remove the edge to disconnect tree[v].erase(centroid), // the component from the tree build(v, centroid);&#125; 改成不会产生指针失效的版本也不行，会超时。我目前看到了两种比较好的解决方案： 仍然用set，但是在for循环中不从centroid对应的set删除，在for循环结束后再统一清空 改用vector，单独记录删除标记 然后我想了想，觉得自己的LCA写的恐怕大有问题（因为太久没写了），于是就找了个地方，抄了一下LCA的主要计算过程。这之后我觉得没有什么问题了，但是交上去却持续WA。我感到很困惑，查了又查，却找不到什么错误。最后我找到了一份相当不错的结构和我类似的参考代码，抱着“模块化debug”的心情把我的代码中的LCA整个换成了这份代码里的LCA—— 结果竟然就过了！！！ 原来我太久没写LCA，把初始化时求2^k级祖先的内外循环给搞反了。推导father[i][j]时可能需要的father[?][j-1]的第一维是不确定的，因此应该把j放在外层循环。 123456void lca_init() &#123; for (int j = 1; j &lt; 21; j++) &#123; for (int i = 1; i &lt;= n; i++) father[i][j] = father[father[i][j-1]][j-1]; &#125;&#125; 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;vector&gt;#include &lt;set&gt;using namespace std;int n, m;typedef long long LL;vector&lt;int&gt; G[100002];bool deleted[100002];int subTreeSize[100002];int cd_father[100002];int father[100002][21];LL dist[100002];LL ans[100002];// 计算父结点和结点深度（用于LCA）void dfs(int cur, int parent, int depth) &#123; father[cur][0] = parent == -1 ? cur : parent; dist[cur] = depth; for (int u: G[cur]) if (u != parent) &#123; dfs(u, cur, depth + 1); &#125;&#125;// LCA初始化void lca_init() &#123; for (int j = 1; j &lt; 21; j++) &#123; for (int i = 1; i &lt;= n; i++) father[i][j] = father[father[i][j-1]][j-1]; &#125;&#125;// 计算x和y的LCAint get_lca(int x, int y) &#123; if (dist[x] &lt; dist[y]) swap(x, y); int d = dist[x] - dist[y]; for (int i = 20; i &gt;= 0; i--) &#123; if (d &amp; (1 &lt;&lt; i)) x = father[x][i]; &#125; if (x == y) return x; for (int i = 20; i &gt;= 0; i--) &#123; if (father[x][i] != father[y][i]) &#123; x = father[x][i]; y = father[y][i]; &#125; &#125; return father[x][0];&#125;// 根据LCA和深度计算x和y在树中的距离LL get_dist(int x, int y) &#123; int fa = get_lca(x, y); return dist[x] + dist[y] - 2 * dist[fa];&#125;// 计算子树大小（每次重心剖分的子树都需要）void get_size(int cur, int parent) &#123; subTreeSize[cur] = 1; for (int u: G[cur]) &#123; if (!deleted[u] &amp;&amp; u != parent) &#123; get_size(u, cur); subTreeSize[cur] += subTreeSize[u]; &#125; &#125;&#125;// 计算重心int get_centroid(int cur, int parent, int n) &#123; for (int u: G[cur]) &#123; if (!deleted[u] &amp;&amp; u != parent &amp;&amp; subTreeSize[u] &gt; n / 2) return get_centroid(u, cur, n); &#125; return cur;&#125;// 递归进行重心剖分void centroid_decomposition(int cur, int parent) &#123; get_size(cur, parent); int centroid = get_centroid(cur, parent, subTreeSize[cur]); cd_father[centroid] = parent; // 这里采取的则是一种比较愚蠢的策略，单独为结点记录了删除标记…… deleted[centroid] = true; for (int u: G[centroid]) if (!deleted[u] &amp;&amp; u != parent) centroid_decomposition(u, centroid);&#125;// 将a更新为红色结点void update(int a) &#123; int b = a; // 对于a在CD树中的每个祖先（包括a），更新a到它的距离 // 注意不是a在CD树中到它的距离！！！ while (b != -1) &#123; ans[b] = min(ans[b], get_dist(a, b)); b = cd_father[b]; &#125;&#125;// 查询a和最近的红色结点之间的距离int query(int a) &#123; int b = a; LL x = 1e9; // 对于a在CD树中的每个祖先（包括a），取答案为（a到该祖先的距离+该祖先到最近红色结点距离）的最小值 // 注意距离不是CD树中的距离！！！ while (b != -1) &#123; x = min(x, ans[b] + get_dist(a, b)); b = cd_father[b]; &#125; return x;&#125;int main() &#123; scanf(\"%d %d\", &amp;n, &amp;m); int a, b; int t, v; for (int i = 0; i &lt; n - 1; i++) &#123; scanf(\"%d %d\", &amp;a, &amp;b); G[a].push_back(b); G[b].push_back(a); &#125; // 一些必要的初始化 dfs(1, -1, 0); lca_init(); centroid_decomposition(1, -1); for (int i = 1; i &lt;= n; i++) ans[i] = 1e9; update(1); for (int i = 0; i &lt; m; i++) &#123; scanf(\"%d %d\", &amp;t, &amp;v); if (t == 1) update(v); else printf(\"%d\\n\", query(v)); &#125; return 0;&#125; Codeforces 321C. Ciel the Commander 题意 给定一棵树，要求把上面的所有结点用A到Z标记，使得对于任意两个标记相同的结点，它们之间的最短路上至少有一个标记（字典序）更小的结点。 分析 只要会重心剖分，想到这道题要用到重心剖分并不难（……这好像是句废话，考虑到这道题是作为例题出现的……），所以难点在于如何证明重心剖分得到的是最优解。（对于实现而言，这并不是个难点） 题解里给出了两种证明思路。第一种是自顶向下构造。显然，rank为A的结点只能有一个。选定一个结点为rank A之后，树会被分成几个连通分量，这些连通分量之间不会有非法路径（因为必须要通过这个结点），所以可以单独考虑这些连通分量，于是我们得到了一个递归解法。问题是应该怎么选择A。单从连通分量的大小来考虑，我们希望这些连通分量的大小尽量小，所以不妨取rank A结点为重心。然后判断CD树的高度是否大于26就行。 不过，问题是我觉得不能单从连通分量的大小来考虑。但到底怎么考虑比较好，这个我也不知道…… 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;set&gt;using namespace std;set&lt;int&gt; g[100005];int cd_father[100005];int subSize[100005];int cd_depth[100005];int n;int maxDepth;int get_size(int cur, int p) &#123; subSize[cur] = 1; for (int u: g[cur]) if (u != p) subSize[cur] += get_size(u, cur); return subSize[cur];&#125;int get_centroid(int cur, int p, int n) &#123; for (int u: g[cur]) if (u != p &amp;&amp; subSize[u] &gt; n / 2) return get_centroid(u, cur, n); return cur;&#125;void centroid_decomposition(int cur, int p, int depth) &#123; int n = get_size(cur, p); int centroid = get_centroid(cur, p, n); cd_father[centroid] = p; cd_depth[centroid] = depth; maxDepth = max(depth, maxDepth); for (int u: g[centroid]) if (u != p) &#123; g[u].erase(centroid); centroid_decomposition(u, centroid, depth + 1); &#125; g[centroid].clear();&#125;int main() &#123; cin &gt;&gt; n; int u, v; for (int i = 1; i &lt; n; i++) &#123; cin &gt;&gt; u &gt;&gt; v; g[u].insert(v); g[v].insert(u); &#125; centroid_decomposition(1, -1, 0); if (maxDepth &gt;= 26) &#123; cout &lt;&lt; \"Impossible!\" &lt;&lt; endl; return 0; &#125; for (int i = 1; i &lt;= n; i++) cout &lt;&lt; (char) (cd_depth[i] + 'A') &lt;&lt; ' '; cout &lt;&lt; endl; return 0;&#125;","categories":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/categories/Codeforces/"}],"tags":[{"name":"alg:Centroid Decomposition","slug":"alg-Centroid-Decomposition","permalink":"https://zhanghuimeng.github.io/tags/alg-Centroid-Decomposition/"}]},{"title":"Codeforces Global Round 1总结","slug":"2019-02-14-Codeforces-Global-Round-1总结","date":"2019-02-14T14:38:41.000Z","updated":"2019-02-14T14:38:41.000Z","comments":true,"path":"post/codeforces-global-round-1/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-global-round-1/","excerpt":"","text":"因为写总结和做题实在太艰难了，我决定以后CF每场比赛只写一篇总结…… 1110A 题目来源：https://codeforces.com/contest/1110/problem/A 提交次数：1/1 题意 分析 代码 1110D 题目来源：https://codeforces.com/contest/1110/problem/D 提交次数：1/1 题意 给定若干个1和m之间的整数，定义triplet为形如(x, x, x)或(x, x+1, x+2)的元组，问这些整数最多一共能组成多少个triplet？ 分析 这道题有一个非常必要的观察：如果有大于等于三个的形如[x, x+1, x+2]的triplet，那么完全可以把其中的三个替换成[x, x, x]，[x+1, x+1, x+1]和[x+2, x+2, x+2]。这也就意味着对于每一个x，形如[x-2, x-1, x]的triplet最多只有2个。[1] 然后我就想了一种错漏百出的方法，调了一个下午，终于调出来了。 令f[i][x][y]表示考虑前i-1个数组成的triplet，a[i-1]还剩x个，a[i-2]还剩y个时的triplet总数。我心想：既然连续的triplet最多只有2个，那么x和y的上限就都是2。（后来事实证明这很离谱）于是列出向后的转移方程： 123456789101112// 不组成形如(i-2, i-1, i)的tripletif (a[i] &gt;= 0) f[i+1][(a[i] - 0) % 3][x - 0] = max(f[i+1][(a[i]- 0) % 3][x - 0], f[i][x][y] + 0 + (a[i] - 0) / 3);// 组成一个形如(i-2, i-1, i)的tripletif (a[i] &gt;= 1 &amp;&amp; x &gt;= 1 &amp;&amp; y &gt;= 1) f[i+1][(a[i] - 1) % 3][x - 1] = max(f[i+1][(a[i] - 1) % 3][x - 1], f[i][x][y] + 1 + (a[i] - 1) / 3);// 组成两个形如(i-2, i-1, i)的tripletif (a[i] &gt;= 2 &amp;&amp; x &gt;= 2 &amp;&amp; y &gt;= 2) f[i+1][(a[i] - 2) % 3][x - 2] = max(f[i+1][(a[i] - 2) % 3][x - 2], f[i][x][y] + 2 + (a[i] - 2) / 3); 跑一下看看，发现错得离谱。思考了一段时间之后，发觉这个转移方程“太准确了”。比如说，a[4]=2时，f[4][2][2]可以转移到f[5][1][1]，但也应该可以转移到f[5][0][1]和f[5][1][0]（丢掉一些4和3也是可以的）。于是把转移方程修改如下，加入了后面两维的更多可能性： 12345678910111213141516171819202122if (a[i] &gt;= 0) &#123; for (int k = 0; k &lt;= min(a[i], 2); k++) &#123; for (int j = 0; j &lt;= x - 0; j++) &#123; f[i+1][k][j] = max(f[i+1][k][j], f[i][x][y] + 0 + (a[i] - k) / 3); &#125; &#125;&#125;if (a[i] &gt;= 1 &amp;&amp; x &gt;= 1 &amp;&amp; y &gt;= 1) &#123; for (int k = 0; k &lt;= min(a[i] - 1, 2); k++) &#123; for (int j = 0; j &lt;= x - 1; j++) &#123; f[i+1][k][j] = max(f[i+1][k][j], f[i][x][y] + 1 + (a[i] - k - 1) / 3); &#125; &#125;&#125;if (a[i] &gt;= 2 &amp;&amp; x &gt;= 2 &amp;&amp; y &gt;= 2) &#123; for (int k = 0; k &lt;= min(a[i] - 2, 2); k++) &#123; f[i+1][k][x - 2] = max(f[i+1][k][x - 2], f[i][x][y] + 2 + (a[i] - k - 2) / 3); &#125;&#125; 结果还是不对。经过更加漫长的debug，我意识到这种做法里的上限不能是2，因为它表示的是整体剩下的上限，而不是一共有多少个以它结尾的triplet。于是我直接把上限改成了6（既然有三种triplet的可能性），然后就过了（虽然耗时非常长）。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int n, m;int cnt[1000005];int f[1000005][7][7];int main() &#123; cin &gt;&gt; n &gt;&gt; m; int *a = cnt + 1; // 处理i-2的边缘情况 for (int i = 0; i &lt; n; i++) &#123; int x; cin &gt;&gt; x; a[x]++; &#125; int ans = 0; for (int i = 1; i &lt;= m + 1; i++) &#123; for (int x = 0; x &lt;= min(6, a[i-1]); x++) for (int y = 0; y &lt;= min(6, a[i-2]); y++) &#123; if (a[i] &gt;= 0) &#123; for (int k = 0; k &lt;= min(a[i], 6); k++) &#123; for (int j = 0; j &lt;= x - 0; j++) &#123; f[i+1][k][j] = max(f[i+1][k][j], f[i][x][y] + 0 + (a[i] - k) / 3); &#125; &#125; &#125; if (a[i] &gt;= 1 &amp;&amp; x &gt;= 1 &amp;&amp; y &gt;= 1) &#123; for (int k = 0; k &lt;= min(a[i] - 1, 6); k++) &#123; for (int j = 0; j &lt;= x - 1; j++) &#123; f[i+1][k][j] = max(f[i+1][k][j], f[i][x][y] + 1 + (a[i] - k - 1) / 3); &#125; &#125; &#125; if (a[i] &gt;= 2 &amp;&amp; x &gt;= 2 &amp;&amp; y &gt;= 2) &#123; for (int k = 0; k &lt;= min(a[i] - 2, 6); k++) &#123; f[i+1][k][x - 2] = max(f[i+1][k][x - 2], f[i][x][y] + 2 + (a[i] - k - 2) / 3); &#125; &#125; &#125; &#125; for (int x = 0; x &lt;= 6; x++) for (int y = 0; y &lt;= 6; y++) ans = max(ans, f[m + 2][x][y]); cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 1110F 题目来源：https://codeforces.com/contest/1110/problem/F 提交次数：1/1 题意 给定一棵带权树，所有结点按DFS遍历顺序从1到n编号，回答q次询问：给定整数v、l和r，找到从结点v到编号在l和r之间的叶结点之间的最短距离。 分析 题解里给出了一种很类似于可持久化线段树的离线方法：对根结点记录它到每个叶子的距离，然后从根结点走到需要查询的结点v，同时根据边权更新它到叶子的距离。不过并不是很详细。[1:1] 另一种方法是使用重心剖分（centroid decomposition，我就简称CD了）。首先对树进行重心剖分。对于每个叶结点，将它存储在它在重心剖分树的每个祖先结点中，也就是对重心剖分树中的每个结点，维护它子树中的叶结点的一个list，包括编号和（到该结点的）距离。需要回答询问时，对于结点v在重心剖分树中的每个祖先结点，查询该结点对应的叶结点中，编号在l和r之间的叶结点中的最短距离。这一步可以用线段树。[2] 不妨举个例子。这是CF上的第五个测试数据： 123456789101112131415161718192010 101 122 893 203 373 152 437 88 311 528 8 91 1 87 7 104 3 49 3 87 7 96 7 102 3 76 8 107 1 4 真的去写的时候，照例遇到了一万个问题，不过幸好这次有一份写得相当不错的代码[3]可以参照，省了很多时间。重心剖分的模板每次都背错这种愚蠢的事情就不说了，不过仍然会遇到如何组织树的这个问题。之前已经说过了，其实用修正过写法的set和vector加上删除标志都可以接受；但这次需要存边权，换成map听起来有点不太像一棵树。（倒不如说是我觉得这样遍历太麻烦了）所以换成了vector&lt;pair&lt;int, long long&gt;&gt;。 除了重心剖分以外，为了计算距离，当然LCA也是需要的。这次我虽然基本没有背错LCA模板，但我忘记这是棵带权树了。当然改起来很容易，把深度改成到根结点的距离就行。 初始化的部分倒是挺好写的——如果某个结点是叶子，那么就把它加到它在CD树的所有祖先（包括自己）的叶结点list中，同时计算距离。在这一步（或者不如说是下一步）中，我没有意识到这个list可能是空的，因为CD树的叶结点不一定是原树中的叶结点，所以仍然花了一些debug的时间。 所以下面得给每个结点都建一棵线段树。还采用自顶向下的那种方法就实在太冗长了，于是我直接抄了[3:1]中的zkw_cf线段树，这个东西是对zkw线段树的改进，不仅是自底向上的，而且只需要使用2*n的空间，不需要和2的幂对齐了。不过我还没太搞明白这是怎么做到的，就直接抄了。。。 下面这个问题花了我很久去debug，听起来十分愚蠢，但事实就是这样的……CD树上每个叶结点的线段树都是做了离散化的，只包含有的叶结点的编号。所以需要查的时候，显然需要找到编号的index。所以下面的问题是：对于排好序的pair&lt;int, LL&gt; a[n]和l &lt;= r，如何找到最左边的满足a[i].first &gt;= l的i和最右边的满足a[i].first &lt;= r的i？答案当然是二分查找，但是过程相当tricky……总之我最后也是又抄代码了。 最后一个问题很傻逼。我又忘记在CD树中从下向上查时，两个结点的距离不能用它们到中间结点的距离的和来推导了，这只能重新直接在原树中算…… 总的来说这算法比较慢。我现在懒得去分析复杂度了…… 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstdio&gt;#include &lt;set&gt;#include &lt;vector&gt;#include &lt;map&gt;using namespace std;typedef long long LL;int q, n;vector&lt;pair&lt;int, LL&gt;&gt; tree[500005];bool deleted[500005];int cd_father[500005];int father[500005][30];LL dist[500005];int level[500005];int subSize[500005];// 抄来的zkw_cf线段树struct TreeNode &#123; vector&lt;pair&lt;int, LL&gt;&gt; leaves; vector&lt;LL&gt; tree; int n; void init() &#123; n = leaves.size(); sort(leaves.begin(), leaves.end()); tree.resize(2 * n); for (int i = 0; i &lt; n; i++) tree[n + i] = leaves[i].second; for (int i = n - 1; i &gt; 0; i--) tree[i] = min(tree[2 * i], tree[2 * i + 1]); &#125; LL query(int l, int r, bool convert = false) &#123; if (leaves.size() == 0 || r &lt; leaves.front().first || leaves.back().first &lt; l) return 1e16; if (convert) &#123; // 抄的代码（注意r是开区间，这是这种线段树写法的要求） l = lower_bound(leaves.begin(), leaves.end(), make_pair(l, (LL) -1)) - leaves.begin(); r = lower_bound(leaves.begin(), leaves.end(), make_pair(r + 1, (LL) -1)) - leaves.begin(); &#125; LL ans = 1e16; for (l += n, r += n; l &lt; r; l /= 2, r /= 2) &#123; if (l &amp; 1) ans = min(ans, tree[l++]); if (r &amp; 1) ans = min(ans, tree[--r]); &#125; return ans; &#125;&#125; segTree[500005];void dfs(int cur, int parent, LL d, int l) &#123; dist[cur] = d; level[cur] = l; father[cur][0] = parent == -1 ? cur : parent; for (int i = 0; i &lt; tree[cur].size(); i++) if (tree[cur][i].first != parent) dfs(tree[cur][i].first, cur, d + tree[cur][i].second, l + 1);&#125;void lca_init() &#123; for (int dep = 1; dep &lt; 30; dep++) for (int i = 1; i &lt;= n; i++) father[i][dep] = father[father[i][dep-1]][dep-1];&#125;int get_lca(int x, int y) &#123; if (level[x] &lt; level[y]) swap(x, y); int d = level[x] - level[y]; for (int i = 0; i &lt; 30; i++) if (d &amp; (1 &lt;&lt; i)) x = father[x][i]; if (x == y) return x; for (int i = 29; i &gt;= 0; i--) if (father[x][i] != father[y][i]) x = father[x][i], y = father[y][i]; return father[x][0];&#125;LL get_dist(int x, int y) &#123; return dist[x] + dist[y] - 2 * dist[get_lca(x, y)];&#125;int dfs_sub_size(int cur, int parent) &#123; subSize[cur] = 1; for (int i = 0; i &lt; tree[cur].size(); i++) &#123; int u = tree[cur][i].first; if (u != parent &amp;&amp; !deleted[u]) subSize[cur] += dfs_sub_size(u, cur); &#125; return subSize[cur];&#125;int get_centroid(int cur, int parent, int n) &#123; for (int i = 0; i &lt; tree[cur].size(); i++) if (tree[cur][i].first != parent &amp;&amp; !deleted[tree[cur][i].first] &amp;&amp; subSize[tree[cur][i].first] &gt; n / 2) return get_centroid(tree[cur][i].first, cur, n); return cur;&#125;void centroid_decomposition(int cur, int parent) &#123; int n = dfs_sub_size(cur, parent); int centroid = get_centroid(cur, parent, n); cd_father[centroid] = parent; deleted[centroid] = true; for (int i = 0; i &lt; tree[centroid].size(); i++) &#123; int u = tree[centroid][i].first; if (u != parent &amp;&amp; !deleted[u]) centroid_decomposition(u, centroid); &#125;&#125;void init() &#123; dfs(1, -1, 0, 0); lca_init(); centroid_decomposition(1, -1); for (int i = 2; i &lt;= n; i++) &#123; if (tree[i].size() != 1) continue; // 是叶子 int cur = i; while (cur != -1) &#123; segTree[cur].leaves.emplace_back(i, get_dist(i, cur)); cur = cd_father[cur]; &#125; &#125; for (int i = 1; i &lt;= n; i++) &#123; segTree[i].init(); &#125;&#125;LL query(int v, int l, int r) &#123; LL ans = 1e18; int p = v; while (p != -1) &#123; // upDist并不是累加的！（某个bug曾经出现的位置） ans = min(ans, segTree[p].query(l, r, true) + get_dist(v, p)); p = cd_father[p]; &#125; return ans;&#125;int main() &#123; scanf(\"%d %d\", &amp;n, &amp;q); for (int i = 2; i &lt;= n; i++) &#123; int p, w; scanf(\"%d %d\", &amp;p, &amp;w); tree[i].emplace_back(p, w); tree[p].emplace_back(i, w); &#125; init(); int v, l, r; for (int i = 0; i &lt; q; i++) &#123; scanf(\"%d %d %d\", &amp;v, &amp;l, &amp;r); printf(\"%lld\\n\", query(v, l, r)); &#125; return 0;&#125; The Editorial of the First Codeforces Global Round ↩︎ ↩︎ Codeforces - comment of gaurav172 ↩︎ tfg’s solution for 1110F ↩︎ ↩︎","categories":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/categories/Codeforces/"}],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"}]},{"title":"Leetcode 992. Subarrays with K Different Integers","slug":"2019-02-12-Leetcode-992-Subarrays-with-K-Different-Integers","date":"2019-02-12T17:30:55.000Z","updated":"2019-02-14T00:00:05.000Z","comments":true,"path":"post/Leetcode 992. Subarrays with K Different Integers/","link":"","permalink":"https://zhanghuimeng.github.io/post/Leetcode 992. Subarrays with K Different Integers/","excerpt":"","text":"题目来源：https://leetcode.com/problems/subarrays-with-k-different-integers/description/ 标记难度：Hard 提交次数：1/1 代码效率： 两个滑动窗口：28.89%（340ms） 一个滑动窗口： 题意 给定数组A，求A中恰好含有k个不同元素的子数组的数量。 分析 从数据范围来看，显然N^2的算法是过不了的。所以比赛的时候我就想了一种这样的算法： 遍历数组元素 用指针i和j分别表示从当前元素开始，含有k个不同元素的最短子数组的结尾元素和最长子数组的结尾元素 用两个map分别维护这两个子数组中的元素 需要移动到下一个元素时，从map中删除当前元素，并移动指针直到满足要求为止。显然i和j的位置是递增的 这就相当于维护了两个滑动窗口。显然每个元素最多进出每个集合一次，所以整体复杂度应该是O(N)。（虽然常数实在很大……） 这个算法应该和题解是很相似的。 当然别人还有一些更神奇的做法，比如lee215的另辟蹊径的方法。他做了一件这样的事情： 对于某个K，遍历数组元素 对于每个A[j]，找到使得A[i...j]中恰好有K个不同元素的最大的i，记j-i+1为以j结尾的最多有K个不同元素的子数组的数量 令f(K)表示数组中最多有K个不同元素的子数组的数量 则所求结果为f(K) - f(K-1) 还真是一个独到的想法，虽然有些不明白他是怎么想出来的…… 还有一种更有趣的方法[1]，没有显式地维护两个滑动窗口。我觉得这种方法的核心思路其实是这样的： 对于每一个数组元素A[i]，记sMin为使得A[sMin...i]中包含K个不同元素的最小index，sMax为使得A[sMax...i]中包含K个不同元素的最大index 那么显然A[sMin...i]和A[sMax...i]包含的元素是一样的（虽然可能个数不同） 考虑从A[i]转移到A[i+1]的情况： 如果A[i+1]是窗口中已经出现过的元素，则sMin不变，sMax可能会减小 如果A[i+1]是窗口中没有出现过的元素，则sMin = sMax + 1，sMax &gt;= sMin 所以维护sMax对应的小窗口就够了。 以及，有一个可以大幅度提速的优化。题目里给了数组元素的范围（&lt;=N），因此可以用数组代替map。 代码 两个滑动窗口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution &#123;public: int subarraysWithKDistinct(vector&lt;int&gt;&amp; A, int K) &#123; map&lt;int, int&gt; beginMap; map&lt;int, int&gt; endMap; int ans = 0; int end1, end2 = A.size() - 1; for (int i = 0; i &lt; A.size(); i++) &#123; if (beginMap.size() &lt; K) &#123; beginMap[A[i]]++; endMap[A[i]]++; if (beginMap.size() == K) end1 = i; &#125; else &#123; if (endMap.find(A[i]) == endMap.end()) &#123; end2 = i - 1; break; &#125; endMap[A[i]]++; &#125; &#125; if (beginMap.size() &lt; K) return 0; // end1和end2是两个窗口结尾的指针 ans += end2 - end1 + 1; for (int i = 1; i &lt; A.size(); i++) &#123; beginMap[A[i - 1]]--; endMap[A[i - 1]]--; if (beginMap[A[i - 1]] == 0) beginMap.erase(A[i - 1]); if (endMap[A[i - 1]] == 0) endMap.erase(A[i - 1]); while (end1 &lt; A.size() - 1) &#123; if (beginMap.size() == K) &#123; break; &#125; end1++; beginMap[A[end1]]++; &#125; if (beginMap.size() &lt; K) break; while (end2 &lt; A.size() - 1) &#123; if (endMap.size() &lt; K || endMap.size() == K &amp;&amp; endMap.find(A[end2 + 1]) != endMap.end()) &#123; end2++; endMap[A[end2]]++; &#125; else break; &#125; if (endMap.size() &lt; K) break; ans += end2 - end1 + 1; &#125; return ans; &#125;&#125;; 一个滑动窗口 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int subarraysWithKDistinct(vector&lt;int&gt;&amp; A, int K) &#123; int sMin = 0, sMax = 0; unordered_map&lt;int, int&gt; window; int ans = 0; for (int i = 0; i &lt; A.size(); i++) &#123; // sMin不变，只修改sMax if (window.size() &lt; K || window.find(A[i]) != window.end()) &#123; window[A[i]]++; while (window.size() == K &amp;&amp; window[A[sMax]] &gt; 1) &#123; window[A[sMax]]--; sMax++; &#125; &#125; // sMin和sMax都改变 else &#123; window[A[i]]++; sMin = sMax + 1; while (window.size() &gt;= K) &#123; if (window.size() == K &amp;&amp; window[A[sMax]] == 1) break; window[A[sMax]]--; if (window[A[sMax]] == 0) window.erase(A[sMax]); sMax++; &#125; &#125; if (window.size() == K) ans += sMax - sMin + 1; &#125; return ans; &#125;&#125;; votrubac’s solution - C++ with picture, 7 lines 56 ms ↩︎","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 991. Broken Calculator","slug":"2019-02-11-Leetcode-991-Broken-Calculator","date":"2019-02-11T15:00:35.000Z","updated":"2019-02-13T17:05:00.000Z","comments":true,"path":"post/leetcode-991-broken-calculator/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-991-broken-calculator/","excerpt":"","text":"题目来源：https://leetcode.com/problems/broken-calculator/description/ 标记难度：Medium 提交次数：1/1 代码效率：100.00%（4ms） 题意 给定两个数X和Y，可以对X执行以下两种操作： 乘2 减1 问最少需要对X执行多少次操作才能将X变成Y？（X和Y的范围都是1e9） 分析 比赛的时候我居然首先就写了一个BFS，然后自然是超时了…… 后来就思考怎么用数学方法解决，也没想出来，各种各样奇怪的贪心大部分也是错的。 后来想到了对X的操作就等同于对Y的除2和加1两种操作，不过想到了也没什么大的突破…… 然后就没做出来…… 这道题考虑对Y的操作比考虑对X的操作要更容易。如果对Y加1两次再除2，显然不如先除2再加1，因此不会出现两次连续的加1操作。题解[1]是这么说的，不过我感觉有一点不太严谨。倒不如这么说：首先假设有一个最优的操作顺序，需要除2n次，且在第一次除2之前需要加1a[0]次，在第二次除2之前需要加1a[1]次，……，在最后一次除2之后需要加1a[n]次。此时总操作次数为a[0] + a[1] + ... + a[n] + n。假如存在i &lt; n且a[i] &gt; 1，那显然可以把多余的+1操作下移，变成a'[i] = a[i] - 2 * (a[i]/2)，a'[i+1] = a[i+1] + a[i]/2，总操作次数减少a[i]/2次。如果a'[i+1]仍然大于1，则可以继续尝试下移，直到除了a[n]以外的所有a[i]都变成0或1为止。 事实上我大概是做了一个Exchange类型的贪心证明…… 代码 1234567891011121314151617class Solution &#123;public: int brokenCalc(int X, int Y) &#123; int ans = 0; while (Y &gt; X) &#123; if (Y % 2 == 0) &#123; Y /= 2; ans++; &#125; else &#123; Y = (Y + 1) / 2; ans += 2; &#125; &#125; return ans + (X - Y); &#125;&#125;; Leetcode Official Solution for 991. Broken Calculator ↩︎","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 990. Satisfiability of Equality Equations","slug":"2019-02-11-Leetcode-990-Satisfiability-of-Equality-Equations","date":"2019-02-11T14:52:31.000Z","updated":"2019-02-11T14:52:31.000Z","comments":true,"path":"post/leetcode-990-satisfiability-of-equality-equations/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-990-satisfiability-of-equality-equations/","excerpt":"","text":"题目来源：https://leetcode.com/problems/satisfiability-of-equality-equations/description/ 标记难度：Medium 提交次数：1/1 代码效率：16ms 题意 给定一系列等式，每个等式形如a==b或a!=b，变量名为单个英文小写字母，问这些等式组能否成立？ 分析 这道题的思路很简单：首先将所有a==b等式转化成a和b之间的连边，然后做并查集或DFS，然后再判断形如a!=b的等式中的两个变量是否在同一个连通集中。总之用并查集和DFS都差不多…… 代码 所以我就直接写了并查集…… 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;private: int _fa[26]; void init() &#123; for (int i = 0; i &lt; 26; i++) _fa[i] = i; &#125; int fa(int x) &#123; if (_fa[x] == x) return x; return _fa[x] = fa(_fa[x]); &#125; void merge(int x, int y) &#123; x = fa(x); y = fa(y); _fa[x] = y; &#125; public: bool equationsPossible(vector&lt;string&gt;&amp; equations) &#123; init(); for (string s: equations) &#123; if (s[1] == '=') merge(s[0] - 'a', s[3] - 'a'); &#125; for (string s: equations) &#123; if (s[1] == '!') if (fa(s[0] - 'a') == fa(s[3] - 'a')) return false; &#125; return true; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"翻译：计算几何（USACO）","slug":"2019-02-10-翻译：计算几何（USACO）","date":"2019-02-10T22:23:01.000Z","updated":"2019-02-11T14:08:00.000Z","comments":true,"path":"post/computational-geometry-usaco-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/computational-geometry-usaco-translation/","excerpt":"","text":"这是几乎全部机翻的版本。几乎可以肯定的是，这个翻译需要改进。 先决条件 图论 最短路 工具 本节讨论了几种用于计算各类几何属性的算法，主要基于下面描述的两种操作：叉积和反正切。 叉积 u和v的叉积写作u x v。在计算中，两个三维向量u和v的叉积是下列矩阵的矢量行列式（其中i、j和k分别是x、y和z方向的单位向量）： 123| i j k || ux uy uz || vx vy vz | 这个式子的值为： (uyvz-vyuz)i + (uzvx-uxvz)j + (uxvy-uyvx)k 通过将三维向量的z分量置为0，这一定义可用于二维向量。得到的向量只有z分量有值。 叉积有三条性质： 两个向量的叉积垂直于这两个向量。 叉积的长度等于以下几项的乘积： u的长度 v的长度 u和v夹角的正弦值 在与u和v垂直的两个不同方向中，叉积指向的方向取决于u是在v的“右边”还是“左边”。 这就是右手定则吧。 点积 两个向量u和v的点积是写作u·v的标量。在计算中，它在三维向量中定义为： uxvx + uyvy + uzvz 点积实际上等于以下几项的乘积： u的长度 v的长度 u和v之间夹角的余弦值。 假定u和v不为零，如果点积为负，则u和v的夹角大于90度。如果它为零，则u和v垂直。如果点积为正，则两个向量的夹角为锐角。 反正切 反正切函数计算其正切值等于它的参数的角度，通常返回-pi/2和pi/2之间的一个实数。C中的函数atan2接收两个参数：y轴的差值和x轴的差值（按此顺序！）。它确定给定向量和x轴正半轴之间的角度，并返回一个-pi和pi之间的值。这可以解决除零或需要撰写代码处理x轴负半轴的问题。该atan2函数几乎总是比简单的只有一个参数的反正切函数容易使用。 显然如果只接收一个参数，无法处理向量和x轴垂直的情况（因为会发生除0问题），而且只有正负也无法说明是和正半轴还是负半轴的夹角。 调试中的特殊问题 计算几何题的主要问题是它们会产生许多特殊情况。请留意这些特殊情况，并确保你的程序适用于所有这些情况。 浮点数计算也会产生很多新问题。浮点计算很少是精确的，因为计算机只准确保留了若干比特（位）：要注意这一点。特别注意，在检查两个值是否相等时，不要检查它们是否精确相等，而是检查它们之间的差值是否小于某个范围。 计算几何算法 下面是一些可以帮助你解决计算几何问题的代码片段。 三角形面积 要计算顶点为(a，b，c)的三角形的面积，选择一个顶点（比如说a），并创建从a指向另外两个顶的向量（令u = b - a，v = c - a）。则三角形(a，b，c)的面积是u和v叉积长度的一半。 另一种计算三角形面积的方法是海伦公式。如果三角形的三条边长度分别为a，b，c，令s = s = (a+b+c)/2，则三角形的面积为 sqrt(s*(s-a)*(s-b)*(s-c)) 两条线段是否平行？ 为了检查两条线段是否平行，请沿每条线段创建向量，并检查它们的叉积是否（几乎）为零。 多边形面积 顶点为(x1, y1), …，(xn, yn)的多边形的面积等于行列式： 123 1 | x1 x2 ... xn |--- | | 2 | y1 y2 ... yn | 其中行列式的定义类似于2*2的行列式：x1y2 + x2y3 + … + xny1 - y1x2 - y2x3 - … - ynx1 不过我觉得我一般只会把多边形分成若干个三角形来算…… 点到直线的距离 从点P到线段AB的距离等于叉积的大小，即d(P，AB) = |(P-A）x (B-A)| / | B - A | 。 为了确定从点P到由点A、B和C定义的平面的距离，令n =(B-A) × (C-A)。下列等式即给出距离：d(P，ABC) = (P - A) · n / |n|。 点在直线上 点在直线上当且仅当点到直线的距离为0。 在直线同一侧的点 这个概念只对二维平面有意义。要检查C点和D点是否在直线AB的同一侧，计算(B - A) x (C - A)和(B - A) x (D - A)的z分量。如果z分量具有相同的符号（即它们的乘积是正的），则C和D位于直线AB的同一侧。 点在线段上 为了计算点C是否在线段AB上，检查C是否在直线AB上。如果是，则检查AB的长度是否等于AC和CB的长度之和。 点在三角形中 为了检查点A是否在三角形中，找到三角形内的另一个点B（三个顶点的平均值就可以）。然后，检查点A是否和点B在由三角形的边定义的三条直线的同一侧。 点在凸多边形中 同样的技巧适用于凸多边形： 四（或更多）点共面 为了确定点集是否是共面的，选择三个点，A、B和C。如果对于任何其他点D，((B - A) x (C - A)) · (D - A) ≈ 0，则该点集共面。 先算出三个点对应的平面的法向量…… 两条直线相交 在二维平面中，两条线相交当且仅当它们不平行。 在三维中，当直线AB和CD不平行且A、B、C、D共面时，AB和CD相交。 两条线段相交 在二维平面中，线段AB和CD相交，当且仅当A和B位于直线CD的不同侧且C和D位于直线AB的不同侧时。 请注意，两个检查都是必要的，因为在上图中最后一种情况中，一个检查返回true，而另一个检查才能证明AB和CD不相交。在三维情况中，求解下面的方程组，其中i和j是未知数： 123Ax + (Bx - Ax) i = Cx + (Dx - Cx) jAy + (By - Ay) i = Cy + (Dy - Cy) jAz + (Bz - Az) i = Cz + (Dz - Cz) j 如果该方程组具有解(i，j)，其中0 &lt;= i &lt;= 1且0 &lt;= j &lt;= 1，则线段相交于点(Ax + (Bx - Ax)i, Ay + (By - Ay)i, Az + (Bz - Az) i。 两条直线的交点 对于二维平面中的直线AB和CD，计算它们交点的最直接方法是求解以下两方程两未知数的方程组： 12Ax + (Bx - Ax)i = Cx + (Dx - Cx) jAy + (By - Ay)i = Cy + (Dy - Cy) j 交点坐标为： (Ax + (Bx - Ax) i, Ay + (By - Ay) i) 在三维情况下，求解与检查线段交叉时相同的方程组，则交点坐标为： (Ax + (Bx - Ax)i, Ay + (By - Ay)i, Az + (Bz - Az)i) 检查二维多边形的凸性 为了检查二维多边形的凸性，按顺时针顺序遍历多边形的顶点。对于所有的连续三个顶点(A，B，C)，计算叉积(B - A) x (C - A)。如果 得到的所有向量的z分量都是正的，则多边形是凸的。 点在非凸多边形中 为了计算某点是否在非凸多边形内，从该点沿随机方向发出一条射线，并计算它与多边形相交的次数。如果射线在顶点或沿边缘与多边形相交，则选择一个新方向。否则，当且仅当射线与多边形相交奇数次时，该点才在多边形内。 此方法也适用于三维（和更高维度），但对相交的限制是只在面上相交，而不是在顶点或边上。 计算几何方法 计算几何题引入了几种不同的技巧，可用于减少运行时间或估计解。 蒙特卡洛方法 第一种计算几何技巧基于随机性。我们不是计算某事发生的概率，而是模拟随机事件并计算它发生的次数。如果模拟了足够多的事件，则这两个值之间的差异将变得非常小。 这有助于确定图形面积大小之类内容。我们不是直接计算区域，而是确定一个边界框，然后向框中抛出“飞镖”，并估计击中图形的概率是多少。如果计算得足够准确，这可以很好地估计实际面积。 这种方法的问题是，获得良好的相对误差（误差除以实际值）需要大量成功的事件。如果事件发生的概率非常小，则该方法不会产生很好的结果。 分区 分区是一种提高计算几何算法速度的方法。这需要将平面分成多个部分（通常通过网格，但有时也会按辐射切开或其他方法），并将对象分到对应的区域中。当在某个图形中查找对象时，只需要检查与该图图形具有非零交点的那些部分，从而大大降低了算法的成本。这有助于确定到给定点的距离在某个范围内的对象集和（图形是圆）或检查交叉点（图形是一条直线）。 图论问题 有时看起来像计算几何问题的问题实际上是图论问题。仅仅因为输入是平面中的点并不意味着需要计算几何算法。 例题 移动点 给定平面中的一组线段，以及两个点A和B，能否在不跨越任何线段的情况下从A移动到B？ 分析：线段将平面划分为区域。确定这些区域，并检查A和B是否位于同一区域。 问题是怎么确定这些区域，感觉有些麻烦…… 自行车路线 给定一系列互不交叉建筑的以及它们的起点和终点位置，找到从A到B的不经过任何建筑物的最短路径。 分析：这实际上是一个图论问题。结点是起始位置和结束位置，以及建筑物的顶点。如果两个结点之间的线段不与任何建筑物相交，则它们之间有边，其权重等于线段的长度。构造完该图后，问题就变成了最短路。 最大化交叉点数量 给定平面中的一组线段，找到可以与一条直线相交的线段的最大数量。 分析：经过一些思考，很显然直线必须通过线段集合中的两个顶点。因此，尝试所有顶点对，并计算每条直线的交叉点数量。将其与分区相结合，可以提供一种运行速度相当快的算法。 或者说，一种最优解可以通过旋转变换成另一个一定至少通过两个顶点的最优解…… 多边形分类 给定定义多边形的一组线段，确定它是否是简单多边形（没有两个非连续线段相交）和凸多边形。 Q：凸多边形一定是简单的吗？","categories":[{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/categories/USACO/"}],"tags":[{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"},{"name":"translation","slug":"translation","permalink":"https://zhanghuimeng.github.io/tags/translation/"}]},{"title":"Leetcode 989. Add to Array-Form of Integer","slug":"2019-02-10-Leetcode-989-Add-to-Array-Form-of-Integer","date":"2019-02-10T20:49:07.000Z","updated":"2019-02-10T20:49:07.000Z","comments":true,"path":"post/leetcode-989-add-to-array-form-of-integer/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-989-add-to-array-form-of-integer/","excerpt":"","text":"题目来源：https://leetcode.com/problems/add-to-array-form-of-integer/description/ 标记难度：Easy 提交次数：1/1 代码效率：144ms 题意 给定一个自然数的各个数位从左到右的数组表示和另一个自然数，求这两个数的和的数组表示。 分析 很简单的加法题的一个小变形。题解的做法跟我差不多：开一个新的数组（因为原来的表示方法不符合一般从右往左表示的规律），从最后一位开始加，最后再把数组倒过来。 代码 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;int&gt; addToArrayForm(vector&lt;int&gt;&amp; A, int K) &#123; vector&lt;int&gt; a; a.push_back(0); for (int i = A.size() - 1; i &gt;= 0; i--) &#123; a.back() += A[i]; a.back() += K % 10; K /= 10; int x = a.back() / 10; a.back() %= 10; a.push_back(x); &#125; while (K &gt; 0) &#123; a.back() += K % 10; K /= 10; int x = a.back() / 10; a.back() %= 10; a.push_back(x); &#125; while (a.size() &gt; 1 &amp;&amp; a.back() == 0) a.pop_back(); reverse(a.begin(), a.end()); return a; &#125;&#125;;","categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"翻译：欧拉路（USACO）","slug":"2019-02-09-翻译：欧拉路（USACO）","date":"2019-02-09T20:54:04.000Z","updated":"2019-02-09T20:54:04.000Z","comments":true,"path":"post/eulerian-tour-usaco-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/eulerian-tour-usaco-translation/","excerpt":"","text":"这是几乎全部机翻的版本。几乎可以肯定的是，这个翻译需要改进。 例题：穿越栅栏 农夫约翰拥有大量围栏，他必须定期检查它们的完整性。农民约翰通过维护围栏的交叉点列表，以及在每个交叉点点结束的围栏来跟踪它们。每个围栏有两个端点，每个端点位于一个交叉点，交叉点可能只是单个围栏的终点。当然，两个以上的围栏也可能共享一个端点。 给定围栏的布局，计算农夫约翰是否有办法骑马去他所有的围栏，且不需要不止一次地穿越围栏。约翰可以在任何地方开始和结束，但不能穿过他的田地（在交叉点之间穿行的唯一方法是沿着围栏）。如果有方法，找出一种方法。 问题的抽象 给定：无向图 找到一条只使用每条边一次的路径。这样的路径称为欧拉路径。如果路径在同一顶点开始和结束，则称为欧拉回路。 算法 检查图中是否有欧拉路径或回路实际上很容易; 使用下列两条规则。 图中有欧拉回路，当且仅当它是连通图（在去掉度数为0的所有结点之后），且每个结点具有“偶数度”。 图中有欧拉路径，当且仅当它是连通图，且除了两个结点之外的每个结点的度数均为偶数。 在第二种情况下，具有奇数度的两个结点中的一个必须是起始结点，而另一个是结束结点。 算法的基本思想是从图的某个结点开始，并确定回到同一结点的回路。现在，随着回路的添加（事实上是以逆序），算法确保从该路径上所有结点出发的所有边都已被使用。如果该路径上还存在一些具有未使用的边的结点，则算法找到从该结点开始的使用这条边的回路，并将该新回路拼接到当前回路中。这一直持续到原始回路中每个结点的所有边都被使用为止，由于图是连通的，这意味着已经使用了所有边，因此得到的回路是欧拉回路。 更正式地说，要确定一个含有欧拉回路的图中的欧拉回路，选择一个起始结点并对其进行递归。在每个递归步骤中： 选择一个起始结点并对该结点进行递归。在每一步中： 如果结点没有邻居，则将结点加入到回路中并返回 如果结点具有邻居，则创建邻居列表并对其进行处理（包括从需要处理的结点列表中删除它们），直到该节点不再有邻居为止 为了处理结点，删除当前结点与其邻居之间的边，递归邻居，然后将当前结点加入到电路中。 这是伪代码： 123456789101112131415161718# circuit是一个全局数组find_euler_circuit circuitpos = 0 find_circuit(node 1)# nextnode和visited是局部数组# 将以逆序找到路径find_circuit(node i) if 结点i没有邻居 then circuit(circuitpos) = 结点i circuitpos = circuitpos + 1 else while (结点i有邻居) 随机选择结点i的邻居结点j delete_edges (结点j, 结点i) find_circuit (结点j) circuit(circuitpos) = 结点i circuitpos = circuitpos + 1 为了找到欧拉路径，只需找到其中一个具有奇数度的结点，并对它调用find_circuit。 这两种算法的时间复杂度都是O(m + n)，其中m是边数，n是结点数，如果图是以邻接表形式存储的话。对于较大的图，存在运行时栈溢出的风险，因此你可能需要使用自己的栈。 执行示例 考虑下图： 假设选择随机邻居时选择的是编号最小的邻居，算法执行过程如下： 栈： 当前位置：1 回路： 栈：1 当前位置：4 回路： 栈：1 4 当前位置：2 回路： 栈：1 4 2 当前位置：5 回路： 栈：1 4 2 5 当前位置：1 回路： 栈：1 4 2 当前位置：5 回路：1 栈：1 4 2 5 当前位置：6 回路：1 栈：1 4 2 5 6 当前位置：2 回路：1 栈：1 4 2 5 6 2 当前位置：7 回路：1 栈：1 4 2 5 6 2 7 当前位置：3 回路：1 栈：1 4 2 5 6 2 7 3 当前位置：4 回路：1 栈：1 4 2 5 6 2 7 3 4 当前位置：6 回路：1 栈：1 4 2 5 6 2 7 3 4 6 当前位置：7 回路：1 栈：1 4 2 5 6 2 7 3 4 6 7 当前位置：5 回路：1 栈：1 4 2 5 6 2 7 3 4 6 当前位置：7 回路：1 5 栈：1 4 2 5 6 2 7 3 4 当前位置：6 回路：1 5 7 栈：1 4 2 5 6 2 7 3 当前位置：4 回路：1 5 7 6 栈：1 4 2 5 6 2 7 当前位置：3 回路：1 5 7 6 4 栈：1 4 2 5 6 2 当前位置：7 回路：1 5 7 6 4 3 栈：1 4 2 5 6 当前位置：2 回路：1 5 7 6 4 3 7 栈：1 4 2 5 当前位置：6 回路：1 5 7 6 4 3 7 2 栈：1 4 2 当前位置：5 回路：1 5 7 6 4 3 7 2 6 栈：1 4 当前位置：2 回路：1 5 7 6 4 3 7 2 6 5 栈：1 当前位置：4 回路：1 5 7 6 4 3 7 2 6 5 2 栈： 当前位置：1 回路：1 5 7 6 4 3 7 2 6 5 2 4 栈： 当前位置： 回路：1 5 7 6 4 3 7 2 6 5 2 4 1 扩展 重边可以通过完全相同的算法来处理。 如果认为自环会为结点度数增加2（一进一出），则自环也可以通过完全相同的算法来处理。 有向图仅当强连通且每个结点的入度等于出度时才有欧拉回路（除了入度和出度均为0的节点）。算法完全相同，只是由于此代码找到环路的方式，您必须以相反的顺序遍历边。 在有向图中找到欧拉路径更难。如果您有兴趣，请阅读Sedgewick的书。 例题 飞机跳跃 给定一系列城市，以及这些城市之间的航班，确定是否存在一个航班序列，使得你顺序搭乘每个航班一次，最后回到开始的地方。 分析：这相当于在有向图中找到欧拉回路。 行进中的奶牛 农夫约翰有两种类型的奶牛：黑色安格斯奶牛和白色泽西奶牛。前几天约翰的妻子琼安将19头奶牛赶到市场上时，注意到四只连续黑白奶牛的所有16种可能性（例如，bbbb，bbbw，bbwb，bbww，…，wwww）都存在。当然，有些组合与其他组合重叠。 给定N（2 &lt;= N &lt;= 15），找到最小的奶牛长度序列，使得N个连续的黑色和白色奶牛的每个组合都出现在该序列中。 分析：图的顶点是N-1头奶牛的可能颜色。位于一个结点处表示最后N-1头奶牛与该结点的颜色匹配。也就是说，对于N = 4，如果最后3头奶牛颜色是wbw，那么你就在wbw节点。每个节点的出度为2，对应于在序列末尾添加黑色或白色奶牛。另外，每个节点的入度为2，对应于最后N-1头奶牛之前的奶牛是黑色还是白色。 嗯……为啥图的顶点是N-1头奶牛的可能颜色，而不是N头呢？ 图是强连通的，并且每个结点的入度等于出度，因此图中有欧拉回路。 和欧拉回路相对应的序列是回路中第一个结点对应的N-1头母牛的序列，之后再加上每条边对应的颜色。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 988. Smallest String Starting From Leaf（树）","slug":"2019-02-05-Leetcode-988-Smallest-String-Starting-From-Leaf（树）","date":"2019-02-05T16:25:48.000Z","updated":"2019-02-05T16:25:48.000Z","comments":true,"path":"post/leetcode-988-smallest String Starting From Leaf（树）/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-988-smallest String Starting From Leaf（树）/","excerpt":"","text":"题目来源：https://leetcode.com/problems/smallest-string-starting-from-leaf/description/ 标记难度：Medium 提交次数：2/4 代码效率： BFS：4ms 暴力：0ms 题意 给定一棵二叉树，令它的每个结点表示一个字符，问从每个叶结点开始，到树根结束的所有字符串中最小的字符串。 分析 考虑到这道题的数据范围（二叉树的最高层的叶结点数量大约最多是总结点数量的一半），完全可以把所有可能的字符串都生成出来，然后从里面找最小的…… 另一种稍微不那么暴力的方法是做BFS，找到出现叶结点的第一层，然后再回溯（或者直接暴力……）。 这道题实现过程中还有另一个问题：如何把单个char赋值给一个string？事实上，直接赋值和cast是不行的；如果想要采用&quot;&quot; + 'a'这种写法，就更是大错特错了，这相当于将指向字符串&quot;&quot;首位的指针加上(int) 'a'…… 所以比较正确的方法是string(1, 'a')。不要把常量字符串加上char……[1] 代码 BFS 这份代码比较愚蠢的一点在于，它居然没有存每个结点对应的字符串，而是只存了每个结点的父节点的位置，这么写大概就是故意增加复杂度了…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: string smallestFromLeaf(TreeNode* root) &#123; vector&lt;pair&lt;TreeNode*, pair&lt;int, int&gt;&gt;&gt; q; // node, father, depth int start = 0, end; q.emplace_back(root, make_pair(-1, 0)); while (start &lt; q.size()) &#123; end = q.size(); while (start &lt; end) &#123; TreeNode* p = q[start].first; int depth = q[start].second.second; if (p-&gt;left != NULL) q.emplace_back(p-&gt;left, make_pair(start, depth + 1)); if (p-&gt;right != NULL) q.emplace_back(p-&gt;right, make_pair(start, depth + 1)); start++; &#125; &#125; vector&lt;pair&lt;int, string&gt;&gt; ans; // index, string for (int i = q.size() - 1; i &gt;= 0; i--) &#123; TreeNode* p = q[i].first; int depth = q[i].second.second; if (p-&gt;left == NULL &amp;&amp; p-&gt;right == NULL) ans.emplace_back(i, string(1, p-&gt;val + 'a')); &#125; string minimal; while (ans.size() &gt; 0) &#123; vector&lt;pair&lt;int, string&gt;&gt; a; minimal = \"\"; for (int i = 0; i &lt; ans.size(); i++) &#123; minimal = minimal == \"\" || minimal &gt; ans[i].second ? ans[i].second : minimal; &#125; for (int i = 0; i &lt; ans.size(); i++) &#123; if (ans[i].second == minimal) &#123; int last = q[ans[i].first].second.first; if (last == -1) return minimal; a.emplace_back(last, minimal + (char) (q[last].first-&gt;val + 'a')); &#125; &#125; ans = a; &#125; return minimal; &#125;&#125;; 暴力 123456789101112131415161718192021class Solution &#123;private: string ans; void dfs(TreeNode* root, string s) &#123; if (root == NULL) return; s += (char) (root-&gt;val + 'a'); if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; reverse(s.begin(), s.end()); ans = ans == \"\" || s &lt; ans ? s : ans; return; &#125; dfs(root-&gt;left, s); dfs(root-&gt;right, s); &#125; public: string smallestFromLeaf(TreeNode* root) &#123; dfs(root, \"\"); return ans; &#125;&#125;; stackoverflow - C++ convert from 1 char to string? [closed] ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 987. Vertical Order Traversal of a Binary Tree（树）","slug":"2019-02-04-Leetcode-987-Vertical-Order-Traversal-of-a-Binary-Tree（树）","date":"2019-02-04T21:59:35.000Z","updated":"2019-02-05T16:21:00.000Z","comments":true,"path":"post/leetcode-987-vertical-order-traversal-of-a-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-987-vertical-order-traversal-of-a-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/vertical-order-traversal-of-a-binary-tree/description/ 标记难度：Medium 提交次数：1/1 代码效率：0ms 题意 给定一棵二叉树，定义每个结点的坐标如下：如果父结点的坐标是(X, Y)，则左子结点的坐标是(X - 1, Y - 1)，右子结点的坐标是(X - 1, Y + 1)。将横坐标相同的结点的值放在一个列表中，按值排序，并将这些列表按横坐标排序。 分析 总的来说是道简单的题，用一个map存放横坐标相同的结点的值，然后再排序即可。不过我倒是复习了一下怎么遍历C++ map……（如果不用语法糖的话）[1]： 12345678// 定义迭代器map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt;::iterator it;// 用迭代器进行遍历for (it = nodeMap.begin(); it != nodeMap.end(); it++) &#123; // 用指针进行访问 sort(it-&gt;second.begin(),it-&gt;second.end()); ...&#125; 代码 1234567891011121314151617181920212223242526class Solution &#123;private: map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt; nodeMap; // x -&gt; (-y, value) void dfs(int x, int y, TreeNode* root) &#123; if (root == NULL) return; nodeMap[x].emplace_back(-y, root-&gt;val); dfs(x - 1, y - 1, root-&gt;left); dfs(x + 1, y - 1, root-&gt;right); &#125; public: vector&lt;vector&lt;int&gt;&gt; verticalTraversal(TreeNode* root) &#123; dfs(0, 0, root); vector&lt;vector&lt;int&gt;&gt; ans; map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt;::iterator it; for (it = nodeMap.begin(); it != nodeMap.end(); it++) &#123; vector&lt;int&gt; cols; sort(it-&gt;second.begin(),it-&gt;second.end()); for (int i = 0; i &lt; it-&gt;second.size(); i++) cols.push_back(it-&gt;second[i].second); ans.push_back(cols); &#125; return ans; &#125;&#125;; stackoverflow - Sort Vector in a Map c++ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 986. Interval List Intersections","slug":"2019-02-03-Leetcode-986-Interval-List-Intersections","date":"2019-02-04T00:19:53.000Z","updated":"2019-02-04T21:55:00.000Z","comments":true,"path":"post/leetcode-986-interval-list-intersections/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-986-interval-list-intersections/","excerpt":"","text":"题目来源：https://leetcode.com/problems/interval-list-intersections/description/ 标记难度：Medium 提交次数：2/2 代码效率： 奇怪的做法：28ms 正常的合并：24ms 题意 有A和B两个闭区间数组，它们分别都是排过序的，且每个数组里的区间之间互不相交。请求出两个数组中闭区间的交。 分析 这道题的数据范围并不大（1000），所以我比赛的时候随便乱做了一下，也就过了。 不过正解是这样的：首先考虑最小的两个闭区间A[0]和B[0]，不失一般性，假设A[0]的右端点小于等于B[0]的右端点。由于B中的区间是互不相交的，因此A[0]只有可能与B[0]相交，不可能与B中其他的端点相交。因此我们可以在判断完后将A[0]丢掉，然后重新考虑新的A和B的相交情况。于是就得到了一个O(N)的算法。[1] 代码 奇怪的做法 12345678910111213141516171819202122232425262728293031class Solution &#123;private: bool intersect(Interval x1, Interval x2) &#123; if (x1.end &lt; x2.start || x2.end &lt; x1.start) return false; return true; &#125; pair&lt;int, int&gt; getIntsc(Interval x1, Interval x2) &#123; return make_pair(max(x1.start, x2.start), min(x1.end, x2.end)); &#125; public: vector&lt;Interval&gt; intervalIntersection(vector&lt;Interval&gt;&amp; A, vector&lt;Interval&gt;&amp; B) &#123; int start = 0; int n = A.size(), m = B.size(); vector&lt;pair&lt;int, int&gt;&gt; a; for (int i = 0; i &lt; n; i++) &#123; while (start &lt; m &amp;&amp; B[start].end &lt; A[i].start &amp;&amp; !intersect(A[i], B[start])) start++; if (start &gt;= m) break; for (int j = start; j &lt; m; j++) if (intersect(A[i], B[j])) a.push_back(getIntsc(A[i], B[j])); else break; &#125; sort(a.begin(), a.end()); vector&lt;Interval&gt; ans; for (int i = 0; i &lt; a.size(); i++) ans.emplace_back(a[i].first, a[i].second); return ans; &#125;&#125;; 正常的做法 1234567891011121314151617class Solution &#123;public: vector&lt;Interval&gt; intervalIntersection(vector&lt;Interval&gt;&amp; A, vector&lt;Interval&gt;&amp; B) &#123; int i = 0, j = 0; vector&lt;Interval&gt; ans; while (i &lt; A.size() &amp;&amp; j &lt; B.size()) &#123; if (A[i].end &lt; B[j].start) i++; else if (B[j].end &lt; A[i].start) j++; else &#123; ans.emplace_back(max(A[i].start, B[j].start), min(A[i].end, B[j].end)); if (A[i].end &lt; B[j].end) i++; else j++; &#125; &#125; return ans; &#125;&#125;; Leetcode Official Solution for 986 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 985. Sum of Even Numbers After Queries","slug":"2019-02-03-Leetcode-985-Sum-of-Even-Numbers-After-Queries","date":"2019-02-03T19:02:27.000Z","updated":"2019-02-03T19:02:27.000Z","comments":true,"path":"post/leetcode-985-sum-of-even-numbers-after-queries/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-985-sum-of-even-numbers-after-queries/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sum-of-even-numbers-after-queries/description/ 标记难度：Easy 提交次数：1/1 代码效率：96ms 题意 给定一个数组A，对其中的数做以下操作： 更新：A[index] += val 查询：问A中所有偶数的和 分析 首先预处理出A中所有偶数的和，然后在每次更新的时候，对这个和相应地进行更新。总的来说是道水题…… 代码 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;int&gt; sumEvenAfterQueries(vector&lt;int&gt;&amp; A, vector&lt;vector&lt;int&gt;&gt;&amp; queries) &#123; int n = A.size(); int sum = 0; for (int i = 0; i &lt; n; i++) if (A[i] % 2 == 0) sum += A[i]; vector&lt;int&gt; ans; for (int i = 0; i &lt; queries.size(); i++) &#123; int x = queries[i][0], k = queries[i][1]; if (A[k] % 2 == 0) &#123; if (x % 2 == 0) sum += x; else sum -= A[k]; &#125; else &#123; if (x % 2 != 0) sum += A[k] + x; &#125; A[k] += x; ans.push_back(sum); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 128. Longest Consecutive Sequence","slug":"2019-02-01-Leetcode-128-Longest-Consecutive-Sequence","date":"2019-02-01T16:04:06.000Z","updated":"2019-02-01T16:04:06.000Z","comments":true,"path":"post/leetcode-128-longest-consecutive-sequence/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-128-longest-consecutive-sequence/","excerpt":"","text":"题目来源：https://leetcode.com/problems/longest-consecutive-sequence/description/ 标记难度：Hard 提交次数：2/2 代码效率： 排序：100.00%（4ms） Hash Set：100.00%（4ms） 题意 给定一个（未排序的）整数数组，找到最长的连续整数序列的长度。要求复杂度是O(n)。 分析 虽然说要求复杂度是O(n)，但是我想都没想就排了个序……然后直接扫描一遍数组就可以了。 题解里给出了不排序的做法：把每个数都存到一个哈希表里，然后对于每个数，如果它之前没有出现在某个连续序列里（也就是说比它少1的数不存在），则尝试寻找以它为开头的连续整数序列的长度。 代码 排序 12345678910111213141516171819class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 0) return &#123;&#125;; // …… sort(nums.begin(), nums.end()); int ans = -1; int cnt = 1; for (int i = 1; i &lt; nums.size(); i++) &#123; if (nums[i] == nums[i-1]) continue; if (nums[i] == nums[i-1] + 1) &#123; cnt++; ans = max(ans, cnt); &#125; else cnt = 1; &#125; return max(ans, cnt); &#125;&#125;; 哈希表 12345678910111213141516171819class Solution &#123;public: int longestConsecutive(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 0) return &#123;&#125;; unordered_set&lt;int&gt; s; for (int num: nums) s.insert(num); int maxn = -1; for (int num: nums) &#123; if (s.find(num - 1) == s.end()) &#123; int l = 1; while (s.find(num + l) != s.end()) l++; maxn = max(maxn, l); &#125; &#125; return maxn; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"}]},{"title":"Codeforces 1107E. Vasya and Binary String（DP）","slug":"2019-01-31-Codeforces-1107E-Vasya-and-Binary-String（DP）","date":"2019-01-31T17:31:57.000Z","updated":"2019-01-31T17:31:57.000Z","comments":true,"path":"post/codeforces-1107e-vasya-and-binary-string/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1107e-vasya-and-binary-string/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1107/problem/E 提交次数：1/1 题意 给定一个长度为n的只包含0和1的字符串，将该串中连续i个相同字符消去将得到a[i]的收益，问消去整个字符串能得到的最大收益是多少？ 分析 在不会做的三道题上鸽了好久，最后还是觉得DP最好写…… 这个题解[soln1]特别简明扼要，大概抓住了问题的本质，不过我可能还没有完全理解它： 每一个状态都可以用[start, end, prefix]表示，其中start和end是字符串中的起始和结束index（不妨假设两端都是闭区间）（不是也行），prefix是字符串前面附加的和s[start]相等的字符的数量（包括s[start]）（不包括大概也行） 每一个状态都有两种递推方法： 第一种是直接消去字符串前面附加的字符：dp[start, end, prefix] = a[prefix] + dp[start + 1, end, 1] 第二种是在字符串其他位置找到一个和s[start]相同的字符，然后消去中间的字符，获得一个更大的前缀：dp[start, end, prefix] = max(dp[start+1, i-1, 1] + dp[i, end, prefix+1]) (start &lt; i &lt;= end, s[i] == s[start]) 虽然这个做法看起来很有道理，但其实我会有几个疑问。比如说，一些状态看起来其实是等价的：对于字符串&quot;0001&quot;，dp[0, 3, 1]和dp[2, 3, 3]表示的都是整个字符串。显然我们在递推过程中更容易得到前一种（没有被简化的）状态。那这两种状态有什么关系呢？是否需要手动简化？事实上，并不需要手动简化，dp[0, 3, 1]在递推中会自动得到dp[1, 3, 2]这个状态，并且进一步得到dp[2, 3, 3]。所以，与其说后一种状态是“简化之后的”，不如说是另一种对状态的看法，而且是一种一般化的表示。 至于递推的顺序，大概是得end - start从小到大，且prefix从小到大。这听起来有点麻烦（而且可能会增加复杂度），不如就写成递归形式算了。 [soln1]: Codeforces Blog - Quick unofficial editorial for Educational Round 59 (Div. 2) [soln2]: Codeforces Blog - Educational Codeforces Round 59 Editorial 代码 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;typedef long long int LL;int n;bool s[105];LL a[105];LL f[105][105][105];LL calc(int start, int end, int p) &#123; if (f[start][end][p] != -1) return f[start][end][p]; if (start &gt; end) return 0; if (start == end) &#123; f[start][end][p] = a[p]; return f[start][end][p]; &#125; f[start][end][p] = a[p] + calc(start + 1, end, 1); for (int i = start + 1; i &lt;= end; i++) &#123; if (s[i] != s[start]) continue; f[start][end][p] = max(f[start][end][p], calc(start + 1, i - 1, 1) + calc(i, end, p + 1)); &#125; return f[start][end][p];&#125;int main() &#123; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; char ch; cin &gt;&gt; ch; s[i] = ch - '0'; &#125; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; a[i]; memset(f, -1, sizeof(f)); cout &lt;&lt; calc(0, n-1, 1) &lt;&lt; endl;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"}]},{"title":"USACO 2.3.2: Cow Pedigrees（DP）","slug":"2019-01-31-USACO-2-3-2-Cow-Pedigrees（DP）","date":"2019-01-31T01:32:06.000Z","updated":"2019-01-31T01:32:06.000Z","comments":true,"path":"post/usaco-2-3-2-cow-pedigrees/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-3-2-cow-pedigrees/","excerpt":"","text":"题意 见洛谷 P1472 奶牛家谱 Cow Pedigrees。 求所有高度为K，结点数量为N的二叉树个数。 分析 我在这道题上花了好久！之前Leetcode上有道类似的题（Leetcode 894. All Possible Full Binary Trees），不过那道题是要生成所有完全二叉树，而不是计数。 一个很简单的思路是这样的： 用f[n][k]记录高度为k，结点数量为n的二叉树数量 固定左子树高度为k-1，枚举左子树结点个数和右子树高度（显然左子树结点数量确定后，右子树结点数量也确定了） （适当地）乘2（因为只固定了左子树的高度，差不多只考虑了一半情况；但是去重还需要仔细考虑……） 但是去重就出了一点问题。最开始我直接把所有结果都乘2，结果发现显然乘多了。比如说，左右两侧高度和结点数都相同的情况就不需要乘2。但是这样仍然不对。经过了比较漫长的手算和debug过程，我发现，左右两侧高度相同的情况都不需要乘2——因为它们都会出现在枚举中。举个例子： f[5][3]和f[7][3]都会作为左边的二叉树出现在枚举中。 题解里的思路就稍微好（不容易出错）一点：分别枚举左边比右边深，右边比左边深和左右一样深的三种情况。这个时候如果还需要明确地按子树的不同高度进行枚举未免太麻烦，所以就用一个辅助数组g[n][k]存所有高度&lt;= k且结点数量为n的二叉树的数量。 不过整体复杂度仍然都是O(N^3)的。 吐槽1：我之前的确很少（如果不是没有）见到要求结果模9901的。 吐槽2：这道题的文件名是nocows，听起来和NOCOW很像啊…… 代码 我的DP 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/*ID: zhanghu15TASK: nocowsLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;ofstream fout(\"nocows.out\");ifstream fin(\"nocows.in\");const LL P = 9901;LL f[201][101]; // f[i][j]：i个结点的高度为j的二叉树的数量int N, K;LL calc(int num, int height) &#123; if (f[num][height] != -1) return f[num][height]; if (num == 1 &amp;&amp; height == 1) &#123; f[num][height] = 1; return 1; &#125; if (num &lt; 2*height - 1) &#123; f[num][height] = 0; return 0; &#125; if (height &lt;= 0) &#123; f[num][height] = 0; return 0; &#125; f[num][height] = 0; // 一侧结点数为s，高度为height-1 // 另一侧结点数为num-s-1，高度&lt;=height-1 for (int s = 1; s &lt;= num - 2; s += 2) &#123; if (calc(s, height-1) == 0) continue; for (int h = 1; h &lt;= height - 1; h++) &#123; f[num][height] += calc(s, height-1) * calc(num-s-1, h); // 去重的正确姿势好难…… if (h != height-1) f[num][height] += calc(s, height-1) * calc(num-s-1, h); f[num][height] %= P; &#125; &#125; return f[num][height];&#125;int main() &#123; fin &gt;&gt; N &gt;&gt; K; memset(f, -1, sizeof(f)); fout &lt;&lt; calc(N, K) &lt;&lt; endl; return 0;&#125; 题解的DP 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/*ID: zhanghu15TASK: nocowsLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;ofstream fout(\"nocows.out\");ifstream fin(\"nocows.in\");const LL P = 9901;LL f[201][101]; // f[i][j]：i个结点的高度为j的二叉树的数量LL g[201][101]; // g[i][j]：i个结点的高度&lt;=j的二叉树的数量int N, K;int main() &#123; fin &gt;&gt; N &gt;&gt; K; f[1][1] = 1; // 像这样要用到辅助数组的时候，就不如写bottom-up的迭代形式了 for (int i = 1; i &lt;= N; i += 2) &#123; for (int j = 1; j &lt;= K; j++) &#123; for (int k = 1; k &lt;= i - 2; k++) &#123; // 左边深度为j-1，右边深度&lt;=j-2 f[i][j] += f[k][j - 1] * g[i - k - 1][j - 2]; // 左边深度&lt;=j-2，右边深度为j-1 f[i][j] += g[k][j - 2] * f[i - k - 1][j - 1]; // 两边深度都是j-1 f[i][j] += f[k][j - 1] * f[i - k - 1][j - 1]; f[i][j] %= P; &#125; for (int h = j; h &lt;= K; h++) g[i][h] = (g[i][h] + f[i][j]) % P; &#125; &#125; fout &lt;&lt; f[N][K] &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.3.1: Longest Prefix（DP）","slug":"2019-01-30-USACO-2-3-1-Longest-Prefix（DP）","date":"2019-01-30T20:25:13.000Z","updated":"2019-01-30T20:25:13.000Z","comments":true,"path":"post/usaco-2-3-1-longest-prefix/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-3-1-longest-prefix/","excerpt":"","text":"题意 见洛谷 P1470 最长前缀 Longest Prefix。 给定若干个字符串和另一个字符串S，问S的能由上述字符串组成的最长的前缀的长度。 分析 普通的动态规划。刚才好像刚刚在Leetcode上做了一道很相似的题：139. Word Break 一种转移方法是从前转移：对于当前的字符串结尾，枚举所有前缀，找到能够和它匹配的，判断减去匹配部分之后的字符串能否被构成。 另一种转移方法则是向后转移：对于当前（可行的）字符串末尾，枚举所有前缀，找到能够和后面的字符串匹配的，然后记减去前缀后的字符串为可行。这种方法可以利用Trie来进行优化，比前一种更快。 代码 普通的DP 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*ID: zhanghu15TASK: prefixLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;vector&lt;string&gt; prefix;bool ok[200000];int main() &#123; ofstream fout(\"prefix.out\"); ifstream fin(\"prefix.in\"); string p; while (fin &gt;&gt; p) &#123; if (p == \".\") break; prefix.push_back(p); &#125; string s; while (fin &gt;&gt; p) s += p; int n = s.length(), m = prefix.size(); int ans = 0; // ok[i]：以i为结尾的字符串是否可行 for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (prefix[j].size() - 1 &gt; i) continue; if (s.substr(i - prefix[j].size() + 1, prefix[j].size()) != prefix[j]) continue; if (i == prefix[j].size() - 1 || ok[i - prefix[j].size()]) &#123; ok[i] = true; break; &#125; &#125; ans = ok[i] ? i + 1 : ans; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 普通的Trie 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/*ID: zhanghu15TASK: prefixLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;vector&lt;string&gt; prefix;bool f[200005];struct TrieNode &#123; TrieNode* ch[26]; bool isEnd; TrieNode() &#123; memset(ch, 0, sizeof(ch)); isEnd = false; &#125;&#125;;int main() &#123; ofstream fout(\"prefix.out\"); ifstream fin(\"prefix.in\"); string pre; TrieNode* root = new TrieNode(); while (fin &gt;&gt; pre) &#123; if (pre == \".\") break; prefix.push_back(pre); TrieNode* p = root; for (char c: pre) &#123; if (p-&gt;ch[c - 'A'] == NULL) p-&gt;ch[c - 'A'] = new TrieNode(); p = p-&gt;ch[c - 'A']; &#125; p-&gt;isEnd = true; &#125; string s, t; while (fin &gt;&gt; t) s += t; int n = s.length(); int ans = 0; // f[i]：以i结尾的字符串是否可行 for (int i = 0; i &lt; n; i++) &#123; if (i != 0 &amp;&amp; !f[i - 1]) continue; TrieNode* p = root; for (int j = i; j &lt; n; j++) &#123; p = p-&gt;ch[s[j] - 'A']; if (p == NULL) break; if (p-&gt;isEnd) f[j] = true; &#125; &#125; for (int i = 0; i &lt; n; i++) if (f[i]) ans = max(ans, i + 1); fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.2.4: Party Lamps（枚举）","slug":"2019-01-30-USACO-2-2-4-Party-Lamps（枚举）","date":"2019-01-30T20:07:50.000Z","updated":"2019-01-30T20:07:50.000Z","comments":true,"path":"post/usaco-2-2-4-party-lamps/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-2-4-party-lamps/","excerpt":"","text":"题意 见洛谷 P1468 派对灯 Party Lamps。 有N盏灯和4个按钮： 按钮1：按下后所有灯的状态都会改变 按钮2：按下后奇数编号的灯的状态会改变 按钮3：按下后偶数编号的灯的状态会改变 按钮4：按下后编号模3余1的灯的状态会改变 所有灯起初都是打开的，给定一些灯的终止状态和总共按下按钮的次数，问是否存在对应的终态？如果可能，输出所有可能的终态。 分析 显然一个直觉是，同一个按钮只能按0或1次，按多了就和按的次数模2次效果是一样的。所以一共只有2^4=16种可能，枚举所有的可能，判断次数模2的取值是否相符以及各个灯的终态是否相符即可。 看了题解，发现这个直觉还不够厉害。事实上每6盏灯的状态都是重复的（6是2和3的公倍数）： 1234press 1: oooooooooooo -&gt; xxxxxxxxxxxxpress 2: oooooooooooo -&gt; xoxoxoxoxoxopress 3: oooooooooooo -&gt; oxoxoxoxoxoxpress 4: oooooooooooo -&gt; xooxooxooxoo 所以直接枚举6盏灯的状态就行了。同时可以得到一个推论，编号模6相等的灯的终态必定相同。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/*ID: zhanghu15TASK: lampsLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int N, C;int finalState[101];bool state[101];vector&lt;string&gt; output;int main() &#123; ofstream fout(\"lamps.out\"); ifstream fin(\"lamps.in\"); fin &gt;&gt; N &gt;&gt; C; memset(finalState, -1, sizeof(finalState)); int x; while (fin &gt;&gt; x) &#123; if (x == -1) break; finalState[x] = 1; &#125; while (fin &gt;&gt; x) &#123; if (x == -1) break; finalState[x] = 0; &#125; memset(state, 1, sizeof(state)); // 这里直接写了一个四层循环…… for (int b1 = 0; b1 &lt; 2; b1++) &#123; if (b1 == 1) &#123; for (int i = 1; i &lt;= N; i++) state[i] = !state[i]; &#125; for (int b2 = 0; b2 &lt; 2; b2++) &#123; if (b2 == 1) &#123; for (int i = 1; i &lt;= N; i += 2) state[i] = !state[i]; &#125; for (int b3 = 0; b3 &lt; 2; b3++) &#123; if (b3 == 1) &#123; for (int i = 2; i &lt;= N; i += 2) state[i] = !state[i]; &#125; for (int b4 = 0; b4 &lt; 2; b4++) &#123; if (b4 == 1) &#123; for (int i = 1; i &lt;= N; i += 3) state[i] = !state[i]; &#125; if (b1 + b2 + b3 + b4 &lt;= C &amp;&amp; (C - b1 - b2 - b3 - b4) % 2 == 0) &#123; bool ok = true; for (int i = 1; i &lt;= N; i++) &#123; if (finalState[i] != -1 &amp;&amp; state[i] != finalState[i]) &#123; ok = false; break; &#125; &#125; if (ok) &#123; string s; for (int i = 1; i &lt;= N; i++) s += (char)(state[i] + '0'); output.push_back(s); &#125; &#125; if (b4 == 1) &#123; for (int i = 1; i &lt;= N; i += 3) state[i] = !state[i]; &#125; &#125; if (b3 == 1) &#123; for (int i = 2; i &lt;= N; i += 2) state[i] = !state[i]; &#125; &#125; if (b2 == 1) &#123; for (int i = 1; i &lt;= N; i += 2) state[i] = !state[i]; &#125; &#125; if (b1 == 1) &#123; for (int i = 1; i &lt;= N; i++) state[i] = !state[i]; &#125; &#125; // 忘了这回事，于是错了一次…… if (output.size() == 0) &#123; fout &lt;&lt; \"IMPOSSIBLE\" &lt;&lt; endl; return 0; &#125; sort(output.begin(), output.end()); for (int i = 0; i &lt; output.size(); i++) fout &lt;&lt; output[i] &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 22. Generate Parentheses","slug":"2019-01-30-Leetcode-22-Generate-Parentheses","date":"2019-01-30T16:50:27.000Z","updated":"2019-02-01T14:41:00.000Z","comments":true,"path":"post/leetcode-22-generate-parentheses/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-22-generate-parentheses/","excerpt":"","text":"题目来源：https://leetcode.com/problems/generate-parentheses/description/ 标记难度：Medium 提交次数：2/2 代码效率： DFS：100.00%（0ms） DP：100.00%（0ms） 题意 生成所有括号对数为n的合法小括号组合。 分析 我最开始以为用普通的迭代就可以解决（每次在已经生成的组合之后加一对括号或者套上一对括号），后来发觉好像不太对，所以就改为用DFS（或者说回溯）：记录已经添加的左括号和右括号的数量，然后加上左括号，或者在右括号总数不超过左括号总数的前提下加上右括号。这样就可以不重不漏地生成所有结果了。 另一种比较有趣的方法类似于递推（大概也更容易计算数量）：对于每个合法括号序列，考虑和左侧第一个左括号配对的右括号的位置。这对括号内部一定是一个合法括号序列，后面跟着的也是一个合法括号序列。然后枚举就可以了。[1] 这样肯定可以推导出合法括号序列的数量的……好像就是卡特兰数。Leetcode 894. All Possible Full Binary Trees的思路和这道题很类似，而且确实是卡特兰数…… 代码 DFS 12345678910111213141516171819class Solution &#123;private: void dfs(int left, int right, string s, vector&lt;string&gt;&amp; ans, int&amp; n) &#123; if (left == n &amp;&amp; right == n) &#123; ans.push_back(s); return; &#125; if (left &lt; n) dfs(left + 1, right, s + '(', ans, n); if (right &lt; left) dfs(left, right + 1, s + ')', ans, n); &#125; public: vector&lt;string&gt; generateParenthesis(int n) &#123; if (n == 0) return &#123;&#125;; vector&lt;string&gt; ans; dfs(0, 0, \"\", ans, n); return ans; &#125;&#125;; DP 1234567891011121314151617181920212223class Solution &#123;private: map&lt;int, vector&lt;string&gt;&gt; pMap; public: vector&lt;string&gt; generateParenthesis(int n) &#123; if (pMap.find(n) != pMap.end()) return pMap[n]; if (n == 0) &#123; pMap[n] = &#123;\"\"&#125;; return pMap[n]; &#125; vector&lt;string&gt; a; for (int i = 0; i &lt;= n - 1; i += 1) &#123; vector&lt;string&gt; in = generateParenthesis(i); vector&lt;string&gt; back = generateParenthesis(n - i - 1); for (string x: in) for (string y: back) a.push_back(\"(\" + x + \")\" + y); &#125; pMap[n] = a; return a; &#125;&#125;; [https://leetcode.com/problems/generate-parentheses/solution/](Leetcode Official Solution for 22. Generate Parentheses) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"}]},{"title":"Leetcode 10. Regular Expression Matching（DP）","slug":"2019-01-30-Leetcode-10-Regular-Expression-Matching（DP）","date":"2019-01-30T15:47:38.000Z","updated":"2019-01-30T15:47:38.000Z","comments":true,"path":"post/leetcode-10-regular-expression-matching/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-10-regular-expression-matching/","excerpt":"","text":"题目来源：https://leetcode.com/problems/regular-expression-matching/description/ 标记难度：Hard 提交次数：2/8 代码效率： 递归：40ms DP：4ms 题意 给定一个字符串和一个只包含小写字母、.和*的模板字符串，问这两个字符串能否匹配？ 分析 这道题我看到过大概也有些日子了，但是当时完全不知道应该怎么做，满脑子都是什么“把正则表达式转化成非确定有限状态自动机（NFA），然后再转换成确定有限自动机（DFA），然后再进行匹配……”当然，要是真这么写出来，肯定也不是不能做，但是我也懒得去写…… 于是这回我就直接先写了个递归匹配，居然就过了。当然，这大概是因为数据比较弱…… 结果“正解”（或者说时间复杂度和编程复杂度都比较合理的一种解法）竟然是动态规划。想了想，其实挺合理的：不就是简化一下递归匹配方法的状态数量吗。 代码 递归 1234567891011121314151617181920212223class Solution &#123;public: bool isMatch(string s, string p) &#123; int n = s.length(), m = p.length(); if (n == 0 &amp;&amp; m == 0) return true; if (m == 0) return false; if (m &gt; 1 &amp;&amp; p[1] != '*' || m == 1) &#123; if (n == 0) return false; if (p[0] == '.') return isMatch(s.substr(1, n - 1), p.substr(1, m - 1)); else &#123; if (s[0] != p[0]) return false; return isMatch(s.substr(1, n - 1), p.substr(1, m - 1)); &#125; &#125; for (int i = 0; i &lt;= n; i++) &#123; if (isMatch(s.substr(i, n - i), p.substr(2, m - 2))) return true; if (p[0] != '.' &amp;&amp; s[i] != p[0]) break; &#125; return false; &#125;&#125;; DP DP的解法其实就是在递归解法上改出来的。结果因为各种各样的细节WA了超级多次…… 顺便还复习了一下多维vector的初始化：vector&lt;vector&lt;int&gt;&gt; vec(r, vector&lt;int&gt;(c, 0));[1] 如果真的是面试题，很难一遍写对的吧。 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;private: int ns, np; string s, p; vector&lt;vector&lt;int&gt;&gt; f; // ls和lp是串和模板串剩余的长度 // 考虑的是s[-ls:]和p[-lp:] bool calc(int ls, int lp) &#123; if (ls == 0 &amp;&amp; lp == 0) return true; if (lp == 0) return false; if (f[ls][lp] != -1) return f[ls][lp]; // 不是匹配多个的* if (lp &gt; 1 &amp;&amp; p[np - lp + 1] != '*' || lp == 1) &#123; if (ls == 0 || p[np - lp] != '.' &amp;&amp; s[ns - ls] != p[np - lp]) &#123; f[ls][lp] = false; return false; &#125; f[ls][lp] = calc(ls - 1, lp - 1); return f[ls][lp]; &#125; // 是匹配多个的*，尝试匹配i个 for (int i = 0; i &lt;= ls; i++) &#123; if (calc(ls - i, lp - 2)) &#123; f[ls][lp] = true; return true; &#125; if (p[np - lp] != '.' &amp;&amp; s[ns - ls + i] != p[np - lp]) break; &#125; f[ls][lp] = false; return false; &#125; public: bool isMatch(string s, string p) &#123; ns = s.length(); np = p.length(); this-&gt;s = s; this-&gt;p = p; f = vector&lt;vector&lt;int&gt;&gt;(ns + 1, vector&lt;int&gt;(np + 1, -1)); return calc(ns, np); &#125;&#125;; CSDN - C++——二维vector初始化大小方法 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"}]},{"title":"USACO 2.2.3: Runaround Numbers（数学）","slug":"2019-01-30-USACO-2-2-3-Runaround-Numbers（数学）","date":"2019-01-30T01:32:39.000Z","updated":"2019-01-30T01:32:39.000Z","comments":true,"path":"post/usaco-2-2-3-runaround-numbers/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-2-3-runaround-numbers/","excerpt":"","text":"题意 见洛谷 P1467 循环数 Runaround Numbers。 定义循环数为满足以下条件的整数： 各个数位都不重复 从最左边的数位开始进行如下操作： 向右循环数该数位对应的数字个数 然后从得到的数位开始继续数 在各个数位都（不重不漏地）开始数了一遍之后，会回到最开始的数 给定正整数M，问大于M的下一个循环数是多少？ 分析 按我惯常的习惯，肯定是先去OEIS上查一查，不过结果是并没有。 做题的时候，我首先写了一个暴力判断某个数是否为循环数的代码。本来应该想想怎么优化（毕竟M据说最多9位，如果直接暴力挨个判断比M大的数会超时的吧），但是那天不知道哪根神经出了毛病，直接把暴力给交上去了。结果居然就过了，还挺快……？？ 看了一眼测试数据，发现这范围跟说好的不一样啊，不是说M最多有9位吗，怎么这里最多只有7位？ 1234567891011121314------- test 1 [length 3 bytes] ----99------- test 2 [length 7 bytes] ----111110------- test 3 [length 7 bytes] ----134259------- test 4 [length 7 bytes] ----348761------- test 5 [length 8 bytes] ----1000000------- test 6 [length 8 bytes] ----5000000------- test 7 [length 8 bytes] ----9000000 仔细一想，我意识到，9位的循环数是不存在的：假设这样的循环数是存在的，因为要求各个数位不同，那么必须有一个数位为9；但是这个数位数了9位之后只会回到自己，没办法构成循环。由此还可以得到一个推论，n位的循环数中必然不存在数位n。所以，暴力代码能过这件事看起来就正常一点了。 但是为什么测试数据只有7位呢？我尝试把所有长度&lt;=9位的循环数都打印出来，结果得到的最大的数是9682415。所以，为什么8位的循环数也不存在呢？ 我又仔细想了一下，发现8位的循环数确实不应该存在（而不是我的暴力写错了之类的）。由上面的推论可以得到，8位的循环数中没有8，因此只能是1-7和9这8个数字。假设有这样一个8位的循环数，我们从左侧的第i位出发，遍历了所有数位各一次后，当前的数位应该是(i + 1 + 2 + .. + 7 + 9) % 8，且这个数位应该还是第i位。问题是，1 + 2 + .. + 7 + 9 = 37，这样根本没办法回到原来的位的！所以8位的循环数必然是不存在的。由此还可以得出另一个推论，就是n位的循环数的数位之和必然模n余0。 当然，比较正确（而不依靠随便乱交……）的做法是，枚举出所有长度为n且各个数位不相等的数，然后再判断它们是否为循环数——因为9!=362880，所以不会超时。 题解里还有一种比较神奇的做法——从M直接生成下一个各个数位都不相等的数，然后再判断它们是否为循环数。不过他到底是怎么生成下一个数的我就没细看了…… 分析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*ID: zhanghu15TASK: runroundLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;bool test(int x) &#123; int digits[10]; int cnt[10]; memset(cnt, 0, sizeof(cnt)); int n = 0; while (x &gt; 0) &#123; digits[n++] = x % 10; if (cnt[x % 10]) return false; cnt[x % 10]++; x /= 10; &#125; bool visited[10]; memset(visited, 0, sizeof(visited)); int cur = n - 1; for (int i = 0; i &lt; n; i++) &#123; visited[cur] = true; int next = ((cur - digits[cur]) % n + n) % n; if (visited[next] &amp;&amp; i != n - 1) return false; cur = next; &#125; return cur == n - 1;&#125;int main() &#123; ofstream fout(\"runround.out\"); ifstream fin(\"runround.in\"); int M; fin &gt;&gt; M; for (LL i = M + 1; i &lt;= (LL) 1e10; i++) if (test(i)) &#123; fout &lt;&lt; i &lt;&lt; endl; return 0; &#125; return 0;&#125;","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.2.2: Subset Sums（DP）","slug":"2019-01-30-USACO-2-2-2-Subset-Sums（DP）","date":"2019-01-30T01:05:30.000Z","updated":"2019-01-30T01:05:30.000Z","comments":true,"path":"post/usaco-2-2-2-subset-sums/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-2-2-subset-sums/","excerpt":"","text":"题意 见洛谷 P1466 集合 Subset Sums。 将1到N的整数分成两个和相同的集合，问有多少种分法？ 分析 这道题其实是一道标准的经典DP（只要正确建模）。结果我一看数据范围只有39，第一反应是写了一个Meet-in-the-Middle出来。当然也不是不行…… DP的做法是这样的：把原问题换成，用1到N的整数之和表示某个数字，最多有多少种表示方法？然后思路就很简单了，用f[i][j]表示用前i个整数表示j的方法，f[i][j] = f[i-1][j] + f[i-1][j-i]。 然后我才意识到对N大小的限制主要是为了动态规划的其中一维不要太大…… 代码 DP 12345678910111213141516171819202122232425262728293031323334353637383940/*ID: zhanghu15TASK: subsetLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;#include &lt;map&gt;using namespace std;typedef long long int LL;int N;LL f[40][8000];int main() &#123; ofstream fout(\"subset.out\"); ifstream fin(\"subset.in\"); fin &gt;&gt; N; int sum = N * (N + 1) / 2; if (sum % 2 != 0) &#123; fout &lt;&lt; 0 &lt;&lt; endl; return 0; &#125; f[0][0] = 1; for (int i = 1; i &lt;= N; i++) &#123; for (int j = 0; j &lt; 8000; j++) &#123; f[i][j] = f[i-1][j]; if (j &gt;= i) f[i][j] += f[i-1][j-i]; &#125; &#125; fout &lt;&lt; f[N][sum / 2] / 2 &lt;&lt; endl; return 0;&#125; Meet-in-the-Middle 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/*ID: zhanghu15TASK: subsetLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;#include &lt;map&gt;using namespace std;typedef long long int LL;int main() &#123; ofstream fout(\"subset.out\"); ifstream fin(\"subset.in\"); int N; fin &gt;&gt; N; int sum = N * (N + 1) / 2; if (sum % 2 != 0) &#123; fout &lt;&lt; 0 &lt;&lt; endl; return 0; &#125; int halfSum = sum / 2; int halfN = N / 2; // Meet-in-the-Middle map&lt;int, int&gt; cntMap; // gather [1, halfN] sums for (int i = 0; i &lt; (1 &lt;&lt; halfN); i++) &#123; int sum = 0; for (int j = 0; j &lt; halfN; j++) if (i &amp; (1 &lt;&lt; j)) sum += j + 1; // cout &lt;&lt; i &lt;&lt; ' ' &lt;&lt; sum &lt;&lt; endl; cntMap[sum]++; &#125; // gather [halfN+1, N] sums LL ans = 0; // 注意数据范围…… for (int i = 0; i &lt; (1 &lt;&lt; (N - halfN)); i++) &#123; int sum = 0; for (int j = 0; j &lt; N - halfN; j++) if (i &amp; (1 &lt;&lt; j)) sum += j + halfN + 1; if (cntMap.find(halfSum - sum) != cntMap.end()) &#123; ans += cntMap[halfSum - sum]; &#125; &#125; fout &lt;&lt; ans / 2 &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"},{"name":"alg:Meet in the Middle","slug":"alg-Meet-in-the-Middle","permalink":"https://zhanghuimeng.github.io/tags/alg-Meet-in-the-Middle/"}]},{"title":"USACO 2.2.1: Preface Numbering","slug":"2019-01-30-USACO-2-2-1-Preface-Numbering","date":"2019-01-30T00:44:35.000Z","updated":"2019-01-30T00:44:35.000Z","comments":true,"path":"post/usaco-2-2-1-preface-numbering/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-2-1-preface-numbering/","excerpt":"","text":"题意 见洛谷 P1465 序言页码 Preface Numbering。 求1到N的罗马数字表示中每个字母出现的次数。 分析 这道题出得有点令人无言以对（的简单）的感觉……总之做就是了。 罗马数字表示法和普通的十进制其实很类似，都是用单个数字来表示某个位，而且各个位的规律是差不多的。比如说，我们可以把一个四位的十进制数字这样分解： 个位：1 -&gt; I, 2 -&gt; II, 3 -&gt; III, 4 -&gt; IV, 5 -&gt; V, 6 -&gt; VI, 7 -&gt; VII, 8 -&gt; VIII, 9 -&gt; IX 十位：1 -&gt; X, 2 -&gt; XX, 3 -&gt; XXX, 4 -&gt; XL, 5 -&gt; L, 6 -&gt; LX, 7 -&gt; LXX, 8 -&gt; LXXX, 9 -&gt; XC 百位：1 -&gt; C, 2 -&gt; CC, 3 -&gt; CCC, 4 -&gt; CD, 5 -&gt; D, 6 -&gt; DC, 7 -&gt; DCC, 8 -&gt; DCCC, 9 -&gt; CM 千位：1 -&gt; M, 2 -&gt; MM, 3 -&gt; MMM（题目里没有更大的数字了） 所以直接按照这个方法去分解就可以啦！ 我写得非常暴力，考虑到各个位之间的规律性，可以写得稍微更简单一点。不过因为数组清零时写成了sizeof(0)WA了一次…… 题解里有各种花式简化方法。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/*ID: zhanghu15TASK: prefaceLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int main() &#123; ofstream fout(\"preface.out\"); ifstream fin(\"preface.in\"); int N; fin &gt;&gt; N; int d[4], n; int ci = 0, cv = 0, cx = 0, cl = 0, cc = 0, cd = 0, cm = 0; for (int i = 1; i &lt;= N; i++) &#123; int x = i; n = 0; memset(d, 0, sizeof(d)); while (x &gt; 0) &#123; d[n++] = x % 10; x /= 10; &#125; cm += d[3]; if (d[2] == 9) // 900 = CM cc++, cm++; else if (5 &lt; d[2] &amp;&amp; d[2] &lt; 9) // 800 = DCCC cd++, cc += d[2] - 5; else if (d[2] == 5) // 500 = D cd++; else if (d[2] == 4) // 400 = CD cc++, cd++; else // 300 = CCC cc += d[2]; if (d[1] == 9) // 90 = XC cx++, cc++; else if (5 &lt; d[1] &amp;&amp; d[1] &lt; 9) // 80 = LXXX cl++, cx += d[1] - 5; else if (d[1] == 5) // 50 = L cl++; else if (d[1] == 4) // 40 = XL cx++, cl++; else // 30 = XXX cx += d[1]; if (d[0] == 9) // 9 = IX ci++, cx++; else if (5 &lt; d[0] &amp;&amp; d[0] &lt; 9) // 8 = VIII cv++, ci += d[0] - 5; else if (d[0] == 5) // 5 = V cv++; else if (d[0] == 4) // 4 = IV ci++, cv++; else // 3 = III ci += d[0]; &#125; if (ci &gt; 0) fout &lt;&lt; \"I \" &lt;&lt; ci &lt;&lt; endl; if (cv &gt; 0) fout &lt;&lt; \"V \" &lt;&lt; cv &lt;&lt; endl; if (cx &gt; 0) fout &lt;&lt; \"X \" &lt;&lt; cx &lt;&lt; endl; if (cl &gt; 0) fout &lt;&lt; \"L \" &lt;&lt; cl &lt;&lt; endl; if (cc &gt; 0) fout &lt;&lt; \"C \" &lt;&lt; cc &lt;&lt; endl; if (cd &gt; 0) fout &lt;&lt; \"D \" &lt;&lt; cd &lt;&lt; endl; if (cm &gt; 0) fout &lt;&lt; \"M \" &lt;&lt; cm &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.1.5: Hamming Codes（枚举？）","slug":"2019-01-29-USACO-2-1-5-Hamming-Codes（枚举？）","date":"2019-01-29T22:49:29.000Z","updated":"2019-01-29T22:49:29.000Z","comments":true,"path":"post/usaco-2-1-5-hamming-codes/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-1-5-hamming-codes/","excerpt":"","text":"题意 见P1461 海明码 Hamming Codes。 找出N个数字，每个数字的长度均为B位，且每两个数之间的海明距离都至少为D。如果有多个解，则输出排序后值最小的解。 分析 当然，我可以直接写个O(2^(2^B))的枚举加剪枝，而且的确能过。不过这是因为数据太弱了，而且刻意出的这么弱。 12345678910111213141516171819202122------- test 1 [length 7 bytes] ----16 7 3------- test 2 [length 6 bytes] ----2 7 7------- test 3 [length 6 bytes] ----3 6 4------- test 4 [length 6 bytes] ----5 5 1------- test 5 [length 7 bytes] ----10 8 4------- test 6 [length 7 bytes] ----20 6 2------- test 7 [length 7 bytes] ----32 5 1------- test 8 [length 7 bytes] ----50 8 2------- test 9 [length 7 bytes] ----60 7 2------- test 10 [length 7 bytes] ----16 8 3------- test 11 [length 7 bytes] ----15 8 4 在上述测试数据下，暴力方法的运行时间为： 1234567891011121314151617Compiling...Compile: OKExecuting... Test 1: TEST OK [0.004 secs, 1388 KB] Test 2: TEST OK [0.004 secs, 1308 KB] Test 3: TEST OK [0.004 secs, 1328 KB] Test 4: TEST OK [0.004 secs, 1392 KB] Test 5: TEST OK [0.000 secs, 1312 KB] Test 6: TEST OK [0.000 secs, 1292 KB] Test 7: TEST OK [0.000 secs, 1304 KB] Test 8: TEST OK [0.000 secs, 1292 KB] Test 9: TEST OK [0.000 secs, 1304 KB] Test 10: TEST OK [0.000 secs, 1392 KB] Test 11: TEST OK [0.000 secs, 1308 KB]All tests OK. 来个N=64, B=8, D=4这样的数据，暴力解法得跑到天荒地老。 我的一种想法是，把这2^B个数字当做图的结点，数字之间的海明距离当做边权来建图，然后这个问题就变成了类似于找最大团。但是问题是我们需要找的不只是一个最大团，而是一个排序后数字最小的最大团，好像就不符合一般的问题范畴了。[1] 总之今天也是不想学习最大团算法的一天…… 代码 如果把每次的判断__builtin_popcount(code[i] ^ next)都换成查表，常数应该能减少一点，但是并不能改变这个算法复杂度实在太高的事实…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*ID: zhanghu15TASK: hammingLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int N, B, D;int code[64];int MAX;bool found;void dfs(int n) &#123; if (n == N) &#123; found = true; return; &#125; int next; if (n == 0) next = 0; else next = code[n - 1] + 1; for (; next &lt;= MAX; next++) &#123; if (found) return; bool ok = true; for (int i = 0; i &lt; n; i++) &#123; if (__builtin_popcount(code[i] ^ next) &lt; D) &#123; ok = false; break; &#125; &#125; if (!ok) continue; code[n] = next; dfs(n + 1); &#125;&#125;int main() &#123; ofstream fout(\"hamming.out\"); ifstream fin(\"hamming.in\"); fin &gt;&gt; N &gt;&gt; B &gt;&gt; D; MAX = (1 &lt;&lt; B) - 1; dfs(0); for (int i = 0; i &lt; N; i++) &#123; fout &lt;&lt; code[i]; if (i % 10 == 9 || i == N - 1) fout &lt;&lt; endl; else fout &lt;&lt; ' '; &#125; return 0;&#125; wikipedia - Clique problem ↩︎","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.1.4: Healthy Holsteins（枚举）","slug":"2019-01-29-USACO-2-1-4-Healthy-Holsteins（枚举）","date":"2019-01-29T21:58:34.000Z","updated":"2019-01-29T21:58:34.000Z","comments":true,"path":"post/usaco-2-1-4-healthy-holsteins/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-1-4-healthy-holsteins/","excerpt":"","text":"题意 见P1460 健康的荷斯坦奶牛 Healthy Holsteins。 给定一些稻草（种类数量&lt;=15），每种稻草可以为奶牛提供若干数量的若干种维他命，问最少需要多少种稻草才能为奶牛提供足够的维他命？ 分析 我最开始以为这是一道01背包题，然后发现维他命有25种，25维的01背包可还行？最后发现原来稻草最多只有15种，那就直接2^G枚举好了。 代码 这次的枚举是用循环写的（而不是DFS之类）。但仔细想想，这个写法（专指这道题的写法）不怎么样，外面还加了一层处理稻草个数的循环。虽然这道题里可以把这个循环去掉然后手动判断稻草个数，但在其他很多状态DP里不如写成递归的…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/*ID: zhanghu15TASK: holsteinLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int V;int need[25];int sum[25];int G;int scoop[15][25];int main() &#123; ofstream fout(\"holstein.out\"); ifstream fin(\"holstein.in\"); fin &gt;&gt; V; for (int i = 0; i &lt; V; i++) fin &gt;&gt; need[i]; fin &gt;&gt; G; for (int i = 0; i &lt; G; i++) for (int j = 0; j &lt; V; j++) fin &gt;&gt; scoop[i][j]; for (int num = 1; num &lt;= G; num++) &#123; for (int x = 0; x &lt; (1 &lt;&lt; G); x++) &#123; if (__builtin_popcount(x) != num) continue; memset(sum, 0, sizeof(sum)); for (int i = 0; i &lt; G; i++) &#123; if ((x &amp; (1 &lt;&lt; i)) == 0) continue; for (int j = 0; j &lt; V; j++) sum[j] += scoop[i][j]; &#125; bool ok = true; for (int i = 0; i &lt; V; i++) &#123; if (sum[i] &lt; need[i]) &#123; ok = false; break; &#125; &#125; if (ok) &#123; fout &lt;&lt; num; for (int i = 0; i &lt; G; i++) if (x &amp; (1 &lt;&lt; i)) fout &lt;&lt; ' ' &lt;&lt; i + 1; fout &lt;&lt; endl; return 0; &#125; &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.1.3: Sorting a Three-Valued Sequence（贪心）","slug":"2019-01-29-USACO-2-1-3-Sorting-a-Three-Valued-Sequence-（贪心）","date":"2019-01-29T21:36:00.000Z","updated":"2019-01-29T21:36:00.000Z","comments":true,"path":"post/usaco-2-1-3-sorting-a-three-valued-sequence/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-1-3-sorting-a-three-valued-sequence/","excerpt":"","text":"题意 见洛谷 P1459 三值的排序 Sorting a Three-Valued Sequence。 给定一个只包含1，2，3的数组，问将这个数组排序最少需要多少次交换。 分析 这个好像是之前的翻译：贪心算法（USACO）的原题……所以做法也没什么好说的了。首先找出一次交换可以解决的“错位”二元组的数量，然后再找出需要两次交换才能解决的“错位”三元组的数量即可。只要仔细一想就可以发现，每种二元组和三元组的数量是固定的，只跟每个“区域”（排序之后某种元素应该占的位置）内的其他元素的数量相关。 以及我觉得这道题和Codeforces 1102D. Balanced Ternary String有一点点像。（虽然像的程度很有限就是了……） 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*ID: zhanghu15TASK: sort3LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int N;int a[1000];int num[4];int cnt[4][4];int main() &#123; ofstream fout(\"sort3.out\"); ifstream fin(\"sort3.in\"); fin &gt;&gt; N; for (int i = 0; i &lt; N; i++) &#123; fin &gt;&gt; a[i]; num[a[i]]++; &#125; int start = 0; // cnt[i][j]：在i“区域”内j的数量 for (int i = 1; i &lt;= 3; i++) &#123; for (int j = 0; j &lt; num[i]; j++) &#123; cnt[i][a[start + j]]++; &#125; start += num[i]; &#125; int swaps = 0; // 一次交换能解决的数所需交换次数 for (int i = 1; i &lt;= 3; i++) &#123; for (int j = 1; j &lt;= 3; j++) &#123; if (i == j) continue; // 尽可能地将i区域内的j和j区域内的i相交换 int x = min(cnt[i][j], cnt[j][i]); swaps += x; cnt[i][j] -= x; cnt[j][i] -= x; &#125; &#125; // 两次交换能解决的数所需交换次数 for (int i = 1; i &lt;= 3; i++) &#123; for (int j = 1; j &lt;= 3; j++) &#123; if (i == j) continue; int k = 6 - i - j; // 尽可能地将i区域内的j和j区域内的k交换，然后再和k区域内的i交换 int x = min(min(cnt[i][j], cnt[j][k]), cnt[k][i]); swaps += x * 2; cnt[i][j] -= x; cnt[j][k] -= x; cnt[k][i] -= x; &#125; &#125; fout &lt;&lt; swaps &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.1.2: Ordered Fractions（数学）","slug":"2019-01-29-USACO-2-1-2-Ordered-Fractions（数学）","date":"2019-01-29T20:52:21.000Z","updated":"2019-01-29T20:52:21.000Z","comments":true,"path":"post/usaco-2-1-2-ordered-fractions/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-1-2-ordered-fractions/","excerpt":"","text":"题意 见洛谷 P1458 顺序的分数 Ordered Fractions。 给定N，求[0, 1]范围内分母小于等于N的所有既约分数，按大小排序。（1 &lt;= N &lt;= 160） 分析 作为一道普通的题……可以说它是考察运算符重载之类的花样的（至少对C++选手是这样）。当然也可以写得更简单一些。总之，我就直接枚举了所有这个范围内的分数，把所有既约分数找出来，排了个序，然后输出。 法里数列（Farey sequence） 当然，这道题的题解里还有另一个生成解法： 首先生成列表[0/1, 1/1] 在列表的每两个分数之间插入一个新的分数，其分子和分母各为相邻两个分数分子和分母的和；于是得到：[0/1, 1/2, 1/1] 以此类推：[0/1, 1/3, 1/2, 2/3, 1/1] 继续以此类推：[0/1, 1/4, 1/3, 2/5, 1/2, 3/5, 2/3, 3/4, 1/1] 直到新生成的分数的分母都大于N为止 我觉得这个方法很神奇。通过非常简单的数学推导就可以说明，将两个分数的分子和分母分别相加，得到的新分数的值位于这两个分数之间： 已知a1b1&lt;a2b2\\frac{a_1}{b_1} &lt; \\frac{a_2}{b_2}b1​a1​​&lt;b2​a2​​，即a1b2&lt;a2b1a_1b_2 &lt; a_2b_1a1​b2​&lt;a2​b1​； 两侧都加上a1b1a_1b_1a1​b1​，化简后得到a1b1&lt;a1+a2b1+b2\\frac{a_1}{b_1} &lt; \\frac{a_1 + a_2}{b_1 + b_2}b1​a1​​&lt;b1​+b2​a1​+a2​​； 另一侧同理。 当然，这并不能说明很多其他的问题，比如为什么这种生成方法生成的都是既约分数，而且是不重不漏的。这时候就需要使用Farey sequence的一些性质了。n阶的Farey sequence就是我们题目里所求的序列。它的一个性质是这样的：如果a/ba/ba/b和c/dc/dc/d在某阶的Farey sequence中是相邻的，那么当Farey sequence的阶增加，它们之间出现的第一项就是(a+c)/(b+d)(a+c)/(b+d)(a+c)/(b+d)，且这一项会第一次出现在b+db + db+d阶的数列中。这个生成算法就利用了这一性质：它每次生成的并不严格是某一阶的Farey sequence，而可能会多一些项出来；不过这并不重要，因为它们迟早会出现的。 还有一些详细的分析就不写了，总之这个想法很有趣。 代码 普通的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*ID: zhanghu15TASK: frac1LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;struct Frac &#123; // 我着实不想去记分子和分母的英文了…… int up; int down; Frac() &#123; up = down = 0; &#125; Frac(int x, int y) &#123; up = x; down = y; &#125; friend bool operator &lt; (const Frac&amp; f1, const Frac&amp; f2) &#123; return f1.up * f2.down &lt; f1.down * f2.up; &#125;&#125;;int gcd(int a, int b) &#123; if (b == 0) return a; return gcd(b, a % b);&#125;Frac f[160000];int N;int main() &#123; ofstream fout(\"frac1.out\"); ifstream fin(\"frac1.in\"); fin &gt;&gt; N; int n = 0; for (int i = 1; i &lt;= N; i++) &#123; for (int j = 0; j &lt;= i; j++) &#123; if (gcd(i, j) &gt; 1) continue; f[n++] = Frac(j, i); &#125; &#125; sort(f, f + n); for (int i = 0; i &lt; n; i++) fout &lt;&lt; f[i].up &lt;&lt; '/' &lt;&lt; f[i].down &lt;&lt; endl; return 0;&#125; Farey数列生成器 1234567891011121314151617181920212223242526272829303132333435/*ID: zhanghu15TASK: frac1LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;ofstream fout(\"frac1.out\");ifstream fin(\"frac1.in\");int N;void farey(int a1, int b1, int a2, int b2) &#123; if (b1 + b2 &gt; N) return; farey(a1, b1, a1 + a2, b1 + b2); fout &lt;&lt; (a1 + a2) &lt;&lt; '/' &lt;&lt; (b1 + b2) &lt;&lt; endl; farey(a1 + a2, b1 + b2, a2, b2);&#125;int main() &#123; fin &gt;&gt; N; fout &lt;&lt; \"0/1\" &lt;&lt; endl; farey(0, 1, 1, 1); fout &lt;&lt; \"1/1\" &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 2.1.1: The Castle（DFS）","slug":"2019-01-29-USACO-2-1-1-The-Castle（BFS）","date":"2019-01-29T20:30:43.000Z","updated":"2019-01-29T20:30:43.000Z","comments":true,"path":"post/usaco-2-1-1-the-castle/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-2-1-1-the-castle/","excerpt":"","text":"题意 见洛谷 P1457 城堡 The Castle。 有一个M*N的方格图（1 &lt;= M,N &lt;= 50），其中方格外侧有一整圈墙，有些方格线上有墙。问这些墙形成了多少个房间，以及去掉一堵墙能形成的最大房间的面积？ 分析 应该可以说是标准的Floodfill算法了。算法流程如下： 对于每一个格子，如果它还没有被访问到，则房间数+1，并从该格子开始DFS 在DFS过程中，将访问到的每一个格子都标为当前房间数（于是立刻可以得到共有多少个房间） 对于每一堵墙，判断它两侧的格子是否属于不同房间，如果是，则拆掉这面墙可以将这两个房间连起来，且新房间的面积是原来两个房间的和 Floodfill的时间复杂度是O(M*N)，枚举墙的时间复杂度也是O(M*N)，因此总复杂度为O(M*N)。 代码 其他部分都没有什么难的，但是在答案去重这部分遇到了一点小问题。题目要求以某个格子北侧或东侧的形式打印需要的墙，且： 选择拆除后得到的房间面积最大的墙 如果面积相同，则选择最靠西的格子 如果同样靠西，则选择最靠北的格子 如果同样靠北，则优先选择格子东侧的墙 这可真是复杂的要求…… 所以我也写了一堆复杂的判断条件…… 顺带一提，我终于意识到现在USACO题目左边（可能会出现）的数字是你已经通过了多少个样例了…… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/*ID: zhanghu15TASK: castleLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int M, N;// west, north, east, southint mx[4] = &#123; 0, -1, 0, 1&#125;;int my[4] = &#123;-1, 0, 1, 0&#125;;int module[50][50];int visited[50][50];int cnt[2501];int n;void dfs(int x, int y) &#123; for (int i = 0; i &lt; 4; i++) &#123; if (module[x][y] &amp; (1 &lt;&lt; i)) continue; int nx = x + mx[i], ny = y + my[i]; if (nx &lt; 0 || nx &gt;= N || ny &lt; 0 || ny &gt;= M) continue; if (visited[nx][ny]) continue; visited[nx][ny] = n; cnt[n]++; dfs(nx, ny); &#125;&#125;int main() &#123; ofstream fout(\"castle.out\"); ifstream fin(\"castle.in\"); fin &gt;&gt; M &gt;&gt; N; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; M; j++) fin &gt;&gt; module[i][j]; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; M; j++) &#123; if (!visited[i][j]) &#123; n++; visited[i][j] = n; cnt[n]++; dfs(i, j); &#125; &#125; fout &lt;&lt; n &lt;&lt; endl; int maxn = -1; for (int i = 1; i &lt;= n; i++) maxn = max(maxn, cnt[i]); fout &lt;&lt; maxn &lt;&lt; endl; maxn = -1; char ch; int x, y; // 事实证明光靠顺序去重不太可行 for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; M; j++) &#123; if (j &lt; M - 1 &amp;&amp; visited[i][j] != visited[i][j+1]) &#123; int sum = cnt[visited[i][j]] + cnt[visited[i][j+1]]; if (sum &gt; maxn || (sum == maxn &amp;&amp; (j &lt; y || (j == y &amp;&amp; i &gt; x)))) &#123; maxn = sum; ch = 'E'; x = i + 1; y = j + 1; &#125; &#125; if (i &gt; 0 &amp;&amp; visited[i-1][j] != visited[i][j]) &#123; int sum = cnt[visited[i][j]] + cnt[visited[i-1][j]]; if (sum &gt; maxn || (sum == maxn &amp;&amp; (j &lt; y || (j == y &amp;&amp; i &gt; x)))) &#123; maxn = sum; ch = 'N'; x = i + 1; y = j + 1; &#125; &#125; &#125; &#125; fout &lt;&lt; maxn &lt;&lt; endl; fout &lt;&lt; x &lt;&lt; ' ' &lt;&lt; y &lt;&lt; ' ' &lt;&lt; ch &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Codeforces 1107D. Compression（数学）","slug":"2019-01-29-Codeforces-1107D-Compression（数学）","date":"2019-01-29T03:16:08.000Z","updated":"2019-02-05T23:02:00.000Z","comments":true,"path":"post/codeforces-1107d-compression/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1107d-compression/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1107/problem/D 提交次数：2/2 题意 给定一个n*n的01矩阵A，定义A的x-压缩矩阵B为n/x * n/x大小的矩阵，且对于i∈[1,n], j∈[1,n]i \\in [1, n], \\, j \\in [1, n]i∈[1,n],j∈[1,n]，有 A[i][j]=B[⌈ix⌉][⌈jx⌉]A[i][j] = B[\\lceil \\frac{i}{x} \\rceil][\\lceil \\frac{j}{x} \\rceil] A[i][j]=B[⌈xi​⌉][⌈xj​⌉] 显然必须要求x整除n，且A中映射到B中同一位置的不同元素必须相等。问x的最大值是多少。 分析 这道题我比赛的时候看错题了。不过其实它并不是很难。显然有 B[i][j]=A[(i−1)x+1...x][(j−1)x+1...x]B[i][j] = A[(i-1)x + 1...x][(j-1)x + 1...x] B[i][j]=A[(i−1)x+1...x][(j−1)x+1...x] [soln1]: Codeforces Blog - Quick unofficial editorial for Educational Round 59 (Div. 2) [soln2]: Codeforces Blog - Educational Codeforces Round 59 Editorial 比较简单的解法1 显然每个B[i][j]都对应A中的一块矩形区域。那么就直接查看A中的这些矩形区域是否都为0或者都为1。但是这样做的话，每个x需要的复杂度是n^2，很可能太慢了。（事实上并不慢，因为x的总数是σ(n)\\sigma(n)σ(n)，它的一个显然的上界是n\\sqrt{n}n​。） 不过还是可以做点优化的，求出包含A中左上元素的每个矩形的面积，然后就可以用它们加加减减来求出任何矩形的面积了。然后就可以直接判断每个矩形是否为全0或全1了…… 上图中： Area(x1, y1, x2, y2) = S[x2][y2] - S[x2][y1-1] - S[x1-1][y2] + S[x1-1][y1-1] 对于每个x，一共有(n/x)2(n/x)^2(n/x)2个矩形需要考虑。由于 ∑x∣n(n/x)2=n2∑x∣n1/x2&lt;n2∑x=1+∞1/x2=n2π2/6\\sum_{x | n} (n/x)^2 = n^2 \\sum_{x | n} 1/x^2 &lt; n^2 \\sum_{x=1}^{+\\infty}1/x^2 = n^2 \\pi^2/6 x∣n∑​(n/x)2=n2x∣n∑​1/x2&lt;n2x=1∑+∞​1/x2=n2π2/6 因此这个方法的复杂度是O(n^2)。[soln1] 更复杂一些的解法2 这种方法更巧妙（不过大概也更难想到）。 找出矩形中每一行中所有连续的0或1线段的长度的最大公约数 对矩形的每一列同样求最大公约数 则该最大公约数就是所求x 如果矩形能被压缩，则显然上述条件是满足的。从上述条件推出能被压缩也是比较简单的：首先将每一行压缩成n/x个点，然后再对列进行压缩即可。[soln2] 代码 解法1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;bool matrix[5205][5205];int colSum[5205][5205];int sum[5205][5205];int n;// 求左上角坐标为(lr, lc)，右下角坐标为(rr, rc)的矩形和int getSum(int lr, int lc, int rr, int rc) &#123; int s11 = sum[lr-1][lc-1]; int s12 = sum[lr-1][rc] - s11; return sum[rr][rc] - s12 - sum[rr][lc-1];&#125;int main() &#123; cin &gt;&gt; n; char c; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 0; j &lt; n / 4; j++) &#123; scanf(\" %c\", &amp;c); int x = '0' &lt;= c &amp;&amp; c &lt;= '9' ? c - '0' : c - 'A' + 10; matrix[i][j*4 + 1] = (x &amp; 8) &gt; 0; matrix[i][j*4 + 2] = (x &amp; 4) &gt; 0; matrix[i][j*4 + 3] = (x &amp; 2) &gt; 0; matrix[i][j*4 + 4] = (x &amp; 1) &gt; 0; &#125; &#125; // 求和 // sum[i][j]：右下端点为(i, j)的矩形的和 for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; colSum[i][j] = colSum[i-1][j] + matrix[i][j]; &#125; &#125; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; sum[i][j] = sum[i][j-1] + colSum[i][j]; &#125; &#125; for (int x = n; x &gt;= 1; x--) &#123; if (n % x != 0) continue; bool ok = true; for (int i = 1; i &lt;= n; i += x) &#123; for (int j = 1; j &lt;= n; j += x) &#123; int s = getSum(i, j, i + x - 1, j + x - 1); if (!(s == 0 || s == x * x)) &#123; ok = false; break; &#125; &#125; if (!ok) break; &#125; if (ok) &#123; cout &lt;&lt; x &lt;&lt; endl; return 0; &#125; &#125; return 0;&#125; 解法2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;bool matrix[5205][5205];int n;int gcd(int a, int b) &#123; if (b == 0) return a; return gcd(b, a % b);&#125;int main() &#123; cin &gt;&gt; n; char c; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 0; j &lt; n / 4; j++) &#123; scanf(\" %c\", &amp;c); int x = '0' &lt;= c &amp;&amp; c &lt;= '9' ? c - '0' : c - 'A' + 10; matrix[i][j*4 + 1] = (x &amp; 8) &gt; 0; matrix[i][j*4 + 2] = (x &amp; 4) &gt; 0; matrix[i][j*4 + 3] = (x &amp; 2) &gt; 0; matrix[i][j*4 + 4] = (x &amp; 1) &gt; 0; &#125; &#125; int ans = n; for (int i = 1; i &lt;= n; i++) &#123; int start = 1; for (int j = 2; j &lt;= n + 1; j++) &#123; if (j &gt; n || matrix[i][j] != matrix[i][j-1]) &#123; ans = gcd(ans, j - start); start = j; &#125; &#125; &#125; for (int i = 1; i &lt;= n; i++) &#123; int start = 1; for (int j = 2; j &lt;= n + 1; j++) &#123; if (j &gt; n || matrix[j][i] != matrix[j-1][i]) &#123; ans = gcd(ans, j - start); start = j; &#125; &#125; &#125; cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Codeforces 1107C. Brutality（贪心），及比赛（Educational Codeforces Round 59）总结","slug":"2019-01-28-Codeforces-1107C-Brutality（贪心），及比赛（Educational-Codeforces-Round-59）总结","date":"2019-01-28T18:06:49.000Z","updated":"2019-01-28T18:06:49.000Z","comments":true,"path":"post/codeforces-1107c-brutality-and-educational-codeforces-round-59-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1107c-brutality-and-educational-codeforces-round-59-summary/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1107/problem/C 提交次数：1/1 题意 给定n个英文小写字符和对应的n个值，按某个字符就可以得到对应的值，不能连续按某个字符超过k次，问得到的值的总和最大是多少。 分析 这次比赛我做得乱七八糟。从提交数量来看，C应该是道很简单的题，但是我却做不出来。事后我发现我看错题了。 PS. 我决定以后CF比赛中我能做出来的题就不写题解了。不然题目实在太多了。。。 对于一串连续的字符，如果它的长度超过了k，那么从里面挑k个最大值就行。没了！ （比赛的时候我以为是要把这个串分割成若干个长度小于k的串。） [soln1]: Codeforces Blog - Quick unofficial editorial for Educational Round 59 (Div. 2) [soln2]: Codeforces Blog - Educational Codeforces Round 59 Editorial 代码 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;typedef long long LL;int k, n;LL a[200005];char s[200005];int main() &#123; cin &gt;&gt; n &gt;&gt; k; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; &#125; cin &gt;&gt; s; LL ans = 0; int start = 0; for (int i = 1; i &lt;= n; i++) &#123; if (i == n || s[i] != s[i-1]) &#123; if (i - start &gt; k) sort(a + start, a + i); for (int j = 0; j &lt; k &amp;&amp; i-j-1 &gt;= start; j++) ans += a[i - j - 1]; start = i; &#125; &#125; cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Leetcode 984. String Without AAA or BBB（贪心）","slug":"2019-01-28-Leetcode-984-String-Without-AAA-or-BBB（贪心）","date":"2019-01-28T17:52:38.000Z","updated":"2019-01-28T17:52:38.000Z","comments":true,"path":"post/leetcode-984-string-without-aaa-or-bbb/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-984-string-without-aaa-or-bbb/","excerpt":"","text":"题目来源：https://leetcode.com/problems/string-without-aaa-or-bbb/description/ 标记难度：Easy 提交次数：1/1 代码效率：100.00%（0ms） 题意 给定自然数A和B，返回任意满足下列要求的字符串S： S的长度为A+B，且恰好包含A个&quot;a&quot;，B个&quot;b&quot; S中不包含任何&quot;aaa&quot; S中不包含任何&quot;bbb&quot; 分析 其实就是要求返回一个&quot;a&quot;/&quot;aa&quot;和&quot;b&quot;/&quot;bb&quot;交替出现的字符串。这道题怎么想都能做，不过我觉得一种比较简单的方法是，轮流在字符串后面添加&quot;a&quot;和&quot;b&quot;，如果当前A &gt; B就添加两个&quot;a&quot;，否则添加一个&quot;a&quot;，然后再考虑&quot;b&quot;的情形，以此类推。 我写得比较麻烦，题解里更简洁一些。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: string strWithout3a3b(int A, int B) &#123; string s; string a = \"a\", b = \"b\"; // 确保第一个字符可以是A对应的字符 if (A &lt; B) &#123; swap(a, b); swap(A, B); &#125; while (A &gt; 0 || B &gt; 0) &#123; // 添加一个a，两个a还是不添加？ if (A &gt; B) &#123; if (A &gt;= 2) &#123; s += a + a; A -= 2; &#125; else if (A &gt; 0) &#123; s += a; A--; &#125; &#125; else if (A &gt; 0) &#123; s += a; A--; &#125; // 添加一个b，两个b还是不添加？ if (B &gt; A) &#123; if (B &gt;= 2) &#123; s += b + b; B -= 2; &#125; else if (B &gt; 0) &#123; s += b; B--; &#125; &#125; else if (B &gt; 0) &#123; s += b; B--; &#125; &#125; return s; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 983. Minimum Cost For Tickets（DP）","slug":"2019-01-28-Leetcode-983-Minimum-Cost-For-Tickets（DP）","date":"2019-01-28T16:55:05.000Z","updated":"2019-01-28T16:55:05.000Z","comments":true,"path":"post/leetcode-983-minimum-cost-for-tickets/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-983-minimum-cost-for-tickets/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-cost-for-tickets/description/ 标记难度：Medium 提交次数：2/2 代码效率： 按连续日期DP：100.00%（0ms） 按离散日期DP：100.00%（0ms） 题意 你需要在一年里的某些日期旅行；你可以购买1天票、7天票和30天票，每种票的价格不同。问最少花多少钱才能使得需要旅行的每一天都有票？ 分析 很简单的DP。如果写的是按连续日期DP的话，那f[i]就表示直到第i天都有合理的票（有些日期需要票，有些则不一定需要）的最少的花费；如果写的是按普通日期DP的话，那f[i]就表示直到第day[i]天都有合理的票的最少的花费。 代码 按连续日期DP 1234567891011121314151617181920212223242526class Solution &#123;public: int mincostTickets(vector&lt;int&gt;&amp; days, vector&lt;int&gt;&amp; costs) &#123; int f[366]; f[0] = 0; int i = 0; for (int j = 1; j &lt;= 365; j++) &#123; while (days[i] &lt; j &amp;&amp; i &lt; days.size()) i++; if (i &lt; days.size() &amp;&amp; j == days[i]) &#123; f[j] = 1e9; // 1 day f[j] = min(f[j], f[j-1] + costs[0]); // 7 days // buy on day f[j-k+1] for (int k = 1; k &lt;= 7 &amp;&amp; j - k &gt;= 0; k++) f[j] = min(f[j], f[j-k] + costs[1]); // 30 days for (int k = 1; k &lt;= 30 &amp;&amp; j - k &gt;= 0; k++) f[j] = min(f[j], f[j-k] + costs[2]); &#125; else f[j] = f[j-1]; &#125; return f[365]; &#125;&#125;; 按离散日期DP 123456789101112131415161718192021222324class Solution &#123;public: int mincostTickets(vector&lt;int&gt;&amp; days, vector&lt;int&gt;&amp; costs) &#123; int f[365]; int N = days.size(); for (int i = 0; i &lt; N; i++) &#123; if (i == 0) &#123; f[0] = min(costs[0], costs[1]); f[0] = min(costs[2], f[0]); continue; &#125; f[i] = f[i-1] + costs[0]; // 感觉这个转移条件也是有点奇怪…… for (int j = 1; j &lt;= 30 &amp;&amp; j &lt;= i; j++) &#123; int x = j &lt; i ? f[i-j-1] : 0; if (days[i] - days[i-j] + 1 &lt;= 7) f[i] = min(f[i], x + costs[1]); if (days[i] - days[i-j] + 1 &lt;= 30) f[i] = min(f[i], x + costs[2]); &#125; &#125; return f[N - 1]; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 982. Triples with Bitwise AND Equal To Zero（DP）","slug":"2019-01-28-Leetcode-982-Triples-with-Bitwise-AND-Equal-To-Zero（DP）","date":"2019-01-28T16:16:26.000Z","updated":"2019-01-28T16:16:26.000Z","comments":true,"path":"post/leetcode-982-triples-with-bitwise-and-equal-to-zero/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-982-triples-with-bitwise-and-equal-to-zero/","excerpt":"","text":"题目来源：https://leetcode.com/problems/triples-with-bitwise-and-equal-to-zero/description/ 标记难度：Hard 提交次数：2/2 代码效率： 我的做法：64.71%（876ms） DP法：82.35%（184ms） 题意 给定数组A（每个数在[0, 2^16)范围内），问所有满足A[i] &amp; A[j] &amp; A[k] == 0的三元组(i, j, k)的个数。 0 &lt;= A.length &lt;= 1000。 分析 比赛的时候我觉得这道题很难，所以没去做它。后来我就想了这样的一种做法： 用O(N^2)的时间复杂度枚举所有的二元组(i, j)与的结果，存入map中，进行计数 对于map中的每种可能结果，找到其中中每个为1的位都为0的A[i]的个数 总的时间复杂度是O(min(N^2, 65536) * 16 * N)。 事实上我觉得这种做法没什么道理，只是因为题目整体的复杂度实在很低才过的…… “与”这个操作让我想起了之前做的一道利用“或”的题目：Leetcode 898. Bitwise ORs of Subarrays。这道题的核心思路之一是，将一个数或上另一个数不会使其中为1的位的数量减少，只会增加，所以不论或上多少个数，不同的数的最大的数量也只有32个。如果把这个思路搬到这道题中，就是将一个数与上另一个数，0的数量不会减少吧。不过这道题一共最多也只有3个数与在一起，这么想好像也没什么意思。 随便看了看题解区，感觉大部分解法都透着一股别扭劲，没什么特别值得一看的。不过这个动态规划解法还挺有趣的： 令f[i][state]表示从A中总共选出i个数，这i个数的与是state的情况的数量 初始化：f[1][A[i]] = 1 更新：f[i][state &amp; A[j]] += f[i-1][state] 总复杂度为O(3 * 2^16 * N)。 [wangzi]: Java DP O(3 * 2^16 * n) time O(n) space 代码 我的方法 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: int countTriplets(vector&lt;int&gt;&amp; A) &#123; bool isZero[16][1000]; int N = A.size(); map&lt;int, int&gt; cnt2; for (int i = 0; i &lt; N; i++) &#123; int x = A[i]; for (int j = 0; j &lt; 16; j++) isZero[j][i] = (x &amp; (1 &lt;&lt; j)) == 0; &#125; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) cnt2[A[i] &amp; A[j]]++; int ans = 0; for (const auto&amp; i: cnt2) &#123; int x = i.first; bool andZero[1000]; memset(andZero, 1, sizeof(andZero)); for (int j = 0; j &lt; 16; j++) &#123; if (x &amp; (1 &lt;&lt; j)) &#123; for (int k = 0; k &lt; N; k++) andZero[k] &amp;= isZero[j][k]; &#125; &#125; int cnt = 0; for (int j = 0; j &lt; N; j++) if (andZero[j]) cnt++; ans += cnt * i.second; &#125; return ans; &#125;&#125;; DP法 12345678910111213141516171819class Solution &#123;public: int countTriplets(vector&lt;int&gt;&amp; A) &#123; int f[4][1 &lt;&lt; 16]; int N = A.size(); memset(f, 0, sizeof(f)); for (int i = 0; i &lt; N; i++) f[1][A[i]]++; // 注意更新方式 for (int i = 1; i &lt; 3; i++) &#123; for (int state = 0; state &lt; (1 &lt;&lt; 16); state++) &#123; if (f[i][state] == 0) continue; for (int j = 0; j &lt; N; j++) f[i + 1][state &amp; A[j]] += f[i][state]; &#125; &#125; return f[3][0]; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 981. Time Based Key-Value Store（二分查找）","slug":"2019-01-27-Leetcode-981-Time-Based-Key-Value-Store（二分查找）","date":"2019-01-27T21:32:53.000Z","updated":"2019-01-28T00:21:00.000Z","comments":true,"path":"post/leetcode-981-time-based-key-value-store/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-981-time-based-key-value-store/","excerpt":"","text":"题目来源：https://leetcode.com/problems/time-based-key-value-store/description/ 标记难度：Medium 提交次数：1/1 代码效率：33.33%（212ms） 题意 给定一系列set和get操作，其中： 每个set操作包含一个key，一个value和一个timestamp，其中timestamp是严格递增的 每个get操作包含一个key和一个timestamp，要求找出与这个key相等且时间戳&lt;=timestamp的set操作中时间戳最大的set对应的value 所有操作总数不超过12万次。 分析 这个题目咋一看很唬人，其实完全不是那么回事。解题思路很简单： 用一个map维护set操作的key对应的value和timestamp对的列表 对于每个get操作，从key对应的列表中通过二分查找，找到最大的符合要求的timestamp对应的value 如果map用的是Hash Table，记总操作次数为N，那么set的复杂度是O(1)，get的复杂度是O(log(N))；如果用的是树结构的话，那set的复杂度就是O(log(N))，get的复杂度是O(log^2(N))（不过显然可以把它写得更好一些）。 这次我写了二分查找。一般来说，如果二分查找（m = (l + r) / 2）之后的转移条件是l = m + 1，r = m的话，那循环条件就可以写成l &lt; r；但是如果转移条件是l = m，r = m - 1的话，循环条件就需要写成l &lt; r-1，然后判断l还是r是解…… 代码 1234567891011121314151617181920212223242526272829class TimeMap &#123;private: map&lt;string, vector&lt;pair&lt;int, string&gt;&gt;&gt; mmap; public: TimeMap() &#123; &#125; void set(string key, string value, int timestamp) &#123; mmap[key].emplace_back(timestamp, value); &#125; string get(string key, int timestamp) &#123; if (mmap.find(key) == mmap.end()) return \"\"; int n = mmap[key].size(); if (mmap[key][0].first &gt; timestamp) return \"\"; // 二分查找 int l = 0, r = n - 1; while (l &lt; r - 1) &#123; int m = (l + r) / 2; if (mmap[key][m].first &lt;= timestamp) l = m; else r = m - 1; &#125; if (mmap[key][r].first &lt;= timestamp) return mmap[key][r].second; return mmap[key][l].second; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Binray Search","slug":"alg-Binray-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binray-Search/"}]},{"title":"Leetcode 980. Unique Paths III（状态DP）","slug":"2019-01-21-Leetcode-980-Unique-Paths-III（DP）","date":"2019-01-21T11:04:51.000Z","updated":"2019-01-21T21:16:00.000Z","comments":true,"path":"post/leetcode-980-unique-paths-iii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-980-unique-paths-iii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/unique-paths-iii/description/ 标记难度：Hard 提交次数：2/8 代码效率： DP：16ms DFS：4ms 题意 有一个二维的方格图，每个格子里有一个值： 1表示起始格子 2表示终止格子 0表示其他可以走的格子 -1表示障碍物 问从起始格子走到终止格子，且把其他可以走的格子都不重不漏地走完一遍的方法总数。 分析 第一个想法就是状态压缩DP啦……但是这次我写好之后却发现f[20][1 &lt;&lt; 20]这么大的数组会MLE！！！虽然Leetcode经常只会报RE就是了……然后我稍微试了一下，发现静态数组定义在类私有变量里一定会MLE，定义在函数里则不会MLE，但是也非常靠近MLE的边缘（再来几个栈帧大概也就爆了）；如果动态分配数组，Run Code时可以正常运行，但提交时也会MLE。交了八次主要就是在试验这些，最后也没试出来Memory Limit是多少。 总之Leetcode这一点非常烦。结论：用递归写法，用map当数组。 除此之外，这道题还有一点需要注意，就是障碍格子的处理。其他就没有什么了。复杂度是O(N * 2^N)，其中N是格子总数。 我之前的非递归写法需要保证已访问格子数少的状态先被计算出来，所以会多出来一个N的常数项，不过因为N一般很小，所以也不是什么大问题。不过递归写法就不需要专门操心格子的计算顺序问题……而且还可以省空间，唉。 另一种方法是DFS……或者说直接暴力。我本来以为这种方法肯定不能过的，结果发现在适当的剪枝下完全可以。但是这个复杂度我就不会估计了。 代码 DP 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution &#123;private: int n, m, N; map&lt;pair&lt;int, int&gt;, int&gt; f; int obsMask; int obsCnt; int start, end; int mx[4] = &#123;0, 0, 1, -1&#125;, my[4] = &#123;1, -1, 0, 0&#125;; // state里是包括自己的 int calc(int x, int y, int state, vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int g = x * m + y; pair&lt;int, int&gt; p(g, state); if (f.find(p) != f.end()) return f[p]; // 障碍代表的格子一直都处于visited状态 if (__builtin_popcount(state) == obsCnt + 1) &#123; if (state == (obsMask | (1 &lt;&lt; start))) f[p] = 1; else f[p] = 0; return f[p]; &#125; int f1 = 0; for (int i = 0; i &lt; 4; i++) &#123; int nx = x + mx[i], ny = y + my[i]; if (nx &lt; 0 || nx &gt;= n || ny &lt; 0 || ny &gt;= m) continue; if (grid[nx][ny] == -1) continue; int ng = nx * m + ny; if (!(state &amp; (1 &lt;&lt; ng))) continue; f1 += calc(nx, ny, state ^ (1 &lt;&lt; g), grid); &#125; f[p] = f1; return f1; &#125; public: int uniquePathsIII(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; n = grid.size(); m = grid[0].size(); N = m * n; obsCnt = 0; for (int i = 0; i &lt; N; i++) &#123; int x = i / m, y = i % m; if (grid[x][y] == 2) end = i; else if (grid[x][y] == 1) start = i; else if (grid[x][y] == -1) &#123; obsMask |= 1 &lt;&lt; i; obsCnt++; &#125; &#125; return calc(end / m, end % m, (1 &lt;&lt; N) - 1, grid); &#125;&#125;; DFS 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;private: bool visited[20][20]; int mx[4] = &#123;0, 0, 1, -1&#125;, my[4] = &#123;1, -1, 0, 0&#125;; int n, m; int tot; int ans; void dfs(int x, int y, int depth, vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; if (depth == tot - 1) &#123; if (grid[x][y] == 2) ans++; return; &#125; if (grid[x][y] == 2) return; // 一个小的剪枝 for (int i = 0; i &lt; 4; i++) &#123; int nx = x + mx[i], ny = y + my[i]; if (nx &lt; 0 || nx &gt;= n || ny &lt; 0 || ny &gt;= m) continue; if (visited[nx][ny] || grid[nx][ny] == -1) continue; visited[nx][ny] = true; dfs(nx, ny, depth + 1, grid); visited[nx][ny] = false; &#125; &#125; public: int uniquePathsIII(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; n = grid.size(); m = grid[0].size(); tot = 0; int startx, starty; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (grid[i][j] != -1) tot++; if (grid[i][j] == 1) startx = i, starty = j; &#125; &#125; ans = 0; memset(visited, 0, sizeof(visited)); visited[startx][starty] = true; dfs(startx, starty, 0, grid); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"[object Object]","slug":"object-Object","permalink":"https://zhanghuimeng.github.io/tags/object-Object/"}]},{"title":"Leetcode 979. Distribute Coins in Binary Tree（树）","slug":"2019-01-21-Leetcode-979-Distribute-Coins-in-Binary-Tree（树）","date":"2019-01-21T00:24:25.000Z","updated":"2019-01-21T00:37:00.000Z","comments":true,"path":"post/leetcode-979-distribute-coins-in-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-979-distribute-coins-in-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/distribute-coins-in-binary-tree/description/ 标记难度：Medium 提交次数：1/1 代码效率：8ms 题意 有一颗二叉树，共有N个结点，每个结点上有若干枚硬币，硬币总数为N。每次操作可以把一枚硬币移动到相邻的结点。问最少进行几次操作，才能使每个结点上恰好有一枚硬币？ 分析 我觉得这道题挺简单的…… 我的思路很简单：先DFS，到达最底层之后判断每个叶结点上的硬币数量node-&gt;val是否恰好为1，如果大于1则把多出来的硬币向父结点移动，总移动数量+=node-&gt;val-1，如果小于1则把少的硬币向父结点移动，也就是移动-(1-node-&gt;val)枚硬币，总移动数量+=1-node-&gt;val。对于其他的结点，因为它们的子结点都已经递归处理完了，所以有多出来的硬币的时候，只能向上移动若干枚硬币或者负的若干枚硬币，也就是和叶结点差不多。 这里面比较好的是移动负数枚硬币这个想法，否则可能还得做第二次递归。 代码 1234567891011121314151617181920class Solution &#123;private: int ans; int dfs(TreeNode* root) &#123; if (root == NULL) return 0; int x = dfs(root-&gt;left) + dfs(root-&gt;right); x += root-&gt;val; ans += abs(x - 1); root-&gt;val = 1; return x - 1; &#125; public: int distributeCoins(TreeNode* root) &#123; ans = 0; dfs(root); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 978. Longest Turbulent Subarray","slug":"2019-01-20-Leetcode-978-Longest-Turbulent-Subarray","date":"2019-01-20T17:05:26.000Z","updated":"2019-01-20T21:19:00.000Z","comments":true,"path":"post/leetcode-978-longest-turbulent-subarray/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-978-longest-turbulent-subarray/","excerpt":"","text":"题目来源：https://leetcode.com/problems/longest-turbulent-subarray/description/ 标记难度：Easy 提交次数：1/1 代码效率：124ms 题意 给定一个正整数数组A，求其中满足turbulent性质的最长子数组的长度： 满足A[i] &gt; A[i+1] &lt; A[i+2] &gt; ... A[j] 或A[i] &lt; A[i+1] &gt; A[i+2] &lt; ... A[j] （其实就是要上下波动。） 分析 我比赛时的想法很简单：维护两个数组up和down，up[i]表示以i为结尾且A[i-1]&lt;A[i]的turbulent子数组最大长度，down[i]表示以i为结尾且A[i-1]&gt;A[i]的turbulent子数组最大长度，然后交替进行递推。 其实这种做法有一些冗余，因为显然只有A[i-1]&lt;A[i]时up[i]才有意义（否则肯定只能取1）；down[i]同理。题解里给出了一种维护这些关系的方法：把原来的数组丢掉，只留下两个数之间的相对关系。对于数组A = [9,4,2,10,7,8,8,1,9]，令B为比较的结果，记大于号为1，小于号为-1，等号为0。因为A[0]=9 &gt; 4=A[1]，因此B[0]=1；因为A[1]=4 &gt; 2=A[2]，因此B[1]=1；因为A[2]=2 &lt; 10=A[3]，因此B[2]=-1；……[1] 以此类推，得到B = [1, 1, -1, 1, -1, 0, -1, 1]。此时我们只需要贪心地尝试把B分成若干个最长的1和-1交替的子序列即可，如[1], [1, -1, 1, -1], [0], [-1, 1]。因为此时B中的每个数表示的是A中两个数的关系，所以边缘处（重复）的数得到了比较好的处理：如[1]代表[9, 4]，[1, -1, 1, -1]代表[4, 2, 10, 7, 8]，[0]代表[8, 8]，[-1, 1]代表[8, 1, 9]。 代码 123456789101112131415161718192021class Solution &#123;public: int maxTurbulenceSize(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int up[n], down[n]; int ans = 0; up[0] = down[0] = 1; for (int i = 1; i &lt; n; i++) &#123; up[i] = down[i] = 1; if (A[i] &gt; A[i-1]) up[i] = down[i-1] + 1; if (A[i] &lt; A[i-1]) down[i] = up[i-1] + 1; &#125; for (int i = 0; i &lt; n; i++) &#123; ans = max(ans, up[i]); ans = max(ans, down[i]); &#125; return ans; &#125;&#125;; Leetcode Offical Solution for 978. Longest Turbulent Subarray ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 977. Squares of a Sorted Array","slug":"2019-01-20-Leetcode-977-Squares-of-a-Sorted-Array","date":"2019-01-20T14:49:13.000Z","updated":"2019-01-20T17:02:00.000Z","comments":true,"path":"post/leetcode-977-squares-of-a-sorted-array/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-977-squares-of-a-sorted-array/","excerpt":"","text":"题目来源：https://leetcode.com/problems/squares-of-a-sorted-array/description/ 标记难度：Easy 提交次数：2/3 代码效率： 排序：124ms 双指针：104ms 题意 给定一组已经排序了的整数，返回它们的平方排序后的结果。 分析 最简单的方法就是直接平方之后排序，复杂度是O(N^log(N))。 复杂一点的话，就是利用这些整数已经排序了的条件，找到中间最靠近0的数，然后分别“合并”两边平方的大小。举个例子：对于[-3, -2, -1, 4, 5, 6]，这么做相当于合并[-1, -2, -3]和[4, 5, 6]平方的结果。具体的实现方法也是用两个指针。[1] 代码 排序 12345678910class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; B; for (int x: A) B.push_back(x*x); sort(B.begin(), B.end()); return B; &#125;&#125;; 双指针 实现的时候需要稍微注意一下判断条件…… 12345678910111213141516171819202122class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int i = 0; while (i &lt; n - 1 &amp;&amp; A[i] &lt; 0) i++; if (A[i] &gt; 0) i--; int j = i + 1; vector&lt;int&gt; ans; while (i &gt;= 0 || j &lt; n) &#123; if (i &lt; 0 || j &lt; n &amp;&amp; abs(A[i]) &gt;= abs(A[j])) &#123; ans.push_back(A[j] * A[j]); j++; &#125; else if (j &gt;= n || i &gt;= 0 &amp;&amp; abs(A[i]) &lt;= abs(A[j])) &#123; ans.push_back(A[i] * A[i]); i--; &#125; &#125; return ans; &#125;&#125;; Leetcode official solution for 977. Squares of a Sorted Array ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Codeforces 1102F. Elongated Matrix（DP）","slug":"2019-01-19-Codeforces-1102F-Elongated-Matrix（DP）","date":"2019-01-19T16:59:52.000Z","updated":"2019-01-21T23:57:00.000Z","comments":true,"path":"post/codeforces-1102f-elongated-matrix/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102f-elongated-matrix/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/F 提交次数：2/3 题意 给定一个n（1&lt;=n&lt;=16）行m列的矩阵，重新排列矩阵的各行，使得逐列遍历矩阵时相邻两个数之差绝对值的最小值最大。 分析 还是一道状态压缩DP。首先计算出每两行之间的距离（注意第一行和最后一行的距离）。 然后对于每种状态，枚举可能的起始结点，最大化路径上边权重的最小值。状态总数是n * 2^n（末尾结点*状态总数），枚举起始结点的代价为O(n)，枚举上一个结点的代价是O(n)，总计算复杂度是O(n^3 * 2^n)。如果不用递归还要多一个O(n)，不知道有没有解决这个问题的方法。 另一种比较神奇的方法是二分答案，然后在图上寻找回路。题解里的具体方法是这样的：枚举起始点i，对于每个点j，寻找一条从i到j的经过了所有结点的路径，然后再判断j到i是否有路径。题解[1]里这种方法的复杂度是O(n^2 * log(MAXN) * 2^n)。但是我并不会题解里的写法，所以我写出来的还是平凡的O(n^3 * 2^n)的求哈密顿回路法…… 代码 迭代写法的DP 相当慢…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;cstdio&gt;using namespace std;int a[16][10000];int nextOk[16][16];int firstLastOk[16][16];int f[16][16][1 &lt;&lt; 16];int n, m, k;int main() &#123; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; m; j++) scanf(\"%d\", &amp;a[i][j]); for (int i = 0; i &lt; n; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; int x = 1e9; for (int k = 0; k &lt; m; k++) &#123; x = min(x, (int) abs(a[i][k] - a[j][k])); if (x == 0) break; &#125; nextOk[i][j] = nextOk[j][i] = x; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; int x = 1e9; for (int k = 1; k &lt; m; k++) &#123; x = min(x, (int) abs(a[j][k-1] - a[i][k])); if (x == 0) break; &#125; firstLastOk[i][j] = x; &#125; &#125; if (n == 1) &#123; cout &lt;&lt; firstLastOk[0][0] &lt;&lt; endl; return 0; &#125; int ans = 0; // 枚举路径长度 for (int len = 1; len &lt;= n; len++) &#123; for (int status = 0; status &lt; (1 &lt;&lt; n); status++) &#123; if (__builtin_popcount(status) != len) continue; for (int first = 0; first &lt; n; first++) &#123; if (!(status &amp; (1 &lt;&lt; first))) continue; if (len == 1) &#123; f[first][first][status] = 1e9; continue; &#125; for (int cur = 0; cur &lt; n; cur++) &#123; if (!(status &amp; (1 &lt;&lt; cur)) || first == cur) continue; f[first][cur][status] = 0; for (int last = 0; last &lt; n; last++) &#123; if (!(status &amp; (1 &lt;&lt; last)) || cur == last) continue; int x = min(f[first][last][status ^ (1 &lt;&lt; cur)], nextOk[last][cur]); if (len == n) x = min(x, firstLastOk[first][cur]); f[first][cur][status] = max(f[first][cur][status], x); &#125; if (len == n) ans = max(f[first][cur][status], ans); &#125; &#125; &#125; &#125; cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 递归写法的DP+二分答案 因为常数写多了所以甚至更慢了…… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;using namespace std;int a[16][10000];int nextOk[16][16];int firstLastOk[16][16];int f[16][1 &lt;&lt; 16];bool g[16][16];int n, m, k;int calc(int x, int state) &#123; if (f[x][state] != -1) return f[x][state]; f[x][state] = 0; for (int i = 0; i &lt; n; i++) &#123; if (i != x &amp;&amp; (state &amp; (1 &lt;&lt; i)) &amp;&amp; g[i][x] &amp;&amp; calc(i, state ^ (1 &lt;&lt; x))) &#123; f[x][state] = 1; break; &#125; &#125; return f[x][state];&#125;bool isOk(int thres) &#123; memset(g, 0, sizeof(g)); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (i != j &amp;&amp; nextOk[i][j] &gt;= thres) g[i][j] = true; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; memset(f, -1, sizeof(f)); // 因为这句memset位置错了，调了一阵子 // 控制只能从i开始 for (int j = 0; j &lt; n; j++) f[j][1 &lt;&lt; j] = j == i ? 1 : 0; for (int j = 0; j &lt; n; j++) &#123; if (firstLastOk[i][j] &gt;= thres) &#123; if (calc(j, (1 &lt;&lt; n) - 1)) return true; &#125; &#125; &#125; return false;&#125;int main() &#123; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; m; j++) scanf(\"%d\", &amp;a[i][j]); for (int i = 0; i &lt; n; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; int x = 1e9; for (int k = 0; k &lt; m; k++) &#123; x = min(x, (int) abs(a[i][k] - a[j][k])); if (x == 0) break; &#125; nextOk[i][j] = nextOk[j][i] = x; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; int x = 1e9; for (int k = 1; k &lt; m; k++) &#123; x = min(x, (int) abs(a[j][k-1] - a[i][k])); if (x == 0) break; &#125; firstLastOk[i][j] = x; &#125; &#125; if (n == 1) &#123; cout &lt;&lt; firstLastOk[0][0] &lt;&lt; endl; return 0; &#125; // 二分答案 // 这个写法是从题解里抄的（感觉也不是很优雅啊） // &lt;del&gt;谁叫你也写不出优雅的&lt;/del&gt; int l = 0, r = 1e9; while (l &lt; r - 1) &#123; int m = (l + r) &gt;&gt; 1; if (isOk(m)) l = m; else r = m; &#125; if (isOk(r)) cout &lt;&lt; r &lt;&lt; endl; else cout &lt;&lt; l &lt;&lt; endl; return 0;&#125; Codeforces Round #531 (Div. 3) Editorial ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Binary Search","slug":"alg-Binary-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"alg:Bitmasks","slug":"alg-Bitmasks","permalink":"https://zhanghuimeng.github.io/tags/alg-Bitmasks/"}]},{"title":"Codeforces 1102E. Monotonic Renumeration（数组）","slug":"2019-01-17-Codeforces-1102E-Monotonic-Renumeration（数组）","date":"2019-01-17T17:08:19.000Z","updated":"2019-01-19T16:52:00.000Z","comments":true,"path":"post/codeforces-1102e-monotonic-renumeration/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102e-monotonic-renumeration/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/E 提交次数：1/1 题意 给定一个长度为n的数组a，要求为a生成一个对应的数组b，满足： b[0] = 0 对于任意0 &lt;= i &lt; j &lt;= n，如果满足a[i] == a[j]，必有b[i] == b[j]（不过a[i] != a[j]时也可能有b[i] == b[j]） 任取0 &lt;= i &lt; n - 1，必有b[i] = b[i+1]或b[i] + 1 = b[i+1] 问共有多少种可能的b。 分析 显然b[i]是一个递增序列，因此可以自然推出，若a[i] == a[j]，则必有b[i] == b[i+1] == ... = b[j]，也就是说，对于a中任意位置两个相等的元素，它们在b中对应的是一整段相等的元素。显然这种元素相等是可能会发生重叠的，因此一个自然的想法就是，把重复的元素建模成线段，然后合并发生overlap的线段以得到相等元素的最长长度。 我的做法是，从后向前遍历a，如果发现当前元素和后面的元素重复了，则取index最靠后的元素，组成一条线段，插入到栈中与其他元素合并；否则把它自己的index作为一条线段插入到栈中。最后栈中留下的就是几条互不相交（且并组成了整个区间）的线段。 对于（除了第一条之外）每条线段，我们可以选择让它的值和前一条相等，也可以选择让它的值是前一条+1。每种选择都会导致生成一种新的b。于是结果是2^{线段数-1}。 例子：对于a = {1, 2, 1, 2, 3}，1对应的线段是[0, 2]，2对应的线段是[1, 3]，3对应的线段是[4, 4]；合并之后得到两条线段，[0, 3]和[1, 4]；只有两种b，分别是{0, 0, 0, 0, 0}和{0, 0, 0, 0, 1}。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;map&gt;using namespace std;int a[200005];int n;typedef long long int LL;const LL P = 998244353;LL pow2(LL x) &#123; LL pow = 2, ans = 1; while (x &gt; 0) &#123; if (x &amp; 1) ans = (ans * pow) % P; pow = (pow * pow) % P; x &gt;&gt;= 1; &#125; return ans;&#125;int main() &#123; map&lt;int, int&gt; indMap; vector&lt;pair&lt;int, int&gt;&gt; s; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; if (indMap.find(a[i]) == indMap.end()) &#123; indMap[a[i]] = i; &#125; &#125; for (int i = n - 1; i &gt;= 0; i--) &#123; pair&lt;int, int&gt; interval; if (indMap.find(a[i]) != indMap.end() &amp;&amp; indMap[a[i]] &lt; i) &#123; interval = make_pair(indMap[a[i]], i); &#125; else &#123; interval = make_pair(i, i); &#125; if (!s.empty() &amp;&amp; s.back().first &lt;= interval.first &amp;&amp; s.back().second &gt;= interval.second) continue; if (!s.empty() &amp;&amp; interval.second &gt;= s.back().first) &#123; interval.second = s.back().second; s.pop_back(); s.push_back(interval); &#125; if (s.empty() || interval.second &lt; s.back().first) s.push_back(interval); &#125; int cnt = 0; if (!s.empty() &amp;&amp; s.front().second &lt; n - 1) cnt++; if (!s.empty() &amp;&amp; s.back().first &gt; 0) cnt++; for (int i = 0; i &lt; s.size(); i++) &#123; cnt++; // 本条线段和前一条线段之间的间隔 if (i &gt; 0 &amp;&amp; s[i - 1].second &lt; s[i].first - 1) cnt++; &#125; cout &lt;&lt; pow2(cnt - 1) &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"}]},{"title":"Codeforces 1102D. Balanced Ternary String（贪心）","slug":"2019-01-17-Codeforces-1102D-Balanced-Ternary-String（贪心）","date":"2019-01-17T16:51:58.000Z","updated":"2019-01-17T17:05:00.000Z","comments":true,"path":"post/codeforces-1102d-balanced-ternary-string/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102d-balanced-ternary-string/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/D 提交次数：1/1 题意 给定一个只包含0、1、2的长度是3的倍数的字符串，要求替换最少数量的字符，使得其中0、1、2的数量相等，且得到的字符串字典序最小。 分析 这道题让我想起之前的某道USACO题（Sorting a Three-Valued Sequence）。好吧，其实没啥太大的关系（除了都是三值序列以外）。 既然要求替换最少数量的字符，那么把什么字符换成什么字符，以及换多少个其实都是确定的。如果这一点听起来不是很直接的话……比如，0的数量和1的数量都比n/3多，那么多出来的0和1都要换成2。如果0的数量和1的数量都比n/3少，那么多出来的2要分别换成0和1。实际上只有这两种情况。 然后就可以开始考虑怎么换了。显然，如果要把小的字符换成大的字符，应该从后向前换，换完为止；如果把大的字符换成小的字符，应该从前往后换，也是换完为止。 光考虑这一点还不够。比如说我们需要把两个0换成1，两个0换成2，那么应该先（从后向前）换2，再（从后向前）换1。 然后就能过啦。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;using namespace std;int n;int a[300000];int cnt[3];int main() &#123; char c; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; c; a[i] = c - '0'; cnt[a[i]]++; &#125; int m = n / 3; // 从i改成j int order[3][3] = &#123; &#123;2, 1, 0&#125;, &#123;0, 1, 2&#125;, &#123;0, 1, 2&#125; &#125;; for (int i = 0; i &lt; 3; i++) &#123; for (int j1 = 0; j1 &lt; 3; j1++) &#123; int j = order[i][j1]; if (i == j) continue; if (cnt[i] == m || cnt[j] == m) continue; if (cnt[i] &lt; m || cnt[j] &gt; m) continue; // 从后向前改 if (i &lt; j) &#123; for (int k = n - 1; k &gt;= 0; k--) &#123; if (cnt[i] == m || cnt[j] == m) break; if (a[k] == i) &#123; a[k] = j; cnt[i]--; cnt[j]++; &#125; &#125; &#125; // 从前向后改 if (i &gt; j) &#123; for (int k = 0; k &lt; n; k++) &#123; if (cnt[i] == m || cnt[j] == m) break; if (a[k] == i) &#123; a[k] = j; cnt[i]--; cnt[j]++; &#125; &#125; &#125; &#125; &#125; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i]; cout &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1102C. Doors Breaking and Repairing（博弈）","slug":"2019-01-17-Codeforces-1102C-Doors-Breaking-and-Repairing（博弈）","date":"2019-01-17T16:34:56.000Z","updated":"2019-01-17T16:46:00.000Z","comments":true,"path":"post/codeforces-1102c-doors-breaking-and-repairing/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102c-doors-breaking-and-repairing/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/C 提交次数：1/1 题意 有n扇门，每扇门的耐久度是a[i]，两个人轮流对这些门做一些操作： 我可以任选一扇门，如果它的耐久度是b[i]，则可以将它降低到max(0, b[i]-x) 之后对方可以选择一扇门，如果它的耐久度是b[i]且b[i] &gt; 0，则可以将它增加到b[i]+y 两人轮流进行游戏 游戏共有10^100轮。问游戏结束后耐久度变成0的门的数量最多是多少？ 分析 这道题说是博弈论，其实没啥博弈的……（或者说没有什么复杂的算法） 如果x &gt; y，那么最后肯定是我方完全胜利（这么多轮，无论对方怎么加耐久，我们都可以和对方对敲，然后把所有门都敲爆……）。 如果x &lt;= y，事情就变得有些复杂了。如果我们任选一扇门来敲（且没有敲到0），那么对方在下一轮就可以把它补好，甚至比之前还牢靠（y &gt; x）；所以我们选能敲到0的门才有效果。对方的最佳策略显然就是把那些耐久值&lt;=x的门赶紧补齐，补到一下敲不坏为止。所以我方能最终敲坏的门的数量就是耐久值&lt;=x的门的总数除2（取ceil）（因为是我方先开始游戏，可以多敲坏一扇门）。 代码 1234567891011121314#include &lt;iostream&gt;using namespace std;int a[100];int main() &#123; int n, x, y, cnt = 0; cin &gt;&gt; n &gt;&gt; x &gt;&gt; y; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; if (a[i] &lt;= x) cnt++; &#125; if (x &gt; y) cout &lt;&lt; n &lt;&lt; endl; else cout &lt;&lt; (cnt + 1) / 2 &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Games","slug":"alg-Games","permalink":"https://zhanghuimeng.github.io/tags/alg-Games/"}]},{"title":"Codeforces 1102B. Array K-Coloring（贪心）","slug":"2019-01-17-Codeforces-1102B-Array-K-Coloring（贪心）","date":"2019-01-17T16:09:08.000Z","updated":"2019-01-17T16:28:00.000Z","comments":true,"path":"post/codeforces-1102b-array-k-coloring/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102b-array-k-coloring/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/B 提交次数：1/4 题意 给定n个整数，要求将它们染成k种颜色，满足： 每种颜色至少出现一次 相同的整数不能染成相同的颜色 求任意一种染色方法。 分析 比赛的时候被Hack了，不过好像也无所谓，因为被Hack说明本来就做错了（ 最开始的做法是这样的： 计算每种整数的数量（如果有超过k个的，则显然无法满足要求） 为每种整数记录当前颜色上限，当前出现过的颜色的upper-bound 如果当前整数之前还没有被染过色，则将它对应的初始颜色值设为当前upper-bound；否则进行对应的染色，更新颜色上限和upper-bound 显然这种做法存在一个问题：颜色还是会重复，在比较tricky的情况下就会爆掉，比如n=k的情况。于是我被hack了。 这个做法的想法本身倒是没有什么问题，在颜色还没有出现完之前，认定每种整数出现颜色的起始值是之前所有类型整数的数量之和就行了。 题解里的做法看起来更巧妙（不过复杂度升高了……），就是先把整个数组排序，然后直接把每个元素染成颜色i % k。这样，连续的小于k个元素恰好不会被染成重复的颜色。[1]这也说明了，判断完整数数量之后，只要n&gt;=k，就不会有失败的情况…… 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int a[5000];int cnt[5001];int colorCnt[5001];int color[5000];int main() &#123; int n, k; cin &gt;&gt; n &gt;&gt; k; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; cnt[a[i]]++; &#125; // 必然失败的情况 for (int i = 1; i &lt;= 5000; i++) &#123; if (cnt[i] &gt; k) &#123; cout &lt;&lt; \"NO\" &lt;&lt; endl; return 0; &#125; &#125; int nextColor = 1, maxColor = -1; for (int i = 0; i &lt; n; i++) &#123; // 如果nextColor大于k，说明已经全部出现完了，可以随便染 if (colorCnt[a[i]] == 0) &#123; colorCnt[a[i]] = nextColor &gt; k ? 1 : nextColor; nextColor += cnt[a[i]]; &#125; // 模k循环染色 color[i] = colorCnt[a[i]]++; if (colorCnt[a[i]] &gt; k) colorCnt[a[i]] -= k; maxColor = max(color[i], maxColor); &#125; if (nextColor &lt; k) &#123; cout &lt;&lt; \"NO\" &lt;&lt; endl; return 0; &#125; cout &lt;&lt; \"YES\" &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; color[i] &lt;&lt; ' '; cout &lt;&lt; endl; return 0;&#125; Codeforces Round #531 (Div. 3) Editorial ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Leetcode 976. Largest Perimeter Triangle","slug":"2019-01-16-Leetcode-976-Largest-Perimeter-Triangle","date":"2019-01-16T02:21:37.000Z","updated":"2019-01-16T22:54:00.000Z","comments":true,"path":"post/leetcode-976-largest-perimeter-triangle/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-976-largest-perimeter-triangle/","excerpt":"","text":"题目来源：https://leetcode.com/problems/largest-perimeter-triangle/description/ 标记难度：Easy 提交次数：1/1 代码效率：20.00%（64ms） 题意 给定N个正数（N&lt;=10000），求以这些正数作为边长能组成的周长最大的三角形的周长。 分析 我第一次看的时候看成了面积，好在及时纠偏了。（问题：如果是面积，那应该怎么做呢？） 显然，用O(N^3)的方法（枚举每种组合成三角形的方式）可做，但是肯定会超时。那么不妨考虑只选两条边，然后用某种方法选出最大的第三条边的过程。（虽然O(N^2)也会超时，但是姑且先这么做着。） 不妨先将数组A排序。如果先尝试选出较小的两条边A[i]和A[j]（i &lt; j），那么第三条边A[k]需要满足A[j]-A[i] &lt; A[k] &lt; A[i]+A[j]。那么肯定是选择小于A[i]+A[j]的最大的A[k]。而且我们希望A[i]+A[j]尽量大…… 用上面这种思路肯定是可以做出来的，因为它本质上和这一种一样，不过我觉得这样更好想一些。先尝试选择较大的两条边A[j]和A[k]，则A[i]需要满足A[k]-A[j] &lt; A[i] &lt; A[j]+A[k]。因为A[i]是较小的边，因此必然满足A[i] &lt; A[j]+A[k]，于是只需考虑A[i] &gt; A[k]-A[j]这一条件。在选定A[k]之后，选择最大的比它小的A[j]（也就是A[k-1]）可以同时最大化这条边的边长和A[i]，因此只需对于每个k &gt;= 2，找出满足A[i] &gt; A[k]-A[k-1] &amp;&amp; i &lt; k-1的最大的i。 这种做法的复杂度是O(N*log(N))，排序是O(N*log(N))，对于每个k求upper-bound也是O(N*log(N))。 显然后一个O(N*log(N))有点儿蠢。如果满足A[i] &gt; A[k]-A[k-1]的最小的i小于k-1，那么无论如何都应该选择A[i] = A[k-2]；否则就找不到满足条件的三角形。所以直接看A[k]、A[k-1]和A[k-2]就可以了！ 事实上，按照题解的说法：假设三条边的边长是a, b, c，且满足a &lt;= b &lt;= c，那么这三条边能组成三角形的充要条件是a + b &gt; c。对于每个c，考虑最大的a, b就足够了！[1] 代码 这里是比较愚蠢的做法…… 123456789101112131415class Solution &#123;public: int largestPerimeter(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int ans = 0; sort(A.begin(), A.end()); for (int i = n - 2; i &gt; 0; i--) &#123; int thes = A[i+1] - A[i]; int idx = upper_bound(A.begin(), A.end(), thes) - A.begin(); if (idx &lt; n &amp;&amp; idx &lt; i) ans = max(ans, A[i+1] + A[i] + A[i - 1]); &#125; return ans; &#125;&#125;; Leetcode Official Solution for 976 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 975. Odd Even Jump（栈）","slug":"2019-01-16-Leetcode-975-Odd-Even-Jump（栈）","date":"2019-01-16T02:20:44.000Z","updated":"2019-01-17T15:46:00.000Z","comments":true,"path":"post/leetcode-975-odd-even-jump/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-975-odd-even-jump/","excerpt":"","text":"题目来源：https://leetcode.com/problems/odd-even-jump/description/ 标记难度：Hard 提交次数：2/2 代码效率： 单调栈：100.00%（72ms） 平衡树：60.56%（100ms） 题意 We need to jump higher and lower alternately to the end. [1] 这句题目描述太精妙了，以至于我深感自己理解能力和语言描述能力的匮乏。 简单来说就是，从数组的某个index出发，先跳到它后面的比它大的元素中最小的元素（如果有相同元素则选择最靠左的一个），再跳到它后面的比它小的元素中最大的元素（相同时仍然选择最靠左的一个），交替采取这两种跳法，直到跳不动了为止。问从多少个index出发可以最终跳到最后一个元素。 分析 法一：单调栈 我在做题之前得到了一点提示（这道题应该用栈来做），遂在一通魔调之后搞出了一个能过的单调栈解法。说起来，我还是看了这次的题解才知道这种方法的名字应该叫单调栈（monotonic stack）。于是我决定把之前用这个算法的文章的标签修改一下…… 和之前的那些单调栈相比，这次的做法没什么大的差异，但解决平局的方法有所不同。以index为第二关键字对数组排序之后，找右侧更大的数的时候，需要倒序遍历数组，单调栈正好可以处理平局的问题；但找右侧更小的数的时候，正序遍历数组，对于大小相同的数，index较小的先出现，较大的后出现，之后的数就找不到index较小的数了。 所以找右侧更小的数的时候，需要把大小相同的数按index倒序排序。 单调栈中index的大小和左右侧有关，排序的顺序和大小有关。 法二：平衡树 但是实际上我已经做单调栈的题太多以至于过拟合了。之前我还会想到平衡树的解法的……现在已经只会单调栈啦！！！[1:1] 结果在这个解法上还是遇到了问题。第一个问题就是不要用std::upper_bound，要用map.upper_bound（针对内部容器实现的，和针对map实现的区别）。第二个问题是，题目要求是带等号的，而upper_bound找不到等号，所以要修改一下得到的结果。 代码 单调栈 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution &#123;public: int oddEvenJumps(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int odd[n], even[n]; stack&lt;pair&lt;int, int&gt;&gt; s; vector&lt;pair&lt;int, int&gt;&gt; indices; for (int i = 0; i &lt; n; i++) indices.emplace_back(A[i], -i); sort(indices.begin(), indices.end()); for (int i = 0; i &lt; n; i++) indices[i].second = -indices[i].second; for (int i = 0; i &lt; n; i++) &#123; while (!s.empty() &amp;&amp; indices[i].second &gt; s.top().second) &#123; s.pop(); &#125; if (s.empty()) even[indices[i].second] = -1; else even[indices[i].second] = s.top().second; s.push(indices[i]); &#125; s = stack&lt;pair&lt;int, int&gt;&gt;(); indices.clear(); for (int i = 0; i &lt; n; i++) indices.emplace_back(A[i], i); sort(indices.begin(), indices.end()); for (int i = n - 1; i &gt;= 0; i--) &#123; while (!s.empty() &amp;&amp; indices[i].second &gt; s.top().second) s.pop(); if (s.empty()) odd[indices[i].second] = -1; else odd[indices[i].second] = s.top().second; s.push(indices[i]); &#125; int oddjump[n], evenjump[n]; int ans = 0; for (int i = n - 1; i &gt;= 0; i--) &#123; if (odd[i] != -1) oddjump[i] = evenjump[odd[i]]; else oddjump[i] = i; if (even[i] != -1) evenjump[i] = oddjump[even[i]]; else evenjump[i] = i; if (oddjump[i] == n - 1) ans++; &#125; return ans; &#125;&#125;; 平衡树 12345678910111213141516171819202122232425262728class Solution &#123;public: int oddEvenJumps(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int odd[n], even[n]; even[n-1] = odd[n-1] = n - 1; int ans = 1; map&lt;int, int&gt; treeSet; treeSet[A[n-1]] = n - 1; for (int i = n - 2; i &gt;= 0; i--) &#123; auto si = treeSet.upper_bound(A[i]); auto bi = treeSet.lower_bound(A[i]); if (si != treeSet.begin()) even[i] = odd[(--si)-&gt;second]; else even[i] = -1; if (bi != treeSet.end()) odd[i] = even[bi-&gt;second]; else odd[i] = -1; treeSet[A[i]] = i; if (odd[i] == n - 1) ans++; &#125; return ans; &#125;&#125;; lee215’s solution for 975 - [Java/C++/Python] DP idea, Using TreeMap or Stack ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Monotonic Stack","slug":"alg-Monotonic-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Monotonic-Stack/"}]},{"title":"Leetcode 974. Subarray Sums Divisible by K","slug":"2019-01-16-Leetcode-974-Subarray-Sums-Divisible-by-K","date":"2019-01-16T02:02:39.000Z","updated":"2019-01-16T02:19:39.000Z","comments":true,"path":"post/leetcode-974-subarray-sums-divisible-by-k/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-974-subarray-sums-divisible-by-k/","excerpt":"","text":"题目来源：https://leetcode.com/problems/subarray-sums-divisible-by-k/description/ 标记难度：Medium 提交次数：1/1 代码效率：60.00%（36ms） 题意 给定整数数组A，求所有满足和模K余0的子数组的数量。 分析 比赛的时候，我的做法是：依次扫描数组，求前缀和之后模N，从map里读出这个余数对应的前缀和数量，加到ans里，然后余数对应前缀和数量+1。原理非常简单，子数组和可以用前缀和之差来表示。需要注意的是，0也代表没有前缀时的和。 不过这么做其实并不本质。首先，前缀和模K是一个比较小的数，可以用数组来做（而不一定需要map）。其次，实际上求每种余数对应前缀和里取两个的结果就可以了！也就是直接用组合数去算。[1] 显然这么做更加本质。 （以及这让我发现了(n2)=n(n−1)2=1+2+⋯+(n−1)\\binom{n}{2} = \\frac{n(n-1)}{2} = 1 + 2 + \\cdots + (n-1)(2n​)=2n(n−1)​=1+2+⋯+(n−1)这个事实，我火星了） 代码 123456789101112131415class Solution &#123;public: int subarraysDivByK(vector&lt;int&gt;&amp; A, int K) &#123; map&lt;int, int&gt; cntMap; int sum = 0, ans = 0; cntMap[0]++; for (int i = 0; i &lt; A.size(); i++) &#123; sum += A[i]; int mod = (sum % K + K) % K; if (cntMap[mod] &gt; 0) ans += cntMap[mod]; cntMap[mod]++; &#125; return ans; &#125;&#125;; Leetcode Official Solution for 974 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 973. K Closest Points to Origin（数学）","slug":"2019-01-15-Leetcode-973-K-Closest-Points-to-Origin（数学）","date":"2019-01-15T17:13:52.000Z","updated":"2019-01-17T15:51:00.000Z","comments":true,"path":"post/leetcode-973-k-closest-points-to-origin/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-973-k-closest-points-to-origin/","excerpt":"","text":"题目来源：https://leetcode.com/problems/k-closest-points-to-origin/description/ 标记难度：Easy 提交次数：2/5 代码效率： 普通方法：80.0%（208ms） 堆：60.00%（212ms） 快排：40.00%（224ms） 题意 给定平面上的若干个（&lt;=10000）点，求距离原点最近的K个点。保证结果对应的点集唯一，以任意顺序返回都可以。 分析 其实我睡过了这次比赛。随后又撞上期末考试和毕设，感觉流年不利。 显然可以把距离算出来之后排序，然后取前K个点，时间复杂度为O(N*log(N))。 如果想做得更好一点的话，可以用一个大小为K的堆来维护距离前K小的点，时间复杂度为O(N*log(K))。 题解里给出了一种神奇的方法，思路是用类似于快排的方法求前K小的点，感觉很有趣。不过为了严格起见，大概还是要每次随机选主元才行……[1] 快排！快排！ 为了写好题解里快排的方法，浪费了一两个小时。我果然又把快排的写法忘光了！姑且先总结一下。 快排的第一种写法不妨称之为交替填坑法。这种做法的核心规律是，先把序列最靠左的元素拿出来作为主元（并空出来一个坑），然后从右向左找到第一个可以填这个坑的元素（也就是第一个比主元小的元素），把它拿出来填到这个坑里。此时右边就空出来一个新坑。然后从左边刚被填完的坑向右扫描，找到第一个能够填右边的坑的元素（也就是第一个比主元大的元素），把它拿出来填到右边的坑里。此时左边又空出来一个新坑……以此类推。最后中间剩下一个坑，满足左边的元素都比主元小，右边的元素都比主元大，再把主元填到这个坑里。 以序列[3, 6, 5, 4, 2, 1, 0]为例： 1234567891011121314151617181920212223242526272829303132333435| 3 | 6 | 5 | 4 | 2 | 1 | 0 | ^pivotpivot = 3, remove pivot| x | 6 | 5 | 4 | 2 | 1 | 0 | i jpivot = 3, move A[j] to A[i], i++| 0 | 6 | 5 | 4 | 2 | 1 | x | i jpivot = 3, move A[i] to A[j], j--| 0 | x | 5 | 4 | 2 | 1 | 6 | i jpivot = 3, move A[j] to A[i], i++| 0 | 1 | 5 | 4 | 2 | x | 6 | i jpivot = 3, move A[i] to A[j], j--| 0 | 1 | x | 4 | 2 | 5 | 6 | i jpivot = 3, move A[j] to A[i], i++| 0 | 1 | 2 | 4 | x | 5 | 6 | i jpivot = 3, move A[i] to A[j], j--| 0 | 1 | 2 | x | 4 | 5 | 6 | i jfound i==j, put pivot into i (or j)| 0 | 1 | 2 | 3 | 4 | 5 | 6 | i j 显然可以看出，每个周期包含两次指针移动和交换，其中i和j的含义是分阶段而不同的。 此处有坑，明天再填。 2019.1.17 UPDATE：坑应该是填不动了。简单来说，还有一种常用的写法是不移出主元，而是让它在里面跟着交换。这两种写法都解决不了主元重复的问题，此时最好改成CLRS式的写法。 代码 普通方法 1234567891011121314class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; kClosest(vector&lt;vector&lt;int&gt;&gt;&amp; points, int K) &#123; vector&lt;pair&lt;int, int&gt;&gt; toSort; for (int i = 0; i &lt; points.size(); i++) &#123; toSort.emplace_back(points[i][0] * points[i][0] + points[i][1] * points[i][1], i); &#125; sort(toSort.begin(), toSort.end()); vector&lt;vector&lt;int&gt;&gt; ans; for (int i = 0; i &lt; K; i++) ans.push_back(points[toSort[i].second]); return ans; &#125;&#125;; 堆 12345678910111213141516class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; kClosest(vector&lt;vector&lt;int&gt;&gt;&amp; points, int K) &#123; priority_queue&lt;pair&lt;int, int&gt;&gt; q; for (int i = 0; i &lt; points.size(); i++) &#123; q.emplace(points[i][0] * points[i][0] + points[i][1] * points[i][1], i); if (q.size() &gt; K) q.pop(); &#125; vector&lt;vector&lt;int&gt;&gt; ans; while (!q.empty()) &#123; ans.push_back(points[q.top().second]); q.pop(); &#125; return ans; &#125;&#125;; 快排 123456789101112131415161718192021222324252627282930class Solution &#123;private: int dist(vector&lt;int&gt;&amp; p) &#123; return p[0] * p[0] + p[1] * p[1]; &#125; void partition(vector&lt;vector&lt;int&gt;&gt;&amp; points, int l, int r, int&amp; K) &#123; if (l &gt;= r) return; if (l &gt;= K) return; if (r &lt; K) return; // int x = rand() % (r - l + 1) + l; int x = l; int i = l, j = r; int pivot = dist(points[x]); while (i &lt; j) &#123; // why &lt;, not &lt;=? while (dist(points[i]) &lt; pivot &amp;&amp; i &lt; j) i++; while (pivot &lt; dist(points[j]) &amp;&amp; i &lt; j) j--; if (i &lt; j) swap(points[i], points[j]); &#125; partition(points, l, i - 1, K); partition(points, i + 1, r, K); &#125; public: vector&lt;vector&lt;int&gt;&gt; kClosest(vector&lt;vector&lt;int&gt;&gt;&amp; points, int K) &#123; partition(points, 0, points.size() - 1, K); return vector(points.begin(), points.begin() + K); &#125;&#125;; Leetcode Official Solution for 973. K Closest Points to Origin ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Sort","slug":"alg-Sort","permalink":"https://zhanghuimeng.github.io/tags/alg-Sort/"}]},{"title":"Codeforces 1102A. Integer Sequence Dividing，及比赛（Codeforces Round","slug":"2019-01-10-Codeforces-1102A-Integer-Sequence-Dividing，及比赛（Codeforces-Round-531-Div-3-）总结","date":"2019-01-10T00:56:36.000Z","updated":"2019-01-17T16:03:00.000Z","comments":true,"path":"post/codeforces-1102a-integer-sequence-dividing-and-contest-531-div-3-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1102a-integer-sequence-dividing-and-contest-531-div-3-summary/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1102/problem/A 提交次数：1/1 题意 将1, 2, ..., n分成两个集合，使得两个集合中的数之和的差的绝对值最小。 分析 这次做的531是div 3，题目相当之简单，我竟然都会做…… 比赛的时候的第一直觉是，n(n+1) / 2模2余0时返回0（可以分成两个相等的集合），模2余1时返回1（大概只能凑成两个差最小为1的集合）。然后就这样交上去了。 题解里给出了证明。不妨考虑n, n-1, n-2, n-3这四个数：我们总可以把n和n-3放到集合A中，把n-1和n-2放到集合B中，两边的和是一样的；以此类推，这样我们就只需考虑n mod 4的情形。n mod 4等于0或3时，可以得到相同的和；等于1或2时只能得到相差为1。[1] 另一种方法是证明，对于1, 2, ..., n，我们总能得到任意从0到n(n+1) / 2的子集和。证明方法大概很简单，可以用数学归纳法，0到n的子集和易证，再多的话，减去一些就可以了。 我总觉得之前在CF上做过这道题，而且还认真考虑过分法，但是找不到题目了，真是魔幻。。 代码 1234567891011#include &lt;iostream&gt;using namespace std;typedef long long int LL;int main() &#123; LL n; cin &gt;&gt; n; LL prod = n * (n + 1) / 2; if (prod % 2 == 0) cout &lt;&lt; 0 &lt;&lt; endl; else cout &lt;&lt; 1 &lt;&lt; endl; return 0;&#125; Codeforces Round #531 (Div. 3) Editorial ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 972. Equal Rational Numbers","slug":"2019-01-07-Leetcode-972-Equal-Rational-Numbers","date":"2019-01-07T01:14:10.000Z","updated":"2019-01-07T02:00:00.000Z","comments":true,"path":"post/leetcode-972-equal-rational-numbers/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-972-equal-rational-numbers/","excerpt":"","text":"题目来源：https://leetcode.com/problems/equal-rational-numbers/description/ 标记难度：Hard 提交次数：2/4 代码效率： 转成分数：4ms 精度hack：4ms 题意 给定两个普通小数或循环小数的字符表示，问这两个小数是否相等。 分析 比赛的时候我没做出来，准确的说法是没做完（因为期间有其他的事情）。我的思路是这样的： 记小数的三个部分分别为A，B，C：则这个小数实际上就是A.BCCCCC...。记这个小数为x，在它两侧分别乘上10^B.length和10^(B.length + C.length)，则会得到 12 10^B.length x = AB.CCCC...10^(B.length + C.length) x = ABC.CCCC... 下式减上式，得到 110^B.length (10^C.length - 1) x = ABC - AB 即 1x = (ABC - AB) / (10^B.length (10^C.length - 1)) 分别求出分子分母后化简，即可判断两个分数是否相同。 当然我知道，看到这道题的第一个思路一般是直接判断这两个数转成double之后是否相等。这样做显然可能有精度问题，不过因为题目要求中整数部分和非重复部分长度都很短，所以把重复部分多重复几次，还是有可能过的。[1] 代码 分数转换 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Solution &#123; typedef long long int LL; private: LL pow10(int i) &#123; LL x = 1; while (i--) x *= 10; return x; &#125; LL gcd(LL x, LL y) &#123; if (y == 0) return x; return gcd(y, x % y); &#125; pair&lt;LL, LL&gt; toFrac(LL A, LL lb, LL B, LL lc, LL C) &#123; if (lb == 0 &amp;&amp; lc == 0) return &#123;A, 1&#125;; if (lc == 0) return &#123;A * pow10(lb) + B, pow10(lb)&#125;; LL up, down; // 分子和分母（我懒得记它们的英文了，就分数线上下好了） LL ABC = (A * pow10(lb) + B) * pow10(lc) + C; LL AB = A * pow10(lb) + B; up = ABC - AB; down = pow10(lb) * (pow10(lc) - 1); LL g = gcd(up, down); up /= g; down /= g; return &#123;up, down&#125;; &#125; // 将小数表示分成A（整数）、B（不重复部分小数）、C（重复部分小数）三个部分 // 虽然也许用stod和substr之类的函数会更快…… void parse(string S, LL&amp; A, LL&amp; lb, LL&amp; B, LL&amp; lc, LL&amp; C) &#123; int flag = 0; A = lb = B = lc = C = 0; for (char ch: S) &#123; if (flag == 0) &#123; if ('0' &lt;= ch &amp;&amp; ch &lt;= '9') A = A * 10 + ch - '0'; else if (ch == '.') &#123; flag = 1; lb = B = 0; &#125; &#125; if (flag == 1) &#123; if ('0' &lt;= ch &amp;&amp; ch &lt;= '9') &#123; B = B * 10 + ch - '0'; lb++; &#125; else if (ch == '(')&#123; flag = 2; lc = C = 0; &#125; &#125; if (flag == 2) &#123; if ('0' &lt;= ch &amp;&amp; ch &lt;= '9') &#123; C = C * 10 + ch - '0'; lc++; &#125; &#125; &#125; &#125; public: bool isRationalEqual(string S, string T) &#123; LL A, lb, B, lc, C; parse(S, A, lb, B, lc, C); pair&lt;LL, LL&gt; p1 = toFrac(A, lb, B, lc, C); parse(T, A, lb, B, lc, C); pair&lt;LL, LL&gt; p2 = toFrac(A, lb, B, lc, C); return p1 == p2; &#125;&#125;; 精度hack 1234567891011121314151617class Solution &#123;private: double convert(string S) &#123; int i = S.find('('); if (i == -1) return stod(S); string start = S.substr(0, i); string rep = S.substr(i + 1, S.length() - i - 2); for (int j = 0; j &lt; 20; j++) start += rep; return stod(start); &#125; public: bool isRationalEqual(string S, string T) &#123; return convert(S) == convert(T); &#125;&#125;; lee215’s solution for Leetcode 972 - [C++/Python] Easy Cheat ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 971. Flip Binary Tree To Match Preorder Traversal（树）","slug":"2019-01-07-Leetcode-971-Flip-Binary-Tree-To-Match-Preorder-Traversal（树）","date":"2019-01-07T00:41:33.000Z","updated":"2019-01-07T01:12:00.000Z","comments":true,"path":"post/leetcode-971-flip-binary-tree-to-match-preorder-traversal/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-971-flip-binary-tree-to-match-preorder-traversal/","excerpt":"","text":"题目来源：https://leetcode.com/problems/flip-binary-tree-to-match-preorder-traversal/description/ 标记难度：Medium 提交次数：1/1 代码效率：12ms 题意 给定一棵二叉树（每个结点对应的值都是唯一的）和一个前序遍历序列，问，能否通过交换其中一些结点左右子树，使得这棵树的前序遍历结果和给定的相同？ 分析 既然是前序遍历，那么接下来的遍历序列中的第一个值必然需要和根结点相同，如果不等，则肯定不能实现。 接下来的问题就是要不要翻转。如果有左子结点，那么下一个值必然是左子结点的值；否则，如果有右子结点，下一个值必然是右子结点的值；否则（也就是说没有子结点），下一个值和之前的遍历相关，可能是父节点的右子结点之类的。 所以做出翻转的决策就很简单：如果左子结点有值，且这个值和遍历序列中预期的下一个值不等，那么就交换左右子树（显然不交换肯定不行了）。判断是否可行的方法也很简单，在上述翻转的基础上，每次都判断当前根结点的值和遍历序列中预期的值是否相等。 事实上，这个判断左子结点的方法是题解[1]里给出的。我比赛的时候用的是，判断是否有右子结点，如果有的话，它的值如果和预期的下一个值相等，才有可能有必要进行交换（当然也有可能根本实现不了）。这个判断本质上和上述方法是一样的。 代码 1234567891011121314151617181920212223242526272829class Solution &#123; vector&lt;int&gt; ans; int index; int n; bool pre(TreeNode* root, vector&lt;int&gt;&amp; voyage) &#123; if (root == NULL) return true; if (root-&gt;val != voyage[index]) return false; if (index == n - 1 &amp;&amp; (root-&gt;left != NULL || root-&gt;right != NULL)) return false; // cout &lt;&lt; root-&gt;val &lt;&lt; endl; if (root-&gt;left != NULL &amp;&amp; root-&gt;right != NULL &amp;&amp; voyage[index + 1] == root-&gt;right-&gt;val) &#123; swap(root-&gt;left, root-&gt;right); ans.push_back(root-&gt;val); &#125; index++; if (!pre(root-&gt;left, voyage)) return false; if (!pre(root-&gt;right, voyage)) return false; return true; &#125; public: vector&lt;int&gt; flipMatchVoyage(TreeNode* root, vector&lt;int&gt;&amp; voyage) &#123; index = 0; n = voyage.size(); bool ok = pre(root, voyage); if (!ok) return &#123;-1&#125;; return ans; &#125;&#125;; Leetcode Official Solution - 971. Flip Binary Tree To Match Preorder Traversal ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"USACO 1.6.3: Superprime Rib","slug":"2019-01-06-USACO-1-6-3-Superprime-Rib","date":"2019-01-06T20:27:39.000Z","updated":"2019-01-06T20:51:39.000Z","comments":true,"path":"post/usaco-1-6-3-superprime-rib/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-6-3-superprime-rib/","excerpt":"","text":"题意 见洛谷 P1218 [USACO1.5]特殊的质数肋骨 Superprime Rib。 定义super prime为每个前缀都是质数的数。例：7，73，733，7331都是质数，所以7331是super prime。给定N，问在所有长度为N的数里，有哪些数是super prime？ 分析 这其实是一道搜索题。先搜索出长度为N-1的所有super prime，然后在这些数后面分别加上1，3，7，9（去掉2和5的倍数），判断得到的数是否为质数，然后就得到了长度为N的super prime。super prime的总数并不多，所以直接这样搜就可以了，也没有更多需要剪枝的。 题解的方法比我还暴力。我先打了个1-10000的质数表；题解根本没管这个，直接DFS搜索树，然后对每个数暴力枚举2, 3, 5, 7, 9…是否是它的因子…… 查了一下，这个数列是有正式定义的（只不过正式定义并不叫super prime，super-prime是别的东西），叫做Right-truncatable primes，在OEIS上的编号为A024770。好像没有什么特别有趣的性质。[1] 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*ID: zhanghu15TASK: sprimeLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int N;int prime[10000];int n;bool isPrime[10000];void init() &#123; memset(isPrime, 1, sizeof(isPrime)); isPrime[1] = false; for (int i = 2; i &lt; 10000; i++) &#123; if (isPrime[i]) &#123; prime[n++] = i; for (int j = i * i; j &lt; 10000; j += i) isPrime[j] = false; &#125; &#125;&#125;bool checkIsPrime(int x) &#123; if (x &lt; 10000) return isPrime[x]; for (int i = 0; i &lt; n; i++) if (x % prime[i] == 0) return false; return true;&#125;int main() &#123; ofstream fout(\"sprime.out\"); ifstream fin(\"sprime.in\"); fin &gt;&gt; N; init(); vector&lt;int&gt; sprimes = &#123;2, 3, 5, 7&#125;; for (int i = 2; i &lt;= N; i++) &#123; vector&lt;int&gt; next; for (int x: sprimes) &#123; for (int j = 1; j &lt;= 9; j++) &#123; int y = x * 10 + j; if (checkIsPrime(y)) next.push_back(y); &#125; &#125; sprimes = next; &#125; for (int x: sprimes) fout &lt;&lt; x &lt;&lt; endl; return 0;&#125; OEIS - A024770 Right-truncatable primes: every prefix is prime. ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.6.2: Prime Palindromes","slug":"2019-01-06-USACO-1-6-2-Prime-Palindromes","date":"2019-01-06T20:26:00.000Z","updated":"2019-01-07T21:10:00.000Z","comments":true,"path":"post/usaco-1-6-2-prime-palindromes/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-6-2-prime-palindromes/","excerpt":"","text":"题意 见P1217 [USACO1.5]回文质数 Prime Palindromes。 求[a, b]（5 &lt;= a &lt; b &lt;= 100,000,000）中所有的质回文数。 分析 上次从Leetcode 906中学到的技巧是，在需要找出具有某种性质的回文数时，先生成回文数，再判断性质。这是因为生成回文数的方法实际上是很简单的，随便拿一个数，把它反过来再接到后面就行。当然，需要注意生成奇数和偶数长度两种回文数的方法。 还有就是，需要判断10^8范围内的数是否为质数时，只需要打10^4范围内的表，这是因为，10^8范围内的合数必然有10^4范围内的因子。 怎么确定上下界是一个问题。我的方法是分别计算出a和b的长度，然后只生成在相应长度范围的回文数；生成之后再判断是否在范围内。 题解里更详细地叙述了从小到大生成回文数的过程： 生成长度为1的回文数：用1..9进行翻转，重复中间字符，得到1..9 生成长度为2的回文数：用1..9进行翻转，不重复中间字符，得到11..99 生成长度为3的回文数：用10..99进行翻转，重复中间字符，得到101...999 生成长度为4的回文数：用10..99进行翻转，不重复中间字符，得到1001...9999 由于回文数一共也只有10000个左右，直接全生成出来再判断是否在[a, b]范围内也可以。 另一个观察是，任何长度为偶数的回文数都是11的倍数，所以可以不管除了11之外的所有长度为偶数的回文数。[1] 质回文数也是一个被正式定义了的序列。[2] 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/*ID: zhanghu15TASK: pprimeLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;typedef long long int LL;int prime[10000];int n;bool isPrime[10000];void init() &#123; memset(isPrime, 1, sizeof(isPrime)); isPrime[1] = false; for (int i = 2; i &lt; 10000; i++) &#123; if (isPrime[i]) &#123; prime[n++] = i; for (int j = i * i; j &lt; 10000; j += i) isPrime[j] = false; &#125; &#125;&#125;bool checkIsPrime(LL x) &#123; if (x &lt; 10000) return isPrime[x]; for (int i = 0; i &lt; n; i++) &#123; if (x % prime[i] == 0) return false; &#125; return true;&#125;LL getPalindrome(LL x, int isOdd) &#123; LL l = 0, d[10], y = x; while (y &gt; 0) &#123; d[l++] = y % 10; y /= 10; &#125; for (int i = isOdd; i &lt; l; i++) x = x*10 + d[i]; return x;&#125;int getLen(LL x) &#123; int l = 0; while (x &gt; 0) &#123; l++; x /= 10; &#125; return l;&#125;int pow10[10] = &#123;1, 10, (int) 1e2, (int) 1e3, (int) 1e4, (int) 1e5, (int) 1e6, (int) 1e7, (int) 1e8, (int) 1e9&#125;;int main() &#123; ofstream fout(\"pprime.out\"); ifstream fin(\"pprime.in\"); int a, b; fin &gt;&gt; a &gt;&gt; b; // 算出[1, 10000]范围内所有的质数 init(); // 枚举奇数和偶数长度的回文数（注意long long int） int len1 = getLen(a) / 2, len2 = ceil(getLen(b) / 2.0); for (int l = len1; l &lt;= len2; l++) &#123; for (LL i = pow10[l]; i &lt; pow10[l+1]; i++) &#123; LL x = getPalindrome(i, 1); if (a &lt;= x &amp;&amp; x &lt;= b &amp;&amp; checkIsPrime(x)) fout &lt;&lt; x &lt;&lt; endl; &#125; for (LL i = pow10[l]; i &lt; pow10[l+1]; i++) &#123; LL x = getPalindrome(i, 0); if (a &lt;= x &amp;&amp; x &lt;= b &amp;&amp; checkIsPrime(x)) fout &lt;&lt; x &lt;&lt; endl; &#125; &#125; return 0;&#125; stackexchange - Proving a palindromic integer with an even number of digits is divisible by 11 ↩︎ OEIS - A002385 Palindromic primes: prime numbers whose decimal expansion is a palindrome. ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.6.1: Number Triangles","slug":"2019-01-06-USACO-1-6-1-Number-Triangles","date":"2019-01-06T20:25:07.000Z","updated":"2019-01-07T20:28:00.000Z","comments":true,"path":"post/usaco-1-6-1-number-triangles/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-6-1-number-triangles/","excerpt":"","text":"题意 见P1216 [IOI1999][USACO1.5]数字三角形 Number Triangles。 给定一个数字三角形，问从顶到底最大的路径和。 分析 非常简单的DP。对于每个点，判断从上左方走过来还是从上右方走过来和最大即可。上次从Leetcode 931中学到一点，对于这样的题，可以不新开一个数组，直接在输入数组上DP。 自底向上做当然也可以，就是有点怪异…… 代码 12345678910111213141516171819202122232425262728293031/*ID: zhanghu15TASK: numtriLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int tri[1001][1001];int main() &#123; ofstream fout(\"numtri.out\"); ifstream fin(\"numtri.in\"); int R; fin &gt;&gt; R; int ans = -1; for (int i = 1; i &lt;= R; i++) &#123; for (int j = 1; j &lt;= i; j++) &#123; fin &gt;&gt; tri[i][j]; tri[i][j] += max(tri[i-1][j], tri[i-1][j-1]); if (i == R) ans = max(ans, tri[i][j]); &#125; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 970. Powerful Integers","slug":"2019-01-06-Leetcode-970-Powerful-Integers","date":"2019-01-06T19:37:46.000Z","updated":"2019-01-07T00:40:00.000Z","comments":true,"path":"post/leetcode-970-powerful-integers/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-970-powerful-integers/","excerpt":"","text":"题目来源：https://leetcode.com/problems/powerful-integers/description/ 标记难度：Medium 提交次数：1/1 代码效率：4ms 题意 给定正整数x和y（1 &lt;= x, y &lt;= 100），求所有在[1, bound]（0 &lt;= bound &lt;= 10^6）范围内的x^i + y^j，要求去重。 分析 去掉x或y为1的情况，由于log(1000000) / log(2) = 19，所以可以直接枚举所有x和y的幂和，然后去重。总的来说很简单。 代码 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: vector&lt;int&gt; powerfulIntegers(int x, int y, int bound) &#123; if (x &gt; y) swap(x, y); if (x == 1 &amp;&amp; y == 1) &#123; if (bound &gt;= 2) return &#123;2&#125;; else return &#123;&#125;; &#125; if (x == 1) &#123; vector&lt;int&gt; ans; int yj = 1; for (int j = 0; yj &lt;= bound; j++) &#123; int t = yj + 1; if (t &lt;= bound) ans.push_back(t); &#125; return ans; &#125; unordered_set&lt;int&gt; numbers; vector&lt;int&gt; ans; int xi = 1; for (int i = 0; xi &lt;= bound; i++) &#123; int yj = 1; for (int j = 0; yj &lt;= bound; j++) &#123; int t = xi + yj; if (t &lt;= bound &amp;&amp; numbers.find(t) == numbers.end()) &#123; numbers.insert(t); ans.push_back(t); &#125; yj *= y; &#125; xi *= x; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 969. Pancake Sorting（排序）","slug":"2019-01-06-Leetcode-969-Pancake-Sorting（排序）","date":"2019-01-06T19:00:07.000Z","updated":"2019-01-06T19:35:00.000Z","comments":true,"path":"post/leetcode-969-pancake-sorting/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-969-pancake-sorting/","excerpt":"","text":"题目来源：https://leetcode.com/problems/pancake-sorting/description/ 标记难度：Medium 提交次数：1/1 代码效率：8ms 题意 给定一个数组A（其中的元素是[1, 2, ..., A.length]的排列），定义pancake flip操作为翻转A中前k个数，其中k &lt;= A.length。要求通过最多10 * A.length词操作将A排序。求操作序列。 分析 比赛的时候我的想法很简单：因为每次操作影响的只有前k个数，所以不妨考虑先排好A中靠后的数，这样之后的操作就不会影响它们。于是就可以得到一个很显然的思路：需要把i放到i位置时，就找到i，先通过一次操作把它flip到数组开头，再通过一次操作把它flip到i位置。这样，操作次数最多为2 * A.length，符合要求。 以序列[3, 1, 5, 2, 4]为例： 将5放到第5位： flip 3：[5, 1, 3, 2, 4] flip 5：[4, 2, 3, 1, 5] 将4放到第4位： flip 1（不需要） flip 4：[1, 3, 2, 4, 5] 将3放到第3位： flip 2：[3, 1, 2, 4, 5] flip 3：[2, 1, 3, 4, 5] 将2放到第2位： flip 1（不需要） flip 2：[1, 2, 3, 4, 5] 将1放到第1位（已经在第1位了） 这是一种非常straightforward的方法，题解也是这么做的。 而且显然上述方法已经说明，flip操作能够将任意排列变换成其他任意排列。 我的问题是： 直接模拟的复杂度为O(N^2)（因为每次翻转操作的复杂度是O(N)），能否降低复杂度？ 这样得到的是否为最优解？ 第二个问题的答案是，显然不是，这种做法只是给出了一个上界（至多2*N - 3次翻转必然可以完成排序，至于为什么少了3次，请考虑只剩1和2时的情形）。而且找到最优解是一个NP-难问题。那么我就不再耗费我可怜的脑细胞在这个问题上了。顺便一提，比尔·盖茨证明了这个问题的上界是5(N+5) / 3；目前最优的结果是18N / 11。[1] 经过一些思考和查找资料，我认为我目前无法回答第一个问题。 代码 1234567891011121314151617181920212223class Solution &#123;private: vector&lt;int&gt; ans; void flip(int k, vector&lt;int&gt;&amp; A) &#123; for (int i = 0; i &lt; k - i - 1; i++) swap(A[i], A[k - i - 1]); ans.push_back(k); &#125; public: vector&lt;int&gt; pancakeSort(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); for (int i = n; i &gt;= 1; i--) &#123; // put i on place i int index = 0; while (A[index] != i &amp;&amp; index &lt; n) index++; if (index == i - 1) continue; flip(index + 1, A); flip(i, A); &#125; return ans; &#125;&#125;; 原来Pancake Sorting这个名字并不是乱起的！wikipedia - Pancake sorting ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Sort","slug":"alg-Sort","permalink":"https://zhanghuimeng.github.io/tags/alg-Sort/"}]},{"title":"Leetcode 968. Binary Tree Cameras（DP）","slug":"2018-12-31-Leetcode-968-Binary-Tree-Cameras（DP）","date":"2018-12-31T15:47:19.000Z","updated":"2018-12-31T17:00:00.000Z","comments":true,"path":"post/leetcode-968-binary-tree-cameras/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-968-binary-tree-cameras/","excerpt":"","text":"题目来源：https://leetcode.com/problems/numbers-with-same-consecutive-differences/description/ 标记难度：Hard 提交次数：2/5 代码效率： DP：12ms（100.00%） 贪心：12ms（100.00%） 题意 给定一棵二叉树，要求在上面一些结点上放照相机（照相机可以覆盖结点自己、它的父结点和子结点），使得所有的结点都被覆盖，且被放照相机的结点总数最少。 分析 比赛的时候我认为这是一道树状DP，但是太困了写不动了。但是我还是相信自己是对的，并且在比赛之后成功写了出来，并且写对了。结果看了看题解，大家都在用贪心，有种恍如隔世的感觉…… 贪心法 令状态0表示该结点还没有被cover，1表示该结点上有一个照相机，2表示该结点上没有照相机但是已经被cover了。（前提：这个结点对应的子树除了它自己以外已经全都被cover了。） 令叶结点的状态为0；对于一个结点，如果它的至少一个子结点状态为0，则它的状态为1；如果它的子结点状态均不为0，且至少一个子结点状态为1，则它的状态为2；否则它的状态为0。状态为1时照相机计数+1。 注意边界条件（如果根节点的状态为0，则需要多加一个照相机）。[1] 我实在想不通怎么证明这个解法的正确性（虽然我觉得它确实很有道理）。 DP 我这个方法听起来就比较冗杂（但是我认为很好理解）。令f[node]表示覆盖完node对应的子树所需的最少照相机数，则 12345678f[node] = min( // node上放照相机，node.left和node.right上可以放，也可以不放 min(f[node.left], f[node.left.left] + f[node.left.right]) + min(f[node.right], f[node.right.left] + f[node.right.right]), // node.left上放照相机，node.left.left和node.left.right上可以放，也可以不放 min(f[node.left.left], f[node.left.left.left] + f[node.left.left.right]) + min(f[node.left.right], f[node.left.right.left] + f[node.left.right.right]) + 1 + f[node.right], // node.right上放照相机，node.right.left和node.right.right上可以放，也可以不放 min(f[node.right.left], f[node.right.left.left] + f[node.right.left.right]) + min(f[node.right.right], f[node.right.right.left] + f[node.right.right.right]) + 1 + f[node.left]); 显然为了覆盖到子树的根结点，只需要考虑它自己上面放照相机，它的左子结点放照相机和右子结点放照相机三种情况就够了。 代码 贪心法 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;private: int ans = 0; // 0 = not covered // 1 = has camera // 2 = covered by camera (no camera) int dfs(TreeNode* root) &#123; if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) return 0; int needCamera = 0; int covered = 0; if (root-&gt;left != NULL) &#123; int state = dfs(root-&gt;left); if (state == 0) needCamera = 1; if (state == 1) covered = 1; &#125; if (root-&gt;right != NULL) &#123; int state = dfs(root-&gt;right); if (state == 0) needCamera = 1; if (state == 1) covered = 1; &#125; if (needCamera) &#123; ans++; return 1; &#125; if (covered) return 2; return 0; &#125; public: int minCameraCover(TreeNode* root) &#123; int state = dfs(root); if (state == 0) ans++; return ans; &#125;&#125;; DP法 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;private: int getF(TreeNode* root) &#123; return root == NULL ? 0 : root-&gt;val; &#125; void dfs(TreeNode* root) &#123; if (root == NULL) return; dfs(root-&gt;left); dfs(root-&gt;right); if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; root-&gt;val = 1; return; &#125; root-&gt;val = 1e9; // put on root TreeNode* l = root-&gt;left; TreeNode* r = root-&gt;right; TreeNode* ll = l == NULL ? NULL : l-&gt;left; TreeNode* lr = l == NULL ? NULL : l-&gt;right; TreeNode* rl = r == NULL ? NULL : r-&gt;left; TreeNode* rr = r == NULL ? NULL : r-&gt;right; root-&gt;val = min(min(getF(l), getF(ll) + getF(lr)) + min(getF(r), getF(rl) + getF(rr)) + 1, root-&gt;val); // 也要考虑到不完全覆盖的情况！ // put on left TreeNode* lll = ll == NULL ? NULL : ll-&gt;left; TreeNode *llr = ll == NULL ? NULL : ll-&gt;right; TreeNode* lrl = lr == NULL ? NULL : lr-&gt;left; TreeNode *lrr = lr == NULL ? NULL : lr-&gt;right; root-&gt;val = min(min(getF(ll), getF(lll) + getF(llr)) + min(getF(lr), getF(lrl) + getF(lrr)) + 1 + getF(r), root-&gt;val); // put on right TreeNode* rll = rl == NULL ? NULL : rl-&gt;left; TreeNode* rlr = rl == NULL ? NULL : rl-&gt;right; TreeNode* rrl = rr == NULL ? NULL : rr-&gt;left; TreeNode* rrr = rr == NULL ? NULL : rr-&gt;right; root-&gt;val = min(min(getF(rl), getF(rll) + getF(rlr)) + min(getF(rr), getF(rrl) + getF(rrr)) + 1 + getF(l), root-&gt;val); &#125; public: int minCameraCover(TreeNode* root) &#123; dfs(root); return root-&gt;val; &#125;&#125;; lee215’s solution for Leetcode 968 - [Java/C++/Python] Greedy DFS ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 967. Numbers With Same Consecutive Differences","slug":"2018-12-31-Leetcode-967-Numbers-With-Same-Consecutive-Differences","date":"2018-12-31T14:55:39.000Z","updated":"2018-12-31T15:09:00.000Z","comments":true,"path":"post/leetcode-967-numbers-with-same-consecutive-differences/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-967-numbers-with-same-consecutive-differences/","excerpt":"","text":"题目来源：https://leetcode.com/problems/numbers-with-same-consecutive-differences/description/ 标记难度：Medium 提交次数：1/3 代码效率：8ms（100.00%） 题意 找出所有长度为N的数字，它们连续两位的差的绝对值都是K。数字不应含有前导零。 分析 这道题很显然很简单……首先是初始条件：{1, 2, 3, ..., 9}。然后枚举N-1次，每次都对集合中现有的元素尝试在后面加上新的一位，满足它和前一位的差的绝对值是K。 我中间写挂了一次是因为忘了去重了！如果K=0，当前数字的最后一位是d，则很显然可能存在d+0=d-0的情况。这是一个很好的边界条件…… 以及我没看出来这道题有什么DP的影子……如果加长N并且只问总数还差不多。 代码 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; numsSameConsecDiff(int N, int K) &#123; if (N == 1) return &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; vector&lt;int&gt; a = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; for (int i = 1; i &lt; N; i++) &#123; vector&lt;int&gt; b; int M = a.size(); for (int j = 0; j &lt; M; j++) &#123; int x = a[j]; int d = x % 10; if (d + K &lt;= 9) b.push_back(x * 10 + d + K); // Note: if K == 0, then we need to deduplicate... if (d - K &gt;= 0 &amp;&amp; d + K != d - K) b.push_back(x * 10 + d - K); &#125; a = b; &#125; return a; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 966. Vowel Spellchecker（字符串）","slug":"2018-12-31-Leetcode-966-Vowel-Spellchecker（字符串）","date":"2018-12-31T14:21:11.000Z","updated":"2018-12-31T14:37:00.000Z","comments":true,"path":"post/leetcode-966-vowel-spellchecker/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-966-vowel-spellchecker/","excerpt":"","text":"题目来源：https://leetcode.com/problems/univalued-binary-tree/description/ 标记难度：Medium 提交次数：1/2 代码效率：112ms（40.00%） 题意 给定一个wordlist，其中包含了若干个单词（只包含英文字母的字符串），给定一系列query，要求从wordlist中找出匹配单词： 如果wordlist中包含单词与该query相同，则直接返回query 如果在不考虑大小写的情况下，wordlist中包含单词与该query相同（例：&quot;AbC&quot;和&quot;aBc&quot;是相同的），则返回第一个匹配单词 如果在不考虑大小写和将所有元音字母认为是同一个字母的情况下，wordlist中包含单词与该query相同（例：&quot;Aab&quot;与&quot;eIb&quot;是相同的），则返回第一个匹配单词 分析 首先一个事实是，O(N*M)（N = wordlist.size()，M = queries.size()）的算法是过不了的，因为N, M &lt;= 5000。那么显然就要用到哈希表了。 首先用一个set&lt;string&gt; exact存储原来的单词 然后用一个map&lt;string, int&gt; lower存储每个单词的lowercase版本到它的索引，如果一个lowercase版本对应多个单词，则只存储第一个出现的单词的索引 然后用一个map&lt;string, int&gt; vowel存储每个单词的lowercase且把所有元音都替换成&quot;a&quot;的版本到它的索引，如果一个替换后的版本对应多个单词，则只存储第一个出现的单词的索引 最后，对于每一个query，分别在这三个结构里查找，如果查到则立刻返回，否则最后返回&quot;&quot; 总的来说也不是很难。我WA了一次，主要是因为没看清，替换元音字母的同时也要替换大小写…… 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123;private: string toLower(string x) &#123; string l; for (char ch: x) l += 'A' &lt;= ch &amp;&amp; ch &lt;= 'Z' ? ch - 'A' + 'a' : ch; return l; &#125; string toVowel(string x) &#123; string v; for (char ch: x) v += ch == 'e' || ch == 'i' || ch == 'o' || ch == 'u' ? 'a' : ch; return v; &#125; public: vector&lt;string&gt; spellchecker(vector&lt;string&gt;&amp; wordlist, vector&lt;string&gt;&amp; queries) &#123; set&lt;string&gt; exact; map&lt;string, int&gt; lower; map&lt;string, int&gt; vowel; for (int i = 0; i &lt; wordlist.size(); i++) &#123; exact.insert(wordlist[i]); string l = toLower(wordlist[i]); if (lower.find(l) == lower.end()) lower[l] = i; string v = toVowel(l); if (vowel.find(v) == vowel.end()) vowel[v] = i; &#125; vector&lt;string&gt; ans; for (string x: queries) &#123; string l = toLower(x); string v = toVowel(l); if (exact.find(x) != exact.end()) ans.push_back(x); else if (lower.find(l) != lower.end()) ans.push_back(wordlist[lower[l]]); else if (vowel.find(v) != vowel.end()) ans.push_back(wordlist[vowel[v]]); else ans.push_back(\"\"); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 965. Univalued Binary Tree（树）","slug":"2018-12-31-Leetcode-965-Univalued-Binary-Tree（树）","date":"2018-12-31T02:27:41.000Z","updated":"2018-12-31T14:17:00.000Z","comments":true,"path":"post/leetcode-965-univalued-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-965-univalued-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/univalued-binary-tree/description/ 标记难度：Easy 提交次数：1/1 代码效率：4ms（100.00%） 题意 判断一棵二叉树中结点的值是否都相同。 分析 直接DFS判断即可。用其他遍历方法当然也行。总之是道很简单的题。 代码 1234567891011121314151617class Solution &#123;private: int univalue; bool dfs(TreeNode* root) &#123; if (root == NULL) return true; if (root-&gt;val != univalue) return false; return dfs(root-&gt;left) &amp;&amp; dfs(root-&gt;right); &#125; public: bool isUnivalTree(TreeNode* root) &#123; univalue = root-&gt;val; return dfs(root); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 326. Power of Three（数学）","slug":"2018-12-27-Leetcode-326-Power-of-Three","date":"2018-12-28T01:13:46.000Z","updated":"2018-12-28T20:00:00.000Z","comments":true,"path":"post/leetcode-326-power-of-three/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-326-power-of-three/","excerpt":"","text":"题目来源：https://leetcode.com/problems/least-operators-to-express-number/ 标记难度：Easy 提交次数：4/4 代码效率： 模3法：84ms（19.17%） 算log法：88ms（13.78%） 打表法：80ms（30.44%） 除法：84ms（19.38%） 题意 给定一个整数，判断它是否是3的幂。 追加：可以不用循环和递归吗？ 分析 这可能确实是个水题，但是看到解法的数量[1]和testcase的数量时，我改变了想法。还是有值得一写的东西的。 最简单的想法就是把这个数不断除3，直到只剩1（是3的幂）或者除不尽（不是3的幂）为止。复杂度为O(log(N))。 上述想法的一个升级版是，不妨直接计算出log(N)/log(3)，然后判断结果是否为整数。显然需要考虑到运算精度的问题。我感觉可能专门有一些testcase是考察精度取多小的，最后我发现1e-10是比较合理的。事实上int范围内的3的幂最大是1162261467，而log(1162261467)/log(3) - log(1162261467 - 1)/log(3) = 7.83e-10，log(1162261467 + 1)/log(3) - log(1162261467)/log(3) = 7.83e-10，能判断出这么小的精度就够了。 这不禁会让人想到打表这种方法，毕竟int范围内的3的幂一共也没几个，从1到1162261467（3^19）。 除了打表之外，还有一种更简单的方法。直接用1162261467去除N，能除尽就是3的幂，除不尽就不是……真是简单粗暴。 代码 模3法 1234567891011class Solution &#123;public: bool isPowerOfThree(int n) &#123; if (n &lt;= 0) return false; while (n &gt; 1) &#123; if (n % 3 != 0) return false; n /= 3; &#125; return true; &#125;&#125;; 算log法 123456789class Solution &#123;public: bool isPowerOfThree(int n) &#123; if (n &lt;= 0) return false; double pow = log(n) / log(3); // cout &lt;&lt; pow - floor(pow) &lt;&lt; ' ' &lt;&lt; ceil(pow) - pow &lt;&lt; endl; return pow - floor(pow) &lt;= 1e-10 || ceil(pow) - pow &lt;= 1e-10; &#125;&#125;; 神奇的方法 非常简洁…… 123456class Solution &#123;public: bool isPowerOfThree(int n) &#123; return !(n &lt;= 0) &amp;&amp; 1162261467 % n == 0; &#125;&#125;; LeetCode Official Solution - 326. Power of Three ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 964. Least Operators to Express Number","slug":"2018-12-23-Leetcode-964-Least-Operators-to-Express-Number","date":"2018-12-23T19:33:23.000Z","updated":"2018-12-27T21:24:00.000Z","comments":true,"path":"post/leetcode-964-least-operators-to-express-number/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-964-least-operators-to-express-number/","excerpt":"","text":"题目来源：https://leetcode.com/problems/least-operators-to-express-number/ 标记难度：Hard 提交次数：1/3 代码效率：93.04% 题意 给定正整数x，要求用x和运算符+-*/组成表达式，表达式值为target，问最少使用多少个运算符。 其中： /返回的是有理数 没有括号 优先级和平时相同 不允许使用单目运算符- 分析 比赛的时候看到这题，我感到非常懵逼。随便想了一下，大概只想到，这道题大概是要求a[0] + a[1]*x + a[2]*x^2 + ... = target。如果先不管运算符的数量，第一个问题是怎么把target拼出来。考虑到可以使用m/m=1，target肯定可以拼出来，问题是怎么拼比较好。我没有多认真想，比赛就完了。 事后发现似乎需要用到类似于记忆化搜索的方法。 这道题在本质上非常类似于进制表示： target=a0+a1x+a2x2+⋯target = a_0 + a_1 x + a_2 x^2 + \\cdots target=a0​+a1​x+a2​x2+⋯ 但是很大的一个区别在于，它对系数（理论上）没有限制，也因此对xxx的最大幂次没有限制（因为系数可以是负的）。而且我们的目标是最小化代价。容易推断出，生成一个xxx的幂次的代价为（包含前面的+/-运算符）： $$ cost(x^e) = \\begin{cases} 2 & e = 0\\\\ e & e \\ge 1 \\end{cases} $$ 显然，如果要生成一个aexea_e x^eae​xe，最优的选择是都采用+或者都采用-运算符（因为同时用显然是浪费）。 因此整体的代价可以表示为 cost=2⋅abs(a0)+2⋅abs(a1)+3⋅abs(a2)+⋯cost = 2 \\cdot abs(a_0) + 2 \\cdot abs(a_1) + 3\\cdot abs(a_2) + \\cdots cost=2⋅abs(a0​)+2⋅abs(a1​)+3⋅abs(a2​)+⋯ 不妨首先把targettargettarget表示成普通的xxx进制的形式： target=b0+b1x+b2x2+⋯+bnxn, 0≤bi&lt;xtarget = b_0 + b_1 x + b_2 x^2 + \\cdots + b_n x^n, \\, 0 \\le b_i &lt; x target=b0​+b1​x+b2​x2+⋯+bn​xn,0≤bi​&lt;x 可以认为aia_iai​是在bib_ibi​的基础上得到的，例如： target=(b0−x+x2)+(b1+1)x+(b2−1)x2+⋯target = (b_0 - x + x^2) + (b_1+1)x + (b_2-1) x^2 + \\cdots target=(b0​−x+x2)+(b1​+1)x+(b2​−1)x2+⋯ 这个式子看起来好像借位，不过比实际中的借位要自由，因为现实的进制中不会出现b0b_0b0​这一位向b2b_2b2​借位的情况。 此时有a0=b0−x+x2, a1=b1+1, a2=b2−1a_0 = b_0 - x + x^2, \\, a_1 = b_1 + 1, \\, a_2 = b_2 - 1a0​=b0​−x+x2,a1​=b1​+1,a2​=b2​−1。显然此时整体的代价也变化了： cost=2b0+2b1+3b2+⋯cost = 2b_0 + 2b_1 + 3b_2 + \\cdots cost=2b0​+2b1​+3b2​+⋯ cost′=2⋅∣b0−x+x2∣+2⋅∣b1+1∣+3⋅∣b2−1∣+⋯cost&#x27; = 2\\cdot |b_0 - x + x^2| + 2 \\cdot |b_1 + 1| + 3 \\cdot |b_2 - 1| + \\cdots cost′=2⋅∣b0​−x+x2∣+2⋅∣b1​+1∣+3⋅∣b2​−1∣+⋯ 显然我们希望整体代价最小。考虑到x&gt;=2x &gt;= 2x&gt;=2，显然可以得出这样一个结论：从比前一位更往前的位借位是不值得的，而且一定是借一个负位。原因很简单：假定bib_ibi​从bjb_jbj​借了kkk位（j≥i+2j \\geq i+2j≥i+2），则这两位的cost之和从∣bi∣(i+1)+∣bj∣(j+1)|b_i| (i+1) + |b_j|(j + 1)∣bi​∣(i+1)+∣bj​∣(j+1)变成了∣bi+kxj−i∣(i+1)+∣bj−k∣(j+1)|b_i + k x^{j-i}| (i+1) + |b_j-k|(j + 1)∣bi​+kxj−i∣(i+1)+∣bj​−k∣(j+1)。通过各种分类讨论可以发现，这个cost不可能减小。（懒得去讨论了……） 所以可以用递推的方法来考虑这个问题：令 $$ \\begin{aligned} f[i][0] =& \\min{cost(a_0 + a_1 x + a_2 x^2 + \\cdots + a_i x^i)} \\\\ f[i][1] =& \\min{cost(a_0 + a_1 x + a_2 x^2 + \\cdots + (a_i - x) x^i)} \\end{aligned} $$ 也就是说f[i][1]f[i][1]f[i][1]是借了一个负位之后最小可能的表示的代价。则 $$ \\begin{aligned} f[i+1][0] =& \\min{cost(a_0 + a_1 x + a_2 x^2 + \\cdots + a_i x^i + a_{i+1} x^{i+1})} \\\\ =& \\min cost(a_0 + a_1 x + a_2 x^2 + \\cdots + a_i x^i) + cost(a_{i+1}x^{i+1}), \\\\ & cost(a_0 + a_1 x + a_2 x^2 + \\cdots + (a_i - x) x^i) + cost((a_{i+1} + 1)x^{i+1}) \\\\ =& \\min{f[i][0] + a_{i+1}(i+1), \\, f[i][1] + (a_{i+1} + 1)(i + 1)} \\end{aligned} $$ 同理： $$f[i+1][1] = \\min{f[i][0] + |a[i+1] - x|(i+1), \\, f[i][1] + |a[i+1] - x + 1| (i + 1)}$$ 然后就可以递推了，时间复杂度为O(log(N))。 从借位的想法translate到递推还是不太容易啊…… 代码 我也不知道我怎么会开大小到1000的数组的…… 以及，考虑到有借位的可能，需要递推到f[n]，而不是f[n-1]。 1234567891011121314151617181920class Solution &#123;public: int leastOpsExpressTarget(int x, int target) &#123; int a[1000], n = 0; memset(a, 0, sizeof(a)); int t = target; while (t &gt; 0) &#123; a[n++] = t % x; t /= x; &#125; int f[1000][2]; f[0][0] = 2 * a[0]; f[0][1] = 2 * abs(a[0] - x); for (int i = 1; i &lt;= n; i++) &#123; f[i][0] = min(f[i-1][0] + a[i] * i, f[i-1][1] + (a[i] + 1) * i); f[i][1] = min(f[i-1][0] + abs(a[i] - x) * i, f[i-1][1] + abs(a[i] - x + 1) * i); &#125; return f[n][0] - 1; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 963. Minimum Area Rectangle II","slug":"2018-12-23-Leetcode-963-Minimum-Area-Rectangle-II","date":"2018-12-23T19:17:41.000Z","updated":"2018-12-27T03:20:00.000Z","comments":true,"path":"post/leetcode-963-minimum-area-rectangle-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-963-minimum-area-rectangle-ii/","excerpt":"","text":"题目来源： 标记难度：Medium 提交次数：3/7 代码效率： hash向量：120ms 枚举三个点：32ms 枚举圆心和半径：24ms（87.12%） 题意 给定平面上若干个（&lt;=400个）整点，问能够组成的面积最小的矩形的面积是多少。 分析 我的做法听起来有点奇怪：用O(N^2)的时间把每两个点组成的向量算出来，然后对于相同的向量（也就是说它们对应的4个点可以组成平行四边形），判断对应的4个点能否组成矩形。我感觉时间复杂度大概是O(N^3)，加上map应该算是O(log(N))。考试后我才开始思考，这道题和之前的Leetcode 939. Minimum Area Rectangle好像没什么区别，为什么我没有用那种直接O(N^3)枚举三个点，再直接算出第四个点的方法呢…… 以及，这道题我好像因为不存在矩形时输出0和叉积结果有可能为负数错了好几次…… 比较简单的一种方法： 枚举矩形的三个点（注意顺序），判断组成的两条边是否相互垂直 用哈希表查第四个点是否存在，如果存在则计算面积 这种方法是O(N^3)的。 另一种时间复杂度更小的方法是，枚举每两个点连线中点和长度，然后检查所有中点和长度相同的点对能否组成矩形。据说每种点对的数量是O(log(N))的，所以我感觉这种方法的复杂度应该是O(N^2*log(N)^2)？也可能我想错了。 这个方法调了我几个小时，核心在于两点，一是我居然把Point的构造函数写成int的了然后忘掉了，以为自己用的是double；二是傻逼了，忘记矩形的对角线不垂直了……（你在想什么） 也是好久没正经写过计算几何的题了……（说得就好像你正经写过一样） 代码 奇怪的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Solution &#123;private: struct Point &#123; int x, y; Point(int _x, int _y) &#123; x = _x; y = _y; &#125; friend bool operator &lt; (const Point&amp; p1, const Point&amp; p2) &#123; if (p1.x != p2.x) return p1.x &lt; p2.x; return p1.y &lt; p2.y; &#125; friend bool operator == (const Point&amp; p1, const Point&amp; p2) &#123; return p1.x == p2.x &amp;&amp; p1.y == p2.y; &#125; friend Point operator - (const Point&amp; p1, const Point&amp; p2) &#123; return Point(p1.x - p2.x, p1.y - p2.y); &#125; friend int cross(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.y - p2.x * p1.y; &#125; friend int dot(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.x + p1.y * p2.y; &#125; void print() &#123; cout &lt;&lt; '(' &lt;&lt; x &lt;&lt; ',' &lt;&lt; y &lt;&lt; ')'; &#125; &#125;; typedef Point Vector; public: double minAreaFreeRect(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; vector&lt;Point&gt; a; int N = points.size(); for (int i = 0; i &lt; N; i++) &#123; a.emplace_back(points[i][0], points[i][1]); &#125; sort(a.begin(), a.end()); int ans = 0; map&lt;Vector, vector&lt;int&gt;&gt; vmap; for (int i = 0; i &lt; N; i++) &#123; for (int j = i + 1; j &lt; N; j++) &#123; Vector v = a[j] - a[i]; for (int k: vmap[v]) &#123; // a[i].print(); a[j].print(); a[k].print(); cout &lt;&lt; endl; Vector v2 = a[k] - a[i]; if (dot(v, v2) != 0) continue; int area = cross(v, v2); if (area &lt;= 0) continue; ans = ans == 0 ? area : min(ans, area); &#125; vmap[v].push_back(i); &#125; &#125; return ans; &#125;&#125;; 枚举三个点的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Solution &#123;private: struct Point &#123; int x, y; Point(int _x, int _y) &#123; x = _x; y = _y; &#125; friend bool operator &lt; (const Point&amp; p1, const Point&amp; p2) &#123; if (p1.x != p2.x) return p1.x &lt; p2.x; return p1.y &lt; p2.y; &#125; friend bool operator == (const Point&amp; p1, const Point&amp; p2) &#123; return p1.x == p2.x &amp;&amp; p1.y == p2.y; &#125; friend Point operator + (const Point&amp; p1, const Point&amp; p2) &#123; return Point(p1.x + p2.x, p1.y + p2.y); &#125; friend Point operator - (const Point&amp; p1, const Point&amp; p2) &#123; return Point(p1.x - p2.x, p1.y - p2.y); &#125; friend int cross(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.y - p2.x * p1.y; &#125; friend int dot(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.x + p1.y * p2.y; &#125; &#125;; public: double minAreaFreeRect(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; set&lt;Point&gt; s; // 不能用unordered_set…… vector&lt;Point&gt; p; int N = points.size(); for (int i = 0; i &lt; N; i++) &#123; p.emplace_back(points[i][0], points[i][1]); s.insert(p.back()); &#125; int ans = -1; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) &#123; if (i == j) continue; for (int k = 0; k &lt; N; k++) &#123; if (i == k || j == k) continue; if (dot(p[i] - p[j], p[k] - p[j]) != 0) continue; Point p4 = p[k] + p[i] - p[j]; if (s.find(p4) != s.end()) &#123; int area = abs(cross(p[i] - p[j], p[k] - p[j])); ans = ans == -1 ? area : min(ans, area); &#125; &#125; &#125; return ans == -1 ? 0 : ans; &#125;&#125;; 枚举圆心和半径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class Solution &#123;private: struct Point &#123; double x, y; Point(double _x, double _y) &#123; x = _x; y = _y; &#125; friend bool operator &lt; (const Point&amp; p1, const Point&amp; p2) &#123; if (abs(p1.x - p2.x) &gt; 1e-6) return p1.x &lt; p2.x; return p1.y &lt; p2.y; &#125; friend bool operator == (const Point&amp; p1, const Point&amp; p2) &#123; return abs(p1.x - p2.x) &lt;= 1e-6 &amp;&amp; abs(p1.y - p2.y) &lt;= 1e-6; &#125; friend Point operator + (const Point&amp; p1, const Point&amp; p2) &#123; return Point(p1.x + p2.x, p1.y + p2.y); &#125; friend Point operator - (const Point&amp; p1, const Point&amp; p2) &#123; return Point(p1.x - p2.x, p1.y - p2.y); &#125; friend Point operator / (const Point&amp; p1, const double&amp; a) &#123; return Point(p1.x / a, p1.y / a); &#125; friend double cross(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.y - p2.x * p1.y; &#125; friend double dot(const Point&amp; p1, const Point&amp; p2) &#123; return p1.x * p2.x + p1.y * p2.y; &#125; double length2() &#123; return x * x + y * y; &#125; void print() &#123; cout &lt;&lt; '(' &lt;&lt; x &lt;&lt; ',' &lt;&lt; y &lt;&lt; ')'; &#125; &#125;; typedef Point Vector; public: double minAreaFreeRect(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; map&lt;pair&lt;Point, int&gt;, vector&lt;int&gt;&gt; mmap; vector&lt;Point&gt; p; int N = points.size(); for (int i = 0; i &lt; N; i++) p.emplace_back(points[i][0], points[i][1]); sort(p.begin(), p.end()); for (int i = 0; i &lt; N; i++) for (int j = i + 1; j &lt; N; j++) &#123; Vector v = p[j] - p[i]; mmap[make_pair((p[i] + p[j]) / 2, v.length2())].push_back(i); &#125; double ans = -1; for (const auto&amp; pa: mmap) &#123; Point center = pa.first.first; for (int i = 0; i &lt; pa.second.size(); i++) &#123; // cout &lt;&lt; pa.second[i] &lt;&lt; ' '; for (int j = i + 1; j &lt; pa.second.size(); j++) &#123; int i1 = pa.second[i], j1 = pa.second[j]; double area = 2 * abs(cross(p[i1] - center, p[j1] - center)); ans = ans &lt; 0 ? area : min(ans, area); &#125; &#125; &#125; return max(ans, 0.0); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Geometry","slug":"alg-Geometry","permalink":"https://zhanghuimeng.github.io/tags/alg-Geometry/"}]},{"title":"Leetcode 962. Maximum Width Ramp","slug":"2018-12-23-Leetcode-962-Maximum-Width-Ramp","date":"2018-12-23T16:59:56.000Z","updated":"2018-12-24T02:16:00.000Z","comments":true,"path":"post/leetcode-962-maximum-width-ramp/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-962-maximum-width-ramp/","excerpt":"","text":"题目来源：https://leetcode.com/problems/maximum-width-ramp/description/ 标记难度：Medium 提交次数：2/3 代码效率： 排序：124ms 栈：68ms 题意 给定数组A，找到满足i &lt; j且A[i] &lt;= A[j]的(i, j)中j - i的最大值。如果没有则返回0。 分析 这道题我的做法是这样的：将数组排序（并记录原来的index），然后遍历数组，记录并不断更新已经出现过的index的最小值，将当前的index[i]减去该最小值即可求出所有可能的(x, i)中i - x的最大值。 做的时候因为没有判断好不存在的情况而错了一次。我好像经常因为这种问题犯错。 其实做的时候我隐约感觉到了也许可以用到栈（我之前在Leetcode 84. Largest Rectangle in Histogram）中详细总结了相关内容），但是比赛的时候没仔细思考。 如果需要用到栈，那么不妨把问题化归成这样：对于每个j，找到满足A[i] &lt;= A[j]的最小的i &lt;= j（如果这个i是存在的）。比如说，我们现在有一个A[i]，那么它右边的A[i+1], A[i+2], ...如果&gt;= A[i]，则它们对结果是毫无意义的，因为我们需要尽量选择靠左的且值比较小的数，A[i]必然会是一个更好的选择。所以可以维护一个值递减的栈（这次不需要弹出了），然后对于每个元素，用二分查找的方式找到最好的candidate，并且在它比栈顶还小的情况下入栈。[1] 很有趣的一点是，之前的问题都是“找到距离最近的元素”，所以直接用栈就可以维护局部性。这次要找到“距离尽量远的元素”，单用栈大概就不够了，需要加上二分查找。 代码 12345678910111213141516171819class Solution &#123;public: int maxWidthRamp(vector&lt;int&gt;&amp; A) &#123; // 对于每个数，找到左边比它小的最靠左的数 // 将index排序，找到左边最小的index vector&lt;pair&lt;int, int&gt;&gt; a; for (int i = 0; i &lt; A.size(); i++) a.emplace_back(A[i], i); sort(a.begin(), a.end()); int N = a.size(); // 我好像经常犯这一类边界条件的错误。 int minn = N + 1, ans = 0; for (int i = 0; i &lt; N; i++) &#123; ans = max(ans, a[i].second - minn); minn = min(minn, a[i].second); &#125; return ans; &#125;&#125;; 栈 12345678910111213141516171819202122class Solution &#123;public: int maxWidthRamp(vector&lt;int&gt;&amp; A) &#123; vector&lt;pair&lt;int, int&gt;&gt; s; int ans = 0; for (int i = 0; i &lt; A.size(); i++) &#123; if (s.empty() || s.back().first &gt; A[i]) s.emplace_back(A[i], i); else &#123; int l = 0, r = s.size(); while (l &lt; r) &#123; int mid = (l + r) / 2; if (s[mid].first &gt; A[i]) l = mid + 1; else r = mid; &#125; if (l &lt; s.size()) ans = max(ans, i - s[l].second); &#125; &#125; return ans; &#125;&#125;; lee215’s solution for Leetcode 962 - [Java/C++/Python] O(N) Using Stack ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 961. N-Repeated Element in Size 2N Array","slug":"2018-12-23-Leetcode-961-N-Repeated-Element-in-Size-2N-Array","date":"2018-12-23T11:58:28.000Z","updated":"2018-12-24T01:46:00.000Z","comments":true,"path":"post/leetcode-961-n-repeated-element-in-size-2n-array/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-961-n-repeated-element-in-size-2n-array/","excerpt":"","text":"题目来源：https://leetcode.com/problems/n-repeated-element-in-size-2n-array/description/ 标记难度：Easy 提交次数：4/4 代码效率： 排序：36ms 计数：32ms reduce：40ms 随机：40ms 题意 有一个长度为2N的数组，其中有N+1个不同元素，且只有一个元素出现了N次。返回这个元素。 分析 比赛时我用的是最简单的方法，排序：排序之后直接比较前后的数是否相等。 排序可以说是最low的方法了（复杂度高达O(N^2)），但在比赛时根据KISS原则，这么写也是合理的。 用哈希表显然也可以做，方法十分简单，不多说了。 下一种方法基于一种有趣的观察，我称之为reduce：把一个整个数组的性质（N个重复数字，不妨设为x；其他N个数字都是不重复的）缩小到其中一部分元素的性质。在所有的长度为4的子序列中，其中必然至少有一个出现了两个x。原因是这样的：考虑把这个子序列分成两个长度为2的子序列：由鸽巢原理，其中必然至少有一个数字是x。但是单看长度为2的子序列是无法判断的（因为x只会出现N次，无法保证一定会出现包含两个x的子序列），所以只能看长度为4的子序列。如果至少有一个出现了两个x的长度为2的子序列，则包含这个子序列的长度为4的子序列必然也至少包含两个x；如果每个长度为2的子序列都只有一个x，那么仍然至少存在一个出现了两个x的长度为4的子序列。[1] 最后一种不太有趣的解法是随机。每次随机取两个元素，然后判断它们是否相等，不相等则继续找。 代码 排序 1234567891011class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; sort(A.begin(), A.end()); for (int i = 1; i &lt; A.size(); i++) &#123; if (A[i-1] == A[i]) return A[i]; &#125; return -1; &#125;&#125;; 计数 1234567891011class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; unordered_set&lt;int&gt; s; for (int x: A) &#123; if (s.find(x) != s.end()) return x; s.insert(x); &#125; return -1; &#125;&#125;; reduce 感觉还是写得有点复杂。不需要用这么多判断。 1234567891011class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; for (int i = 0; i &lt; A.size() - 3; i++) &#123; if (A[i] == A[i+1] || A[i] == A[i+2] || A[i] == A[i+3]) return A[i]; if (A[i+1] == A[i+2] || A[i+1] == A[i+3]) return A[i+1]; if (A[i+2] == A[i+3]) return A[i+2]; &#125; return -1; &#125;&#125;; 随机 123456789101112class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; int N = A.size(); while (true) &#123; int i1 = rand() % N, i2 = rand() % N; if (i1 == i2) continue; if (A[i1] == A[i2]) return A[i1]; &#125; return -1; &#125;&#125;; LeetCode Official Solution - 961. N-Repeated Element in Size 2N Array ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 960. Delete Columns to Make Sorted III（DP）","slug":"2018-12-16-Leetcode-960-Delete-Columns-to-Make-Sorted-III（DP）","date":"2018-12-16T22:26:13.000Z","updated":"2018-12-16T22:47:00.000Z","comments":true,"path":"post/leetcode-960-delete-columns-to-make-sorted-iii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-960-delete-columns-to-make-sorted-iii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/delete-columns-to-make-sorted-iii/description/ 标记难度：Hard 提交次数：1/1 代码效率：24ms 题意 有N个只包含小写字母的长度相同的字符串。把它们从上到下排成一个矩阵，从中删除一些列，使得剩下的列从左到右是非降序的。问最少删除几列。 分析 有人说这道题很难（从提交情况来看，确实很难）。但我完全没有觉得它难，因为在做这个系列的第一题（Leetcode 944. Delete Columns to Make Sorted）的时候，我就差点把题意当成了这一道，所以我早就知道这道题怎么解了。 解法很简单。当成一个最长不降子序列问题就可以。两列满足不降的条件是，对应的每对字符都是不降的。所以复杂度是O(N*M^2)。 随便讲两句废话。按Leetcode的记录，我已经参加了21场比赛了，从8月14日到12月15日。这期间很多事情在逐渐发生变化。比如我的rating不再变了，对活跃在题解区的几个人有了更多了解，lee215除了在题解区写题解之外还开始在简书上发中文题解和在youtube上发视频，今天正好一共刷了233道题。我感觉，只要我在Leetcode上还有做起来费劲的题，刷Leetcode就不是没有价值的，因为掌握不止要看“会”，还要看“熟练度”；但是刷Leetcode还是远远不够的。 据说Leetcode用户觉得最难的题目类型是动态规划。 今天去考了CSP，感觉自己还是菜。翻翻《算法竞赛入门经典训练指南》，感觉自己不会的topic比会的多多了。等到寒假我打算尝试把USACO做完，并且开始打CF的div3之类的。 代码 1234567891011121314151617181920212223242526class Solution &#123;public: int minDeletionSize(vector&lt;string&gt;&amp; A) &#123; // 真·最长不降子序列 int f[101]; int ans = -1; int N = A.size(), M = A[0].length(); f[0] = 1; for (int i = 1; i &lt; M; i++) &#123; f[i] = 1; for (int j = 0; j &lt; i; j++) &#123; bool isOk = true; for (int k = 0; k &lt; N; k++) &#123; if (A[k][j] &gt; A[k][i]) &#123; isOk = false; break; &#125; &#125; if (!isOk) continue; f[i] = max(f[i], f[j] + 1); &#125; ans = max(f[i], ans); &#125; return M - ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 959. Regions Cut By Slashes（图）","slug":"2018-12-16-Leetcode-959-Regions-Cut-By-Slashes（图）","date":"2018-12-16T21:50:08.000Z","updated":"2018-12-16T22:22:00.000Z","comments":true,"path":"post/leetcode-959-regions-cut-by-slashes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-959-regions-cut-by-slashes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/regions-cut-by-slashes/description/ 标记难度：Medium 提交次数：2/5 代码效率： 并查集：12ms DFS：28ms 题意 用字符画的形式给定一个N*N的格子里的分割线，如： 12\\//\\ 问图中共有多少个连通区域。 分析 比赛的时候我就想到了把每个格子分成四个三角形的方法。但是我当时尝试在类里开一个3600*3600的静态数组，所以RE了。不过它只会RE而不会报MLE，这令人很难调试……反正直接用邻接矩阵肯定是不行的。 一种方法是直接绕开邻接矩阵和邻接表，用并查集来解决。 另一种看起来很神奇的方法[1]是，直接用upscale的思路把每个格子分成9块，然后令线的方格为障碍物，其他方格为可通过，这样也可以做DFS（或者说floodfill）。事实上这种建模的思路是隐式地建了每个小方格和周围的4个方格之间的图。 最后，当然用邻接表+DFS也可以啦。 代码 并查集 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;private: int _fa[3600]; int N, M; void init() &#123; for (int i = 0; i &lt; M; i++) _fa[i] = i; &#125; int fa(int x) &#123; return x == _fa[x] ? x : _fa[x] = fa(_fa[x]); &#125; void merge(int x, int y) &#123; x = fa(x); y = fa(y); _fa[x] = y; &#125; public: int regionsBySlashes(vector&lt;string&gt;&amp; grid) &#123; // 4N^2 small triangles N = grid.size(); M = 4*N*N; init(); // initial merge for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) &#123; int n = 4*(i*N + j); if (i &lt; N - 1) &#123; int n1 = 4*((i+1)*N + j); merge(n+2, n1); &#125; if (j &lt; N - 1) &#123; int n1 = 4*(i*N + j+1); merge(n+1, n1+3); &#125; &#125; for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; N; j++) &#123; int n = 4*(i*N + j); if (grid[i][j] != '/') &#123; merge(n, n+1); merge(n+2, n+3); &#125; if (grid[i][j] != '\\\\') &#123; merge(n, n+3); merge(n+1, n+2); &#125; &#125; &#125; int ans = 0; for (int i = 0; i &lt; M; i++) &#123; if (fa(i) == i) ans++; &#125; return ans; &#125;&#125;; DFS 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Solution &#123;private: int N; vector&lt;int&gt; G[3600]; void connect(int x, int y) &#123; G[x].push_back(y); G[y].push_back(x); &#125; bool visited[3600]; void dfs(int x) &#123; for (auto const&amp; y: G[x]) if (!visited[y]) &#123; visited[y] = true; dfs(y); &#125; &#125; public: int regionsBySlashes(vector&lt;string&gt;&amp; grid) &#123; N = grid.size(); // initial links for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) &#123; int n = 4*(i*N + j); if (i &lt; N - 1) &#123; int n1 = 4*((i+1)*N + j); connect(n+1, n1+3); &#125; if (j &lt; N - 1) &#123; int n1 = 4*(i*N + j+1); connect(n+2, n1); &#125; &#125; // grid picture for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; N; j++) &#123; int n = 4*(i*N + j); if (grid[i][j] != '\\\\') &#123; connect(n, n+3); connect(n+1, n+2); &#125; if (grid[i][j] != '/') &#123; connect(n, n+1); connect(n+2, n+3); &#125; &#125; &#125; int ans = 0; memset(visited, 0, sizeof(visited)); for (int i = 0; i &lt; 4*N*N; i++) &#123; if (!visited[i]) &#123; visited[i] = true; ans++; dfs(i); &#125; &#125; return ans; &#125;&#125;; vortrubac’s Solution for Leetcode 959 - C++ with picture, DFS on upscaled grid ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Graph","slug":"alg-Graph","permalink":"https://zhanghuimeng.github.io/tags/alg-Graph/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Union-find Forest","slug":"alg-Union-find-Forest","permalink":"https://zhanghuimeng.github.io/tags/alg-Union-find-Forest/"}]},{"title":"Leetcode 958. Check Completeness of a Binary Tree（树）","slug":"2018-12-16-Leetcode-958-Check-Completeness-of-a-Binary-Tree（树）","date":"2018-12-16T20:20:28.000Z","updated":"2018-12-16T21:29:00.000Z","comments":true,"path":"post/leetcode-958-check-completeness-of-a-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-958-check-completeness-of-a-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/check-completeness-of-a-binary-tree/description/ 标记难度：Medium 提交次数：2/4 代码效率： 比赛时的做法：4ms 题解的做法：4ms 题意 判断一棵树是否为完全二叉树。 分析 比赛的时候我的做法是，首先给整棵树做一个层次遍历，然后尝试找到完全二叉树里第一个位于倒数第二层的至少有一个空孩子的结点；如果在更高的层就有结点没有两个孩子，或者发现之后的结点又有孩子了，则这不是完全二叉树。不过这种判断有很多tricky的地方，所以我错了两次。而且代码写得很不优雅。不过当然比赛时写代码的第一目标也不是优雅…… 题解[1]的做法不错：直接判断按照一个堆的形态来组织树，能否得到一个中间没有空隙的数组。不需要把数组真的建出来，只要给每个结点分配一个index，然后判断index总数是否和结点总数相同就行了。 代码 层次遍历后直接判断 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: bool isCompleteTree(TreeNode* root) &#123; vector&lt;pair&lt;TreeNode*, int&gt;&gt; q; int maxDepth = -1; int n = 0; q.emplace_back(root, 0); while (n &lt; q.size()) &#123; TreeNode* p = q[n].first; int depth = q[n].second; maxDepth = depth; n++; if (!p-&gt;left &amp;&amp; p-&gt;right) return false; if (p-&gt;left) q.emplace_back(p-&gt;left, depth + 1); if (p-&gt;right) q.emplace_back(p-&gt;right, depth + 1); &#125; if (maxDepth == 0) return true; // 如果不特判大小为1的树会错 bool foundm1 = false; for (int i = 0; i &lt; q.size(); i++) &#123; TreeNode* p = q[i].first; int depth = q[i].second; if (foundm1) &#123; if (p-&gt;left || p-&gt;right) return false; &#125; else &#123; // 因为没加depth != maxDepth所以错了一次；显然最后一层也是没有孩子的 if (depth != maxDepth - 1 &amp;&amp; depth != maxDepth &amp;&amp; (!p-&gt;left || !p-&gt;right)) return false; if (depth == maxDepth - 1 &amp;&amp; (!p-&gt;left || !p-&gt;right)) foundm1 = true; &#125; &#125; return true; &#125;&#125;; 题解的做法 1234567891011121314151617class Solution &#123;public: bool isCompleteTree(TreeNode* root) &#123; vector&lt;pair&lt;TreeNode*, int&gt;&gt; q; q.emplace_back(root, 1); int n = 0; while (n &lt; q.size()) &#123; TreeNode* p = q[n].first; int index = q[n].second; n++; if (p-&gt;left) q.emplace_back(p-&gt;left, index * 2); else if (p-&gt;right) return false; if (p-&gt;right) q.emplace_back(p-&gt;right, index * 2 + 1); &#125; return q.size() == q.back().second; &#125;&#125;; Leetcode Official Solution for 958 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 957. Prison Cells After N Days","slug":"2018-12-16-Leetcode-957-Prison-Cells-After-N-Days","date":"2018-12-16T15:42:09.000Z","updated":"2018-12-16T15:42:09.000Z","comments":true,"path":"post/leetcode-957-prison-cells-after-n-days/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-957-prison-cells-after-n-days/","excerpt":"","text":"题目来源：https://leetcode.com/problems/prison-cells-after-n-days/description/ 标记难度：Medium 提交次数：1/3 代码效率：8ms 题意 给定一行8个格子，用类似于生命游戏的方法进行更新： 如果相邻有2个格子被占用或有2个格子为空，则变为被占用 否则变为空 问N步后这8个格子的状态。N &lt;= 1e9。 分析 比赛的时候看到这道题我就开始慌了，然后错了2次。这次比赛居然有三道Medium，一道Hard，可以说是偏难了。 一个很显然的观察是，两侧的格子在1天后都会变成空并且保持这个状态，所以实际上可以只考虑6个格子的状态。所以状态数量最多只有1+2^6种。不过当成2^8种来做也没什么问题。 显然用线性算法在N=1e9的时候必然会超时。不过，观察到状态必然会重复之后，可以通过找到循环来解决问题。如果第i天的状态与第start天相同，那么循环节的长度为i - start，可以令N = (N - i) % (i - start)，然后找到对应的天数的状态。 我比赛的时候没有写N--，而是i = 0 to N-1，显然前一种比较利于取模，后一种比较麻烦。所以我在给N取模这一点上错了两次。 另一个观察是[1]，因为格子的数量是偶数，所以对于每一种状态，都可以找到一种合法的之前的状态，所以初始状态后一步就可以进入循环；而且循环节长度必然是1、7或14，所以可以在一步之后就按照14为循环节进行操作。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123;private: int encode() &#123; int state = 0; for (int i = 0; i &lt; 8; i++) state = (state &lt;&lt; 1) | s[i]; return state; &#125; void decode(int x) &#123; for (int i = 0; i &lt; 8; i++) &#123; s[7 - i] = (x &amp; 1) &gt; 0; x &gt;&gt;= 1; &#125; &#125; int s[8]; public: vector&lt;int&gt; prisonAfterNDays(vector&lt;int&gt;&amp; cells, int N) &#123; int state = 0; for (int i = 0; i &lt; 8; i++) &#123; s[i] = cells[i]; &#125; state = encode(); unordered_map&lt;int, int&gt; state2num, num2state; for (int i = 0; i &lt; N; i++) &#123; if (state2num.find(state) != state2num.end()) &#123; int start = state2num[state]; int x = (N - i) % (i - start) + start; // 这是对的，但是比较麻烦 state = num2state[x]; decode(state); break; &#125; state2num[state] = i; num2state[i] = state; // 进入下一个状态 int s2[8]; for (int i = 0; i &lt; 8; i++) &#123; int vacuum = 0, occupied = 0; if (i &gt; 0) &#123; if (s[i-1] == 0) vacuum++; else occupied++; &#125; if (i &lt; 7) &#123; if (s[i+1] == 0) vacuum++; else occupied++; &#125; if (vacuum == 2 || occupied == 2) s2[i] = 1; else s2[i] = 0; &#125; memcpy(s, s2, sizeof(s)); state = encode(); &#125; // 返回 for (int i = 0; i &lt; 8; i++) cells[i] = s[i]; return cells; &#125;&#125;; lee215’s Solution for 957 - [Java/Python] Find the Loop, Mod 14 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"USACO 1.5.2: Mother's Milk（BFS）","slug":"2018-12-11-USACO-1-5-2-Mother-s-Milk（BFS）","date":"2018-12-11T20:34:37.000Z","updated":"2019-01-07T20:20:00.000Z","comments":true,"path":"post/usaco-1-5-2-mother-s-milk/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-5-2-mother-s-milk/","excerpt":"","text":"题意 见P1215 [USACO1.4]母亲的牛奶 Mother’s Milk。 有三个容量分别是A，B，C的桶，A，B，C是1到20的整数。初始状态下A和B都是空的，C是满的。可以从一个桶向另一个桶内倒牛奶，直到倒满或者倒空为止。问A为空时C中所有可能的牛奶体积。 分析 非常基础的搜索题。用DFS和BFS都可以。搜就是了…… 一种简化存储状态的方法是，只存两个桶内的牛奶数量，因为牛奶总数是不变的。（不过这个简化看起来没什么意思。） 我看了看题解里所谓的动态规划方法，发现它做的事情与其说是“动态规划”，还不如说是类似于Bellman-Ford的不断松弛，发现一次松弛就继续更新…… 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*ID: zhanghu15TASK: milk3LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int A, B, C;int limit[3];bool states[21][21][21];bool ans[21];void dfs(int s[3]) &#123; if (s[0] == 0) ans[s[2]] = true; for (int i = 0; i &lt; 3; i++) &#123; for (int j = 0; j &lt; 3; j++) &#123; if (i == j) continue; // pour from i to j if (s[i] == 0 || s[j] == limit[j]) continue; int ns[3]; if (s[i] &lt;= limit[j] - s[j]) &#123; ns[i] = 0; ns[j] = s[j] + s[i]; ns[3-i-j] = s[3-i-j]; &#125; else &#123; ns[i] = s[i] - (limit[j] - s[j]); ns[j] = limit[j]; ns[3-i-j] = s[3-i-j]; &#125; if (states[ns[0]][ns[1]][ns[2]]) continue; states[ns[0]][ns[1]][ns[2]] = true; dfs(ns); &#125; &#125;&#125;int main() &#123; ofstream fout(\"milk3.out\"); ifstream fin(\"milk3.in\"); fin &gt;&gt; limit[0] &gt;&gt; limit[1] &gt;&gt; limit[2]; int s[3] = &#123;0, 0, limit[2]&#125;; dfs(s); for (int i = 0; i &lt; limit[2]; i++) if (ans[i]) fout &lt;&lt; i &lt;&lt; ' '; fout &lt;&lt; limit[2] &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"USACO 1.5.1: Arithmetic Progressions（枚举）","slug":"2018-12-11-USACO-1-5-1-Arithmetic-Progressions（枚举）","date":"2018-12-11T20:31:07.000Z","updated":"2019-01-07T20:00:00.000Z","comments":true,"path":"post/usaco-1-5-1-arithmetic-progressions/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-5-1-arithmetic-progressions/","excerpt":"","text":"题意 见洛谷 P1214 [USACO1.4]等差数列 Arithmetic Progressions。 在双平方数集合（p^2 + q^2, 0 &lt;= p, q &lt;= M）中寻找长度为N的等差数列。3 &lt;= N &lt;= 25，1 &lt;= M &lt;= 250。 分析 我的做法是这样的。 首先枚举得到所有双平方数并去重和排序，复杂度为O(M^2)；并且用数组ind记录每个数是否是双平方数，以及如果是，它排序后的index。 枚举公差长度b（1 &lt;= b &lt;= 2*M^2 / (N-1)）：对每个双平方数，用数组maxlen维护以它为结尾的公差为b的等差数列的最大长度。从小到大枚举所有双平方数x： 如果x - b不存在，则记maxlen[x] = 1（即数列中只有它一个数） 如果maxlen[x] &gt;= N，则输出首项为x - (N-1)*b的等差数列（也即输出末项为x的等差数列，这样可以做到不重不漏） 如果x + b也是双平方数，则将maxlen[ind[x + b]]更新为maxlen[x] + 1 这种做法的时间复杂度约为O(M^4 / (N-1))，时间最长的测试点需要2.558s才能通过。 题解里的第一种算法剪枝的方法有些不同。首先也是预处理出所有的双平方数并排序；然后对于任意两个双平方数，判断它们是否有可能成为一个长度为N的等差数列的前两项（判断方法是期望的末项和倒数第二项是否存在），如果有可能，则将这两个数的差记录下来，作为有可能的公差；最后对于每个有可能的公差，列举每个双平方数，判断将这个数作为首项是否存在长度为N的等差数列，如果有则输出。 第二种算法也没剪枝，就直接枚举公差和首项，然后判断是否存在长度为N的等差数列。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/*ID: zhanghu15TASK: ariprogLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int a[62500];int maxlen[62500];bool isBisquare[125001];int ind[125001];int main() &#123; ofstream fout(\"ariprog.out\"); ifstream fin(\"ariprog.in\"); int N, M; fin &gt;&gt; N &gt;&gt; M; int n = 0; for (int i = 0; i &lt;= M; i++) for (int j = i; j &lt;= M; j++) &#123; isBisquare[i*i + j*j] = true; &#125; int m = 2*M*M; memset(ind, -1, sizeof(ind)); for (int i = 0; i &lt;= m; i++) &#123; if (isBisquare[i]) &#123; a[n] = i; ind[i] = n; n++; &#125; &#125; bool found = false; for (int b = 1; b &lt;= m/(N-1); b++) &#123; memset(maxlen, 0, sizeof(maxlen)); for (int i = 0; i &lt; n; i++) &#123; if (maxlen[i] == 0) maxlen[i] = 1; if (maxlen[i] &gt;= N) &#123; fout &lt;&lt; a[i] - (N-1)*b &lt;&lt; ' ' &lt;&lt; b &lt;&lt; endl; found = true; &#125; if (a[i]+b &lt;= m &amp;&amp; ind[a[i]+b] &gt;= 0) &#123; maxlen[ind[a[i]+b]] = maxlen[i] + 1; &#125; &#125; &#125; if (!found) fout &lt;&lt; \"NONE\" &lt;&lt; endl; fin.close(); fout.close(); return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"为什么sigmoid和softmax需要和cross entropy一起计算","slug":"2018-12-11-为什么sigmoid和softmax需要和cross-entropy一起计算","date":"2018-12-11T17:21:00.000Z","updated":"2018-12-11T17:21:00.000Z","comments":true,"path":"post/why-we-should-compute-sigmoid-and-softmax-with-cross-entropy/","link":"","permalink":"https://zhanghuimeng.github.io/post/why-we-should-compute-sigmoid-and-softmax-with-cross-entropy/","excerpt":"","text":"众所周知，TensorFlow中原来是不提供单独的cross entropy loss计算函数的，只有softmax_cross_entropy_with_logits和tf.nn.sigmoid_cross_entropy_with_logits两类。（不过现在Keras里有这种东西了，categorical_crossentropy可以指明输入的是logits而非softmax）。据开发者说，这是因为： We provide optimized cross-entropy implementations that are fused with the softmax/sigmoid implementations because their performance and numerical stability are critical to efficient training. If however you are just interested in the cross entropy itself, you can compute it directly using code from the beginners tutorial: cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) N.B. DO NOT use this code for training. Use tf.nn.softmax_cross_entropy_with_logits() instead.[1] 那么都有些什么问题呢？ softmax计算中的问题 softmax的公式是： $$ y_i = \\frac{e^{x_i}}{\\sum_{i=1}^n e^{x_i}} $$ 一个事实是，如果传入的值稍微大一些，结果就会溢出（因为指数运算的结果太大了）。解决方法是在分式上下除以一个eαe^\\alphaeα： $$ \\begin{aligned} y_i = \\frac{e^{x_i}}{\\sum_{i=1}^n e^{x_i}} = \\frac{e^{x_i - \\alpha}}{\\sum_{i=1}^n e^{x_i - \\alpha}} \\end{aligned} $$ 令α=max⁡(x1,⋯ ,xn)\\alpha = \\max{(x_1, \\cdots, x_n)}α=max(x1​,⋯,xn​)，则xi−α≤0x_i - \\alpha \\leq 0xi​−α≤0，exi−αe^{x_i - \\alpha}exi​−α的结果趋近于0，不会发生溢出。[2] 结论：不要自己直接手算softmax。 sigmoid计算中的问题 sigmoid的公式是： y=11+e−xy = \\frac{1}{1 + e^{-x}} y=1+e−x1​ 这看起来还比较简单，不过仍然要注意分母溢出的问题。之前scipy的expit曾经出过这样的一个bug。在xxx为正数时，它计算的是exex+1\\frac{e^x}{e^x + 1}ex+1ex​，而python的math.exp在x≥710x \\geq 710x≥710时会溢出。所以expit(710)也会溢出。[3] 结论：最好也不要自己手算sigmoid。 cross entropy计算中的问题 交叉熵的公式是： L=−∑i=1nyilog⁡y^iL = -\\sum_{i=1}^n y_i \\log{\\hat{y}_i} L=−i=1∑n​yi​logy^​i​ 其中yiy_iyi​是正确（分类）结果（概率），y^i\\hat{y}_iy^​i​是模型输出的分类概率。 一般来说，这个函数的输入都是softmax或者sigmoid之后的结果，从数学上说，可以保证在(0,1)(0, 1)(0,1)范围内；但是计算机的表示范围是有限的，很可能会出现y^i=0\\hat{y}_i = 0y^​i​=0的情况。如果不管的话，结果就会直接溢出变成nan。所以至少要做一下预处理，把接近0的y^i\\hat{y}_iy^​i​变成ϵ\\epsilonϵ之类的。 Keras的实现中还把接近1的y^i\\hat{y}_iy^​i​变成了1−ϵ1 - \\epsilon1−ϵ，这一点我还没想清楚为什么。[4] 结论：也不要自己手算交叉熵。 （我之前确实遇到过nan的情况。） softmax + cross entropy 把softmax代入到cross entropy的公式中： $$ \\begin{aligned} L &= -\\sum_{i=1}^n y_i \\log{\\hat{y}_i} \\\\ &= -\\sum_{i=1}^n y_i \\log{\\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}} \\\\ &= -\\sum_{i=1}^n y_i \\left(x_i - \\log{\\sum_{j=1}^n e^{x_j}}\\right) \\\\ &= -\\sum_{i=1}^n x_i y_i + \\left(\\sum_{i=1}^n y_i\\right) \\left(\\log{\\sum_{j=1}^n e^{x_j}}\\right) \\end{aligned}$$ 显然上式里只有log⁡∑j=1nexj\\log{\\sum_{j=1}^n e^{x_j}}log∑j=1n​exj​会有数值稳定性问题。可以用类似的方法来处理：令α=max⁡(x1,⋯ ,xn)\\alpha = \\max{(x_1, \\cdots, x_n)}α=max(x1​,⋯,xn​)，则 $$ \\log{\\sum_{i=1}^n e^{x_i}} = \\log{\\left(e^\\alpha \\sum_{i=1}^n e^{x_i - \\alpha}\\right)} = \\alpha + \\log{\\sum_{i=1}^n e^{x_i - \\alpha}} $$ 这样就可以解决直接计算exje^{x_j}exj​溢出的问题了。 sigmoid + cross entropy $$ \\begin{aligned} L &= -\\sum_{i=1}^n y_i \\log{\\hat{y}_i} \\\\ &= -\\sum_{i=1}^n y_i \\log{\\frac{1}{1+e^{-x_i}}} \\\\ &= \\sum_{i=1}^n y_i \\log{(1+e^{-x_i})} \\end{aligned}$$ 如果e−xie^{-x_i}e−xi​很大，那么不需要计算log⁡(1+e−xi)\\log{(1+e^{-x_i})}log(1+e−xi​)（可能会溢出），直接用−xi-x_i−xi​作为估计值。否则e−xie^{-x_i}e−xi​会被截断。 实现 可以看出softmax和cross entropy一起计算效果更好（如果先算出概率分布，由于计算精度的原因，很小的概率会舍入到0，然后直接增大到EPS，所以得到的结果变小了）。 sigmoid和cross entropy一起计算效果也更好，原因是类似的。 结论：TensorFlow的API这样设计是有原因的（虽然我还是觉得应该给一个算cross entropy的API），为了保证数值稳定性，应该尽量用API，不要自己写。 TensorFlow issue - Why is there no support for directly computing cross entropy? ↩︎ 知乎 - Softmax函数与交叉熵 ↩︎ scipy issue - expit does not handle large arguments well ↩︎ tensorflow issue - Why is there no support for directly computing cross entropy? - comment ↩︎","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://zhanghuimeng.github.io/tags/Machine-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://zhanghuimeng.github.io/tags/TensorFlow/"}]},{"title":"Leetcode 956. Tallest Billboard（DP）","slug":"2018-12-09-Leetcode-956-Tallest-Billboard（DP）","date":"2018-12-09T19:44:33.000Z","updated":"2018-12-09T20:36:00.000Z","comments":true,"path":"post/leetcode-956-tallest-billboard/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-956-tallest-billboard/","excerpt":"","text":"题目来源：https://leetcode.com/problems/tallest-billboard/description/ 标记难度：Hard 提交次数：1/2 代码效率： 动态规划：136ms 中间相遇：184ms 题意 给定&lt;=20根棍子，要求从中拿出一些，分成两组，使得每组的棍子长度之和相等。保证所有棍子的长度之和最大是5000。 分析 在比赛的时候我能想到的最好的解法是这样的： 枚举第一组都有哪些棍子（2^20） 对于剩下的棍子，用动态规划的方法判断能否组成第一组已有的长度（5000*20） 显然这个算法是会超时的。但是也许它已经接近正解了。 解法1：-1,0,1背包 把这个问题看成是扩展版的01背包问题：对于每根棍子，我们可以把它加入背包中，不加入背包中，还可以把它从背包中减去。 令f[i][j]表示用前i根棍子能否组成和为j的长度（j有可能是负的）。则f[i+1][j] = f[i][j] || f[i][j-rods[i+1]] || f[i][j+rods[i+1]]。为了找到可能的最大长度，用辅助数组g[i][j]记录f[i][j]为真时，最大可能的正长度之和。算法的复杂度为O(10000*N)。[1] 解法2：中间相遇法 把rods数组分成大致相等的两半，然后对每一半都枚举每根棍子是+，-还是0。然后对于左边的一半得到的和，在右边寻找这个和的负值是否存在。最后取最大值。算法复杂度为O(3^(N/2))。 这个算法也需要记录最大可能的正长度之和。 代码 解法1：扩展01背包 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: int tallestBillboard(vector&lt;int&gt;&amp; rods) &#123; bool f[20][10001]; // f[i][j+5000]（index负数的一种方法） int g[20][10001]; memset(f, 0, sizeof(f)); memset(g, 0, sizeof(g)); int ans = 0; for (int i = 0; i &lt; rods.size(); i++) &#123; f[i][5000] = true; for (int j1 = 0; j1 &lt;= 10000; j1++) &#123; int j = j1 - 5000; // j才是真正的j，j1是j+5000 if (i == 0) &#123; if (j == rods[i]) &#123; f[i][j1] = true; g[i][j1] = rods[i]; &#125; if (j == -rods[i]) f[i][j1] = true; &#125; else &#123; // 三种情况：分别更新g，找到最大值 if (f[i-1][j1]) &#123; f[i][j1] = true; g[i][j1] = max(g[i][j1], g[i-1][j1]); &#125; if (j1 &gt;= rods[i] &amp;&amp; f[i-1][j1-rods[i]]) &#123; f[i][j1] = true; g[i][j1] = max(g[i][j1], g[i-1][j1-rods[i]] + rods[i]); &#125; if (j1 + rods[i] &lt;= 10000 &amp;&amp; f[i-1][j1+rods[i]]) &#123; f[i][j1] = true; g[i][j1] = max(g[i][j1], g[i-1][j1+rods[i]]); &#125; &#125; &#125; ans = max(ans, g[i][5000]); &#125; return ans; &#125;&#125;; 解法2：中间相遇法 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;private: unordered_map&lt;int, int&gt; results; // 和 - 最大正值和 int M, N; int ans; // 枚举棍子状态：sum是和，p是正值和 void dfs(int x, int sum, int p, vector&lt;int&gt;&amp; rods, bool check) &#123; if (x &gt;= rods.size()) &#123; if (!check) results[sum] = max(results[sum], p); else &#123; if (results.find(-sum) != results.end()) ans = max(ans, results[-sum] + p); &#125; return; &#125; dfs(x+1, sum, p, rods, check); dfs(x+1, sum+rods[x], p+rods[x], rods, check); dfs(x+1, sum-rods[x], p, rods, check); &#125; public: int tallestBillboard(vector&lt;int&gt;&amp; rods) &#123; N = rods.size(); if (N == 0) return 0; M = N / 2; vector&lt;int&gt; rod1, rod2; for (int i = 0; i &lt; M; i++) rod1.push_back(rods[i]); for (int i = M; i &lt; N; i++) rod2.push_back(rods[i]); ans = 0; dfs(0, 0, 0, rod1, false); dfs(0, 0, 0, rod2, true); return ans; &#125;&#125;; wangzi6147’s Solution for LeetCode 956 - Java knapsack O(N*sum) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Meet in the Middle","slug":"alg-Meet-in-the-Middle","permalink":"https://zhanghuimeng.github.io/tags/alg-Meet-in-the-Middle/"}]},{"title":"Leetcode 955. Delete Columns to Make Sorted II（贪心）","slug":"2018-12-09-Leetcode-955-Delete-Columns-to-Make-Sorted-II（贪心）","date":"2018-12-09T16:54:51.000Z","updated":"2018-12-09T17:07:51.000Z","comments":true,"path":"post/leetcode-955-delete-columns-to-make-sorted-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-955-delete-columns-to-make-sorted-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/delete-columns-to-make-sorted-ii/description/ 标记难度：Medium 提交次数：1/2 代码效率：8ms 题意 给定N个长度相同的字符串，问从中最少删掉多少列，才能使得删除后的字符串是按字典序排列的。 分析 这道题还挺有趣的。题解里给了一种很明显是stay ahead思路的正确性证明[1]： 如果当前列会导致之前留下的列加上这一列不满足字典序，则这一列必须删除 否则可以说明，留下当前列必然不比删除它更差 由上述说明可以得知，已经留下的列必然是满足字典序的，其中有一些满足严格字典序（大于），有一些则可能不是严格字典序（相等） 对于已经满足严格字典序的字符串，后面加什么都没问题 对于相等的字符串，后面加的第一列必须满足字典序 因此，加上当前这一列之后，相等的字符串可能会变成严格字典序，或者还是相等 也就是说，相等的字符串不会增加，添加新列的难度也不会增加 所以应该尽可能留下当前列 （我写的不好，还是看题解的例子吧，那个例子举得很好。） 代码 但是我觉得我的代码写得还挺巧妙的。 1234567891011121314151617181920212223242526class Solution &#123;public: int minDeletionSize(vector&lt;string&gt;&amp; A) &#123; int n = A.size(), m = A[0].size(); int ans = 0; vector&lt;string&gt; B; for (int i = 0; i &lt; n; i++) &#123; B.push_back(\"\"); &#125; for (int i = 0; i &lt; m; i++) &#123; bool isOk = true; for (int j = 1; j &lt; n; j++) &#123; if (B[j] == B[j-1] &amp;&amp; A[j][i] &lt; A[j-1][i]) &#123; isOk = false; ans++; break; &#125; &#125; if (isOk) &#123; for (int j = 0; j &lt; n; j++) B[j] += A[j][i]; &#125; &#125; return ans; &#125;&#125;; LeetCode Official Solution for 955. Delete Columns to Make Sorted II ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 954. Array of Doubled Pairs（贪心）","slug":"2018-12-09-Leetcode-954-Array-of-Doubled-Pairs（贪心）","date":"2018-12-09T16:30:27.000Z","updated":"2018-12-09T16:48:00.000Z","comments":true,"path":"post/leetcode-954-array-of-doubled-pairs/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-954-array-of-doubled-pairs/","excerpt":"","text":"题目来源：https://leetcode.com/problems/verifying-an-alien-dictionary/description/ 标记难度：Medium 提交次数：1/2 代码效率：104ms 题意 给定一个长度为偶数的数组A，问能否将A排序，使得对于每个0&lt;=i&lt;len(A)/2，都有A[2*i+1] = A[2*i]。-100000&lt;=A[i]&lt;=100000。 事实上就是每个数都要和一个是它的二倍或者二分之一的数配对…… 分析 我发现赛后这道题的函数签名也改了，从bool canSortDoubled(vector&lt;int&gt;&amp; A)变成了bool canReorderDoubled(vector&lt;int&gt;&amp; A)…… 而且我比赛时的代码写错了……忘了判断大数是否被耗尽的情况…… 这也能过？看来数据太弱了。 这道题用贪心就可以解决。对于当前还剩的绝对值最小的数，它必然需要和它的两倍的数配对；最后所有的数都需要配对完。以及0只能自己和自己配对，所以0的总数应该是偶数。 代码 1234567891011121314151617181920212223242526class Solution &#123;public: bool canReorderDoubled(vector&lt;int&gt;&amp; A) &#123; int positive[100001], negative[100001]; memset(positive, 0, sizeof(positive)); memset(negative, 0, sizeof(negative)); for (int x: A) &#123; if (x &gt;= 0) positive[x]++; else negative[-x]++; &#125; if (positive[0] % 2 != 0) return false; for (int i = 1; i &lt;= 100000; i++) &#123; if (positive[i] != 0) &#123; if (i &gt; 50000 || positive[i*2] &lt; positive[i]) return false; positive[i*2] -= positive[i]; &#125; &#125; for (int i = 1; i &lt;= 100000; i++) &#123; if (negative[i] != 0) &#123; if (i &gt; 50000 || negative[i*2] &lt; negative[i]) return false; negative[i*2] -= negative[i]; &#125; &#125; return true; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 953. Verifying an Alien Dictionary（hash），及周赛（114）总结","slug":"2018-12-09-Leetcode-953-Verifying-an-Alien-Dictionary（hash）","date":"2018-12-09T16:07:16.000Z","updated":"2018-12-09T16:23:00.000Z","comments":true,"path":"post/leetcode-953-verifying-an-alien-dictionary-hash/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-953-verifying-an-alien-dictionary-hash/","excerpt":"","text":"题目来源：https://leetcode.com/problems/verifying-an-alien-dictionary/description/ 标记难度：Easy 提交次数：1/1 代码效率：8ms 题意 给定一堆字符串和一个字母排列order，问在该字母表顺序下，这些字符串是否是排好序的。 分析 这次我还是去参加了internal contest。但是这次的状况比较混乱，第三题出现了函数签名搞错的情况，赛后也没有人统计反馈改题什么的。（虽然也许我知道为什么。）这次我第四题没做出来。 这道题很水。一种方法是手动比较相邻两个字符串的大小（注意“空”和“有字符”的情况的比较）[1]；另一种方法就是直接根据字母排列把字符串映射到正常顺序，然后直接比较[2]。 代码 1234567891011121314151617181920class Solution &#123;public: bool isAlienSorted(vector&lt;string&gt;&amp; words, string order) &#123; int orderMap[26]; for (int i = 0; i &lt; 26; i++) &#123; orderMap[order[i] - 'a'] = i; &#125; vector&lt;string&gt; mappedWords; for (string word: words) &#123; string x = word; for (int i = 0; i &lt; x.length(); i++) x[i] = orderMap[x[i] - 'a'] + 'a'; mappedWords.push_back(x); &#125; for (int i = 1; i &lt; mappedWords.size(); i++) if (mappedWords[i] &lt; mappedWords[i-1]) return false; return true; &#125;&#125;; LeetCode Official Solution for 953. Verifying an Alien Dictionary ↩︎ lee215’s Solution for LeetCode 953 - [C++/Python] Mapping to Normal Order ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"USACO 1.4.6: Ski Course Design（暴力）","slug":"2018-12-03-USACO-1-4-6-Ski-Course-Design（暴力）","date":"2018-12-03T20:36:31.000Z","updated":"2018-12-08T20:56:00.000Z","comments":true,"path":"post/usaco-1-4-6-ski-course-design/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-6-ski-course-design/","excerpt":"","text":"题意 见洛谷 P3650。 有N座山，每座山有一个高度（[0, 100]范围内）。现在需要修改这些山的高度（每座山只修改一次），使得最高的山和最低的山之间的高度差不大于17；修改高度的代价是高度变化值的平方。问如何修改才能使总代价最小。N&lt;=1000。 分析 还是暴力。这次题解里给的方法是，枚举所有的长度为17的区间，然后对于每个区间，计算把所有山的高度修改到这个区间内的代价。算法复杂度为O(N*M)，其中M是区间总数（也就是大约100个，实际84个），已经足够了。 当然事实上可以把复杂度减到更低，用计数排序的方法来统计山的高度，然后对于每个区间，计算把每种高度（可能对应几座山）修改到区间内的代价。复杂度是O(M^2)。我是这么写的。 这道题有非暴力的做法吗？我感觉是有的。（当然，现在用不上，但是如果数据范围变大就能用上了。） 代码 暴力 123456789101112131415161718192021222324252627282930313233343536373839/*ID: zhanghu15TASK: skidesignLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int cnt[101];int main() &#123; ofstream fout(\"skidesign.out\"); ifstream fin(\"skidesign.in\"); int N; fin &gt;&gt; N; for (int i = 0; i &lt; N; i++) &#123; int x; fin &gt;&gt; x; cnt[x]++; &#125; int ans = -1; // take i as the base for (int i = 0; i &lt;= 83; i++) &#123; int low = i, high = i + 17, cur = 0; for (int j = 0; j &lt;= 100; j++) &#123; if (cnt[j] == 0) continue; if (j &lt; low) cur += (low - j) * (low - j) * cnt[j]; else if (j &gt; high) cur += (j - high) * (j - high) * cnt[j]; &#125; ans = ans == -1 ? cur : min(ans, cur); &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 非暴力 TBD","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.4.5: Wormholes（暴力）","slug":"2018-12-03-USACO-1-4-5-Wormholes","date":"2018-12-03T20:34:27.000Z","updated":"2018-12-08T20:55:00.000Z","comments":true,"path":"post/usaco-1-4-5-wormholes/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-5-wormholes/","excerpt":"","text":"题意 见USACO 2013 December Contest, Bronze Problem 3. Wormholes。 原来USACO是会新加题的吗！！因为是新题所以好像洛谷没有…… 在一个平面上有最多12个虫洞（偶数个），虫洞两两相连，可以互相传送；Bessie在平面上只会向+x方向移动。问有多少种虫洞连接方式会让Bessie困在循环中， 分析 这道题我做了好久，设计得相当不错，真是相当不错，我本来以为是暴力水题的来着…… 需要注意的一点是，Bessie是向+x方向走，所以能够相互走到的是相邻且y坐标相等的虫洞，不是x坐标相等的虫洞……我最开始就写错了，后来就直接把x和y换了一下。 遍历虫洞两两相连的方法可以直接用回溯法解决。问题显然在于得到一个连接顺序之后，怎么判定有环。最开始我直接把这个问题建模成了“判断一张图上是否有环”，图上的边就是相连的虫洞和能相互走到的虫洞。然后我就挂了。问题在于，“连接虫洞的边”和“走路能到的边”不是一种边，在实际判定有环的时候，必须交替着走，而且判定有环的时候，不止要看虫洞是否重复，也要看上一条边是否重复，因为显然，走路到达一个虫洞（然后传送）和传送到达一个虫洞（然后开始走路）是两种不同的情况。 这些问题我搞了一晚上……然后错了三次，我注意到USACO左侧开始有一个类似于&quot;3/10&quot;的标签了，这是否意味着交10次就不能再交了（还是交满10次自动出题解）？ 题解里又有一个视频（大概因为是新题吧），里面的解法很巧妙：既然必须交替走两种边，那我一次就走两条边，传送1次+走路一次……这写法真简明扼要。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*ID: zhanghu15TASK: wormholeLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int N;pair&lt;int, int&gt; wormholes[12];int walkPairing[12];int wormholePairing[12];bool visited[12][2]; // 记录走/跳是必要的int ans;// 两类边交替走，找环bool dfs(bool isWalking, int x) &#123; if (visited[x][isWalking]) return true; visited[x][isWalking] = true; if (isWalking &amp;&amp; walkPairing[x] != -1) return dfs(!isWalking, walkPairing[x]); else if (!isWalking) return dfs(!isWalking, wormholePairing[x]); return false;&#125;void backtrack(int cur) &#123; // 找到了一组合法的配对 if (cur == N) &#123; // 尝试DFS找环 for (int i = 0; i &lt; N; i++) &#123; memset(visited, 0, sizeof(visited)); if (dfs(true, i)) &#123; ans++; break; &#125; &#125; return; &#125; if (wormholePairing[cur] != -1) backtrack(cur + 1); else &#123; for (int i = cur + 1; i &lt; N; i++) &#123; if (wormholePairing[i] != -1) continue; wormholePairing[cur] = i; wormholePairing[i] = cur; backtrack(cur + 1); wormholePairing[cur] = wormholePairing[i] = -1; &#125; &#125;&#125;int main() &#123; ofstream fout(\"wormhole.out\"); ifstream fin(\"wormhole.in\"); fin &gt;&gt; N; // x和y坐标搞反了…… for (int i = 0; i &lt; N; i++) fin &gt;&gt; wormholes[i].second &gt;&gt; wormholes[i].first; // 找能走到的虫洞 sort(wormholes, wormholes+N); memset(walkPairing, -1, sizeof(walkPairing)); for (int i = 1; i &lt; N; i++) if (wormholes[i-1].first == wormholes[i].first) walkPairing[i-1] = i; // 寻找所有可能的虫洞配对方法 memset(wormholePairing, -1, sizeof(wormholePairing)); backtrack(0); fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"论文：deepQuest: A Framework for Neural-based Quality Estimation","slug":"2018-12-03-论文：deepQuest-A-Framework-for-Neural-based-Quality-Estimation","date":"2018-12-03T16:01:27.000Z","updated":"2018-12-03T16:01:27.000Z","comments":true,"path":"post/deepquest-a-framework-for-neural-based-quality-estimation/","link":"","permalink":"https://zhanghuimeng.github.io/post/deepquest-a-framework-for-neural-based-quality-estimation/","excerpt":"","text":"论文地址：http://aclweb.org/anthology/C18-1266 这篇文章的主要内容是实现了一个新的叫deepQuest的QE系统（已开源），里面包含了之前sentence-level QE的SOTA（现在已经不是了），POSTECH和他们这次新发明的Bi-RNN两个sentence-level的系统，以及在这两个sentence-level基础上的document-level QE系统，发布了一个新的Resources for document-level Quality Estimation数据集（也已开源），并在WMT 17和上述数据集上报告了结果。结果表明，Bi-RNN在sentence-level上效果不如POSTECH（但是训练快），作为document-level的基础系统效果更好。 论文内容 sentence-level QE通常预测的是机器翻译输出结果的post-editing effort，但document-level QE通常是在全自动的MT应用场景下预测文档质量分数（而非PE）。目前所有的神经网络QE方法都有复杂的结构，需要预训练和手动提取feature，而且没有document-level的方法。（吐槽：事实上我觉得预训练和复杂的网络结构都是必要的，甚至是很必要的……）所以我们提出了一个新的sentence-level方法（Bi-RNN），它不需要预训练，结构很简单，训练起来很快。我们还提出了一个新的神经网络的document-level的方法，它可以将任何细粒度的QE方法的结果进行综合，得到更粗粒度的QE结果，比如将sentence-level的输出综合处理得到document-level的结果。经过在sent-level和doc-level的一些欧洲语言的SMT和NMT上输出的测试，我们发现，对高质量NMT输出进行QE的主要挑战是在已经很流利的文本中找出错误。 Sentence-level 作者首先实现了WMT 17的冠军系统POSTECH。这个系统分成两个部分： predictor：encoder-decoder RNN，基于context对词进行预测，生成表示向量 estimator：Bi-RNN，根据predictor生成的表示向量进行打分 其中predictor部分需要大量预训练。（这就和QEBrain的思路基本上是一样的，只不过具体用的架构不太一样。我可能还是需要去读一下具体是怎么做的。） 然后实现了新的一种架构，Bi-RNN。这个方法的思路非常简单： 对输入和输出分别进行word embedding 分别用一个bi-RNN对输入和输出的embedding进行学习，得到一系列隐状态hjh_jhj​（两个RNN分开训练，但是输出结果连在一起，一起进行attention） 对所有的隐状态进行attention，得到加权后的和 进行sigmoid，将输出作为分数 attention的公式为： $$ \\alpha_j = \\frac{\\exp{(W_a h_j^T)}}{\\sum_{k=1}^{J} \\exp{(W_a h_j^T)}} \\\\ v = \\sum_{j=1}^J \\alpha_j h_j $$ Document-level 之前我们可以看到，Bi-RNN输出了一个vvv向量，实际上可以把它看做是一个对整个句子的表示。POSTECH中Predictor也会输出一个类似的向量。我们可以把这些向量表示再做一次Bi-RNN，对结果进行attention（或者直接用最后一个隐状态），得到整个文档对应的向量，再对这个向量进行sigmoid，得到文档对应的分数。 测试结果 Sentence-level 测试使用的是WMT 2017 QE的官方数据的一个超集，包括NMT和SMT的翻译结果，其中包括： En-De：28000句（IT领域） En-Lv：18768句（生命科学领域） 数据使用TERCOM进行标注，分数采用HTER。POSTECH的predictor使用Europarl和WMT 2017 News translation Task的语料进行预训练。 一些实现细节（当然，代码里有更多的细节）： 使用Keras进行实现（而且似乎支持Theano和TensorFlow两种backend） 使用GRU作为RNN单元 word embedding维度为300 词表大小为30K encoder隐藏层单元大小为50 用Adadelta optimizer最小化MSE 可以得出以下结论： En-De数据集中NMT的翻译质量高于SMT，而En-Lv数据集中NMT的翻译质量不如SMT，这影响了各个方法的表现 POSTECH方法在SMT数据上的表现比在NMT数据上高40%，这可能受到了数据质量或者句子长度的影响 无预训练的POSTECH方法表现不如Bi-RNN，这可能是因为Bi-RNN能够把握NMT数据的流利度 （但是，还是有预训练的POSTECH方法效果最好） Document-level 预测的分数采用的是几种BLEU值： document-level BLEU（使用NLTK进行打分） wBLEU：文档中句子BLEU值的加权平均，权重是句子长度 tBLEU：也是句子的BLEU值的加权平均，但是权重是TFIDF；对每个文档，都学习一个新的TFIDF模型，并据此计算TFIDF分数 $$ \\text{wBLEU}_d = \\frac{\\sum_{i=1}^D \\text{len}(R_i)\\text{BLEU}_i}{\\sum_{i=1}^D \\text{len}(R_i)} $$ $$ \\text{tBLEU} = \\sum_{i=1}^D \\text{TFIDF}_i \\text{BLEU}_i $$ 在document-level的测试中，使用的数据是WMT News Task中这几年提交的机器翻译结果，作者对数据进行了一定筛选，并把相应的数据集开源了（docQE）。 document-level系统使用的是POSTECH/Bi-RNN系统输出的句子表示，并测试了使用attention/只使用最后一个状态的结果。 通过上述结果可以发现： tBLEU标记下QE系统表现最好，BLEU标记下QE系统表现最差。这可能是因为tBLEU的计算方式和这种从word representation到sentence到document的结构是最类似的。 以Bi-RNN作为输入representation的效果整体优于POSTECH，而且训练得还快。 attention的贡献不是统计显著的，这可能是因为相关距离会变化，很难找到最优的权重。 单独筛选训练数据不会提高表现。 POSTECH非常需要预训练。 De-En和En-Ru的预测难度最大，这可能是因为语言之间词序差异很大，相关的MT输出质量通常也比较低。 运行结果 TBD","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"},{"name":"Quality Estimation","slug":"Quality-Estimation","permalink":"https://zhanghuimeng.github.io/tags/Quality-Estimation/"}]},{"title":"USACO 1.4.4: Combination Lock（暴力）","slug":"2018-12-03-USACO-1-4-4-Combination-Lock（暴力）","date":"2018-12-03T15:00:44.000Z","updated":"2018-12-03T15:00:44.000Z","comments":true,"path":"post/usaco-1-4-4-combination-lock/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-4-combination-lock/","excerpt":"","text":"题意 见洛谷 P2963。 有一些密码锁组合（形如[1, 2, 3]，每个数的范围是[1, N]），定义两个组合每个位置上的数相差两个位置以内时是接近的（密码锁是一个圈，所以1和N是相邻的）。给定两个已知组合，问所有组合里和这两个组合中的至少一个接近的有多少。 分析 暴力方法和上一道题如出一辙。可能需要注意的两点： 要求是和至少一个组合接近，而不是每个位置上的数和至少一个组合在这个位置上的数相近。不过这一点仍然可以用来剪枝。 如何判断接近。题解里的方法是abs(a-b) &lt;= 2 || abs(a-b) &gt;= N-2；我写的是(a-b+N) % N &lt;= 2 || (b-a+N) % N &lt;= 2。这两者应该都是对的。嗯，总之就是需要注意一下。 这道题题解里竟然有个录像，讲得很不错。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041/*ID: zhanghu15TASK: comboLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;bool isNear(int a, int b, int N) &#123; return (a-b+N) % N &lt;= 2 || (b-a+N) % N &lt;= 2;&#125;int main() &#123; ofstream fout(\"combo.out\"); ifstream fin(\"combo.in\"); int N; int combo1[3]; int combo2[3]; fin &gt;&gt; N; fin &gt;&gt; combo1[0] &gt;&gt; combo1[1] &gt;&gt; combo1[2]; fin &gt;&gt; combo2[0] &gt;&gt; combo2[1] &gt;&gt; combo2[2]; int ans = 0; for (int c1 = 1; c1 &lt;= N; c1++) &#123; if (!isNear(combo1[0], c1, N) &amp;&amp; !isNear(combo2[0], c1, N)) continue; for (int c2 = 1; c2 &lt;= N; c2++) &#123; if (!isNear(combo1[1], c2, N) &amp;&amp; !isNear(combo2[1], c2, N)) continue; for (int c3 = 1; c3 &lt;= N; c3++) &#123; if (isNear(combo1[0], c1, N) &amp;&amp; isNear(combo1[1], c2, N) &amp;&amp; isNear(combo1[2], c3, N) || isNear(combo2[0], c1, N) &amp;&amp; isNear(combo2[1], c2, N) &amp;&amp; isNear(combo2[2], c3, N)) ans++; &#125; &#125; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.4.3: Prime Cryptarithm（暴力）","slug":"2018-12-03-USACO-1-4-3-Prime-Cryptarithm","date":"2018-12-03T11:03:04.000Z","updated":"2018-12-03T11:03:04.000Z","comments":true,"path":"post/usaco-1-4-3-prime-cryptarithm/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-3-prime-cryptarithm/","excerpt":"","text":"题意 见洛谷 P1211。 分析 是个水题。开始时我还觉得会很难写，结果发现，与其正经地去按位搜索，不如直接枚举所有的两位数和三位数，判断它们和它们的乘积的中间结果是否满足题目要求。这样就非常好写了。 对于难（时间复杂度高的）题来说，当然还是得正经搜索，但对于简单题，改成这样简单的搜索反而更好。这是我从Leetcode 401. Binary Watch里学到的。题解也是这个做法。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*ID: zhanghu15TASK: crypt1LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;bool digits[10];bool isOk(int number, int length = -1) &#123; int i = 0; while (number &gt; 0) &#123; if (!digits[number % 10]) return false; number /= 10; i++; &#125; if (length != -1 &amp;&amp; i != length) return false; return true;&#125;int main() &#123; ofstream fout(\"crypt1.out\"); ifstream fin(\"crypt1.in\"); int N; fin &gt;&gt; N; for (int i = 0; i &lt; N; i++) &#123; int x; fin &gt;&gt; x; digits[x] = true; &#125; int ans = 0; for (int mul1 = 111; mul1 &lt;= 999; mul1++) &#123; if (!isOk(mul1)) continue; for (int mul2 = 11; mul2 &lt;= 99; mul2++) &#123; if (!isOk(mul2)) continue; int part1 = (mul2 % 10) * mul1; if (!isOk(part1, 3)) continue; int part2 = (mul2 / 10) * mul1; if (!isOk(part2, 3)) continue; int res = mul1 * mul2; if (!isOk(res, 4)) continue; ans++; &#125; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"记一次难忘的Leetcode Internel Contest","slug":"2018-12-01-记一次难忘的Leetcode-Internel-Contest","date":"2018-12-02T16:53:24.000Z","updated":"2018-12-06T00:31:00.000Z","comments":true,"path":"post/an-unforgettable-leetcode-internel-contest/","link":"","permalink":"https://zhanghuimeng.github.io/post/an-unforgettable-leetcode-internel-contest/","excerpt":"","text":"（这名字起得很像小学生了） 11月28日的时候，我收到了LeetCode的一封邮件，邀请我参加11月30日的第一次LeetCode Internal Contest。这场比赛仅对一小部分内部用户开放，目的是在正式比赛之前确保所有的题目都没有问题。这场比赛不会计入global ranking，参与之后也不能再参加之后的正式比赛。而且参加的用户会发LeetCoin。 我想，这听起来很有趣。虽然我不能去参加正式比赛提高自己的rating了，但是我还是可以比赛，而且还可以给LeetCode提bug，而且还可以获得一些LeetCoin（虽然这年头这些coin也许不像之前的奖励那样吸引人了）。所以我决定去申请一下。 题目出的锅 以我的评价标准，这场比赛并没有出锅；但是赛后有不少参赛者提出了虽然我没看出来但是好像很有道理的意见。正式比赛中修正了一部分内容。正式比赛过后，internel contest的题也都改过了，所以我只能凭借记忆回想题目哪些部分改了。 949. Largest Time for Given Digits 题目地址 这道题基本没出什么问题，虽然有人尝试了一下负数输入，发现标准答案还是输出了一些东西（而不是报错）。这一点目前还没改。我记得有些LeetCode标程是会assert输入的，不过反正测试数据里肯定没有负数输入，所以好像也无所谓。 我感觉很多人应该都在[0,0,0,0]这个输入上错了一次。考察能否想到corner case应该是这一类题的目的之一，我觉得挺好的。不过这要真是一道面试题的话，我可能会说，我在工作环境中会尽可能调用库来处理时间格式 950. Reveal Cards In Increasing Order 题目地址 很多人都表示很喜欢这道题的思考过程。不过我提出的意见是，我读完整道题和样例之后，并没有明白题目到底是要求返回card的一个order，还是index的一个order。当时样例输入还是[1,2,3,4,5,6,7]（所以返回index order和card order的结果是相同的）。还有人表示，因为样例输入是递增的，而且题目描述里也提到了“递增”（虽然说的是“……返回使card递增的一种排列”），他以为输入已经是递增的了。现在样例输入已经改成了[17,13,11,2,3,5,7]，输出是[2,13,3,11,5,17,7]，所以很显然是要求返回card的order（而且输入也不保证是递增的）。 这道题修改的过程使我发觉，样例也是题目的重要组成部分。有些题目里没有说或者没有说清楚的东西可以通过样例来说明，所以选择一组好的样例（既能帮助说明问题，又不泄露题目想要考察的corner case）是很重要的。当然，有时候样例也起到提示一些corner case，降低题目难度的作用（比如一些复杂的模拟题）。 951. Flip Equivalent Binary Trees 题目地址 好像没有什么修改，至少我没看出来。大家都觉得这道题挺好的。不过似乎某一组测试数据中出现了node value重复的情况，现在应该已经改掉了。 952. Largest Component Size by Common Factor 题目地址 这道题的叙述足够清楚（难点在于怎么做，而不在于怎么理解）；不过现在的版本相比之前还是为样例加上了示意图，这一点挺好的。 我觉得这道题难（从通过率来看），但是没有那么难（从做法上来说，只要把素数打表和并查集结合起来就可以做了）。我记得这道题的难度分值原来是9分，后来调整到了8分；以及我才注意到，原来每场比赛的难度分值之和是固定的24分。 还有人注意到了这样一种现象：有人的做法复杂度比较高，但是由于比赛时提供出错的测试数据，所以他们可能会通过在特定测试点中直接输出结果来规避大数据，并且通过这种方法来通过整道题。之前比赛中的943. Find the Shortest Superstring也有这种现象。这可能是提供测试数据用来debug的OJ的共有问题。目前我看到的和我想到的解决方案包括： 干脆就不显示数据了 造更多的大数据（&gt;100个），增加特判测试点的难度 增加输出量并限制源程序长度，防止打表 禁止这种行为，鼓励选手举报（我觉得这是个非常馊的主意） 参考其他OJ的赛制，比如在比赛中不测大样例，赛后再测 第二和第三种方案都可以增加跳测试点的难度，但大概并不能完全解决这个问题。至于第一种么……我感觉，LeetCode之所以是LeetCode，而不是CodeForces或者UVa或者POJ，比较关键的一点，就是它是给测试数据的，这一点接近于真实的面试环境，而不是ACM环境。（至于其他的点，我觉得LeetCode的社区环境也不错。）反正我做LeetCode Contest而不是CodeForces Contest的最主要的原因就是比赛时也能调试。（其他原因包括时间固定且合适。） 其他感受 这场比赛有种很social的感觉，每人都要做自我介绍什么的……我也藉此了解了几位题解区常见选手，嗯，大家都很强（而且都挺nice的）。能和他们一起参加这场比赛，我感到很荣幸。 发了1000个LeetCoin。不知道啥时候才能攒到换一件衣服。 今天我发现我的rating掉了（因为在正式比赛里我的成绩算是0分）。我对此感觉不是很满意，不更新rating我觉得是合理的，rating掉了算啥情况。。。","categories":[],"tags":[{"name":"Essay","slug":"Essay","permalink":"https://zhanghuimeng.github.io/tags/Essay/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 952. Largest Component Size by Common Factor（图）","slug":"2018-12-02-Leetcode-952-Largest-Component-Size-by-Common-Factor（图）","date":"2018-12-02T15:00:31.000Z","updated":"2018-12-02T16:37:00.000Z","comments":true,"path":"post/leetcode-952-largest-component-size-by-common-factor/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-952-largest-component-size-by-common-factor/","excerpt":"","text":"题目来源：https://leetcode.com/problems/largest-component-size-by-common-factor/description/ 标记难度：Hard 提交次数：7/8 代码效率： 埃式筛法，map存储分解结果，普通并查集：1324ms 埃式筛法，map存储分解结果，size优化并查集：1452, 1848ms 欧拉筛法，map存储分解结果，普通并查集：TLE, 1868ms 埃式筛法（减少素数），map存储分解结果，普通并查集：144ms 素数打表，map存储分解结果，普通并查集：132ms 素数打表，手写链表，普通并查集：132ms 题意 给定一些结点，每个结点上有一个值，令两个结点有边相连当且仅当上面的值有大于1的公因子。问图中最大的连通分量的大小。 结点数量在[1, 20000]范围内，值的大小在[1, 100000]范围内。 分析 这道题有一个显然的做法： 首先打一个质数表。 我之前认为需要打[1, 100000]范围内的质数（事实证明，一共有九千多个），但事实上不需要，只要打[1, sqrt(100000)]范围内的素数就可以了。在做质因数分解的时候，如果用上述范围内的质数没能约到1，则剩下的数必然是个大素数，不需要打表打到这个范围。 打表可以用埃式筛法或者欧拉筛法（我之前在某次模拟赛中做过类似的题）。 然后对每个数值作质因数分解，对每个质数开一个链表（或者类似的结构），如果一个质数是某个数的因数，就把这个数（的index）放到链表中。 然后对每条链表中的值在并查集中作合并操作。 最后找出并查集中最大的集合。 然后可以进行一些优化： 换成欧拉筛法（结果耗时反而变多了） 对并查集进行size优化（结果耗时反而变多了） 只打sqrt(100000)范围内的质数表（耗时骤降，变成约10%） 手工打质数表（耗时稍微减少） map换成手写链表（耗时居然没变） 想到算法的复杂度实际上是O(NP)，少遍历质数表好像的确能降低复杂度…… 以及我在评论区里看到一个直接在做欧拉筛的时候进行合并的方法[1]，非常简洁（但好像没有我快？看来打整张质数表还是太耗费时间了）。 代码 这次提交了很多版本的代码，这里放两个最快的好了。 map版本 132ms。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class Solution &#123;private: // 并查集 int _fa[20005]; int _size[20005]; int n; void init() &#123; for (int i = 0; i &lt; n; i++) &#123; _fa[i] = i; _size[i] = 1; &#125; &#125; int fa(int x) &#123; if (_fa[x] == x) return x; _size[_fa[x]] += _size[x]; _size[x] = 0; return _fa[x] = fa(_fa[x]); &#125; int merge(int x, int y) &#123; x = fa(x); y = fa(y); if (_size[x] &lt; _size[y]) swap(x, y); _fa[y] = x; return fa(y); &#125; int size(int x) &#123; x = fa(x); return _size[x]; &#125; public: int largestComponentSize(vector&lt;int&gt;&amp; A) &#123; int primes[] = &#123;2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317&#125;; int m = sizeof(primes) / sizeof(int); // 质因数分解，插入对应的vector map&lt;int, vector&lt;int&gt;&gt; primeMap; n = A.size(); for (int i = 0; i &lt; n; i++) &#123; int x = A[i]; int j = 0; while (j &lt; m) &#123; if (x == 1) break; while (j &lt; m &amp;&amp; x % primes[j] != 0) j++; if (j &gt;= m) break; while (x % primes[j] == 0) x /= primes[j]; primeMap[primes[j]].push_back(i); j++; &#125; if (x != 1) primeMap[x].push_back(i); &#125; // 合并每个质因数对应的所有数 init(); for (auto const&amp; p: primeMap) &#123; if (p.second.size() &gt; 1) &#123; int fa0 = fa(p.second[0]); for (int i = 1; i &lt; p.second.size(); i++) &#123; fa0 = merge(fa0, p.second[i]); &#125; &#125; &#125; // 找到最大的集合，输出结果 int maxn = -1; for (int i = 0; i &lt; n; i++) maxn = max(maxn, size(i)); return maxn; &#125;&#125;; 链表版本 也是132ms。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293class Solution &#123;private: // 并查集 int _fa[20005]; int _size[20005]; int n; void init() &#123; for (int i = 0; i &lt; n; i++) &#123; _fa[i] = i; _size[i] = 1; &#125; &#125; int fa(int x) &#123; if (_fa[x] == x) return x; _size[_fa[x]] += _size[x]; _size[x] = 0; return _fa[x] = fa(_fa[x]); &#125; int merge(int x, int y) &#123; x = fa(x); y = fa(y); if (_size[x] &lt; _size[y]) swap(x, y); _fa[y] = x; return fa(y); &#125; int size(int x) &#123; x = fa(x); return _size[x]; &#125; // 链表 struct Node &#123; int val; Node* next; Node(int x) &#123; val = x; next = NULL; &#125; &#125;; Node* heads[100000]; inline void insert(int prime, int i) &#123; Node* node = new Node(i); node-&gt;next = heads[prime]; heads[prime] = node; &#125; public: int largestComponentSize(vector&lt;int&gt;&amp; A) &#123; int primes[] = &#123;2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317&#125;; int m = sizeof(primes) / sizeof(int); // 质因数分解，插入对应链表 n = A.size(); memset(heads, 0, sizeof(heads)); for (int i = 0; i &lt; n; i++) &#123; int x = A[i]; int j = 0; while (j &lt; m) &#123; if (x == 1) break; while (j &lt; m &amp;&amp; x % primes[j] != 0) j++; if (j &gt;= m) break; while (x % primes[j] == 0) x /= primes[j]; insert(primes[j], i); j++; &#125; if (x != 1) insert(x, i); &#125; // 合并每个质因数对应的所有数 init(); for (int i = 2; i &lt; 100000; i++) &#123; if (heads[i] != NULL) &#123; int fa0 = fa(heads[i]-&gt;val); Node* p = heads[i]-&gt;next; for (p != NULL; p != NULL; p = p-&gt;next) &#123; fa0 = merge(fa0, p-&gt;val); &#125; &#125; &#125; // 找到最大的集合，输出结果 int maxn = -1; for (int i = 0; i &lt; n; i++) maxn = max(maxn, size(i)); return maxn; &#125;&#125;; groawr’s Solution for Leetcode 952 - C++ Sieve of Erastosthenes ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Graph","slug":"alg-Graph","permalink":"https://zhanghuimeng.github.io/tags/alg-Graph/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Union-find Forest","slug":"alg-Union-find-Forest","permalink":"https://zhanghuimeng.github.io/tags/alg-Union-find-Forest/"}]},{"title":"Leetcode 951. Flip Equivalent Binary Trees（树）","slug":"2018-12-02-Leetcode-951-Flip-Equivalent-Binary-Trees（树）","date":"2018-12-02T13:19:02.000Z","updated":"2018-12-02T14:44:00.000Z","comments":true,"path":"post/leetcode-951-flip-equivalent-binary-trees/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-951-flip-equivalent-binary-trees/","excerpt":"","text":"题目来源：https://leetcode.com/problems/flip-equivalent-binary-trees/description/ 标记难度：Medium 提交次数：1/1 代码效率：4ms 题意 对二叉树定义flip操作：任取一个结点，然后交换它的左子树和右子树。给定两棵二叉树，问经过flip操作后能否使这两棵树相等。 分析 题解[1]中的第一种做法是递归：先判断根是否相等，然后分两种情况进行判断：左子树、右子树分别相等，或者左子树等于右子树，右子树等于左子树。这种做法肯定是对的，但它的复杂度怎么分析呢？不妨设N=2m−1N = 2^m - 1N=2m−1，为满二叉树，时间复杂度为T(N)T(N)T(N)。则 $$T(N) = O(1) + 4T((N-1)/2), \\, T(1)=O(1)$$ 即 $$ \\begin{aligned} T(2^m - 1) =& O(1) + 4T(2^{m-1}-1) \\\\ =& O(1) + O(1) + 2^4T(2^{m-2}-1) \\\\ =& \\cdots \\\\ =& (m-1) O(1) + 2^{2(m-1)}T(1) \\\\ =& O(N^2) \\end{aligned} $$ 分析出来的时间复杂度是O(N^2)，我觉得题解写错了。 第二种做法（也是我的做法）大概更好：为二叉树定义一种“小于”的概念，然后把更小的子树都换到左边，再比较两棵树是否相等；这样每棵树都对应一棵唯一等价的树。当然，这道题规定结点的值都是唯一的，这使得定义方法简化了。如果结点的值可能相等，那仍然大概需要递归定义。比如，先比较根节点的大小，如果相等则递归比较左子树的大小，比较不出来则再比较右子树，什么之类的。 代码 12345678910111213141516171819202122232425262728293031class Solution &#123; void flip(TreeNode* root) &#123; if (root == NULL) return; TreeNode* left = root-&gt;left; TreeNode* right = root-&gt;right; flip(left); flip(right); if (left == NULL &amp;&amp; right == NULL || left != NULL &amp;&amp; right == NULL) return; if (left == NULL &amp;&amp; right != NULL || left-&gt;val &gt; right-&gt;val) &#123; swap(root-&gt;left, root-&gt;right); return; &#125; return; &#125; bool equal(TreeNode* root1, TreeNode* root2) &#123; if (root1 == NULL || root2 == NULL) return root1 == NULL &amp;&amp; root2 == NULL; if (root1-&gt;val != root2-&gt;val) return false; return equal(root1-&gt;left, root2-&gt;left) &amp;&amp; equal(root1-&gt;right, root2-&gt;right); &#125;public: bool flipEquiv(TreeNode* root1, TreeNode* root2) &#123; // always flip the sub-tree with smaller integer left // and flip null right. flip(root1); flip(root2); return equal(root1, root2); &#125;&#125;; LeetCode Official Solution for 951 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 950. Reveal Cards In Increasing Order（数组）","slug":"2018-12-02-Leetcode-950-Reveal-Cards-In-Increasing-Order（数组）","date":"2018-12-02T12:48:25.000Z","updated":"2018-12-02T13:13:00.000Z","comments":true,"path":"post/leetcode-950-reveal-cards-in-increasing-order/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-950-reveal-cards-in-increasing-order/","excerpt":"","text":"题目来源：https://leetcode.com/problems/reveal-cards-in-increasing-order/description/ 标记难度：Medium 提交次数：2/2 代码效率：8ms 题意 有一叠卡片，每张卡片上写着各不相同的数字。对卡片叠重复进行如下操作： 拿出叠顶卡片，记录上面的值 （如果卡片叠非空）把下一张叠顶的卡片放到叠底 问把卡片以什么顺序叠放，才能使得记录的值是顺序递增的？ 分析 其实这道题只要仔细想并不难。用映射的方法来解释比较好。不妨先假设我们拿的是一摞从上到下是1, 2, 3, 4, 5, 6, 7的卡片。进行操作（操作过程略）后，得到的值为1, 3, 5, 7, 4, 2, 6。因此，我们可以得到一张卡片在原来的叠中的index -&gt; 卡片在记录的值中的index的映射表σ\\sigmaσ： 1 2 3 4 5 6 7 1 3 5 7 4 2 6 不妨假设我们的卡片开始时已经排好序了，也就是说，我们期望所有卡片在记录的值中的index顺序是1, 2, …, 7。此时只需应用上述映射表的逆映射σ−1\\sigma^{-1}σ−1，即可得到满足这种性质的卡片在原来的叠中应有的index顺序： 1 2 3 4 5 6 7 1 6 2 5 3 7 4 以及，我本来以为是要返回卡片index的一个order的——也就是说，我们还需要记录卡片排序前后的index映射表——吓死我了。原来直接返回卡片的值就好了。不过，这也不过是多加一个映射而已…… 代码 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; deckRevealedIncreasing(vector&lt;int&gt;&amp; deck) &#123; // get the mapping queue&lt;int&gt; q; int n = deck.size(); int ord2rev[n]; for (int i = 0; i &lt; n; i++) q.push(i); for (int i = 0; i &lt; n; i++) &#123; int x = q.front(); q.pop(); ord2rev[x] = i; if (!q.empty()) &#123; x = q.front(); q.pop(); q.push(x); &#125; &#125; // sort sort(deck.begin(), deck.end()); // apply reversed mapping vector&lt;int&gt; ans; for (int i = 0; i &lt; n; i++) ans.push_back(deck[ord2rev[i]]); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 949. Largest Time for Given Digits（暴力），及周赛（113）总结","slug":"2018-12-02-Leetcode-949-Largest-Time-for-Given-Digits（暴力），及周赛（113）总结","date":"2018-12-02T12:30:04.000Z","updated":"2018-12-02T12:45:00.000Z","comments":true,"path":"post/leetcode-949-largest-time-for-given-digits-and-weekly-contest-113/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-949-largest-time-for-given-digits-and-weekly-contest-113/","excerpt":"","text":"题目来源：https://leetcode.com/problems/largest-time-for-given-digits/description/ 标记难度：Easy 提交次数：1/2 代码效率：4ms 题意 给定4个数字，求出能用这些数字排列成的最大时间（24小时制）。 分析 这次我没参加正式比赛，因为我参加internal contest去了。很有趣，而且有很多感受，我可以再写一篇文章出来了……internal contest虽然人少，也是有计时和排名的，我看了一下，我在正式比赛中大概能排在50-100名左右吧。 这道题看起来很简单，因为“时间”这个属性限制了解的数量，这使得暴力方法非常适用；这一点让我想起之前做的Leetcode 401. Binary Watch，也是暴力方法优于搜索方法的例子。反正就是枚举这4个数字的排列，然后从中选出合法且最大的时间。 但是这道题的通过率相当低（虽然通过的人数显然不低）。（我猜）这是因为很多人都没有处理时间数字前面带0的情况，于是在[0, 0, 0, 0]这样的样例中就挂了。我很难想到什么保证自己能想到这样的corner case的例子，也许只能多练吧。 代码 12345678910111213141516171819class Solution &#123;public: string largestTimeFromDigits(vector&lt;int&gt;&amp; A) &#123; sort(A.begin(), A.end()); int maxtime = -1; string time; do &#123; int hour = A[0] * 10 + A[1]; if (hour &gt;= 24) continue; int minute = A[2] * 10 + A[3]; if (minute &gt;= 60) continue; if (hour * 100 + minute &gt; maxtime) &#123; maxtime = hour * 100 + minute; time = to_string(A[0]) + to_string(A[1]) + \":\" + to_string(A[2]) + to_string(A[3]); &#125; &#125; while (next_permutation(A.begin(), A.end())); return time; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode水题合集","slug":"2020-01-01-Leetcode水题合集","date":"2018-11-28T09:22:54.000Z","updated":"2019-02-09T19:29:00.000Z","comments":true,"path":"post/leetcode-easy-questions/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-easy-questions/","excerpt":"","text":"嗯，即使是我，最终也会发现Leetcode中有些题太水了而不值得专门写一篇post，有些题太愚蠢了而不值得专门写一篇post，等等。但有时候还是有一些可写的东西，所以就放在这里好了。 在LeetCode中卡时 点开0ms Solution的时候常常会见到这样一段： 12345static int speedup=[]()&#123; ios_base::sync_with_stdio(false); cin.tie(nullptr); return 0;&#125;(); 函数内部的内容很好理解：关闭C和C++标准输入输出流的同步，并且将cin和cout解除绑定（在切换时不再自动flush）。[1]但外面包的那一堆看起来很不好懂。事实上这是一个立即执行的Lambda表达式。[2] 简单来说，Lambda表达式的一种形式是[captures] (params) {body}，此时返回值是由return语句推导的。例子： 123456789101112131415// 泛型 lambda ， operator() 是有二个形参的模板auto glambda = [](auto a, auto&amp;&amp; b) &#123; return a &lt; b; &#125;;bool b = glambda(3, 3.14); // ok// 泛型 lambda ， operator() 是有一个形参的模板auto vglambda = [](auto printer) &#123; return [=](auto&amp;&amp;... ts) // 泛型 lambda ， ts 是形参包 &#123; printer(std::forward&lt;decltype(ts)&gt;(ts)...); return [=] &#123; printer(ts...); &#125;; // 空型 lambda （不接收参数） &#125;;&#125;;auto p = vglambda([](auto v1, auto v2, auto v3) &#123; std::cout &lt;&lt; v1 &lt;&lt; v2 &lt;&lt; v3; &#125;);auto q = p(1, 'a', 3.14); // 输出 1a3.14q(); // 输出 1a3.14 所以上图就是一个没有参数、返回值为0且立即执行的Lambda表达式。之所以要写成这样好像也很容易理解，全局变量会先初始化，此时就可以在开始真正的输入输出之前进行优化了。如果直接写到函数里，那这个时候都已经完成读入了…… （感谢rd同学告诉我那是个Lambda函数） 17. Letter Combinations of a Phone Number 题目来源：https://leetcode.com/problems/letter-combinations-of-a-phone-number/description/ 难度：Medium 知识点：字符串 把数字串映射到字母串，每个数字的映射方法是电话按键（例：2 -&gt; abc），问一共有多少种可能的映射方法。 直接……做就……好了。 以及，能不硬编码就不要硬编码…… 12345678910111213141516171819class Solution &#123;public: vector&lt;string&gt; letterCombinations(string digits) &#123; if (digits.size() == 0) return &#123;&#125;; vector&lt;string&gt; ans = &#123;\"\"&#125;; vector&lt;string&gt; a2; vector&lt;string&gt; maps = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; for (char c: digits) &#123; for (string x: ans) &#123; for (char a: maps[c - '0']) a2.push_back(x + a); &#125; swap(ans, a2); a2.clear(); &#125; return ans; &#125;&#125;; 23. Merge k Sorted Lists 题目来源：https://leetcode.com/problems/merge-k-sorted-lists/description/ 难度：Hard 知识点：优先队列 多个有序链表合并。和有序数组合并非常相似，直接用优先队列就好了。 12345678910111213141516171819202122232425class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; ListNode* head = nullptr, *p = nullptr; priority_queue&lt;pair&lt;int, ListNode*&gt;&gt; pq; for (ListNode* q: lists) &#123; if (q != nullptr) pq.emplace(-q-&gt;val, q); &#125; while (!pq.empty()) &#123; ListNode* q = pq.top().second; pq.pop(); if (head == nullptr) &#123; head = p = q; &#125; else &#123; p-&gt;next = q; p = p-&gt;next; &#125; q = q-&gt;next; if (q != nullptr) pq.emplace(-q-&gt;val, q); &#125; return head; &#125;&#125;; 50. Pow(x, n) 题目来源：https://leetcode.com/problems/powx-n/description/ 难度：Medium 知识点：快速幂 这道题的有趣之处是增加了对负数幂的考察（当然这也不是很难）。不过，在-2147483648上卡一下还是令人不那么愉快…… 123456789101112131415class Solution &#123;public: double myPow(double x, int n) &#123; if (n == -2147483648) &#123; double y = myPow(x, n / 2); return y * y; &#125; if (n &lt; 0) return myPow(1 / x, -n); if (n == 0) return 1; if (n == 1) return x; double y = myPow(x * x, n / 2); if (n % 2 == 0) return y; else return y * x; &#125;&#125;; 54. Spiral Matrix 题目来源：https://leetcode.com/problems/spiral-matrix/description/ 难度：Medium 知识点：数组 题意就是绕着一个二维数组矩形向里转圈。比较平凡的做法是开一个布尔数组当做是墙；稍微好一点的做法就是维护每侧已经被访问的厚度。总之也不是很难。 12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; // 又卡了一下大小为0的矩阵…… if (matrix.size() == 0) return &#123;&#125;; int n1 = 0, n2 = matrix.size() - 1, m1 = 0, m2 = matrix[0].size() - 1; int mx[4] = &#123;0, 1, 0, -1&#125;, my[4] = &#123;1, 0, -1, 0&#125;; int k = 0; int r = 0, c = 0; vector&lt;int&gt; ans; while (n1 &lt;= n2 &amp;&amp; m1 &lt;= m2) &#123; // cout &lt;&lt; r &lt;&lt; ' ' &lt;&lt; c &lt;&lt; endl; ans.push_back(matrix[r][c]); int nr = r + mx[k]; int nc = c + my[k]; if (nr &lt; n1 || nr &gt; n2 || nc &lt; m1 || nc &gt; m2) &#123; if (k == 0) n1++; if (k == 1) m2--; if (k == 2) n2--; if (k == 3) m1++; k = (k + 1) % 4; nr = r + mx[k]; nc = c + my[k]; &#125; r = nr; c = nc; &#125; return ans; &#125;&#125;; 66. Plus One 题目来源：https://leetcode.com/problems/plus-one/description/ 难度：Easy 知识点：高精度加法 简化版的高精度加法，只考虑+1的情况。唯一的问题可能是在于，数组是正序给的，首位进位稍微有点麻烦。（当然，也可以说：传参是引用，不要直接在参数上改。） 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int n = digits.size(); digits[n-1]++; for (int i = n - 1; i &gt; 0; i--) &#123; digits[i - 1] += digits[i] / 10; digits[i] %= 10; &#125; if (digits[0] &gt;= 10) &#123; digits.insert(digits.begin(), digits[0] / 10); digits[1] %= 10; &#125; return digits; &#125;&#125;; 108. Convert Sorted Array to Binary Search Tree 题目来源：https://leetcode.com/problems/convert-sorted-array-to-binary-search-tree/description/ 难度：Easy 知识点：Tree 这道题要求把一个排序好的序列转成一棵二叉搜索树，且这棵树是平衡的（任意一个结点的两棵子树的深度之差不超过1）。方法就是每次尽量把序列分成相等的两半，如果不相等右侧多一个结点也没关系。 1234567891011121314151617class Solution &#123;private: TreeNode* dfs(int l, int r, vector&lt;int&gt;&amp; nums) &#123; if (l == r) return new TreeNode(nums[l]); if (l &gt; r) return NULL; int m = (l + r) / 2; TreeNode* root = new TreeNode(nums[m]); root-&gt;left = dfs(l, m - 1, nums); root-&gt;right = dfs(m + 1, r, nums); return root; &#125; public: TreeNode* sortedArrayToBST(vector&lt;int&gt;&amp; nums) &#123; return dfs(0, nums.size() - 1, nums); &#125;&#125;; 139. Word Break 题目来源：https://leetcode.com/problems/word-break/description/ 难度：Medium 知识点：DP 问给定的一组字符串能否拼成另一个字符串。很简单的DP。我闲的没事干所以写了个Trie…… 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;private: struct TrieNode &#123; bool isEnd; TrieNode* ch[26]; TrieNode() &#123; isEnd = false; memset(ch, 0, sizeof(ch)); &#125; &#125;; public: bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; TrieNode* root = new TrieNode(); for (string word: wordDict) &#123; TrieNode* p = root; for (char c: word) &#123; if (p-&gt;ch[c - 'a'] == NULL) p-&gt;ch[c - 'a'] = new TrieNode(); p = p-&gt;ch[c - 'a']; &#125; p-&gt;isEnd = true; &#125; int n = s.length(); bool f[n + 1]; memset(f, 0, sizeof(f)); for (int i = 0; i &lt; n; i++) &#123; if (i != 0 &amp;&amp; !f[i - 1]) continue; TrieNode* p = root; for (int j = i; j &lt; n; j++) &#123; p = p-&gt;ch[s[j] - 'a']; if (p == NULL) break; if (p-&gt;isEnd) f[j] = true; &#125; &#125; return f[n-1]; &#125;&#125;; 140. Word Break II 题目来源：https://leetcode.com/problems/word-break-ii/description/ 难度：Hard 知识点：DP 这道题和上一道的区别是，要求把全部可能的组成方式都打出来——不过，这仍然是一道DP，至少需要记忆化的思想，因为直接递归打印是会超时的。（以及这道题的Solution要求suscribe，我看不到。） 123456789101112131415161718192021222324class Solution &#123;private: map&lt;string, vector&lt;string&gt;&gt; f; public: vector&lt;string&gt; wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; if (f.find(s) != f.end()) return f[s]; vector&lt;string&gt; ans; for (string word: wordDict) &#123; if (word.length() &lt;= s.length() &amp;&amp; s.substr(0, word.length()) == word) &#123; // cout &lt;&lt; word &lt;&lt; endl; if (word == s) ans.push_back(word); else &#123; vector&lt;string&gt; a = wordBreak(s.substr(word.length(), s.length() - word.length()), wordDict); for (string x: a) ans.push_back(word + ' ' + x); &#125; &#125; &#125; f[s] = ans; return ans; &#125;&#125;; 237. Delete Node in a Linked List 题目来源：https://leetcode.com/problems/delete-node-in-a-linked-list/description/ 难度：Easy 知识点：链表 这道题的傻逼之处在于，明明是要删除链表中的结点，最后却变成了（不得不）交换链表中结点的值，这一点也不科学。我的第一个想法是把给定结点（node）之后的值依次前移然后删掉最后一个结点；题解中给出了只需赋值一次的方法，把node-&gt;val替换成node-&gt;next-&gt;val，node-&gt;next也替换成node-&gt;next-&gt;next。但这方法仍然不怎么样。 123456789101112class Solution &#123;public: void deleteNode(ListNode* node) &#123; ListNode* p = node; while (p-&gt;next != nullptr) &#123; p-&gt;val = p-&gt;next-&gt;val; if (p-&gt;next-&gt;next == nullptr) break; p = p-&gt;next; &#125; p-&gt;next = nullptr; &#125;&#125;; 463. Island Perimeter 题目来源：https://leetcode.com/problems/island-perimeter/description/ 难度：Easy 知识点：图 这道题都明确给出了，地图上有且只有一个方格组成的岛，那就直接判断每个方块有几条边框和水邻接就可以了。 123456789101112131415161718class Solution &#123; public: int islandPerimeter(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; if (grid.size() == 0) return 0; int n = grid.size(), m = grid[0].size(); int ans = 0; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (grid[i][j] == 0) continue; if (i == 0 || grid[i-1][j] == 0) ans++; if (i == n -1 || grid[i+1][j] == 0) ans++; if (j == 0 ||grid[i][j-1] == 0) ans++; if (j == m - 1 || grid[i][j+1] == 0) ans++; &#125; &#125; return ans; &#125;&#125;; 657. Robot Return to Origin 题目来源：https://leetcode.com/problems/robot-return-to-origin/description/ 难度：Easy 知识点：字符串 给定一个机器人上下左右移动的路线，问机器人最后有没有回到原来的位置。第一想法是模拟，自然是能过的；不过事实上，回到原点这件事等价于上下位移为0且左右位移为0，所以直接判断位移量就行了。 12345678910111213class Solution &#123;public: bool judgeCircle(string moves) &#123; int x = 0, y = 0; for (char ch: moves) &#123; if (ch == 'R') y++; if (ch == 'L') y--; if (ch == 'U') x--; if (ch == 'D') x++; &#125; return x == 0 &amp;&amp; y == 0; &#125;&#125;; 832. Flipping an Image 题目来源：https://leetcode.com/problems/flipping-an-image/description/ 难度：Easy 知识点：数组 把一个二维数组表示的图片先翻转再反色。没什么特别好说的。 123456789101112131415class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; flipAndInvertImage(vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; int n = A.size(), m = A[0].size(); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m - j - 1; j++) swap(A[i][j], A[i][n - j - 1]); &#125; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) A[i][j] = 1 - A[i][j]; &#125; return A; &#125;&#125;; 840. Magic Squares In Grid 题目来源：https://leetcode.com/problems/magic-squares-in-grid/description/ 难度：Easy 知识点：数组 （数组是知识点不就相当于没有吗） 这道题就是在一个二维数组里寻找所有可能的三阶幻方。因为判断条件比较多，而三阶幻方的阶数又很小，不如直接对每个3x3的方框进行暴力判断。我写了横纵和的递推，当然事实上对角线之和，以及各个数字的出现次数这些都能递推，但就三阶幻方而言，这么做太大张旗鼓了，还不如直接暴力算了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123;public: int numMagicSquaresInside(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int n = grid.size(), m = grid[0].size(); if (n &lt; 3 || m &lt; 3) return 0; int ans = 0; int downSum[n][m], rightSum[n][m]; for (int i = 0; i &lt; m; i++) downSum[0][i] = grid[0][i] + grid[1][i] + grid[2][i]; for (int i = 1; i &lt;= n - 3; i++) for (int j = 0; j &lt; m; j++) downSum[i][j] = downSum[i-1][j] - grid[i-1][j] + grid[i+2][j]; for (int i = 0; i &lt; n; i++) rightSum[i][0] = grid[i][0] + grid[i][1] + grid[i][2]; for (int i = 0; i &lt; n; i++) for (int j = 1; j &lt;= m - 3; j++) rightSum[i][j] = rightSum[i][j-1] - grid[i][j-1] + grid[i][j+2]; int f[20]; for (int i = 0; i &lt;= n - 3; i++) for (int j = 0; j &lt;= m - 3; j++) &#123; int sum = rightSum[i][j]; if (rightSum[i+1][j] != sum || rightSum[i+2][j] != sum || downSum[i][j] != sum || downSum[i][j+1] != sum || downSum[i][j+2] != sum) continue; if (grid[i][j] + grid[i+1][j+1] + grid[i+2][j+2] != sum || grid[i+2][j] + grid[i+1][j+1] + grid[i][j+2] != sum) continue; memset(f, 0, sizeof(f)); for (int i1 = 0; i1 &lt; 3; i1++) for (int j1 = 0; j1 &lt; 3; j1++) f[grid[i+i1][j+j1]]++; bool ok = true; for (int k = 1; k &lt;= 9; k++) if (f[k] != 1) &#123; ok = false; break; &#125; if (!ok) continue; ans++; &#125; return ans; &#125;&#125;; 852. Peak Index in a Mountain Array 题目来源：https://leetcode.com/problems/peak-index-in-a-mountain-array/description/ 难度：Easy 知识点：数组，二分查找 （根本就没有把二分查找用在这种题目上的必要……） 2018.11.28 UPDATE：这道题有一道Follow Up（Leetcode 162）；不应该说二分查找完全没有意义，毕竟可以把复杂度降到log…… 题意是，给定一个单增再单减的数组，问最大值的元素对应的index。 直接扫一遍找到第一个开始单减的数就好了…… 12345678910class Solution &#123;public: int peakIndexInMountainArray(vector&lt;int&gt;&amp; A) &#123; for (int i = 1; i &lt; A.size(); i++) &#123; if (!(A[i] &gt; A[i - 1])) return i - 1; &#125; return -1; &#125;&#125;; 859. Buddy Strings 题目来源：https://leetcode.com/problems/buddy-strings/description/ 难度：Easy 知识点：字符串 这道题就是给你两个字符串，让你判断交换其中一个字符串的两个字母之后两个字符串能否相等。很简单，不过有一些细节，比如，如果两个字符串相等但是每种字母最多只有一个，则不能通过交换使得这两个字符串相等（虽然它们本来就是相等的）。 123456789101112131415161718192021222324class Solution &#123;public: bool buddyStrings(string A, string B) &#123; int n = A.length(); if (n != B.length()) return false; int differCnt = 0, dif[2]; int cnt[26]; memset(cnt, 0, sizeof(cnt)); for (int i = 0; i &lt; n; i++) &#123; cnt[A[i] - 'a']++; if (A[i] != B[i]) &#123; if (differCnt &gt;= 2) return false; dif[differCnt++] = i; &#125; &#125; if (differCnt == 1) return false; if (differCnt == 2 &amp;&amp; A[dif[0]] == B[dif[1]] &amp;&amp; A[dif[1]] == B[dif[0]]) return true; if (differCnt == 0) &#123; for (int i = 0; i &lt; 26; i++) if (cnt[i] &gt;= 2) return true; &#125; return false; &#125;&#125;; stackoverflow - Significance of ios_base::sync_with_stdio(false); cin.tie(NULL); ↩︎ cppreference - Lambda 表达式 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Linked List","slug":"alg-Linked-List","permalink":"https://zhanghuimeng.github.io/tags/alg-Linked-List/"}]},{"title":"Leetcode 947. Most Stones Removed with Same Row or Column（DFS）","slug":"2018-11-25-Leetcode-947-Most-Stones-Removed-with-Same-Row-or-Column（DFS）","date":"2018-11-25T15:48:42.000Z","updated":"2018-11-25T17:01:00.000Z","comments":true,"path":"post/leetcode-947-most-stones-removed-with-same-row-or-column/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-947-most-stones-removed-with-same-row-or-column/","excerpt":"","text":"题目来源：https://leetcode.com/problems/most-stones-removed-with-same-row-or-column/description/ 标记难度：Medium 提交次数：1/1 代码效率：40ms 题意 给定一个2D平面和一些位于自然数坐标上的小石子（坐标不会重复）；如果某个石子和其他石子位于同一行同一列上，则可以把它移除；问最多能移走多少个小石子。 分析 比赛的时候我想了很久也没想出来……（然后就去吃饭了）。我的确想到了把在同一行同一列上的石子都连起来然后找连通子图数量这种做法，但我竟然觉得它有反例……（现在我已经知道我当初是怎么想错的了） 第一个问题是怎么证明一个大的连通子图一定能reduce成一颗石子。我感觉这并不是一件显然的事情。 （嗯，确实没有那么显然……） 一种方法是，构造一颗这个子树的生成树。（从一个无向连通图能够生成一颗生成树这件事应该够显然的了）然后不断移除这棵树的叶子结点，直到最后只剩下根结点。[1] 当然，事实上不需要真的把这些都构造出来，只要知道就可以了。 然后我感觉直接DFS就可以了……并查集当然也可以。 代码 懒得写并查集了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution &#123;private: int n; vector&lt;pair&lt;int, int&gt;&gt; stoneCoors; map&lt;int, vector&lt;int&gt;&gt; rows, cols; set&lt;int&gt; rowsVisited, colsVisited; void dfs(int x, int r, int c) &#123; // cout &lt;&lt; x &lt;&lt;' ' &lt;&lt; r &lt;&lt; ' ' &lt;&lt; c &lt;&lt; endl; if (rowsVisited.find(r) == rowsVisited.end()) &#123; rowsVisited.insert(r); for (int y: rows[r]) if (y != x &amp;&amp; colsVisited.find(stoneCoors[y].second) == colsVisited.end()) dfs(y, stoneCoors[y].first, stoneCoors[y].second); &#125; if (colsVisited.find(c) == colsVisited.end()) &#123; colsVisited.insert(c); for (int y: cols[c]) if (y != x &amp;&amp; rowsVisited.find(stoneCoors[y].first) == rowsVisited.end()) dfs(y, stoneCoors[y].first, stoneCoors[y].second); &#125; &#125; public: int removeStones(vector&lt;vector&lt;int&gt;&gt;&amp; stones) &#123; n = stones.size(); for (int i = 0; i &lt; n; i++) &#123; stoneCoors.emplace_back(stones[i][0], stones[i][1]); &#125; sort(stoneCoors.begin(), stoneCoors.end()); for (int i = 0; i &lt; n; i++) &#123; rows[stoneCoors[i].first].push_back(i); cols[stoneCoors[i].second].push_back(i); &#125; int ans = 0; for (int i = 0; i &lt; n; i++) &#123; if (rowsVisited.find(stoneCoors[i].first) == rowsVisited.end() || colsVisited.find(stoneCoors[i].second) == colsVisited.end()) &#123; // cout &lt;&lt; i &lt;&lt; endl; ans++; dfs(i, stoneCoors[i].first, stoneCoors[i].second); &#125; &#125; return n - ans; &#125;&#125;; Leetcode Official Solution for 947. Most Stones Removed with Same Row or Column ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Union-find Forest","slug":"alg-Union-find-Forest","permalink":"https://zhanghuimeng.github.io/tags/alg-Union-find-Forest/"}]},{"title":"Leetcode 948. Bag of Tokens（贪心）","slug":"2018-11-25-Leetcode-948-Bag-of-Tokens（贪心）","date":"2018-11-25T15:18:56.000Z","updated":"2018-11-25T15:18:56.000Z","comments":true,"path":"post/leetcode-948-bag-of-tokens/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-948-bag-of-tokens/","excerpt":"","text":"题目来源：https://leetcode.com/problems/validate-stack-sequences/description/ 标记难度：Medium 提交次数：1/1 代码效率：4ms 题意 你有两个属性：power和points（初始为0），并且有一些token，每个token自己有一个值（token[i]）。你可以对一个token做如下两种操作之一（或者可以什么都不做）： face up：如果你的power &gt;= token[i]，则可以令power -= token[i]，且points++ face down：如果你的points &gt; 0，则可以令power += token[i]，且points-- 问你可以用这些token达到的最大points数量是多少。 分析 我当时想了好久，怎么平衡两类token的数量（并得到一个合法的操作序列）之类的。但总的来说肯定是这样的：为了最大化points，肯定face up的token的数量越多越好，face down的token的数量越少越好。那么显然需要face up的token的值尽可能小，face down的token的值尽可能大。虽然不知道贪心是不是对的，但不妨先写一个看看……嗯，过了。 贪心的思路就很直接，先把token排序，然后小token从小到大尝试置为face up，直到power不够位置；然后尝试把一个最大的token置为face down，再接着试剩下的小token，以此类推…… 每次Leetcode出这样的题，题解里也不给个形式证明，就很烦。（事实上我感觉贪心几乎是所有算法题里唯一需要形式化证明算法正确性的。）我觉得这可以用stay ahead[1]方法：记算法的每一步操作为A={a1,a2,...,ak}A = \\{a_1, a_2, ..., a_k\\}A={a1​,a2​,...,ak​}，最优解的每一步操作为O={o1,o2,...,ok}O = \\{o_1, o_2, ..., o_k\\}O={o1​,o2​,...,ok​}；令f(⋅)=(points,power)f(\\cdot) = (points, power)f(⋅)=(points,power)为量度函数，规定 $$(points_A, power_A) > (points_B, power_B) \\iff \\begin{cases} points_A > points_B \\\\ points_A = points_B, \\quad power_A > power_B \\end{cases} $$ （就是规定了一个std::pair出来……） 下面用数学归纳法证明f(a1,...,ar)≥f(o1,...,or)f(a_1, ..., a_r) \\geq f(o_1, ..., o_r)f(a1​,...,ar​)≥f(o1​,...,or​)。对于第一步操作，由于贪心算法会尝试选择最小的token进行face down，如果能成功，则point数量会+1，且power数量减小最少，必然有f(a1)&gt;f(o1)f(a_1) &gt; f(o_1)f(a1​)&gt;f(o1​)；否则两种算法必然根本都无法行动。之后的操作也是同理。 代码 代码不重要，贪心比较重要。 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int bagOfTokensScore(vector&lt;int&gt;&amp; tokens, int P) &#123; int maxPoints = 0; int n = tokens.size(); sort(tokens.begin(), tokens.end()); int i = 0, j = n - 1; int power = P, points = 0; while (i &lt;= j) &#123; bool moved = false; // small face up while (tokens[i] &lt;= power &amp;&amp; i &lt;= j) &#123; power -= tokens[i]; points++; i++; moved = true; &#125; maxPoints = max(maxPoints, points); if (i &gt; j) break; // big face down if (points &gt; 0) &#123; power += tokens[j]; points--; j--; moved = true; &#125; if (!moved) break; &#125; return maxPoints; &#125;&#125;; CS 482 2003 - Proof Techniques: Greedy Stays Ahead ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 946. Validate Stack Sequences（栈）","slug":"2018-11-25-Leetcode-946-Validate-Stack-Sequences（栈）","date":"2018-11-25T15:09:53.000Z","updated":"2018-11-25T15:17:00.000Z","comments":true,"path":"post/leetcode-946-validate-stack-sequences/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-946-validate-stack-sequences/","excerpt":"","text":"题目来源：https://leetcode.com/problems/validate-stack-sequences/description/ 标记难度：Medium 提交次数：1/1 代码效率：4ms 题意 给定两个值两两不同的数组（pushed和popped），问它们能否是对一个初始为空的栈进行一系列操作的结果。 分析 一个水题，直接跟着这两个数组模拟就好了，模拟得出来就是可以，模拟不出来就是不行。（简直梦回NOIP普及组笔试题啊……） 代码 123456789101112131415161718class Solution &#123;public: bool validateStackSequences(vector&lt;int&gt;&amp; pushed, vector&lt;int&gt;&amp; popped) &#123; int n = pushed.size(); stack&lt;int&gt; s; int i = 0, j = 0; while (i &lt; n &amp;&amp; j &lt; n) &#123; while ((s.empty() || s.top() != popped[j]) &amp;&amp; i &lt; n) s.push(pushed[i++]); if (s.empty()) break; while (!s.empty() &amp;&amp; j &lt; n &amp;&amp; s.top() == popped[j]) &#123; s.pop(); j++; &#125; &#125; return i == n &amp;&amp; j == n; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 945. Minimum Increment to Make Array Unique（数组），及周赛（112）总结","slug":"2018-11-25-Leetcode-945-Minimum-Increment-to-Make-Array-Unique（数组）","date":"2018-11-25T13:40:38.000Z","updated":"2018-11-25T15:07:00.000Z","comments":true,"path":"post/leetcode-945-minimum-increment-to-make-array-unique-and-weekly-contest-112/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-945-minimum-increment-to-make-array-unique-and-weekly-contest-112/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-increment-to-make-array-unique/description/ 标记难度：Medium 提交次数：2/2 代码效率： 排序：104ms 计数：44ms 题意 给定一个数组A，可以对其中的数进行+1操作，返回能够使得A中所有元素两两不同的操作数量。 分析 这次比赛的题全都很简单，但是第三题我没有想出来……所以最后排名是248 / 3194。基本上彻底是拼手速了。 比赛的时候我的思路就是，先把A排序，然后按顺序判断当前的数是否还没被用过……如果没被用过就记录“下一个没被用的数”；否则将它设置为“下一个没被用的数”，并将这个数+1。然后这样想还是有些复杂；事实上直接和上一个数进行比较就可以了……（因为排序了）。[1]如果用类似于计数排序可以更快一些。[2]我感觉这有一点贪心的思路。 代码 排序 123456789101112131415161718class Solution &#123;public: int minIncrementForUnique(vector&lt;int&gt;&amp; A) &#123; if (A.size() == 0) return 0; sort(A.begin(), A.end()); int minn = A[0] + 1; long long int ans = 0; for (int i = 1; i &lt; A.size(); i++) &#123; if (A[i] &lt; minn) &#123; ans += minn - A[i]; A[i] = minn++; &#125; else minn = A[i] + 1; &#125; return ans; &#125;&#125;; 计数 12345678910111213141516171819class Solution &#123;public: int minIncrementForUnique(vector&lt;int&gt;&amp; A) &#123; int cnt[80005]; memset(cnt, 0, sizeof(cnt)); for (int x: A) cnt[x]++; long long int ans = 0; for (int i = 0; i &lt; 80003; i++) &#123; if (cnt[i] &gt; 1) &#123; cnt[i]--; ans += cnt[i]; cnt[i + 1] += cnt[i]; cnt[i] = 1; &#125; &#125; return ans; &#125;&#125;; lee215’s solution for Leetcode 945 - [C++/Java/Python] Straight Forward ↩︎ official solution for Leetcode 945 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 162. Find Peak Element（二分查找）","slug":"2018-11-25-Leetcode-162-Find-Peak-Element（二分查找）","date":"2018-11-25T10:20:02.000Z","updated":"2018-11-25T13:31:02.000Z","comments":true,"path":"post/leetcode-162-find-peak-element/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-162-find-peak-element/","excerpt":"","text":"题目来源：https://leetcode.com/problems/find-peak-element/description/ 标记难度：Medium 提交次数：2/2 代码效率： 线性扫描：8ms 二分查找：4ms 题意 给定一个数组，其中任意两个相邻元素不等，请返回其中一个peak元素（即比两边元素都大；可以认为nums[-1]=nums[n]=+inf）。 要求代码时间复杂度为O(log(n))。 分析 线性扫描的方法太简单了，不值得细说。不过在写的时候很容易想到一个很有趣的问题：在题设条件下是否保证有这样的peak元素出现呢？我觉得显然是有的。不妨利用反证法：假设这样的peak元素不存在，则对于nums[0]和nums[n-1]，由于它们旁边各有一个比它们小的元素（nums[-1]和nums[n]），为了保证peak元素不存在，必有nums[0] &lt; nums[1]和nums[n-2] &gt; nums[n-1]。然后以此类推，即可推出矛盾。 通过上述方法大概可以想到一种二分的思路。选择i = n/2，判断是否满足nums[i-1] &lt; nums[i] &gt; nums[i+1]： 如果满足，则显然i就是满足要求的peak元素 否则，如果nums[i-1] &lt; nums[i] &lt; nums[i+1]，则必存在一个peak元素位于[i+1, n-1]范围中 如果nums[i-1] &gt; nums[i] &gt; nums[i+1]，则必存在一个peak元素位于[0, i-1]范围中 如果nums[i-1] &gt; nums[i] &lt; nums[i+1]，则i两侧都可能存在peak元素 代码 线性扫描 123456789class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; for (int i = 0; i &lt; nums.size(); i++) if ((i == 0 || nums[i] &gt; nums[i-1]) &amp;&amp; (i == nums.size() - 1 || nums[i] &gt; nums[i+1])) return i; return -1; &#125;&#125;; 二分查找 参考了题解[1]的写法……题解的细节写得还是挺不错的。 12345678910111213class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 1) return 0; int l = 0, r = nums.size() - 1; while (l &lt; r) &#123; int mid = (l + r) / 2; if (nums[mid] &gt; nums[mid + 1]) r = mid; else l = mid + 1; &#125; return l; &#125;&#125;; Leetcode Offcial Solution for 162. Find Peak Element ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Binary Search","slug":"alg-Binary-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search/"}]},{"title":"在VSCode中使用（汉字）等宽字体","slug":"2018-11-19-在VSCode中使用（汉字）等宽字体","date":"2018-11-19T21:18:20.000Z","updated":"2018-11-20T09:12:00.000Z","comments":true,"path":"post/using-chinese-monospace-in-vscode/","link":"","permalink":"https://zhanghuimeng.github.io/post/using-chinese-monospace-in-vscode/","excerpt":"","text":"最近听了同学的意见，把日常的Markdown编辑器（或者不如说是博客编辑器）从Atom换成了VScode。可以对它们作如下比较： 启动速度：Atom &lt; VScode（Atom启动总是特别慢，而且会卡死） 资源占用：Atom &lt; VScode（可能是因为实现机制的原因，Atom一直挺能耗CPU和内存的……） 保存配置：Atom &lt;&lt; VScode 之所以会有这一条，是因为Atom从七月份之后根本没办法保存我的任何配置…… 保存状态：都不怎么样 我弃用Atom的最主要原因是它无法正常保存我的Workspace和Open Editor，每次重启都会发现，它报一堆找不到我七月份的项目的错，而且之前打开的文件列表也回退成七月份的了。经过很多谷歌也没解决这个问题。 VScode能正常保存Workspace，而且挺好用的。但它原生好像根本就没有保存Open Editor这个功能。于是我安装了插件Restore Editors，但是它有时候会挂（比如我上次重启的时候）。所以看来每次重启之前我要检查一遍它有没有真的save。 美观程度：差不多，无论哪种看多了都会习惯的 所以我现在觉得我的这个选择还不错。而且我发现VScode对Markdown的插件支持比Atom好（或者你说我没好好探索Atom插件也行……但那可能说明Atom插件不够友好）。比如说，它有一个格式化表格的功能，看起来非常友好： 但是这种时候人就可能会想要更多的东西。上图中显然英文部分对齐了，但中文部分对不齐，显得有点丑陋（我猜对于强迫症来说应该是极其丑陋吧，还不如不格式化）！问题在于，在（至少是我目前的）VScode的默认字体配置下，中文和英文用的不是同一种字体，虽然英文字体自己等宽，但中文和它不太等宽。 VScode的字体默认配置是Consolas, 'Courier New', monospace。所以现在的中文字体是宋体，英文是Consolas，如果把配置全删掉，就会出现这种效果： 说实话，我认不出这里的英文是什么字体，但反正我觉得不太好看（而且也不等宽）。monospace不好看，而且也对不齐（而且设置Courier New显示的字体居然和monospace是一样的）： 于是我又去谷歌了，找到了一个解决方案：更纱黑体（be5invis/Sarasa-Gothic），一种为中文和日语准备的等宽字体。README里只写了一堆怎么build，但事实上作者编译了Release[1]，直接下载就行。下载之后会得到一堆ttf文件，直接右键全部安装就行（至少Windows是这样的）。安装完之后在Word的字体库里就能找到各种更纱黑体了，但是在VScode中还不能找到，反正我重启了一遍。 效果是这样的： 如果font name设置不对，可以参考这个issue：What shoule be the font name of Sarasa Mono that can be used in vscode? 总之，我觉得这个字体看起来还不错，而且终于对齐了，我很高兴。这个字体的对齐方式应该是两个英文字符对齐一个中文字符（比我想象得不愚蠢多了）。不过还是有一些小bug，在我写文章的时候就发现了，是和对齐相关的： 最右边的“能”字被遮住了大半个。经过实验发现，这个问题可能是省略号导致的。 2018.11.20 UPDATE：作者告诉我等距更纱黑体 SC是Code字体，在这种字体下省略号被当做是half-width character，算是正常表现。Ta叫我去用Term字体，于是换成Sarasa Term SC之后就好了。 https://www.mokeyjay.com/archives/2150 ↩︎","categories":[],"tags":[{"name":"Essay","slug":"Essay","permalink":"https://zhanghuimeng.github.io/tags/Essay/"}]},{"title":"Leetcode 943. Find the Shortest Superstring（DP）","slug":"2018-11-19-Leetcode-943-Find-the-Shortest-Superstring（DP）","date":"2018-11-19T01:36:16.000Z","updated":"2018-11-25T17:41:00.000Z","comments":true,"path":"post/leetcode-943-find-the-shortest-superstring/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-943-find-the-shortest-superstring/","excerpt":"","text":"题目来源：https://leetcode.com/problems/find-the-shortest-superstring/description/ 标记难度：Hard 提交次数：3/4 代码效率：2.93% -&gt; 79.31% 题意 有N个字符串，找到最小的字符串S，使得这N个字符串都是S的子串。其中N&lt;=12，字符串的长度&lt;=20。 分析 这道题比赛的时候我没有做出来，但我自认为自己已经找到了正确的解法（确实差不多是正确的），只要再调一小会就能调出来了！结果事实是又花了两天才弄出来。我犯了这些错误： 在搞错了状态变量的范围的同时没有设置好变量的初值 计算两个字符串的overlap的函数少考虑了一种情况 所以就这样了…… 我觉得比较简单的方法还是状态压缩DP。[1]令dp[mask][i]表示总共包含mask这些字符串，且以A[i]作为结尾的字符串的最小长度（或者最大overlap长度；当字符串都是那么多时，这两者是一样的。然后就可以递推了：dp[mask ^ 1&lt;&lt;j][j] = max(dp[mask][i] + overlap(i, j))。显然，我们事实上可以不用保存具体的字符串（因为有最后一个字符串就够用了），而且可以事先计算出每两个字符串之间的overlap（这样就不需要重复计算）。不过这样就需要最后重建DP过程了……不过字符串处理过程太耗时了，也可以理解…… 不过这样做了之后时间效率大大提高了（从1324ms提高到了28ms） 代码 特别慢的那个就不贴了…… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081class Solution &#123;private: inline int calcOverlap(const string&amp; s1, const string&amp; s2) &#123; int start = s1.length() - s2.length(); start = max(0, start); for (int i = start; i &lt; s1.length(); i++) &#123; int len = s1.length() - i; if (s1.substr(i, len) == s2.substr(0, len)) return len; &#125; return 0; &#125; inline bool contains(int cnt, int i) &#123; return (cnt &amp; (1 &lt;&lt; i)) != 0; &#125; public: string shortestSuperstring(vector&lt;string&gt;&amp; A) &#123; int n = A.size(); if (n == 1) return A[0]; // pre-calculate overlap graph int overlap[n][n]; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; n; j++) overlap[i][j] = calcOverlap(A[i], A[j]); const int MAX_CNT = (1 &lt;&lt; n); int f[MAX_CNT][n], parent[MAX_CNT][n]; for (int i = 0; i &lt; n; i++) &#123; f[1 &lt;&lt; i][i] = 0; parent[1 &lt;&lt; i][i] = -1; &#125; // start DP int ans = -1; int p = -1; for (int cnt = 2; cnt &lt;= n; cnt++) &#123; for (int i = 0; i &lt; MAX_CNT; i++) &#123; if (__builtin_popcount(i) != cnt) continue; // ends with j for (int j = 0; j &lt; n; j++) &#123; if (!contains(i, j)) continue; f[i][j] = -1; int nmask = i ^ (1 &lt;&lt; j); // last one ends with k for (int k = 0; k &lt; n; k++) &#123; if (!contains(nmask, k)) continue; if (f[nmask][k] + overlap[k][j] &gt; f[i][j]) &#123; f[i][j] = f[nmask][k] + overlap[k][j]; parent[i][j] = k; &#125; &#125; if (cnt == n &amp;&amp; f[i][j] &gt; ans) &#123; ans = f[i][j]; p = j; &#125; &#125; &#125; &#125; // rebuild the path string str; int nmask = MAX_CNT - 1; while (true) &#123; int par = parent[nmask][p]; if (par == -1) &#123; str = A[p] + str; break; &#125; str = A[p].substr(overlap[par][p], A[p].length() - overlap[par][p]) + str; nmask ^= (1 &lt;&lt; p); p = par; &#125; return str; &#125;&#125;; Leetcode Official Solution for 943. Find the Shortest Superstring ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 942. DI String Match（数学）","slug":"2018-11-18-Leetcode-942-DI-String-Match（数学）","date":"2018-11-18T23:14:01.000Z","updated":"2018-11-19T01:34:00.000Z","comments":true,"path":"post/leetcode-942-di-string-match/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-942-di-string-match/","excerpt":"","text":"题目来源：https://leetcode.com/problems/delete-columns-to-make-sorted/description/ 标记难度：Easy 提交次数：3/4 代码效率： O(n^2)：336ms outside-in：32ms inside-out：32ms 题意 给定一个DI sequence，求任意一个满足该sequence的0~N-1的排列。 分析 我感觉这道题才应该记Medium…… O(N^2) 这道题一看就让人想起之前的Leetcode 903. Valid Permutations for DI Sequence那道题。那是一道动态规划题，求满足某个DI sequence的排列的总数，核心递推方法是这样的： 从1i的排列得到1i+1的排列，仍满足DI sequence，且结尾是j 将排列中比j大的数都+1，然后把j放在排列的最后，就可以得到一个仍然合法的排列了 在递推过程中通过之前的结尾可以保证满足当前的D/I 然后我就literally地应用了这一方法： 令序列初始为seq = [0]，且保证它始终满足DI性质 如果当前DI sequence的值为D，则令seq += 1，seq.append(0)（保证仍然是0~i的排列，且最后一位是0，必然满足D性质） 否则，seq.append(i)（因为i必然大于之前的所有数） 这个方法没什么问题，不过它是O(N^2)的，太浪费了。 outside-in 这种想法[1]很容易理解，而且它直观地说明了“为什么对于任意DI序列都存在合法的排列”。记录当前还没被用过的最小值（初始为0）和最大值（初始为N-1）；然后，如果当前DI sequence的值为D，则在序列中插入当前最大值（因为这样下一个就必然会比它小）；否则插入当前最小值（因为这样下一个就必然会比它大）。最后这两个值一定是相等的（因为DI sequence的长度为N-1，而每一个sequence中的D/I值都会使当前还没被用过的最小值和最大值之间的差减小1）。 inside-out 这种想法[1:1]和上一种是对称的，区别是，我们记录的是当前已经被用过的最大的值，和当前已经被用过的最小的值。因此我们需要一个初值，也就是S中D的数量。 代码 O(N^2) 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; diStringMatch(string S) &#123; vector&lt;int&gt; ans = &#123;0&#125;; int n = S.length(); for (int i = 0; i &lt; n; i++) &#123; if (S[i] == 'I') ans.push_back(i + 1); else &#123; for (int j = 0; j &lt; ans.size(); j++) ans[j]++; ans.push_back(0); &#125; &#125; return ans; &#125;&#125;; outside-in 1234567891011121314class Solution &#123;public: vector&lt;int&gt; diStringMatch(string S) &#123; int N = S.length() + 1; int minn = 0, maxn = N - 1; vector&lt;int&gt; ans; for (int i = 0; i &lt; N - 1; i++) &#123; if (S[i] == 'D') ans.push_back(maxn--); else ans.push_back(minn++); &#125; ans.push_back(minn); return ans; &#125;&#125;; inside-out 123456789101112131415class Solution &#123;public: vector&lt;int&gt; diStringMatch(string S) &#123; int N = S.length() + 1; int minn = 0, maxn; for (char ch: S) minn += ch == 'D' ? 1 : 0; maxn = minn; vector&lt;int&gt; ans = &#123;minn&#125;; for (int i = 0; i &lt; N - 1; i++) &#123; if (S[i] == 'D') ans.push_back(--minn); else ans.push_back(++maxn); &#125; return ans; &#125;&#125;; lee215’s Solution for Leetcode 942 ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 944. Delete Columns to Make Sorted（贪心）","slug":"2018-11-18-Leetcode-944-Delete-Columns-to-Make-Sorted（贪心）","date":"2018-11-18T22:54:18.000Z","updated":"2018-11-18T23:00:00.000Z","comments":true,"path":"post/leetcode-944-delete-columns-to-make-sorted/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-944-delete-columns-to-make-sorted/","excerpt":"","text":"题目来源：https://leetcode.com/problems/delete-columns-to-make-sorted/description/ 标记难度：Medium 提交次数：1/1 代码效率：68ms 题意 有N个只包含小写字母的长度相同的字符串。把它们从上到下排成一个矩阵，从中删除一些列，使得剩下的列都是从上到下非降序的。问最少删除几列。 分析 明白这道题的题意的时候我都惊了。我本来以为这是一个多字符串的最长不降子序列问题呢……那还有点意思。结果竟然是这样。那就直接把不是非降序的列全都删掉就好了！ （为什么这种题可以被标成Medium啊） 代码 1234567891011121314151617class Solution &#123;public: int minDeletionSize(vector&lt;string&gt;&amp; A) &#123; int n = A.size(), m = A[0].size(); int ans = 0; for (int i = 0; i &lt; m; i++) &#123; bool inc = true; for (int j = 1; j &lt; n; j++) if (A[j-1][i] &gt; A[j][i]) &#123; inc = false; break; &#125; if (!inc) ans++; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 941. Valid Mountain Array（数组），及周赛（111）总结","slug":"2018-11-18-Leetcode-941-Valid-Mountain-Array（数组）","date":"2018-11-18T15:28:04.000Z","updated":"2018-11-18T21:46:04.000Z","comments":true,"path":"post/leetcode-941-valid-mountain-array-and-weekly-contest-111/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-941-valid-mountain-array-and-weekly-contest-111/","excerpt":"","text":"题目来源：https://leetcode.com/problems/valid-mountain-array/description/ 标记难度：Easy 提交次数：2/4 代码效率： two-pass：40ms one-pass：24ms 题意 给定数组A，判断A是否是一个合法的mountain array： A.length &gt;= 3 存在0 &lt; i &lt; A.length - 1使得： A[0] &lt; A[1] &lt; ... &lt; A[i-1] &lt; A[i] A[i] &gt; A[i + 1] &gt; ... &gt; A[A.length - 1] 分析 这次比赛的排名是410 / 3585。前三题都意想不到地简单；第四题的DP有点难想，但我觉得也许给我更多的时间我就能做出来。 然后这道题因为误以为“题目保证A.length&gt;=3”而RE了一次（实际上应该是A.length&gt;=3的输入才需要考虑）。 比赛的时候我整了一个比较复杂的做法：用increasing[i]数组表示是否满足A[0] &lt; A[1] &lt; ... &lt; A[i-1] &lt; A[i]，decreasing[i]数组表示是否满足A[i] &gt; A[i + 1] &gt; ... &gt; A[A.length - 1]，然后寻找是否有同时满足两个条件的i。 上述做法显然太复杂了。实际上直接找到最大的满足A[0] &lt; A[1] &lt; ... &lt; A[i-1] &lt; A[i]的i然后判断A[i] &gt; A[i + 1] &gt; ... &gt; A[A.length - 1]是否成立即可。题解中也是这种做法。[1] 代码 One-pass版本，因为忘记判断0 &lt; i &lt; n - 1，WA了一次。 123456789101112131415class Solution &#123;public: bool validMountainArray(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); if (n &lt; 3) return false; int i = 0; while (A[i] &lt; A[i + 1] &amp;&amp; i &lt; n - 1) i++; if (i == 0 || i == n - 1) return false; while (i &lt; n - 1) &#123; if (A[i] &lt;= A[i + 1]) return false; i++; &#125; return true; &#125;&#125;; Leetcode official solution for 941. Valid Mountain Array ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 940. Distinct Subsequences II（DP）","slug":"2018-11-12-Leetcode-940-Distinct-Subsequences-II（DP）","date":"2018-11-12T01:05:23.000Z","updated":"2018-11-25T18:17:00.000Z","comments":true,"path":"post/leetcode-940-distinct-subsequences-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-940-distinct-subsequences-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/distinct-subsequences-ii/description/ 标记难度：Hard 提交次数：1/3 代码效率： 按序列结尾字母进行递推：12ms 题意 给定字符串S，返回S的不重不漏的非空子序列的总数。 分析 这些做法使我感到，这种计数DP是在非常有限的信息下做到不重不漏地统计的过程，所以保留哪些信息是十分关键的。 按序列可能的结尾位置进行递推 这是题解给出的做法，看起来还不错。[1]用一个数组dp[k]表示S[0:k]中不重复的sequence的数量。在不考虑重复的情况下，dp[k] = 2 * dp[k-1] + 1。问题是如何从中去掉那些重复的sequence。显然那些被重复的原有的sequence的结尾字母必然是S[k]。（想不出来为什么了。。）令last[S[k]]表示S[k]上次出现的位置，则所有会被重复的sequence必然可以用last[S[k]]-1位置的sequence再加上S[k]来组成。（我都不知道我在说什么，还是算了吧。） 按序列结尾位置进行递推 同样用一个数组dp[i]表示以S[i]结尾的和之前不重复的sequence的数量。对于每个dp[i]，枚举j = 0 ... i-1： 假如S[j] != S[i]，说明直接在以S[j]结尾的sequence后面接上S[i]不会导致任何重复，所以S[i] += S[j] 假如S[j] == S[i]（。。。又想不出来为什么了） 按序列结尾字母进行递推 这是我见到的最优雅的做法。[2]用一个数组endsWith[26]来表示（截止到当前位置的字符串）中以每个字母结尾的非空sequence的数量。假设当前这个统计是不重不漏的。考虑加入下一个字母S[i]后增加的所有sequence。在不考虑重复的情况下，这个数量是sum(endsWith) + 1（原来的所有sequence后面加上这个字母，还有这个字母自己）。如果要发生重复，显然那些被重复的序列的结尾只能是S[i]；而那些被重复的以S[i]结尾的sequence去掉S[i]的结果必定以某种形式存在于endsWith数组中，因此它们必定都被重复了一遍：因此重复序列的总数就是endsWith[S[i] - 'a']。于是最后的效果是每次更新的时候endsWith[S[i] - 'a'] = sum(endsWith) + 1。 代码 按序列结尾字母进行递推 我感到我写得并不好，不如原来用std::accumulate的做法优雅。[2:1] 123456789101112131415161718class Solution &#123;public: int distinctSubseqII(string S) &#123; int endsWith[26]; const int MOD = 1e9 + 7; memset(endsWith, 0, sizeof(endsWith)); for (char ch: S) &#123; int sum = 0; for (int i = 0; i &lt; 26; i++) sum = (endsWith[i] + sum) % MOD; endsWith[ch - 'a'] = (sum + 1) % MOD; &#125; int sum = 0; for (int i = 0; i &lt; 26; i++) sum = (endsWith[i] + sum) % MOD; return sum; &#125;&#125;; Leetcode Official Solution for 940 ↩︎ lee215’s Solution for Leetcode 940 ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 939. Minimum Area Rectangle（set）","slug":"2018-11-12-Leetcode-939-Minimum-Area-Rectangle（set）","date":"2018-11-12T00:51:44.000Z","updated":"2018-11-12T01:00:00.000Z","comments":true,"path":"post/leetcode-939-minimum-area-rectangle/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-939-minimum-area-rectangle/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-area-rectangle/description/ 标记难度：Medium 提交次数：1/1 代码效率：396ms 题意 给定若干个xy平面上的点，求这些点能构成的边和x/y轴平行的矩形的面积的最小值。 分析 这道题也很简单。直接把所有点放到一个set里面，然后对于每一对横纵坐标都不相等（也就是它们可以构成一条对角线）的点，构造出另一条对角线（交换横/纵坐标即可得到），然后检查这两个点是否存在即可。我最开始还排了个序，但事实是不需要排序。 题解提示了我一种hash方法，可以不用set&lt;pair&lt;int, int&gt;&gt;，而是改用40001 * x + y，也算是一种策略吧。[1] 代码 1234567891011121314151617181920212223242526272829class Solution &#123;public: int minAreaRect(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; set&lt;pair&lt;int, int&gt;&gt; pointSet; vector&lt;pair&lt;int, int&gt;&gt; pointPairs; for (int i = 0; i &lt; points.size(); i++) &#123; pointPairs.emplace_back(points[i][0], points[i][1]); pointSet.insert(pointPairs.back()); &#125; sort(pointPairs.begin(), pointPairs.end()); int ans = 1600000001; bool found = false; for (int i = 0; i &lt; pointPairs.size(); i++) &#123; for (int j = i + 1; j &lt; pointPairs.size(); j++) &#123; if (pointPairs[i].first == pointPairs[j].first || pointPairs[i].second == pointPairs[j].second) continue; pair&lt;int, int&gt; p1 = pointPairs[i], p2 = pointPairs[j]; swap(p1.second, p2.second); if (pointSet.find(p1) != pointSet.end() &amp;&amp; pointSet.find(p2) != pointSet.end()) &#123; ans = min(ans, abs(pointPairs[i].first - pointPairs[j].first) * abs(pointPairs[i].second - pointPairs[j].second)); found = true; &#125; &#125; &#125; if (!found) ans = 0; return ans; &#125;&#125;; Official Solution for Leetcode 939 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Set","slug":"alg-Set","permalink":"https://zhanghuimeng.github.io/tags/alg-Set/"}]},{"title":"Leetcode 938. Range Sum of BST（树）","slug":"2018-11-12-Leetcode-938-Range-Sum-of-BST（树）","date":"2018-11-12T00:31:39.000Z","updated":"2018-11-12T00:49:00.000Z","comments":true,"path":"post/leetcode-938-range-sum-of-bst/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-938-range-sum-of-bst/","excerpt":"","text":"题目来源：https://leetcode.com/problems/reorder-log-files/description/ 标记难度：Medium 提交次数：1/1 代码效率： 剪枝：120ms 不剪枝：120ms 题意 给定一棵二叉查找树、L和R，返回[L, R]中的结点的值的和。 分析 这个题总的来说很简单。直接DFS，然后根据当前node的值进行剪枝即可。（事实上不剪枝也能过，而且没慢多少。） 代码 不剪枝 12345678class Solution &#123;public: int rangeSumBST(TreeNode* root, int L, int R) &#123; if (root == NULL) return 0; return rangeSumBST(root-&gt;left, L, R) + rangeSumBST(root-&gt;right, L, R) + (L &lt;= root-&gt;val &amp;&amp; root-&gt;val &lt;= R ? root-&gt;val : 0); &#125;&#125;; 剪枝 12345678910class Solution &#123;public: int rangeSumBST(TreeNode* root, int L, int R) &#123; if (root == NULL) return 0; int sum = 0; if (root-&gt;val &gt; L) sum += rangeSumBST(root-&gt;left, L, R); if (root-&gt;val &lt; R) sum += rangeSumBST(root-&gt;right, L, R); return sum + (L &lt;= root-&gt;val &amp;&amp; root-&gt;val &lt;= R ? root-&gt;val : 0); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 937. Reorder Log Files（排序），及周赛（110）总结","slug":"2018-11-11-Leetcode-937-Reorder-Log-Files（排序），及周赛（109）总结","date":"2018-11-11T20:02:09.000Z","updated":"2018-11-12T00:29:00.000Z","comments":true,"path":"post/leetcode-937-reorder-log-files-and-weekly-contest-110/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-937-reorder-log-files-and-weekly-contest-110/","excerpt":"","text":"题目来源：https://leetcode.com/problems/reorder-log-files/description/ 标记难度：Easy 提交次数：1/2 代码效率：12ms 题意 给定一堆log和排序方法，返回排序之后的结果。 分析 这次比赛的排名是528 / 3720。第一题错了一次，然后第四题没有想出正解。这次比赛比较迷的一点是，它推迟了，改成了10:30开始，然后我的电脑中间还没网了，不得不重启一次…… 这道题的考点可以用“Custom Sort”来概括，也许考察语言特性和细节比算法本身要多。然后因为搞错了identifier具体的排序方法还WA了一次。没别的了。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class Solution &#123;private: struct Log &#123; string s; string identifier; vector&lt;string&gt; words; string word; bool isLetter; int index; Log() &#123;&#125; Log(string s, int i) &#123; this-&gt;s = s; this-&gt;index = i; stringstream lineStream(s); lineStream &gt;&gt; identifier; string token; isLetter = true; while (lineStream &gt;&gt; token) &#123; words.push_back(token); word += token; if (isNumeric(token)) isLetter = false; &#125; &#125; bool isNumeric(string s) &#123; for (char ch: s) if (ch &lt; '0' || ch &gt; '9') return false; return true; &#125; friend bool operator &lt; (const Log&amp; l1, const Log&amp; l2) &#123; if (l1.isLetter != l2.isLetter) &#123; if (l1.isLetter) return true; else return false; &#125; if (l1.isLetter &amp;&amp; l2.isLetter) &#123; int i = 0, n = min(l1.words.size(), l2.words.size()); for (i = 0; i &lt; n; i++) if (l1.words[i] != l2.words[i]) return l1.words[i] &lt; l2.words[i]; if (l1.words.size() != l2.words.size()) return l1.words.size() &lt; l2.words.size(); return l1.identifier &lt; l2.identifier; &#125; return l1.index &lt; l2.index; &#125; &#125;; public: vector&lt;string&gt; reorderLogFiles(vector&lt;string&gt;&amp; logs) &#123; vector&lt;Log&gt; Logs; for (int i = 0; i &lt; logs.size(); i++) &#123; Logs.emplace_back(logs[i], i); &#125; sort(Logs.begin(), Logs.end()); vector&lt;string&gt; ans; for (Log log: Logs) ans.push_back(log.s); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Sort","slug":"alg-Sort","permalink":"https://zhanghuimeng.github.io/tags/alg-Sort/"}]},{"title":"论文：Contextual Encoding for Translation Quality Estimation","slug":"2018-11-10-论文：Contextual-Encoding-for-Translation-Quality-Estimation","date":"2018-11-10T20:01:24.000Z","updated":"2018-11-12T19:43:00.000Z","comments":true,"path":"post/contextual-encoding-for-translation-quality-estimation/","link":"","permalink":"https://zhanghuimeng.github.io/post/contextual-encoding-for-translation-quality-estimation/","excerpt":"","text":"论文地址：https://arxiv.org/pdf/1809.00129.pdf 这篇文章也是WMT18 QE Task的提交系统之一，在word-level task上取得了较好的效果（虽然我觉得一部分原因是QEBrain和UNQE没有参加一部分task）。它的主要思路是在之前的一篇文章[1]的基础上做了改进，用卷积层起到类似于attention的作用。这个思路的效果看起来不如一般的attention。（而且文章写得一点也不清楚，代码库也找不到，我还是不知道模型的具体结构是什么样的。） 模型结构 （图里的模型结构画得一点也不确切……） 这篇文章的模型是在[1:1]的基础上改进出来的，中间多加了一层卷积。 模型的输入是三元组⟨s,t,A⟩\\langle s, t, \\mathcal{A} \\rangle⟨s,t,A⟩，其中s=s1,...,sMs = s_1, ..., s_Ms=s1​,...,sM​是源句，t=t1,...,tNt = t_1, ..., t_Nt=t1​,...,tN​是译句，A⊆{(m,n)∣1≤m≤M,1≤n≤N}\\mathcal{A} \\subseteq \\{(m, n) | 1 \\leq m \\leq M, 1 \\leq n \\leq N\\}A⊆{(m,n)∣1≤m≤M,1≤n≤N}是alignment。 模型分成三个主要部分： 词和POS的embedding层 卷积层 RNN和FF层 embedding层的vector是这样构成的（∥\\Vert∥表示row-wise concatenation）： 记embedding的维度为ddd，令源词和译词采用同样的embedding参数，记源词的embedding为esie_{s_i}esi​​，译词的embedding为etje_{t_j}etj​​ 将每个译词自己的embedding和与它对齐的源词的embedding的平均值连接在一起，得到$\\mathbf{x}'_j = ave(e_{s_{\\mathcal{A}(:, t_j)}}) \\Vert e_{t_j}$，这是一个长度为2d2d2d的向量 将x′_j\\mathbf{x}&#x27;\\_jx′_j和x′_j−1\\mathbf{x}&#x27;\\_{j-1}x′_j−1和x′_j+1\\mathbf{x}&#x27;\\_{j+1}x′_j+1连接在一起，得到x_j=x′_j−1∥x′_j∥x′_j+1\\mathbf{x}\\_j = \\mathbf{x}&#x27;\\_{j-1} \\Vert \\mathbf{x}&#x27;\\_j \\Vert \\mathbf{x}&#x27;\\_{j+1}x_j=x′_j−1∥x′_j∥x′_j+1，这是一个长度为6d6d6d的向量 然后将这些vector连接在一起进行卷积（⊕\\oplus⊕表示column-wise concatenation）： 将x_j\\mathbf{x}\\_jx_j连接在一起，构成一个矩阵：x_1:N=x_1⊕x_2...⊕x_N\\mathbf{x}\\_{1:N} = \\mathbf{x}\\_1 \\oplus \\mathbf{x}\\_2 ... \\oplus \\mathbf{x}\\_Nx_1:N=x_1⊕x_2...⊕x_N 然后对上述矩阵进行一维卷积：ci=f(w⋅xi:i+h−1+b)c_i = f(\\mathbf{w} \\cdot \\mathbf{x}_{i:i+h-1} + b)ci​=f(w⋅xi:i+h−1​+b)，得到featurec={c1,c2,...,cN}\\mathbf{c} = \\{c_1, c_2, ..., c_N\\}c={c1​,c2​,...,cN​}（进行了padding） 在不同的窗口大小下（H={1,3,5,7}\\mathcal{H} = \\{1, 3, 5, 7\\}H={1,3,5,7}）各学习nf=64n_f = 64nf​=64个feature，将这些feature连接起来，得到C∈RN×∣H∣⋅nfC \\in \\mathbb{R}^{N \\times |\\mathcal{H}| \\cdot n_f}C∈RN×∣H∣⋅nf​的卷积层输出，相当于每个词由长度为H∣⋅nf=256\\mathcal{H}| \\cdot n_f = 256H∣⋅nf​=256的向量表示（这句是我猜的） 最后再把上述向量和译词的POS tag embedding和与译词对齐的源词的POS tag embedding连接起来（文中没有说POS tag是怎么来的，但[1:2]中是用TurboTagger标记的；我猜可能也要进行平均） 然后对每个词对应的向量表示进行处理（似乎使用了stacked RNN的方法，我还没太搞懂）： 两层FF（ReLU），隐藏层大小为400 一层Bi-GRU，隐藏层大小为200，前向表示和后向表示连接后进行layer normalization 两层FF（ReLU），隐藏层大小为200 一层Bi-GRU，隐藏层大小为100，同样进行layer normalization 一层FF（ReLU），隐藏层大小为100 一层FF（ReLU），隐藏层大小为50 （我猜测每个词对应的网络参数是相同的？） 然后把最后一层输出的FF feature和Marmot输出的31个baseline feature连接起来，通过softmax来预测OK/BAD label。 实验结果 这个模型取得了比较好的结果。 作者还进行了一些sensitivity analysis（调整dropout rate）和ablation analysis（删除模型中的一些部分，观察效果），具体内容就不写了。 Pushing the Limits of Translation Quality Estimation ↩︎ ↩︎ ↩︎","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"},{"name":"Quality Estimation","slug":"Quality-Estimation","permalink":"https://zhanghuimeng.github.io/tags/Quality-Estimation/"}]},{"title":"论文：A Unified Neural Network for Quality Estimation of Machine Translation","slug":"2018-11-07-论文：A-Unified-Neural-Network-for-Quality-Estimation-of-Machine-Translation","date":"2018-11-07T16:02:57.000Z","updated":"2018-11-08T15:57:00.000Z","comments":true,"path":"post/a-unified-neural-network-for-quality-estimation-of-machine-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/a-unified-neural-network-for-quality-estimation-of-machine-translation/","excerpt":"","text":"论文地址：https://www.jstage.jst.go.jp/article/transinf/E101.D/9/E101.D_2018EDL8019/_article/-char/en 这篇论文描述了一种新的用于Quality Estimation的神经网络结构，在WMT18 QE Task中取得了较好的成绩（仅次于QEBrain，同样大大超过了SOTA）。 相关工作 传统的QE方法是把它看成是一个有监督回归/分类模型。典型的做法如QuEst：先从输入中提取feature，再根据feature用SVR进行打分。这种做法存在的问题之一是，提取feature的过程与源语言本身密切相关，因此限制了它在不同语言中的应用。 之后研究者们开始在QE中应用deep learning，可以分成两大类： neural-aware QE：将neural feature（如word embedding、translation condition probability、cross entropy等）集成到QE系统中，可以有效提高系统表现。 pure neural QE：直接建立一个用于QE任务的神经网络；目前的SOTA是用两个分开的网络（RNNsearch predictor + RNN estimator）分别进行训练，然后输出结果。这种方法的表现比neural-aware QE更好。 本文中的做法是将RNNsearch和RNN组成一个整体的网络，共同进行训练。 （之后的实验结果将说明，pure neural QE &gt; neural-aware QE &gt; traditional QE，而在pure neural QE中，unified network又好于separated network。） 模型结构 （这篇文章把模型结构讲得比较细。） 模型分成两个主要模块： RNNsearch：从句对中提取quality vector RNN：用quality vector对翻译质量进行预测，可以看成是有监督回归任务 这两个模块共同进行训练。其中RNNsearch中间生成的context vector是c1,...,cnc_1, ..., c_nc1​,...,cn​，decoder RNN的隐状态是s0,s1,...,sns_0, s_1, ..., s_ns0​,s1​,...,sn​，t1,...,tjt_1, ..., t_jt1​,...,tj​是中间表示，可以通过下式计算： $$t_j = \\tanh{(U_o s_{j-1} + V_o E y_{j-1} + C_o c_j)}$$ 其中Uo,Vo,CoU_o, V_o, C_oUo​,Vo​,Co​是模型参数，EEE是目标语言的embedding矩阵。 给定输入(x1,...,xm)(x_1, ..., x_m)(x1​,...,xm​)，decoder将生成翻译输出(y1,...,yn)(y_1, ..., y_n)(y1​,...,yn​)，其中生成每个词的条件概率为： $$p(y_j | \\{y_1, ..., y_{j-1}\\}, x) = g(y_{j-1}, s_{j-1}, c) = \\frac{\\exp{(y^T_j W_o t_j)}}{\\sum_{k=1}^{K_y} \\exp{(y_k^T W_o t_j)}}$$ 其中WoW_oWo​是权重矩阵。（显然上式只是对yjTWotjy^T_j W_o t_jyjT​Wo​tj​做了一个softmax。）为了通过上述条件概率对翻译质量进行描述，可以这样计算quality vector： $$q_{y_j} = [(y^T_j W_o) \\odot t^T_j]^T$$ （所以这里就直接用了翻译条件概率……） 最后将这些quality vector依次输入到RNN（作者使用的是GRU单元）中，将最后一个输出作为QE得分： $$v_j = f(v_{j-1}, q_{y_j})$$ $$QE_{score} = W_{QE} \\times v_n$$ 其中WQEW_{QE}WQE​是权重矩阵。最终分数没有用logistic sigmoid函数进行平均，而是直接进行了clip。 模型训练 由于QE任务的训练集太小了，因此RNNsearch和QE RNN先分别用平行语料（WMT17翻译任务的训练语料）和QE训练语料进行了预训练，然后才共同用QE训练语料进行训练。训练目标是最小化MAE： J(θ)=1N∑n=1N∣QEscore(x(n),y(n),θ)−HTER(n)∣J(\\theta) = \\frac{1}{N} \\sum{n=1}^{N} |QE_{score}(x^{(n)}, y^{(n)}, \\theta) - HTER^{(n)}| J(θ)=N1​∑n=1N∣QEscore​(x(n),y(n),θ)−HTER(n)∣ 由于模型的各部分是一起训练的，因此输出的quality vector是可以进行训练的（而不是像estimator-predictor方法中，RNNsearch的输出是固定的翻译结果），能够提取出更准确的feature。 实验结果 表中列出的系统包括： QuEst：传统QE方法 SHEF/QUEST-EMB：neural-aware QE方法 JXNU/Emb+RNNLM+QuEst+SNM：neural-aware QE方法 Predictor-Estimator：pure neural QE方法 UNQE：本文的方法 分析结果可以得到以下结论： pure neural QE方法好于neural-aware QE方法好于传统QE方法 UNQE方法好于Predictor-Estimator方法 ensemble是有效的 对预测分数进行logistic sigmoid不如直接进行clip 一些想法 这篇文章的做法是直接利用RNNsearch的翻译结果（或者说生成翻译的条件概率）进行Quality Estimation，那么它和“直接用一个最强的翻译系统进行翻译然后比较翻译结果和实际翻译输出”有什么差异呢？文中也讲到，如果真的直接用一个RNNsearch系统的翻译输出作为feature然后去预测，效果是不如像这个系统这样，将RNNsearch + QE RNN共同进行训练的。我猜测原因可能包括： RNNsearch还是不够好，应该尝试直接用Transformer的翻译输出作为feature进行预测，然后再将结果和QEBrain进行比较 MT系统内部训练时计算loss的方式（应该是cross entropy吧）和HTER打分是有差异的，因此需要额外的训练，使得它不止可以输出正确的翻译，还可以对翻译的实际得分有更好的估计 至于模型本身的结构，作者似乎没有像QEBrain那样考虑不同的estimator结构对结果的影响，如果尝试不同的结构（如LSTM、Bi-LSTM等）是否效果会更好？ 以及一个问题：HTER是对翻译质量的最好的度量方式吗？如果直接换成人类打分（像Task3和Task4那样）会怎样？","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"},{"name":"Quality Estimation","slug":"Quality-Estimation","permalink":"https://zhanghuimeng.github.io/tags/Quality-Estimation/"}]},{"title":"Leetcode 936. Stamping The Sequence（贪心）","slug":"2018-11-04-Leetcode-936-Stamping-The-Sequence（贪心）","date":"2018-11-04T23:07:59.000Z","updated":"2018-11-04T23:07:59.000Z","comments":true,"path":"post/leetcode-936-stamping-the-sequence/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-936-stamping-the-sequence/","excerpt":"","text":"题目来源：https://leetcode.com/problems/stamping-the-sequence/description/ 标记难度：Hard 提交次数：1/1 代码效率：36ms 题意 有一个stamp序列，可以通过不断使它覆盖一个序列的某一部分构造新的序列。问某个序列能否以这种方式构造。 分析 比赛的时候我觉得这道题应该用Trie之类的方法来做。没想到正解是贪心……？ 题目里限定的是，最多可以进行10 * target.length次stamp，但是事实上每个位置最多只需要进行一次stamp（如果stamp两次，则后来的stamp会彻底覆盖前一次），因此最多需要的stamp次数是source.length - target.length。 一种方法是贪心：每次尝试unstamp掉一块序列，直到整个序列被unstamp完为止。[1]不过我不知道怎么证明贪心的正确性…… 另一种方法来自lee215，因为他现在转移到简书写中文题解了，所以我就不再在这里赘述了，不过的确是一种很好的做法。[2] 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123; bool checkStamp(int index, const string&amp; stamp, const string&amp; target) &#123; for (int i = 0; i &lt; stamp.size(); i++) &#123; if (index + i &gt; target.size()) return false; if (stamp[i] != target[index + i] &amp;&amp; target[index + i] != '?') return false; &#125; return true; &#125; bool checkIsOk(const string&amp; target) &#123; for (char ch: target) if (ch != '?') return false; return true; &#125;public: vector&lt;int&gt; movesToStamp(string stamp, string target) &#123; vector&lt;int&gt; ops; int N = target.size(), M = stamp.size(); int cnt = 0; bool stamped[N - M + 1]; memset(stamped, 0, sizeof(stamped)); bool found, ok; while (cnt &lt;= N - M) &#123; found = false, ok = false; for (int i = 0; i &lt;= N - M; i++) if (!stamped[i] &amp;&amp; checkStamp(i, stamp, target)) &#123; for (int j = 0; j &lt; M; j++) target[i + j] = '?'; stamped[i] = true; ops.push_back(i); cnt++; found = true; if (checkIsOk(target)) &#123; ok = true; break; &#125; &#125; if (ok) break; if (!found) break; &#125; if (ok) &#123; reverse(ops.begin(), ops.end()); return ops; &#125; else return &#123;&#125;; &#125;&#125;; Leetcode 936 Solution by zym3008 - [Python] Reverse + Greedy O(N^2M) (w/ Explanation) ↩︎ Leetcode 936 Stamping The Sequence - 题解 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 934. Shortest Bridge（BFS）","slug":"2018-11-04-Leetcode-934-Shortest-Bridge（BFS）","date":"2018-11-04T16:02:37.000Z","updated":"2018-11-04T23:05:00.000Z","comments":true,"path":"post/leetcode-934-shortest-bridge/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-934-shortest-bridge/","excerpt":"","text":"题目来源：https://leetcode.com/problems/number-of-recent-calls/description/ 标记难度：Medium 提交次数：3/6 代码效率： treeSet+Dijstra：140ms 优先队列+Dijstra：120ms BFS：24ms 题意 在一个四连通图上有两个互不连通的子图，求这两个子图之间的最短距离。 分析 刚看到这道题的时候我很晕，不知道该怎么做。遂上网谷歌一下……找到了正确的做法之后，我却把set给写挂了。事实证明，std::set中判断相等的方式是!(a &lt; b) &amp;&amp; !(b &lt; a)而非!(a == b)。这一点是值得注意的。[1] 单就一般的图来说，这道题也不算很难：把子图A的所有结点都作为Dijstra算法的起始结点，然后在子图B的所有结点中取距离最短的。如果没有负权边，则直接在找到第一个子图B结点时结束算法即可。 然后这道题并不是一般的图，而是四连通的方格图，所以BFS就可以了。BFS的常数果然还是小啊…… 代码 用Dijstra的代码太过智障所以就不贴了…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;private: int N; int color[105][105]; int dist[105][105]; int mx[4] = &#123;-1, 1, 0, 0&#125;; int my[4] = &#123;0, 0, -1, 1&#125;; void dfs(int curx, int cury, int c, vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; for (int i = 0; i &lt; 4; i++) &#123; int x = curx + mx[i]; int y = cury + my[i]; if (x &lt; 0 || x &gt;= N || y &lt; 0 || y &gt;= N || A[x][y] != 1 || color[x][y] != -1) continue; color[x][y] = c; dfs(x, y, c, A); &#125; &#125;public: int shortestBridge(vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; N = A.size(); memset(color, -1, sizeof(color)); int colorCnt = 0; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) &#123; if (A[i][j] == 1 &amp;&amp; color[i][j] == -1) &#123; color[i][j] = colorCnt; dfs(i, j, colorCnt, A); colorCnt++; &#125; &#125; queue&lt;pair&lt;int, int&gt;&gt; q; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) &#123; if (color[i][j] == 0) &#123; dist[i][j] = 0; q.push(make_pair(i, j)); &#125; else dist[i][j] = 1e9; &#125; while (!q.empty()) &#123; int x = q.front().first, y = q.front().second; q.pop(); if (color[x][y] == 1) return dist[x][y] - 1; for (int i = 0; i &lt; 4; i++) &#123; int nx = x + mx[i], ny = y + my[i]; if (nx &lt; 0 || nx &gt;= N || ny &lt; 0 || ny &gt;= N || dist[nx][ny] &lt;= dist[x][y] +1) continue; dist[nx][ny] = dist[x][y] + 1; q.push(make_pair(nx, ny)); &#125; &#125; return -1; &#125;&#125;; stackoverflow - std::set with user defined type, how to ensure no duplicates ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 935. Knight Dialer（DP）","slug":"2018-11-04-Leetcode-935-Knight-Dialer（DP）","date":"2018-11-04T14:39:53.000Z","updated":"2018-11-04T15:44:53.000Z","comments":true,"path":"post/leetcode-935-knight-dialer/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-935-knight-dialer/","excerpt":"","text":"题目来源：https://leetcode.com/problems/knight-dialer/description/ 标记难度：Medium 提交次数：2/2 代码效率： 递推：16ms 矩阵乘法：8ms 题意 在如下的电话键盘的数字键上按照“马走日”的方式走N-1步，问最多能生成多少个不同的长度为N的数字。 分析 这道题还是很简单的，就直接递推就可以了。令f[i][j]表示以数字i结尾的走了j步的数的总数（也就是长度为j+1的数）；然后从图中可以得出从哪些数字可以走到i，于是就可以递推了。 矩阵乘法 一个事实是，其实可以把每一步的推导过程写成矩阵乘法。由于 12345678910f[0][i] = (f[4][i-1] + f[6][i-1]) % MOD;f[1][i] = (f[6][i-1] + f[8][i-1]) % MOD;f[2][i] = (f[7][i-1] + f[9][i-1]) % MOD;f[3][i] = (f[4][i-1] + f[8][i-1]) % MOD;f[4][i] = (f[0][i-1] + f[3][i-1] + f[9][i-1]) % MOD;f[5][i] = 0;f[6][i] = (f[0][i-1] + f[1][i-1] + f[7][i-1]) % MOD;f[7][i] = (f[2][i-1] + f[6][i-1]) % MOD;f[8][i] = (f[1][i-1] + f[3][i-1]) % MOD;f[9][i] = (f[2][i-1] + f[4][i-1]) % MOD; 因此 12345678910f[0][i] = [0 0 0 0 1 0 1 0 0 0] * f[0][i-1]f[1][i] = [0 0 0 0 0 0 1 0 1 0] * f[1][i-1]f[2][i] = [0 0 0 0 0 0 0 1 0 1] * f[2][i-1]f[3][i] = [0 0 0 0 1 0 0 0 1 0] * f[3][i-1]f[4][i] = [1 0 0 1 0 0 0 0 0 1] * f[4][i-1]f[5][i] = [0 0 0 0 0 0 0 0 0 0] * f[5][i-1]f[6][i] = [1 1 0 0 0 0 0 1 0 0] * f[6][i-1]f[7][i] = [0 0 1 0 0 0 1 0 0 0] * f[7][i-1]f[8][i] = [0 1 0 1 0 0 0 0 0 0] * f[8][i-1]f[9][i] = [0 0 1 0 1 0 0 0 0 0] * f[9][i-1] 然后就可以利用矩阵快速幂的方法优化成O(log(N))了。真是非常优秀的想法……[1] 以及为什么Leetcode里python可以用numpy啊，这不科学，我希望C++增加Eigen库…… 代码 递推 123456789101112131415161718192021222324252627class Solution &#123;private: long long int f[10][5005];public: int knightDialer(int N) &#123; memset(f, -1, sizeof(f)); const long long int MOD = 1000000007; long long int ans = 0; for (int i = 0; i &lt; 10; i++) f[i][0] = 1; for (int i = 1; i &lt; N; i++) &#123; f[0][i] = (f[4][i-1] + f[6][i-1]) % MOD; f[1][i] = (f[6][i-1] + f[8][i-1]) % MOD; f[2][i] = (f[7][i-1] + f[9][i-1]) % MOD; f[3][i] = (f[4][i-1] + f[8][i-1]) % MOD; f[4][i] = (f[0][i-1] + f[3][i-1] + f[9][i-1]) % MOD; f[5][i] = 0; f[6][i] = (f[0][i-1] + f[1][i-1] + f[7][i-1]) % MOD; f[7][i] = (f[2][i-1] + f[6][i-1]) % MOD; f[8][i] = (f[1][i-1] + f[3][i-1]) % MOD; f[9][i] = (f[2][i-1] + f[4][i-1]) % MOD; &#125; for (int i = 0; i &lt; 10; i++) ans = (ans + f[i][N-1]) % MOD; return ans; &#125;&#125;; 矩阵乘法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Solution &#123;private: struct Matrix &#123; int n, m; long long int mat[20][20]; Matrix(int _n, int _m) &#123; n = _n; m = _m; memset(mat, 0, sizeof(mat)); &#125; friend Matrix operator * (const Matrix&amp; a, const Matrix&amp; b) &#123; int n = a.n, m = b.m; Matrix c(n, m); for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; a.m; j++) for (int k = 0; k &lt; m; k++) &#123; c.mat[i][k] = (c.mat[i][k] + a.mat[i][j] * b.mat[j][k]) % MOD; &#125; return c; &#125; long long int sum() &#123; long long int sum = 0; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; m; j++) sum = (sum + mat[i][j]) % MOD; return sum; &#125; &#125;;public: static const long long MOD = 1000000007; int knightDialer(int N) &#123; Matrix f(10, 1); for (int i = 0; i &lt; 10; i++) f.mat[i][0] = 1; Matrix A(10, 10); A.mat[0][4] = A.mat[0][6] = 1; A.mat[1][6] = A.mat[1][8] = 1; A.mat[2][7] = A.mat[2][9] = 1; A.mat[3][4] = A.mat[3][8] = 1; A.mat[4][0] = A.mat[4][3] = A.mat[4][9] = 1; A.mat[6][0] = A.mat[6][1] = A.mat[6][7] = 1; A.mat[7][2] = A.mat[7][6] = 1; A.mat[8][1] = A.mat[8][3] = 1; A.mat[9][2] = A.mat[9][4] = 1; Matrix I(10, 10); for (int i = 0; i &lt; 10; i++) I.mat[i][i] = 1; Matrix pow2 = A, pow = I; N--; while (N &gt; 0) &#123; if (N % 2 != 0) pow = pow * pow2; pow2 = pow2 * pow2; N &gt;&gt;= 1; &#125; f = pow * f; return f.sum(); &#125;&#125;; lee215’s Solution for Leetcode 915 - Knight Dialer ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 933. Number of Recent Calls（队列），及周赛（109）总结","slug":"2018-11-04-Leetcode-933-Number-of-Recent-Calls（队列）","date":"2018-11-04T11:18:53.000Z","updated":"2018-11-04T14:29:00.000Z","comments":true,"path":"post/leetcode-933-number-of-recent-calls-and-weekly-contest-109/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-933-number-of-recent-calls-and-weekly-contest-109/","excerpt":"","text":"题目来源：https://leetcode.com/problems/number-of-recent-calls/description/ 标记难度：Easy 提交次数：1/1 代码效率：148ms 题意 给定一系列严格递增的ping时间戳，问每个时间戳3000毫秒前共有几次ping。 分析 今天比赛的时候发生了一点incident。实验室没开门，于是我坐在外面的桌子上又冷又没电地打比赛，然后第三题的Dijstra居然还写错了调不出来，最后紧张地在没电和比赛结束之前换成了用priority_queue的做法……（事实证明不加堆优化还是会超时的）然后当然没时间做第四题了。我一眼望去以为第四题要用后缀树之类的做法，结果好像比我想象的要简单。 最后排名是466 / 2948。今天北京下雨了。 直接用队列维护一个时间窗口就可以了。（不知道为什么我比赛的时候用的是deque） 代码 12345678910111213141516class RecentCounter &#123;private: deque&lt;int&gt; pings;public: RecentCounter() &#123; &#125; int ping(int t) &#123; while (!pings.empty() &amp;&amp; pings.front() &lt; t - 3000) pings.pop_front(); pings.push_back(t); return pings.size(); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Queue","slug":"alg-Queue","permalink":"https://zhanghuimeng.github.io/tags/alg-Queue/"}]},{"title":"论文：“Bilingual Expert” Can Find Translation Errors","slug":"2018-11-03-“论文：Bilingual-Expert”-Can-Find-Translation-Errors","date":"2018-11-03T20:09:55.000Z","updated":"2018-11-03T20:09:55.000Z","comments":true,"path":"post/bilingual-expert-can-find-translation-errors/","link":"","permalink":"https://zhanghuimeng.github.io/post/bilingual-expert-can-find-translation-errors/","excerpt":"","text":"论文地址：https://arxiv.org/pdf/1807.09433.pdf 这篇文章描述了2018 WMT Quality Estimation中效果最好的系统。作者认为他们的工作有以下几项主要贡献： 提出了一个新的经过预训练的基于Bi-Transformer的prior-knowledge模型，且可以用于APE（auto post-editing） 提出了3种mis-match feature 用Bi-LSTM通过输入特征进行quality estimation 提出了一种在计算流图中使用BPE的方法 Quality Estimation的传统方法和形式定义 一种传统方法是把预测sentence-level得分看做是一个constraint regression问题，把预测word-level标签看做是sequence labeling问题；然后先提取特征，再对翻译质量进行预测。 从统计学的角度，可以把翻译系统形式化地看成是p(t∣s)=p(t∣z)p(z∣s)p(\\mathbf{t} | \\mathbf{s}) = p(\\mathbf{t} | \\mathbf{z}) p(\\mathbf{z} | \\mathbf{s})p(t∣s)=p(t∣z)p(z∣s)，其中s\\mathbf{s}s表示源句的token sequence，t\\mathbf{t}t表示译句，z\\mathbf{z}z是表示encode过的源句的隐变量。因此，可以把p(z∣s)p(\\mathbf{z} | \\mathbf{s})p(z∣s)看成是encoder，p(t∣z)p(\\mathbf{t} | \\mathbf{z})p(t∣z)看成是decoder。 在QE任务中，MT系统是未知的，输入数据是(s,m,t)(\\mathbf{s}, \\mathbf{m}, \\mathbf{t})(s,m,t)，其中m\\mathbf{m}m是未知系统的输出，t\\mathbf{t}t是对m\\mathbf{m}m post-edit之后的结果。一般来说，至少可以在两个层面对m\\mathbf{m}m进行评价： word-level：根据m\\mathbf{m}m和t\\mathbf{t}t对m\\mathbf{m}m中的token生成的OK/BAD标签 sentence-level：根据m\\mathbf{m}m和t\\mathbf{t}t之间的差异计算HTER分数 因此可以假定训练数据实际上是(s,m,t,h,y)(\\mathbf{s}, \\mathbf{m}, \\mathbf{t}, h, \\mathbf{y})(s,m,t,h,y)，其中hhh是HTER，y\\mathbf{y}y是OK/BAD标签。QE任务即训练回归模型p(h∣s,m)p(h | \\mathbf{s}, \\mathbf{m})p(h∣s,m)和sequence labeling模型p(y∣s,m)p(\\mathbf{y} | \\mathbf{s}, \\mathbf{m})p(y∣s,m)。 （这项工作的架构类似于predictor-estimator的架构，但是两边是共同训练的，因此效果得到提升。） Conditional Language/Feature Extration Model: Bilingual Expert Model 作者首先形式化地描述了如何训练这个模型（实际上我没太看懂）。 通过贝叶斯公式，可以写出隐变量z\\mathbf{z}z的后验分布公式： p(z∣t,s)=p(t∣z)p(z∣s)p(t∣s)p(\\mathbf{z} | \\mathbf{t}, \\mathbf{s}) = \\frac{p(\\mathbf{t} | \\mathbf{z}) p(\\mathbf{z} | \\mathbf{s})}{p(\\mathbf{t} | \\mathbf{s})} p(z∣t,s)=p(t∣s)p(t∣z)p(z∣s)​ 由于p(t∣s)p(\\mathbf{t} | \\mathbf{s})p(t∣s)无法直接计算，因此用分布q(z∣t,s)q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})q(z∣t,s)通过最小化KL散度来逼近实际的后验： min⁡DKL(q(z∣t,s)∣∣p(z∣t,s))\\min{D_{KL} (q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s}) || p(\\mathbf{z} | \\mathbf{t}, \\mathbf{s}))} minDKL​(q(z∣t,s)∣∣p(z∣t,s)) 可以把上述目标函数换成下面这个（我猜这和KL散度的性质有关，但我不会）： $$\\max{\\mathbb{E}_{q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})}[p(\\mathbf{t} | \\mathbf{z})] - D_{KL} (q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s}) || p(\\mathbf{z} | \\mathbf{s}))}$$ 这个新目标函数的优点是不需要直接估计机器翻译模型p(t∣s)p(\\mathbb{t} | \\mathbb{s})p(t∣s)。（至少在这里仍然把MT和QE区分开了，但在实际模型架构中几乎是一样的。）而且可以直接计算p(z∣s)p(\\mathbf{z} | \\mathbf{s})p(z∣s)；左边的期望似然实际上是一个VAE（variational autoencoder），可以进行估计： $$\\max{\\mathbb{E}_{q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})}[p(\\mathbf{t} | \\mathbf{z})] \\approx p(\\mathbf{t} | \\mathbf{\\tilde{z}})}, \\quad \\tilde{z} \\sim q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})$$ 下面只需通过Transformer构造出p(t∣z)p(\\mathbf{t} | \\mathbf{z})p(t∣z)和q(z∣t,s)q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})q(z∣t,s)这两个概率。 Transformer部分模型架构如下图右侧部分： 其中有三个主要模块： self-attention encoder：encode源句 前向+后向self-attention encoder：encode译句 reconstructor：重新生成译句 （这架构和Transformer几乎没有区别……除了译句encoder换成了双向的） 将p(t∣z)p(\\mathbf{t} | \\mathbf{z})p(t∣z)和q(z∣t,s)q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s})q(z∣t,s)进行如下分解： $$p(\\mathbf{t} | \\mathbf{z}) = \\prod_{k} p(t_k | \\overrightarrow{\\mathbf{z}_k}, \\overleftarrow{\\mathbf{z}_k})$$ $$q(\\mathbf{z} | \\mathbf{t}, \\mathbf{s} = \\prod_{k} q(\\overrightarrow{\\mathbf{z}_k} | \\mathbf{s}, \\mathbf{t}_{< k}, \\overleftarrow{\\mathbf{z}_k} | \\mathbf{s}, \\mathbf{t}_{> k})$$ 三种特征 在训练完expert model之后，可以从中提取句对(s,m)(\\mathbf{s}, \\mathbf{m})(s,m)中的3种特征： 隐变量zk\\mathbf{z}_kzk​：它应当包含了源句和译句的所有信息，以及正确翻译第k个token所需的语义信息 token embedding：对于第k个token，使用它前后token的embedding，即$(\\mathbf{e}_{t_{k-1}}, \\mathbf{e}_{t_{k+1}})$ 分类分布：令p(tk∣⋅)p(t_k | \\cdot)p(tk​∣⋅)为类别数量与词表大小相等的分类分布（categorical distribution），则p(tk∣⋅)∼Categorical(softmax(Ik))p(t_k | \\cdot) \\sim \\text{Categorical}(softmax(\\mathbf{I}_k))p(tk​∣⋅)∼Categorical(softmax(Ik​)) 于是可以构造4维的mis-matching feature： $$\\mathbf{f}_k^{mm} = (\\mathbf{I}_{k, m_k}, \\mathbf{I}_{k, i_{max}}, \\mathbf{I}_{k, m_k} - \\mathbf{I}_{k, i_{max}}, \\mathbb{I}_{m_k \\neq i_{max}})$$ 其中mkm_kmk​是翻译输出中的第k个token，imax=arg⁡max⁡iIki_max = \\arg\\max_i{\\mathbf{I}_k}im​ax=argmaxi​Ik​为expert model预期的输出token，I\\mathbb{I}I是概率分布。 （这预期输出token基本上就相当于是自己翻译了一遍吧……） Bi-LSTM Quality Estimation 实验中发现encoder self-attention、Bi-Transformer和Bi-LSTM+CRF的效果都不如普通的Bi-LSTM，可能是因为训练数据不够多。因此直接使用了Bi-LSTM。 Bi-LSTM输入expert model生成的feature： $$\\overrightarrow{\\mathbf{h}_{1:T}}, \\overleftarrow{\\mathbf{h}_{1:T}} = \\text{Bi-LSTM}(\\{\\mathbf{f}_k\\}_{k=1}^T)$$ 然后通过回归方法预测HTER（因为HTER是整个句子的评分，因此只考虑Bi-LSTM的最后两个状态）： $$\\arg\\min{\\lVert h - \\text{sigmoid}(\\mathbf{w}^T [\\overrightarrow{\\mathbf{h}_{T}}, \\overleftarrow{\\mathbf{h}_{T}}]) \\rVert^2_2}$$ 通过sequence labeling方法预测词的标签（其中XENT是cross entropy）： $$\\arg\\min{\\sum_{k=1}^T \\text{XENT}(y_k, \\mathbf{W}[\\overrightarrow{\\mathbf{h}_{k}}, \\overleftarrow{\\mathbf{h}_{k}}])}$$ 计算流图中的BPE 对于sentence-level QE，由于HTER是全局参数，显然使用BPE和不使用BPE没有太大的差别。但是对于word-level QE，BPE下序列的长度Lb≠LωL_b \\neq L_{\\omega}Lb​​=Lω​（原序列长度）。因此作者提出了一种对一个词的所有subword unit的feature进行平均的方法：将BPE信息存储在一个Lω×LbL_{\\omega} \\times L_bLω​×Lb​的稀疏矩阵SSS中，其中仅当第j个subword unit属于第i个词时，sij≠0s_{ij} \\neq 0sij​​=0。此时就可以通过矩阵乘法计算平均后的feature，这使得计算流图是可微的。 通过这一方法使用BPE后，效果有一定的提升。 实验结果 预处理：筛选长度&lt;=70且长度比在1/3~3范围内的句对 参数： Bi-Transformer中每个模块的层数为2 feed-forward层的大小为512 8 head self-attention 总的来说这一模型大获全胜。 在实验中，即使只留下mis-match feature（而去掉另外两种），结果仍然是比较好的（皮尔森相关系数r降低了约0.04）。（这不禁令人怀疑QE和MT到底有什么区别。）","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"},{"name":"Quality Estimation","slug":"Quality-Estimation","permalink":"https://zhanghuimeng.github.io/tags/Quality-Estimation/"}]},{"title":"论文：A Simple, Fast and Effective Reparameterization of IBM Model 2","slug":"2018-10-31-论文：A-Simple-Fast-and-Effective-Reparameterization-of-IBM-Model-2","date":"2018-10-31T15:21:04.000Z","updated":"2018-11-01T21:12:00.000Z","comments":true,"path":"post/a-simple-fast-and-effective-reparameterization-of-ibm-model-2/","link":"","permalink":"https://zhanghuimeng.github.io/post/a-simple-fast-and-effective-reparameterization-of-ibm-model-2/","excerpt":"","text":"论文地址：http://www.aclweb.org/anthology/N13-1073 这篇文章对IBM Model 2，一种在无监督情况下将双语语料进行对齐的方法进行了改进，提高了计算速度和对齐质量。 IBM Model 2 文章本身很短，但是为了明白文章在讲什么，首先需要搞懂IBM Model 2是什么。这篇文章用Fr-En翻译的例子说明了IBM Model 2的定义和训练方法。 用(f1,...,fm)(f_1, ..., f_m)(f1​,...,fm​)表示源句中的mmm个词，(e1,...,el)(e_1, ..., e_l)(e1​,...,el​)表示译句中的lll个词，用(f(k),e(k))(f^{(k)}, e^{(k)})(f(k),e(k))表示第kkk个句对。 IBM Model 2是一种Noisy-Channel Approach，也就是说，它的模型分成以下两个部分： 语言模型：p(e)p(e)p(e)，表示英语句子eee在英语中出现的概率 翻译模型：p(f∣e)p(f | e)p(f∣e)，表示在给定译句为eee的条件下，源句为fff的概率。 有趣的一点是，翻译模型是p(f∣e)p(f | e)p(f∣e)而非p(e∣f)p(e | f)p(e∣f)。（我也不知道为什么） 对齐模型（alignment model） 在翻译模型p(f∣e)p(f | e)p(f∣e)中加入对齐变量（alignment variables）a1,...,am∈0,1,...,la_1, ..., a_m \\in {0, 1, ..., l}a1​,...,am​∈0,1,...,l，得到p(f1...fm,a1...am∣e1...el,m)p(f_1 ... f_m, a_1 ... a_m | e_1 ...e_l, m)p(f1​...fm​,a1​...am​∣e1​...el​,m)。（上述模型假设已知分布p(m∣l)p(m | l)p(m∣l)，因此把mmm看作是定值）。其中aja_jaj​表示源句中的fjf_jfj​与译句中的eaje_{a_j}eaj​​对齐，或者说在概率模型中，fjf_jfj​是由eaje_{a_j}eaj​​生成的；e0e_0e0​表示NULL，如果aj=0a_j = 0aj​=0，说明fjf_jfj​是由NULL生成的。 （上述“生成”说的是概率模型的生成，并不是实际翻译中的生成。） IBM-M2模型的正式定义 一个IBM-M2模型包括一个固定的英语词集合E\\mathcal{E}E，一个固定的法语词集合F\\mathcal{F}F，以及MMM和LLL，分别表示法语和英语句子的最大长度。模型的参数如下： t(f∣e),f∈F,e∈E∪NULLt(f | e), f \\in \\mathcal{F}, e \\in \\mathcal{E} \\cup {\\text{NULL}}t(f∣e),f∈F,e∈E∪NULL：表示从英语词eee生成法语词fff的概率 q(j∣i,l,m),l∈1,...,L,m∈1,...,M,i∈1,...,n,j∈0,...,lq(j | i, l, m), l \\in {1, ..., L}, m \\in {1, ..., M}, i \\in {1, ..., n}, j \\in {0, ..., l}q(j∣i,l,m),l∈1,...,L,m∈1,...,M,i∈1,...,n,j∈0,...,l：英语和法语句子的长度分别为lll和mmm时，ai=ja_i = jai​=j（fif_ifi​与eje_jej​对齐）的概率 对于任意英语句子e1,...,ele_1, ..., e_le1​,...,el​和长度mmm，定义法语句子f1,...,fmf_1, ..., f_mf1​,...,fm​和对齐变量a1,...,ama_1, ..., a_ma1​,...,am​的条件分布为 p(f1...fm,a1...am∣e1...el,m)=∏i=1mq(ai∣i,l,m)t(fi∣eai)p(f_1 ... f_m, a_1 ... a_m | e_1 ... e_l, m) = \\prod_{i=1}^{m} q(a_i | i, l, m) t(f_i | e_{a_i}) p(f1​...fm​,a1​...am​∣e1​...el​,m)=i=1∏m​q(ai​∣i,l,m)t(fi​∣eai​​) 在这个模型中我们使用了一些独立性假设。令LLL为表示英语句子长度的随机变量，E1,...,ElE_1, ..., E_lE1​,...,El​是表示英语句子中的词的随机变量；MMM是表示法语句子长度的随机变量，F1,...,FmF_1, ..., F_mF1​,...,Fm​和A1,...,AmA_1, ..., A_mA1​,...,Am​是表示法语句子中的词和对齐的随机变量，则我们的目标是建立一个这样的模型： P(F1=f1...Fm=fm,A1=a1...Am=am∣E1=e1...El=el,L=l,M=m)P(F_1=f_1 ... F_m=f_m, A_1=a_1 ... A_m=a_m | E_1=e_1 ... E_l=e_l, L=l, M=m) P(F1​=f1​...Fm​=fm​,A1​=a1​...Am​=am​∣E1​=e1​...El​=el​,L=l,M=m) 可以通过链式法则把上式分解成两项的乘积： P(A1=a1...Am=am∣E1=e1...El=el,L=l,M=m)P(A_1=a_1 ... A_m=a_m | E_1=e_1 ... E_l=e_l, L=l, M=m)P(A1​=a1​...Am​=am​∣E1​=e1​...El​=el​,L=l,M=m) P(F1=f1...Fm=fm∣A1=a1...Am=am,E1=e1...El=el,L=l,M=m)P(F_1=f_1 ... F_m=f_m | A_1=a_1 ... A_m=a_m, E_1=e_1 ... E_l=e_l, L=l, M=m)P(F1​=f1​...Fm​=fm​∣A1​=a1​...Am​=am​,E1​=e1​...El​=el​,L=l,M=m) 对于第一项，作如下独立性假设： P(A1=a1...Am=am∣E1=e1...El=el,L=l,M=m)=∏i=1mP(Ai=ai∣L=l,M=m)P(A_1=a_1 ... A_m=a_m | E_1=e_1 ... E_l=e_l, L=l, M=m) = \\prod_{i=1}^{m} P(A_i=a_i | L=l, M=m) P(A1​=a1​...Am​=am​∣E1​=e1​...El​=el​,L=l,M=m)=i=1∏m​P(Ai​=ai​∣L=l,M=m) 即对齐变量AiA_iAi​只与源句和译句的长度有关，和具体的词无关。（显然这只是一种假设） 对于第二项，作如下独立性假设： P(F1=f1...Fm=fm∣A1=a1...Am=am,E1=e1...El=el,L=l,M=m)=∏i=1mP(Fi=fi∣Eai=eai)P(F_1=f_1 ... F_m=f_m | A_1=a_1 ... A_m=a_m, E_1=e_1 ... E_l=e_l, L=l, M=m) = \\prod_{i=1}^{m} P(F_i=f_i | E_{a_i} = e_{a_i}) P(F1​=f1​...Fm​=fm​∣A1​=a1​...Am​=am​,E1​=e1​...El​=el​,L=l,M=m)=i=1∏m​P(Fi​=fi​∣Eai​​=eai​​) 即法语词FiF_iFi​只与和它对齐的英语词EaiE_{a_i}Eai​​有关，和其他词均无关。（显然这只是一种假设） IBM-M2模型的用途 翻译：arg⁡max⁡ep(e)p(f∣e)\\arg\\max_{e} p(e) p(f|e)argmaxe​p(e)p(f∣e) 语言（词法）模型：t(f∣e)t(f | e)t(f∣e) 对齐模型：ai=arg⁡max⁡j∈{0,...,l}(q(j∣i,l,m)×t(fi∣ej))a_i = \\arg\\max_{j\\in\\{0, ..., l\\}} (q(j | i, l, m) \\times t(f_i | e_j))ai​=argmaxj∈{0,...,l}​(q(j∣i,l,m)×t(fi​∣ej​)) 其中对齐模型是比较重要的一种用途。 估计IBM-M2模型的参数 数据观测充分的情况 在这种情况下，我们假设训练数据是这样的：(f(k),e(k),a(k))(f^{(k)}, e^{(k)}, a^{(k)})(f(k),e(k),a(k))。（一般来说，a(k)a^{(k)}a(k)是观察不到的） 这样就可以利用极大似然对参数进行估计： c(e,f)c(e, f)c(e,f)：训练数据中英语词eee与法语词fff对齐的次数 c(e)c(e)c(e)：训练数据中英语词eee与任意法语词对齐的总次数 c(j∣i,l,m)c(j | i, l, m)c(j∣i,l,m)：长度为lll的法语句子中第iii个词与长度为mmm的英语句子中第jjj个词对齐的次数 c(i,l,m)c(i, l, m)c(i,l,m)：训练数据中法语句子长度为lll，英语句子长度为mmm的总数 tML(f∣e)=c(e,f)c(e)t_{ML} (f | e) = \\frac{c(e, f)}{c(e)} tML​(f∣e)=c(e)c(e,f)​ qML(j∣i,l,m)=c(j∣i,l,m)c(i,l,m)q_{ML} (j | i, l, m) = \\frac{c(j | i, l, m)}{c(i, l, m)} qML​(j∣i,l,m)=c(i,l,m)c(j∣i,l,m)​ 数据观测不充分的情况 在这种情况下，我们假设训练数据是这样的：(f(k),e(k))(f^{(k)}, e^{(k)})(f(k),e(k))。我们采用EM算法对参数进行估计： 首先为各tML(f∣e)t_{ML} (f | e)tML​(f∣e)和qML(j∣i,l,m)q_{ML} (j | i, l, m)qML​(j∣i,l,m)参数估计一个初始值（比如随机取值） 按照当前参数取值统计c(e,f)c(e, f)c(e,f)、c(e)c(e)c(e)、c(j∣i,l,m)c(j | i, l, m)c(j∣i,l,m)和c(i,l,m)c(i, l, m)c(i,l,m)的值 更新各tML(f∣e)t_{ML} (f | e)tML​(f∣e)和qML(j∣i,l,m)q_{ML} (j | i, l, m)qML​(j∣i,l,m)参数，迭代直到收敛 其中最主要的区别是把原来的 \\delta(k, i, j) = 1 \\, \\text{if} \\, a_i^{(k)} = j, 0 \\, \\text{otherwise}$$（只有确实对齐时才取1，其他时候取0） 换成了 $$\\delta(k, i, j) = \\frac{q(j | i, l_k, m_k) t(f_i^{(k)} | e_j^{(k)})}{\\sum_{j=0}^{l_k} q(j | i, l_k, m_k) t(f_i^{(k)} | e_j^{(k)})}$$（在当前参数下$a_i=j$的概率） 可以证明EM算法是收敛的，但是可能会收敛到局部极小值。所以可以用Model 1对参数进行初始化。详细的内容略。 ![算法伪代码](algorithm-2.png) ## fast align 这一模型采用了IBM-M2模型的基本思路，但是减少了其中的参数个数。按论文中的表示法，这个模型是这样定义的： * 令$n$表示源句长度，$m$表示译句长度，定义两个新的参数$p_0$和$\\lambda$ * 令$h(i, j, m, n) = -|\\frac{i}{m} - \\frac{j}{n}|$ * 令$\\delta(a_i = j | i, m, n)$表示源句和译句长度分别为$m$和$n$时，$a_i = j$的概率（相当于之前的$q(j | i, l, m)$） * 令$\\theta(e_i | f_{a_i})$表示从英语词$e_i$生成法语词$f_{a_i}$的概率（相当于之前的$t(f | e)$） $$\\delta(a_i = j | i, m, n) = \\begin{cases} p_0 & j = 0 \\\\ (1 - p_0) \\times \\frac{e^{\\lambda h(i, j, m, n)}}{Z_{\\lambda}(i, m, n)} & 0 < j \\leq n \\\\ 0 & \\text{otherwise} \\end{cases} $$ 其中$Z_{\\lambda}(i, m, n) = \\sum_{j&#039;=1}^{n} \\exp{\\lambda h(i, j&#039;, m, n)}$ 这相当于是把原来每组$(i, j, m, n)$都对应一个参数的情况修正成了只通过已知函数$h$和$p_0$、$\\lambda$两个参数来确定对齐。其中$p_0$表示的是无对齐的概率 ### 根据参数计算给定句对的最大似然概率和对齐 给定句对$(f, e)$和参数，则： * 译句中第$i$个词为$e_i$，且$e_i$和$f_{a_i}$对齐的概率为：$p(e_i, a_i | f, m, n) = \\delta(a_i | i, m, n) \\times \\theta(e_i | f_{a_i})$ * 译句中第$i$个词为$e_i$的概率为：$p(e_i | f, m, n) = \\sum_{j=0}^{n} p(e_i, a_i=j | f, m, n)$ * 因此：$p(e | f) = \\prod_{i=1}^{m} p(e_i, a_i=j | f, m, n) = \\prod_{i=1}^{m} \\sum_{j=0}^{n} \\delta(a_i | i, m, n) \\times \\theta(e_i | f_{a_i})$ 通过一些优化手段，我们可以使$\\delta(a_i | i, m, n)$的计算复杂度是$O(1)$的。 --- 显然$\\delta(a_i | i, m, n)$的计算瓶颈在于$Z_{\\lambda}(i, m, n)$；$Z_{\\lambda}(i, m, n)$显然可以在$O(n)$时间复杂度内进行计算，但事实上可以是$O(1)$的。考虑到$h(i, j, m, n) = -|\\frac{i}{m} - \\frac{j}{n}|$，事实上$Z_{\\lambda}(i, m, n)$是两个等比数列的和： * 令$j_{\\uparrow} = \\lfloor \\frac{i \\times n}{m} \\rfloor$，$j_{\\downarrow} = j_{\\uparrow} + 1$ * 则$Z_{\\lambda}(i, m, n) = \\sum_{j&#039;=1}^{j_{\\uparrow}} \\exp{\\lambda h(i, j&#039;, m, n)} + \\sum_{j&#039; = j_{\\downarrow}}^{n} \\exp{\\lambda h(i, j&#039;, m, n)}$ * 其中$\\sum_{j&#039;=1}^{j_{\\uparrow}} \\exp{\\lambda h(i, j&#039;, m, n)} = e^{\\lambda j_{\\uparrow}} + e^{\\lambda (j_{\\uparrow} - 1/n)} + e^{\\lambda (j_{\\uparrow} - 2/n)} + ...$ * $\\sum_{j&#039; = j_{\\downarrow}}^{n} \\exp{\\lambda h(i, j&#039;, m, n)} = e^{\\lambda j_{\\downarrow}} + e^{\\lambda (j_{\\downarrow} - 1/n)} + e^{\\lambda (j_{\\downarrow} - 2/n)} + ...$ 因此可以在$O(1)$时间内计算$Z_{\\lambda}(i, m, n)$。 ### 根据训练数据计算参数 这一模型也可以通过EM算法来进行训练。$\\theta(e_i | f_{a_i})$的更新方法和之前类似，并使用了（一些我看不懂的数学）进行优化；$\\lambda$参数则需要用梯度方法来进行更新（另一些我没看懂的数学）。事实上，$\\delta(j | i, m, n)$的导数也具有类似的规律性，因此也可以用相同的方法来计算梯度，复杂度比较低。 ## 评价 这个模型能够用无监督且非常快速的方式计算出源句和译句之间的对齐，是一种非常有趣且已经被广泛使用的方法。不过由于模型和方法本身的限制，这个模型的对齐质量仍然不是很高。不过，在NMT方法中我们仍然可以利用这一方法生成的对齐的质量来对训练语料进行初步的预处理。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"}]},{"title":"论文：Findings of the WMT 2018 Shared Task on Quality Estimation","slug":"2018-10-29-论文：Findings-of-the-WMT-2018-Shared-Task-on-Quality-Estimation","date":"2018-10-29T16:24:23.000Z","updated":"2018-11-02T22:52:00.000Z","comments":true,"path":"post/findings-of-the-wmt-2018-shared-task-on-quality-estimation/","link":"","permalink":"https://zhanghuimeng.github.io/post/findings-of-the-wmt-2018-shared-task-on-quality-estimation/","excerpt":"","text":"论文地址：Findings of the WMT 2018 Shared Task on Quality Estimation 这篇文章报告了WMT18 Quality Estimation任务的结果。 各系统及提交者 本次参与评测的一共有10个系统（其中UAlacant和RTM因为迟交没有计入正式排名）： 系统名称 提交者 具体提交 参与任务 Task1 Task2 Task3 Task4 CMU-LTI CMU 1. CMU-LTI T2 - 次于QEBrain，和SHEF-PT表现相当 - - JU-USAAR Jadavpur University &amp; University of Saarland 1. Bag-of-Words2. Doc2Vec T2 - 低于baseline - - MQE Vicomtech 1. sMQE2. uMQE T1 和baseline持平 - - - QEbrain 阿里 1. QEBrain DoubleBi w/ BPE+word-tok2. QEBrain DoubleBi w/ BPE+word-tok (ensemble) T1, T2 QEBrain和UNQE并列第一，远高于其他系统 第一名，且gap error detection子任务表现非常好 - - RTM Biçici 1. RTM2. RTM_MIX13. RTM_MIX54. RTM_MIX65. RTM_MIX7 T1-T4 在NMT数据集上接近UNQE和QEBrain的结果 低于baseline 低于baseline 远不如baseline SHEF University of Sheffield 1. SHEF-PT2. SHEF-bRNN3. SHEF-ATT-SUM4. SHEF-PT-indomain5. SHEF-mtl-bRNN6. SHEF-mtl-PT-indomain T1-T4 大致处于排名中间位置 第二名（因为很多系统没有参与Task2） 与baseline相当 略高于baseline TSKQE 汉堡大学 1. TSKQE12. TSKQE2 T1 第三名（低于QEBrain和UNQE） - - - UAlacant University of Alacant 1. UAlacant T1, T2 和baseline相当 低于baseline UNQE 江西师范大学 UNQE T1 和QEBrain并列第一，远高于其他系统 - - - UTaru University of Taru 1. UTartu/QuEst+Attention2. UTartu/QuEst+Att+CrEmb3 T1, T2 略高于baseline 低于baseline - - 可以看出，这次比赛中，QEBrain和UNQE系统的效果是最好的，其次是CMU-LTI、TSKQE和SHEF。 QEBrain（T1，T2，阿里） QEBrain系统的参赛者已经把论文贴到Arxiv上了（“Bilingual Expert” Can Find Translation Errors），之后我会再去仔细读……不过简单来说好像是这样的： feature extraction (target language) model（作为特征提取器） multi-head self-attention 源语言的transformer encoder 目标语言的bi-transformer encoder 预训练过的双向transformer（作为预测器） 输入上述特征提取器得到的特征和baseline系统提供的特征 并且进行了ensemble。 UNQE（T1，江西师范大学） 他们把论文投到IEICE了（A Unified Neural Network for Quality Estimation of Machine Estimation），之后我会再去仔细读……不过简单来说好像是这样的： bi-RNN encoder-decoder + attention：从翻译输出中提取quality vector RNN：通过quality vector预测翻译输出的HTER值 模型进行了预训练；输出结果进行了模型平均。 CMU-LTI（T2，CMU） 他们也把论文贴到arXiv了（Contextual Encoding for Translation Quality Estimation）。模型分为三个主要部分： embedding layer：表示词和POS tag 1d convolution layer：将每个词和它的local context结合起来 stack of feed-forward and RNN: 将每个词和它的global context结合起来；同时输入一些句法feature TSKQE（T1，汉堡大学） 我确实没找到他们今年的论文（只找到了去年的，UHH Submission to the WMT17 Quality Estimation Shared Task）；他们的做法好像是对源句应用sequence kernel、tree kernel，对译句应用candidate translation和back-translation，预测HTER得分。（我并没有看懂这些，好像是一种非深度学习的approach） SHEF（T1-T4，University of Sheffield） 唯一在四个任务上都有正式提交的系统。我仍然没有找到他们今年的论文，但我找到了他们的一个类似的开源项目。今年他们提交了两个不同架构的系统： SHEF-PT：由Predictor和Estimator组成 Predictor：经过一定修改的encoder-decoder RNN模型 Estimator：bi-RNN，基于Predictor的输出进行预测 可以进行multi-task learning SHEF-bRNN： 用两个bi-RNN（GRU）学习(source, translation)对，输出word-level的预测 用attention机制对bi-RNN的输出（word-level的预测）进行加权平均，得到sentence-level的预测 对于phrase-level的预测，他们使用的是标准的基于attention的MT架构，将word-level的预测加权平均得到结果；对于预测source tag的任务，是把两边的输出反过来；对于document-level的任务，同时使用了PT和bRNN两种架构。 剩余的分数不太高的系统就不仔细看了。感觉NN方法占据了绝对优势。 Task1（句级QE）结果及讨论 这一任务的目标是对翻译输出的质量进行打分或排名。训练数据的label包括HTER、post-editing时间和post-editing中键盘敲击统计。 评价方法主要是皮尔森相关系数r（打分）和斯皮尔曼等级相关系数（排名）。 baseline是QUEST++：提取feature，用SVR+RBF kernel进行回归训练。 在该任务上表现最好的系统显然是QEBrain和UNQE，且它们的表现都远好于第三名；其中SHEF-PT是去年在该任务上表现最好的。这说明了Transformer技术应用在QE任务上之后大大提高了QE的表现。 SMT和NMT数据集的生成方法相同（分别用SMT和NMT系统对一个初始数据集进行翻译，进行post-edit，再移除其中过多的HTER=0的句对），但由于NMT的翻译效果远优于SMT，导致NMT数据集比较小，这也使得我们无法直接对SMT和NMT数据集上的结果进行比较；同时，NMT数据集上的平均HTER分数也更低，这些可能是导致En-De数据集上各系统普遍在NMT数据上表现较差的原因。但是在En-Lv数据集上，这一趋势完全是相反的，NMT数据上系统的表现较好。不过系统在不同数据集上的排名是类似的，说明QE系统一般具有鲁棒性。 另一个事实是，没有系统使用了post-editing时间和post-editing中键盘敲击统计这两种label。 Task2（词级QE）结果及讨论 这个任务相当于有三个子任务，分别对三种不同的token进行标记，并分别进行测试： 译句中的普通token：根据post-edited版本进行标注，应被替换和删除的标记为BAD，其余标为OK 译句中的gap token：在译句中每个token之后和句首插入gap token（也就是说，如果原来有N个token，插入之后会变成2*N+1个token），如果gap token对应位置相比post-edited版本发生漏词，则该gap token标记为BAD；否则标为OK 源句中的token：使用fastalign工具将源句和post-edited版本的译句进行对齐；对于源句中的每个token，如果和它对齐的post-edited版本的译句中的token在译句中被删除或替换，则该token标记为BAD；否则标为OK 评价方式：对上述每种token的OK和BAD类别分别计算F1分数并相乘，以F1-mult作为最终评分标准。 baseline：提取feature后，作为sequence prediction问题，用CRF算法进行训练。 由于在各个数据集上进行提交的系统都不太一样，所以很难进行完整的比较。 参与En-De和De-En任务的系统最多；和往年一样，Task1的结果和Task2的结果相关性很强，所以QEBrain在task2也获胜了。由于UNQE等系统没有参与Task2，表现次好的系统是SHEF-PT，落后得稍微少一点。 对于En-De数据集，很显然各个系统在NMT数据集上的表现远差于SMT数据集；而En-Lv数据集中，系统在SMT数据集上表现更好，这和Task1也相同。 只有很少几个系统提交了gap检测和导致错误的源词的新任务；这些系统的表现都比较一般，但结果和在主任务上的表现是相关的。QEBrain系统在gap检测上的表现非常之好（没有在其他任务上提交）。并且从分数可以看出，预测源句中导致错误的token比预测译句中的错误token更难；这可能是因为“源句中导致错误的token”有更多的可能性。 En-Lv NMT数据集上，所有系统都只能达到baseline的效果；En-Cs数据集上所有系统的表现都差不多。这可能是因为预处理数据资源不够。 Task3（短语级QE）结果及讨论 短语有四类标注： OK：正确的短语 BAD：包含错误的短语 BAD_word_order：短语在句中位于错误的位置 BAD_omission：短语前后缺词 这一任务分成两个子任务： Task3a：和Task2一样，在译句中每个token之后和句首插入gap token；然后用SMT decoder将译句分成短语，对短语进行标注：最后将标注结果标到具体的词上，相当于这也是一个word-level的任务 Task3b：直接对短语进行标注，每个短语前后各有一个gap token，gap可能被标注为OK或BAD_omission。 评价方式： Task3a：和Task 2相同，都是OK和BAD类别下的F1-mult Task3b：短语级别的F1-mult 这一任务只有De-En数据集，数据是手动标注的（而非post-edit后再自动生成的）。 baseline：提取feature后，作为sequence labelling问题，用CRF算法进行训练。 和Task2的De-En结果相比，BAD类别的F1分数显著降低了。这一现象可能是因为数据生成的方式导致的，phrase label粒度更粗一些。 事实上，只有SHEF-PT和SHEF-bRNN系统参与了这一任务；它们在Task3a上的表现和baseline差不多，在Task3b上还不如baseline。作者据此认为短语级别的预测仍然是很有挑战的任务，但我觉得样本量太少了，也不是很有代表性。不过这可能说明我们需要更好的神经网络结构。 Task4（文档级QE）结果及讨论 这一任务的要求是对整个文档的翻译质量进行打分。文档中在accuracy、fluency和style三个方面出错的词被标出，并根据严重程度分为minor、major和critical三类；文档的真实得分由人类打出。 评价方式是预测得分和真实得分的皮尔森相关系数r。 baseline：QUEST++ 显然，baseline的得分已经很高了；只有SHEf-PT-indomain的分数稍高于baseline。这说明Task4是一项很难的任务；同时很难评价系统在这一任务上的表现。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"},{"name":"Quality Estimation","slug":"Quality-Estimation","permalink":"https://zhanghuimeng.github.io/tags/Quality-Estimation/"}]},{"title":"Leetcode 932. Beautiful Array（数学）","slug":"2018-10-28-Leetcode-932-Beautiful-Array（数学）","date":"2018-10-28T15:58:38.000Z","updated":"2018-10-28T16:38:38.000Z","comments":true,"path":"post/leetcode-932-beautiful-array/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-932-beautiful-array/","excerpt":"","text":"题目来源：https://leetcode.com/problems/beautiful-array/description/ 标记难度：Medium 提交次数：2/3 代码效率： 直接递归版本：8ms 带cache递归版本：12ms 题意 对于正整数N，称1到N的全排列A为beautiful当且仅当对于任意i &lt; j，不存在满足i &lt; k &lt; j且A[k] * 2 = A[i] + A[j]的k。给定N，请输出任意beautiful的A。 分析 一道很有趣的题。（这次比赛最难的题就是medium了啊）最开始我并没有什么思路。于是我暴力了一下： N=4时的beautiful排列共有10个： 123456789101 3 2 41 3 4 22 1 4 32 4 1 32 4 3 13 1 2 43 1 4 23 4 1 24 2 1 34 2 3 1 N=5时共有20个： 123456781 5 3 2 41 5 3 4 22 1 4 5 32 4 1 5 32 4 3 1 52 4 3 5 12 4 5 1 3... N=6时共有48个： 1234561 5 3 2 6 41 5 3 4 2 61 5 3 4 6 21 5 3 6 2 41 5 6 3 2 4... N=7时共有104个： 12345678910111 5 3 2 7 6 41 5 3 7 2 6 41 5 3 7 4 2 61 5 3 7 4 6 21 5 3 7 6 2 41 5 7 3 2 6 41 5 7 3 4 2 61 5 7 3 4 6 21 5 7 3 6 2 41 5 7 6 3 2 4... 我猜beautiful排列的数量肯定是随N递增的，但和N!比起来大概是稀疏的，所以随机生成一个排列然后再判断它是否具有所需的性质多半不太可取。然后通过观察，我发现很多beautiful排列都是把奇数排在前面，偶数排在后面的！于是就写了一个交上去了。我心想，这样做的道理是，不需要处理偶数和奇数中间的k；两个奇数相加除2如果生成偶数，则偶数肯定不在这些奇数里面…… 于是显然就WA了，没有注意到两个奇数相加除2也可能会生成奇数这一点。 但这就使得我注意到了一种可能存在的递归结构：以N=7为例，先把所有数分成奇数1 3 5 7和偶数2 4 6，然后把1 3 5 7转换成1 2 3 4，2 4 6转换成1 2 3，分别递归执行，得到1 3 2 4和1 3 2之后，再转换回1 5 3 7和2 6 4，把它们拼起来，就可以得到最终结果1 5 3 7 2 6 4。关于这一点的更正式的证明是，beautiful数组（经过转换之后不一定是排列了）满足以下性质[1]： 若A是beautiful数组，则A + x（对数组的每个元素加x）仍是beautiful数组 若A是beautiful数组，则A * x（对数组的每个元素乘x）仍是beautiful数组 若A是beautiful数组，则删除A中的一些元素，A仍是beautiful数组 以及lee215的题解[1:1]质量过于好了，真的，十分推荐阅读，除此之外，还有one-liner版本（仿佛看到了StefanPochmann……） 代码 直接递归 应该把这个函数直接写到beautifulArray函数里去的，而且算法也不是DFS…… 123456789101112131415161718192021class Solution &#123;private: vector&lt;int&gt; dfs(int N) &#123; if (N == 1) return &#123;1&#125;; // 奇数：(x + 1) / 2 // 偶数：x / 2 vector&lt;int&gt; left = dfs((N + 1) / 2); vector&lt;int&gt; right = dfs(N / 2); vector&lt;int&gt; sum; for (int x: left) sum.push_back(x * 2 - 1); for (int x: right) sum.push_back(x * 2); return sum; &#125;public: vector&lt;int&gt; beautifulArray(int N) &#123; return dfs(N); &#125;&#125;; 带cache的递归 12345678910111213141516171819202122232425class Solution &#123;private: unordered_map&lt;int, vector&lt;int&gt;&gt; cache; vector&lt;int&gt; backtrack(int N) &#123; if (cache.find(N) != cache.end()) return cache[N]; // 奇数：(x + 1) / 2 // 偶数：x / 2 vector&lt;int&gt; left = dfs((N + 1) / 2); vector&lt;int&gt; right = dfs(N / 2); vector&lt;int&gt; sum; for (int x: left) sum.push_back(x * 2 - 1); for (int x: right) sum.push_back(x * 2); cache[N] = sum; return sum; &#125;public: vector&lt;int&gt; beautifulArray(int N) &#123; cache[1] = &#123;1&#125;; return backtrack(N); &#125;&#125;; lee215’s Solution for Leetcode 932: [C++/Java/Python] Odd + Even Pattern, O(N) ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 931. Minimum Falling Path Sum（DP）","slug":"2018-10-28-Leetcode-931-Minimum-Falling-Path-Sum（DP）","date":"2018-10-28T15:46:09.000Z","updated":"2018-10-28T15:55:00.000Z","comments":true,"path":"post/leetcode-931-minimum-falling-path-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-931-minimum-falling-path-sum/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-falling-path-sum/description/ 标记难度：Medium 提交次数：1/1 代码效率：8ms 题意 给定一个二维数组A，问经过A的falling path（每一层和上一层所处位置的横坐标绝对值最多相差1）经过的值的和的最小值是多少。 分析 直接DP之。一个细节是，其实可以不新开一个数组，直接在A上DP就行[1]……（当然我知道用滚动数组优化也可以） 代码 123456789101112131415161718192021222324class Solution &#123;public: int minFallingPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; int N = A.size(), M = A[0].size(); int f[N][M]; for (int i = 0; i &lt; M; i++) f[0][i] = A[0][i]; for (int i = 1; i &lt; N; i++) &#123; for (int j = 0; j &lt; M; j++) &#123; if (j == 0) f[i][j] = A[i][j] + min(f[i-1][j], f[i-1][j+1]); else if (j == M - 1) f[i][j] = A[i][j] + min(f[i-1][j], f[i-1][j-1]); else &#123; f[i][j] = min(f[i-1][j-1], f[i-1][j+1]); f[i][j] = min(f[i-1][j], f[i][j]); f[i][j] += A[i][j]; &#125; &#125; &#125; int ans = f[N-1][0]; for (int i = 0; i &lt; M; i++) ans = min(ans, f[N-1][i]); return ans; &#125;&#125;; Official Solution for Leetcode 931. Minimum Falling Path Sum ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 930. Binary Subarrays With Sum（数组）","slug":"2018-10-28-Leetcode-930-Binary-Subarrays-With-Sum（数组）","date":"2018-10-28T15:03:17.000Z","updated":"2018-10-28T15:41:00.000Z","comments":true,"path":"post/leetcode-930-binary-subarrays-with-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-930-binary-subarrays-with-sum/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-subarrays-with-sum/description/ 标记难度：Medium 提交次数：4/4 代码效率： 场上乱写的：108ms 连续0：20ms 前缀和：32ms 题意 给定一个只包含0和1的数组A，问A中有多少个和为S的非空子序列？ 分析 Leetcode最近放题解的速度明显变慢了。这道题并不是很好实现（如果没有想到前缀和的方法的话），所以场上WA了一次。 连续0 这种方法是我在现场想到的：对于一个和为S的非空子序列，它的两侧可能有连续的0，也可能没有。我们可以从两侧都是1的合法的子序列出发，生成对应的所有两侧可能多出来一些0的子序列的数量。这种方法的一个缺点是需要特判S = 0的情形。 我看到的一种比较巧妙的方法是，记录所有1之间的间隔里的0的数量，然后就可以直接枚举和为S的子序列了。[1] 例如：对于序列1 0 0 1 0 1，记录数组会变成zeros = [0, 2, 1, 0]；当S = 2时，可以直接通过(zeros[0] + 1) * (zeros[2] + 1)和(zeros[1] + 1) * (zeros[3] + 1)计算出所有合法子序列的数量。 前缀和 直接用一个map存储前缀和，然后在里面查找对应的值的数量。看起来是十分容易想到的做法，不过我并没有想到。[2] 代码 （场上乱写的就不放了） 连续0 1234567891011121314151617181920212223242526class Solution &#123;public: int numSubarraysWithSum(vector&lt;int&gt;&amp; A, int S) &#123; vector&lt;int&gt; zeros; int cnt = 0; for (int x: A) &#123; if (x == 1) &#123; zeros.push_back(cnt); cnt = 0; &#125; else cnt++; &#125; zeros.push_back(cnt); int ans = 0; if (S == 0) &#123; for (int x: zeros) ans += x * (x + 1) / 2; return ans; &#125; for (int i = 0; i + S &lt; zeros.size(); i++) ans += (zeros[i] + 1) * (zeros[i + S] + 1); return ans; &#125;&#125;; 前缀和 123456789101112131415class Solution &#123;public: int numSubarraysWithSum(vector&lt;int&gt;&amp; A, int S) &#123; unordered_map&lt;int, int&gt; prefixSum; int sum = 0; int ans = 0; prefixSum[0]++; for (int x: A) &#123; sum += x; ans += prefixSum[sum - S]; prefixSum[sum]++; &#125; return ans; &#125;&#125;; Leetcode 930 Solution by Evilnearby - Java O(N) Time O(N) Space, counting contiguous zeros ↩︎ Leetcode 930 Solution by lee215 - [C++/Java/Python] Straight Forward ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 258. Add Digits（数学）","slug":"2018-10-28-Leetcode-258-Add-Digits（数学）","date":"2018-10-28T14:58:04.000Z","updated":"2018-10-28T16:59:00.000Z","comments":true,"path":"post/leetcode-258-add-digits/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-258-add-digits/","excerpt":"","text":"题目来源：https://leetcode.com/problems/add-digits/description/ 标记难度：Easy 提交次数：2/2 代码效率： 暴力法：99.13% 公式法：99.13% 题意 不断对某个数的所有数位求和，直到只剩下一位为止。求最后剩下的一位。 分析 显然可以直接暴力模拟。不过事实上有更好的方法。求得的结果的学名叫数根（digital root）。在十进制下： dr(n)=1+((n−1) mod 9)dr(n) = 1 + ((n-1) \\bmod 9) dr(n)=1+((n−1)mod9) 然后直接代公式就可以了。（至于公式的证明，我觉得可以尝试一下，但现在还是算了吧） 代码 暴力法 123456789101112class Solution &#123;public: int addDigits(int num) &#123; if (num &lt; 10) return num; int x = 0; while (num &gt; 0) &#123; x += num % 10; num /= 10; &#125; return addDigits(x); &#125;&#125;; 公式法 123456class Solution &#123;public: int addDigits(int num) &#123; return 1 + (num - 1) % 9; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 929. Unique Email Addresses（字符串），及周赛（108）总结","slug":"2018-10-28-Leetcode-929-Unique-Email-Addresses（字符串），及周赛（107）总结","date":"2018-10-28T14:29:17.000Z","updated":"2018-10-28T14:54:00.000Z","comments":true,"path":"post/leetcode-929-unique-email-addresses-and-weekly-contest-108/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-929-unique-email-addresses-and-weekly-contest-108/","excerpt":"","text":"题目来源：https://leetcode.com/problems/unique-email-addresses/description/ 标记难度：Easy 提交次数：1/1 代码效率：36ms 题意 给定一系列email地址，求满足以下要求的不重复地址数量： 将email地址分成local name和domain name，形如：local-name@domain-name 数据保证每个地址中有且仅有一个@字符 local name中的.字符应被忽略 local name中的+字符及其后所有字符应被忽略 分析 我这次比赛的最终排名是62 / 3652。但事实上我把前4题都做出来的时候，live排名是三百多名，这听起来就很奇怪了。总之，这次比赛的确比较简单……以及这次比赛第一名是clw。 至于这道题……随便用字符串搞一下就可以了，然后去个重，我就不仔细思考了。 代码 搞了个像状态机一样的东西逐字符处理；不过我觉得还是使用find和split更好。事实上我在场上又忘了字符串处理函数具体怎么用了。 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int numUniqueEmails(vector&lt;string&gt;&amp; emails) &#123; set&lt;string&gt; uniqueEmails; for (string email: emails) &#123; string local; string domain; int status = 0; // 0: not found + / @; // 1: found +; // 2: found @ for (char x: email) &#123; if (x == '+') &#123; if (status == 0) status = 1; else if (status == 2) domain += x; &#125; else if (x == '.') &#123; if (status == 0 || status == 1) continue; if (status == 2) domain += x; &#125; else if (x == '@') status = 2; else &#123; if (status == 0) local += x; else if (status == 2) domain += x; &#125; &#125; // cout &lt;&lt; local + '@' + domain &lt;&lt; endl; uniqueEmails.insert(local + '@' + domain); &#125; return uniqueEmails.size(); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 928. Minimize Malware Spread II（图）","slug":"2018-10-22-Leetcode-928-Minimize-Malware-Spread-II（图）","date":"2018-10-22T00:39:12.000Z","updated":"2018-10-22T01:31:00.000Z","comments":true,"path":"post/leetcode-928-minimize-malware-spread-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-928-minimize-malware-spread-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimize-malware-spread-ii/description/ 标记难度：Hard 提交次数：2/2 代码效率： 暴力DFS：104ms 优化过的DFS：108ms 优化过的并查集：懒得写了 题意 有一个无向图，图中有些结点被感染了，感染会通过图的边传播。现在可以移除一个初始被感染的结点（是移除，而不是让它不被感染），问移除哪一个结点可以使最终被感染的总结点数最小？如果有多个结点，输出编号最小的一个。 分析 呃，这道题的题意正好和我上次看错的是一样的……于是我当然直接用了最暴力的方法，手动模拟每个初始感染结点被删除之后的感染状况。当然我觉得这种方法看起来还不差，因为DFS的复杂度是O(N)，DFSN次的复杂度就是O(N^2)；不过显然我这样想的时候没有考虑到题目里给出的图是邻接矩阵表示（而非邻接表），所以实际复杂度应该是O(N^3)。不过反正N &lt;= 300，N2和N3也差不多。（……） 优化过的DFS 首先将所有初始感染结点从图里移除；然后对于每个初始感染结点，通过DFS找到它能够感染的结点集合；然后对于每个普通结点，找出它会被多少个结点感染。如果它只能被某一个结点感染，移除该结点就可以使得该普通结点不会被感染。然后找到其中的最大值即可。[1] 我的一个疑惑是，为何是把所有初始感染结点都移除，而不是把所有的结点都留在图里，然后找到某一个结点能感染的结点集合？这两点的区别显然是，把其他的结点留在图里之后，某一个结点能感染的结点集合就会变大，甚至包含一些移除了别的结点之后不能被感染的结点，这大约是不合适的。 另一个问题是，考虑到邻接矩阵的问题，这个方法的时间复杂度是不是仍然是O(N^3)……事实证明运行时间差不多。 优化过的并查集 这个方法的思路和上一个差不多，不过是把DFS换成并查集，然后判断每个分量和多少个初始感染结点相邻。（就是写得更明白一点了。）我感觉这个方法是O(N^2)的（因为相比DFS节省了很多无用的计算），不过我现在不是很想写了。[1:1] 代码 暴力DFS 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;private: void dfs(int cur, vector&lt;vector&lt;int&gt;&gt;&amp; graph, int &amp;cnt, const int&amp; removed, bool visited[]) &#123; for (int y = 0; y &lt; graph[cur].size(); y++) &#123; if (graph[cur][y] &amp;&amp; !visited[y] &amp;&amp; y != removed) &#123; visited[y] = true; cnt++; dfs(y, graph, cnt, removed, visited); &#125; &#125; &#125;public: int minMalwareSpread(vector&lt;vector&lt;int&gt;&gt;&amp; graph, vector&lt;int&gt;&amp; initial) &#123; // completely remove sort(initial.begin(), initial.end()); int n = graph.size(); int ans = n + 1, index = -1; bool visited[n]; for (int x: initial) &#123; memset(visited, false, sizeof(visited)); int cnt = 0; for (int y: initial) &#123; if (x != y &amp;&amp; !visited[y]) &#123; visited[y] = true; cnt++; dfs(y, graph, cnt, x, visited); &#125; &#125; if (cnt &lt; ans) &#123; index = x; ans = cnt; &#125; &#125; return index; &#125;&#125;; 优化过的DFS 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Solution &#123;private: void dfs(int cur, const int&amp; x, vector&lt;vector&lt;int&gt;&gt;&amp; graph, bool isRemoved[], unordered_set&lt;int&gt; affect[]) &#123; for (int i = 0; i &lt; graph.size(); i++) &#123; if (graph[cur][i] &amp;&amp; !isRemoved[i] &amp;&amp; affect[x].find(i) == affect[x].end()) &#123; affect[x].insert(i); dfs(i, x, graph, isRemoved, affect); &#125; &#125; &#125;public: int minMalwareSpread(vector&lt;vector&lt;int&gt;&gt;&amp; graph, vector&lt;int&gt;&amp; initial) &#123; int n = graph.size(); bool isRemoved[n]; memset(isRemoved, 0, sizeof(isRemoved)); for (int x: initial) isRemoved[x] = true; // 分别DFS unordered_set&lt;int&gt; affect[n]; for (int x: initial) &#123; isRemoved[x] = false; affect[x].insert(x); dfs(x, x, graph, isRemoved, affect); isRemoved[x] = true; &#125; // 每个结点会被哪些结点感染 unordered_set&lt;int&gt; affectedBy[n]; for (int i = 0; i &lt; n; i++) &#123; for (int x: affect[i]) affectedBy[x].insert(i); &#125; // 只被一个结点感染的结点 int singleCnt[n]; memset(singleCnt, 0, sizeof(singleCnt)); for (int i = 0; i &lt; n; i++) &#123; if (!isRemoved[i] &amp;&amp; affectedBy[i].size() == 1) singleCnt[*affectedBy[i].begin()]++; &#125; // 取最大值 int index = -1, maximum = -1; for (int i = 0; i &lt; n; i++) &#123; if (isRemoved[i] &amp;&amp; singleCnt[i] &gt; maximum) &#123; index = i; maximum = singleCnt[i]; &#125; &#125; return index; &#125;&#125;; Leetcode Official Solution for 928. Minimize Malware Spread II ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Graph","slug":"alg-Graph","permalink":"https://zhanghuimeng.github.io/tags/alg-Graph/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Union-find Forest","slug":"alg-Union-find-Forest","permalink":"https://zhanghuimeng.github.io/tags/alg-Union-find-Forest/"}]},{"title":"Leetcode 927. Three Equal Parts（构造）","slug":"2018-10-21-Leetcode-927-Three-Equal-Parts（构造）","date":"2018-10-21T16:02:50.000Z","updated":"2018-10-22T00:32:50.000Z","comments":true,"path":"post/leetcode-927-three-equal-parts/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-927-three-equal-parts/","excerpt":"","text":"题目来源：https://leetcode.com/problems/three-equal-parts/description/ 标记难度：Hard 提交次数：2/6 代码效率： 暴力set：MLE 枚举构造：212ms 直接构造：44ms 题意 给定一个只由0和1组成的数组，要求把数组分成三份，每一份表示的二进制数都相等。返回一种划分方法。 分析 比赛的时候这道题我做了好久。我先是想了一种比较暴力的方法：把数组所有的前缀去掉前导零后都放到一个set里面，然后再在这个set中查找所有的后缀是否存在，如果存在，则验证去掉前缀和后缀之后剩余的部分是否相等。结果就MLE了，因为花费的内存是O(N^2)。我觉得如果要维持这种做法的话，用Trie会比较好，但是我又不想写Trie。遂MLE/WA了4次。 之后我突然意识到根本没有使用set的必要，因为二进制数相等的前提是长度相等（去掉前导零）。只要确定了后缀去掉前导零之后的长度，就可以立即知道前缀去掉前导零之后的长度了，也即前缀的结束位置；然后判断剩余的部分去掉前导零和它们是否相等就可以了。 更好的方法是直接构造。为了保证三段表示的二进制数各自相等，显然需要保证每一段中1的数量相等；那么，可以先统计1的数量，如果这个数模3不为0则显然没有合法的解；否则就可以得到每一段中应有的1的数量了。然后就可以构造最后一段了：从后向前遍历数组，直到找到相应数量的1为止（因为再向前找只能找到前导0；否则1的数量就不合法了）。此时就可以知道二进制数的长度了，可以构造第一段；然后判断中间的一段和两边是否相等即可。[1] 代码 枚举构造 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;private:public: vector&lt;int&gt; threeEqualParts(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); string S; for (int x: A) S += to_string(x); int start = 0; // remove str1 preceeding 0 while (S[start] == '0' &amp;&amp; start &lt; n) start++; if (start &gt;= n) return &#123;0, n - 1&#125;; for (int i = n - 1; i &gt;= 0; i--) &#123; // str3 = [i, n) int start3 = i; // remove str3 preceeding 0 while (start3 &lt; n &amp;&amp; S[start3] == '0') start3++; if (start3 &gt;= n) start3 = n - 1; string str3 = S.substr(start3, n - start3); string str1 = S.substr(start, n - start3); // assert str1 == str3 if (str1 == str3) &#123; // remove str2 preceeding 0 int start2 = start + str3.size(), end2 = i; if (start2 &gt;= end2) break; // exceeded... while (start2 &lt; end2 &amp;&amp; S[start2] == '0') start2++; if (start2 &gt;= end2) start2 = end2 - 1; string str2 = S.substr(start2, end2 - start2); if (str2 == str3) &#123; return &#123;start + str3.size() - 1, i&#125;; &#125; &#125; &#125; return &#123;-1, -1&#125;; &#125;&#125;; 直接构造 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: vector&lt;int&gt; threeEqualParts(vector&lt;int&gt;&amp; A) &#123; int ones = 0, n = A.size(); string S; for (int x: A) &#123; ones += x; S += to_string(x); &#125; if (ones % 3 != 0) return &#123;-1, -1&#125;; if (ones == 0) return &#123;0, n - 1&#125;; // 构造最后一段 int one = ones / 3; int start3 = n - 1, cnt = 0; string str3; for (int i = n - 1; i &gt;= 0; i--) &#123; cnt += A[i]; if (cnt == one) &#123; start3 = i; str3 = S.substr(i, n - i); break; &#125; &#125; int len = str3.size(); // 构造第一段 int start1 = 0; while (start1 &lt; n &amp;&amp; A[start1] == 0) start1++; string str1 = S.substr(start1, len); if (str1 != str3) return &#123;-1, -1&#125;; // 构造第二段 int start2 = start1 + len; while (start2 &lt; n &amp;&amp; A[start2] == 0) start2++; // 保证str2没有越过str3且中间只有0（作为str3的前导0） if (start2 + len &gt; start3) return &#123;-1, -1&#125;; string str2 = S.substr(start2, len); for (int i = start2 + len; i &lt; start3; i++) if (A[i] != 0) return &#123;-1, -1&#125;; if (str2 != str3) return &#123;-1, -1&#125;; return &#123;start1 + len - 1, start2 + len&#125;; &#125;&#125;; primeNumber’s solution for Leetcode 927 - [C++] O(n) time, O(1) space, 12 ms with explanation &amp; comments ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 926. Flip String to Monotone Increasing（字符串）","slug":"2018-10-21-Leetcode-926-Flip-String-to-Monotone-Increasing（字符串）","date":"2018-10-21T15:23:04.000Z","updated":"2018-10-21T15:48:00.000Z","comments":true,"path":"post/leetcode-926-flip-string-to-monotone-increasing/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-926-flip-string-to-monotone-increasing/","excerpt":"","text":"题目来源：https://leetcode.com/problems/flip-string-to-monotone-increasing/description/ 标记难度：Medium 提交次数：2/2 代码效率： 普通的做法：12ms 神奇的做法：8ms 题意 有一个只包含0和1的串，希望把里面的一些位翻转，使得这个串变成连续的若干个0（可以没有）后跟着连续的若干个1（也可以没有）。问翻转次数最少是多少。 分析 一个立即可以想到的思路是枚举。枚举每一位作为1的起始点，然后根据这一位左边的1的个数和右边的0的个数算出总的翻转次数，然后取最小值。前缀中1的个数和后缀中0的个数都很好维护。 另一个相当神奇的思路[1]应用了贪心法。在从左向右扫描的过程中，我们动态维护这个分割点，分割点左侧1的数量，分割点右侧1的数量和0的数量；一旦发现分割点右侧0的数量超过了1的数量，说明此时把分割点直接右移到当前扫描点可以减小翻转次数。举个例子： S = &quot;00011000&quot; i virtual split point left 1 cnt right 0 cnt right 1 cnt 0 0 (| 00011000) 0 0 0 1 1 (0| 0011000) 0 0 0 2 2 (00| 011000) 0 0 0 3 3 (000| 11000) 0 0 0 4 3 (000|1 1000) 0 0 1 5 3 (000|11 000) 0 0 2 6 3 (000|110 00) 0 1 2 7 3 (000|1100 0) 0 2 2 8 8 (00011000|) 2 0 0 这个算法的正确性怎么证明……好吧，懒得去想了。大概应该用反证法。 代码 普通的做法 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int minFlipsMonoIncr(string S) &#123; int n = S.size(); if (n == 0) return 0; int totZeros = 0, totOnes = 0; // actually, ones array can be omitted. int ones[n]; // num of ones &lt;= i for (int i = 0; i &lt; n; i++) &#123; if (S[i] == '0') &#123; totZeros++; ones[i] = i == 0 ? 0 : ones[i - 1]; &#125; else &#123; totOnes++; ones[i] = i == 0 ? 1 : ones[i - 1] + 1; &#125; &#125; int ans = n; for (int i = 0; i &lt; n; i++) &#123; // flip [i, ) to be 1 int leftOnes = i == 0 ? 0 : ones[i - 1]; int leftFlip = leftOnes; int rightFlip = n - i - (totOnes - leftOnes); // cout &lt;&lt; i &lt;&lt; ' ' &lt;&lt; leftOnes &lt;&lt; ' ' &lt;&lt; leftFlip &lt;&lt; ' ' &lt;&lt; rightFlip &lt;&lt; endl; ans = min(ans, leftFlip + rightFlip); &#125; // flip all to be zero ans = min(totOnes, ans); return ans; &#125;&#125;; 神奇的做法 123456789101112131415class Solution &#123;public: int minFlipsMonoIncr(string S) &#123; int leftOnes = 0, rightOnes = 0, rightZeros = 0; for (int i = 0; i &lt; S.size(); i++) &#123; if (S[i] == '0') rightZeros++; else rightOnes++; if (rightZeros &gt; rightOnes) &#123; // move split point to i leftOnes += rightOnes; rightOnes = rightZeros = 0; &#125; &#125; return leftOnes + rightZeros; &#125;&#125;; Leetcode 926 Solution by vortubac - C++ 4 lines O(n) | O(1), DP ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 925. Long Pressed Name（字符串），及周赛（107）总结","slug":"2018-10-21-Leetcode-925-Long-Pressed-Name（字符串），及周赛（107）总结","date":"2018-10-21T14:48:23.000Z","updated":"2018-10-21T15:15:23.000Z","comments":true,"path":"post/leetcode-925-long-pressed-name-and-weekly-contest-107/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-925-long-pressed-name-and-weekly-contest-107/","excerpt":"","text":"题目来源：https://leetcode.com/problems/long-pressed-name/description/ 标记难度：Easy 提交次数：2/2 代码效率： 暴力的做法：4ms 不太暴力的做法：0ms 题意 有一个叫name的字符串，你在把它录入电脑的时候可能会把某个字母连续重复若干遍（相当于你“长按”了那个按键），问typed串是否有可能是这样形成的。 分析 应当庆祝一下，这次比赛中第一次把所有题都做出来了（当然也是因为题水）。最后得到的排名是128 / 3209，充分说明是题太水了。而且我第三题因为MLE的罚时太多了。不过今天不知道Leetcode是不是出了什么问题，现在官方题解仍未出现。 （虽然我知道我还是很菜，但是我很久以前就写过了，要接受自己的菜然后努力去提升，别人怎么样我是不管的。） 我比赛的时候的做法就是把两个字符串都做了一个连续字符的压缩，然后对压缩之后的结果进行比较。这个方法比较暴力。当然，也可以不那么暴力，也就是不把这个过程显式地写出来。[1] 代码 暴力的做法 1234567891011121314151617181920212223class Solution &#123;public: bool isLongPressedName(string name, string typed) &#123; vector&lt;pair&lt;char, int&gt;&gt; press1, press2; for (char ch: name) &#123; if (press1.size() == 0 || press1.back().first != ch) press1.emplace_back(ch, 1); else press1.back().second++; &#125; for (char ch: typed) &#123; if (press2.size() == 0 || press2.back().first != ch) press2.emplace_back(ch, 1); else press2.back().second++; &#125; if (press1.size() != press2.size()) return false; for (int i = 0; i &lt; press1.size(); i++) if (press1[i] &gt; press2[i]) return false; return true; &#125;&#125;; 不太暴力的做法 参考了[1:1]中的代码。 123456789101112131415class Solution &#123;public: bool isLongPressedName(string name, string typed) &#123; int n = name.size(), m = typed.size(); if (n &gt; m) return false; int i = 0, j = 0; while (i &lt; n || j &lt; m) &#123; if (i &lt; n &amp;&amp; typed[j] == name[i]) i++, j++; else if (i &gt; 0 &amp;&amp; typed[j] == name[i - 1]) j++; else break; &#125; if (i == n &amp;&amp; j == m) return true; return false; &#125;&#125;; Leetcode 925 Solution by votrubac - C++ 2 lines accepted and 5 lines accurate ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"歌词翻译：Pressure's On, by Ceremony (Album: Violence Violence)","slug":"2018-10-16-歌词翻译：Pressure-s-On-by-Ceremony-Album-Violence-Violence","date":"2018-10-16T01:41:38.000Z","updated":"2018-10-21T14:34:00.000Z","comments":true,"path":"post/pressure-s-on-by-ceremony-album-violence-violence-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/pressure-s-on-by-ceremony-album-violence-violence-lyric-translation/","excerpt":"","text":"歌：https://music.163.com/#/song?id=3942657 歌词 翻译 Law’s on my back 法律总挑我毛病 Pressure’s always on 压力持续不断 Never able do things on my own 永远无法做自己的事情 The way we dress disturbs them all 我们的穿着打扮让他们坐立不安 They push us against the wall 他们把我们逼到墙角 They tell us our rights 他们把权利告知我们 Just because we fight 只是因为我们战斗 Can’t understand at all 完全不可理喻 Law’s on my back 法律总挑我毛病 Pressure’s always on 压力持续不断 Never able to do things on my own 永远无法做自己的事情 They keep their eyes on us 他们不断监视我们 Ready for a bust 准备好大干一场 Don’t they have any trust? 他们难道毫不信任我们？ But who are they to say? 但他们又有何资格说话？ I do things my own way 我只是按自己的方式做事 其实我觉得这首歌的歌词只是单纯地在发泄情绪而已。有些前言不搭后语。以及，学到了一个新的表达方式：“on my back”是“找我麻烦，挑我毛病”的意思（我猜在此处肯定不是“把法律的重担背在肩上”的意思……）。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Ceremony","slug":"artist-Ceremony","permalink":"https://zhanghuimeng.github.io/tags/artist-Ceremony/"}]},{"title":"Leetcode 924. Minimize Malware Spread（图论）","slug":"2018-10-14-Leetcode-924-Minimize-Malware-Spread（图论）","date":"2018-10-14T19:49:59.000Z","updated":"2018-10-14T21:08:00.000Z","comments":true,"path":"post/leetcode-924-minimize-malware-spread/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-924-minimize-malware-spread/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimize-malware-spread/description/ 标记难度：Hard 提交次数：3/7 代码效率： 暴力：256ms DFS：216ms 并查集：108ms 题意 有一个无向图，图中有些结点被感染了，感染会通过图的边传播。现在可以移除一个初始被感染的结点，问移除哪一个结点可以使最终被感染的总结点数最小？如果有多个结点，输出编号最小的一个。 分析 我比赛的时候居然交了4次…… 第一次写了一个巨暴力的方法：每次移除一个初始感染结点，然后用DFS计算被感染结点总数。然后我还没写对。题目表明“使一个结点初始不被感染，它仍然有可能被传播到感染”，所以直接把结点从图里去掉是不可取的。而且很不幸的是，我还把graph当成邻接表了（事实上应该是邻接矩阵）。 第二次我尝试调这个暴力，但是我对题意产生了一点误解：如果有多个合法结点，是输出在vector&lt;int&gt; initial中index最小的结点，还是输出编号最小的结点？事实证明应该是编号最小的结点，但我这一次改成了index最小，那自然是没有什么对的可能了。 第三次我还在调这个暴力，但并没有发现核心问题。 第四次我仍然在调这个暴力，此时发现了graph的问题，但还是对题目内容有着非常深刻的误解。（而且此时已经10:55了。） 其实交第一次之前我是想到了正解的（无论是用DFS，还是并查集），但紧接着我就由于各种原因把题给看错了……这可真是太不可取了。 上面说的暴力算法的复杂度应该是O(M * N + M)（M = initial.length，N = graph.length）。原来这样就能过了吗……不愧是1 &lt;= graph.length &lt;= 300。 DFS 这个思路很容易想到。用DFS对图中的连通分量（如果我没有搞错图论术语的话）进行染色，这样就可以知道每个结点对应的连通分量和连通分量的大小了；然后统计每个连通分量中所包含的初始感染结点的数量，如果该连通分量只包含一个初始感染结点，则移除该感染结点可以防止整个连通分量的结点受到感染；否则移除该结点不会改变受感染结点的总数。然后取最小值即可。 DFS的时间复杂度是O(N)，统计结点数量的复杂度是O(M)，总复杂度为O(N + M)。 并查集 这个思路和DFS基本类似，只是换成用并查集来进行着色而已。[1] 代码 暴力 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;private: int n; void dfs(int x, vector&lt;vector&lt;int&gt;&gt;&amp; graph, int&amp; cnt, bool visited[]) &#123; for (int i = 0; i &lt; n; i++) &#123; if (graph[x][i] &amp;&amp; !visited[i]) &#123; cnt++; visited[i] = true; dfs(i, graph, cnt, visited); &#125; &#125; &#125;public: int minMalwareSpread(vector&lt;vector&lt;int&gt;&gt;&amp; graph, vector&lt;int&gt;&amp; initial) &#123; n = graph.size(); bool visited[n]; int minimum = n + 1, index = -1; sort(initial.begin(), initial.end()); for (int i = 0; i &lt; initial.size(); i++) &#123; memset(visited, 0, sizeof(visited)); // remove i int cnt = 0; for (int j = 0; j &lt; initial.size(); j++) &#123; if (j != i &amp;&amp; !visited[initial[j]]) &#123; visited[initial[j]] = true; cnt++; dfs(initial[j], graph, cnt, visited); &#125; &#125; //cout &lt;&lt; initial[i] &lt;&lt; ' ' &lt;&lt; cnt &lt;&lt; endl; if (cnt &lt; minimum) &#123; minimum = cnt; index = initial[i]; &#125; &#125; return index; &#125;&#125;; DFS 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution &#123;private: int n; void dfs(int x, int c, vector&lt;vector&lt;int&gt;&gt;&amp; graph, int color[], int colorNum[]) &#123; for (int y = 0; y &lt; n; y++) if (graph[x][y] &amp;&amp; !color[y]) &#123; color[y] = c; colorNum[c]++; dfs(y, c, graph, color, colorNum); &#125; &#125;public: int minMalwareSpread(vector&lt;vector&lt;int&gt;&gt;&amp; graph, vector&lt;int&gt;&amp; initial) &#123; n = graph.size(); // color the graph int color[n + 1], colorNum[n + 1]; memset(color, 0, sizeof(color)); int c = 1; for (int i = 0; i &lt; n; i++) &#123; if (!color[i]) &#123; color[i] = c; colorNum[c] = 1; dfs(i, c, graph, color, colorNum); c++; &#125; &#125; // find colors of initials // 此处也可以不排序的，多加一些特判就行了…… sort(initial.begin(), initial.end()); int initialsInColors[n + 1]; memset(initialsInColors, 0, sizeof(initialsInColors)); for (int x: initial) &#123; initialsInColors[color[x]]++; &#125; int maxn = -1, index = -1; for (int x: initial) &#123; if (initialsInColors[color[x]] &lt;= 1 &amp;&amp; colorNum[color[x]] &gt; maxn) &#123; maxn = colorNum[color[x]]; index = x; &#125; else if (initialsInColors[color[x]] &gt; 1 &amp;&amp; 0 &gt; maxn) &#123; maxn = 0; index = x; &#125; &#125; return index; &#125;&#125;; 并查集 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123;private: int n; int fa[305], cnt[305]; void init() &#123; for (int i = 0; i &lt; n; i++) &#123; fa[i] = i; cnt[i] = 1; &#125; &#125; int find(int x) &#123; if (x == fa[x]) return x; else &#123; cnt[fa[x]] += cnt[x]; cnt[x] = 0; return fa[x] = find(fa[x]); &#125; &#125; int getcnt(int x) &#123; return cnt[find(x)]; &#125; void merge(int x, int y) &#123; x = find(x); y = find(y); if (cnt[x] &gt;= cnt[y]) swap(x, y); fa[x] = y; find(x); &#125;public: int minMalwareSpread(vector&lt;vector&lt;int&gt;&gt;&amp; graph, vector&lt;int&gt;&amp; initial) &#123; n = graph.size(); init(); for (int i = 0; i &lt; n; i++) for (int j = i + 1; j &lt; n; j++) if (graph[i][j]) merge(i, j); int facnt[n]; memset(facnt, 0, sizeof(facnt)); for (int x: initial) facnt[find(x)]++; int maxn = -1, index = n + 1; for (int x: initial) &#123; if (facnt[find(x)] &lt;= 1 &amp;&amp; (getcnt(x) &gt; maxn || getcnt(x) == maxn &amp;&amp; x &lt; index)) &#123; maxn = getcnt(x); index = x; &#125; else if (0 &gt; maxn || maxn == 0 &amp;&amp; x &lt; index) &#123; maxn = 0; index = x; &#125; &#125; return index; &#125;&#125;; lee215’s Union Found Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Graph","slug":"alg-Graph","permalink":"https://zhanghuimeng.github.io/tags/alg-Graph/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Union-find Forest","slug":"alg-Union-find-Forest","permalink":"https://zhanghuimeng.github.io/tags/alg-Union-find-Forest/"}]},{"title":"Leetcode 923. 3Sum With Multiplicity（数组）","slug":"2018-10-14-Leetcode-923-3Sum-With-Multiplicity（数组）","date":"2018-10-14T16:41:00.000Z","updated":"2018-10-14T17:24:00.000Z","comments":true,"path":"post/leetcode-923-3sum-with-multiplicity/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-923-3sum-with-multiplicity/","excerpt":"","text":"题目来源：https://leetcode.com/problems/3sum-with-multiplicity/description/ 标记难度：Medium 提交次数：3/7 代码效率： 计数：8ms 2Sum：4ms 题意 给定整数数组A和target，返回满足i &lt; j &lt; k, A[i] + A[j] + A[k] == target的(i, j, k)数量。其中3 &lt;= A.length &lt;= 3000，0 &lt;= A[i] &lt;= 100，0 &lt;= target &lt;= 300。 分析 比赛的时候这道题挂了三次： 没有判断k是否在[0, 100]范围内，所以RE了 忘记A[i]的下限是0了，所以WA了 数量计算的时候爆int了，所以又WA了 …… 显然最暴力的做法就是直接枚举，时间复杂度是O(N^3)。当然，这样太暴力了。有两个主要的优化方向： 根据0 &lt;= A[i] &lt;= 100进行去重 根据2Sum或者3Sum的思路进行指针优化 由于数据规模的原因，去重的思路是很容易想到的。至于指针优化，它的思路大概是这样的：如果已经确定了(i, j)，在i不变，j递增的情况下，如果合法的k存在，则k必然是递减的。所以只需要枚举(i, j)并通过这一方法确定k即可。当然，在本题使用去重的情况下，只要在hash表中直接查找target - i - j元素是否存在即可；不过这一思路仍然很有趣。[1] 代码 计数 12345678910111213141516171819202122232425262728class Solution &#123;public: int threeSumMulti(vector&lt;int&gt;&amp; A, int target) &#123; int n = A.size(); long long int cnt[101]; memset(cnt, 0, sizeof(cnt)); for (int i: A) cnt[i]++; long long int ans = 0, MOD = 1000000007; // different: i &lt;= j &lt;= k for (int i = 0; i &lt;= min(100, target); i++) &#123; if (!cnt[i]) continue; for (int j = i; j &lt;= 100 &amp;&amp; i + j &lt;= target &amp;&amp; j &lt;= target - i - j; j++) &#123; int k = target - i - j; if (k &gt; 100) continue; if (!cnt[j] || !cnt[k]) continue; if (i != j &amp;&amp; j != k) ans = (ans + cnt[i] * cnt[j] * cnt[k]) % MOD; else if (i != j &amp;&amp; j == k &amp;&amp; cnt[j] &gt;= 2) ans = (ans + cnt[i] * cnt[j] * (cnt[j] - 1) / 2) % MOD; else if (i == j &amp;&amp; j != k &amp;&amp; cnt[i] &gt;= 2) ans = (ans + cnt[i] * (cnt[i] - 1) * cnt[k] / 2) % MOD; else if (i == j &amp;&amp; j == k &amp;&amp; cnt[i] &gt;= 3) ans = (ans + cnt[i] * (cnt[i] - 1) * (cnt[i] - 2) / 6) % MOD; &#125; &#125; return ans; &#125;&#125;; 2Sum 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: int threeSumMulti(vector&lt;int&gt;&amp; A, int target) &#123; int n = A.size(); int cnt[101]; long long int value[101]; int key[101], m; memset(cnt, 0, sizeof(cnt)); for (int i: A) cnt[i]++; m = 0; for (int i = 0; i &lt;= 100; i++) &#123; if (cnt[i]) &#123; key[m] = i; value[m++] = cnt[i]; &#125; &#125; long long int ans = 0, MOD = 1000000007; // different: i &lt;= j &lt;= k for (int i = 0; i &lt; m; i++) &#123; int k = m - 1; for (int j = i; j &lt;= k; j++) &#123; while (j &lt;= k &amp;&amp; key[i] + key[j] + key[k] &gt; target) k--; if (j &gt; k) break; if (key[i] + key[j] + key[k] &lt; target) continue; if (i &lt; j &amp;&amp; j &lt; k) ans += value[i] * value[j] * value[k] % MOD; else if (i == j &amp;&amp; j &lt; k) ans += (value[i] * (value[i] - 1) * value[k] / 2) % MOD; else if (i &lt; j &amp;&amp; j == k) ans += (value[i] * value[j] * (value[j] - 1) / 2) % MOD; else if (i == j &amp;&amp; j == k) ans += (value[i] * (value[i] - 1) * (value[i] - 2) / 6) % MOD; ans %= MOD; &#125; &#125; return ans; &#125;&#125;; Leetcode 923 - Official Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 922. Sort Array By Parity II（数组）","slug":"2018-10-14-Leetcode-922-Sort-Array-By-Parity-II（数组）","date":"2018-10-14T16:18:57.000Z","updated":"2018-10-14T16:32:00.000Z","comments":true,"path":"post/leetcode-922-sort-array-by-parity-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-922-sort-array-by-parity-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sort-array-by-parity-ii/description/ 标记难度：Easy 提交次数：2/2 代码效率： 额外空间：96ms 双指针：68ms 题意 有一个数组A，其中奇元素和偶元素的数量相等。请把A排序，使得奇元素位于奇数位置，偶元素位于偶数位置。任何满足上述条件的排序都是合法的。 分析 额外空间 需要额外空间的做法是非常简单的：再开一个数组B，维护even和odd指针，对于每一个A[i]，根据它的奇偶性放到B中对应的位置。 双指针 事实上并不需要额外的空间，而仍然可以采用类似于快排的做法：用两个指针分别维护合法的奇序列和合法的偶序列的结束位置，将元素交换，直到排序完成。[1] 代码 额外空间 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; sortArrayByParityII(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; B(A); int odd = 1, even = 0; for (int i = 0; i &lt; A.size(); i++) &#123; if (A[i] % 2 == 1) &#123; B[odd] = A[i]; odd += 2; &#125; else &#123; B[even] = A[i]; even += 2; &#125; &#125; return B; &#125;&#125;; 双指针 123456789101112131415class Solution &#123;public: vector&lt;int&gt; sortArrayByParityII(vector&lt;int&gt;&amp; A) &#123; int odd = 1, even = 0, n = A.size(); while (odd &lt; n &amp;&amp; even &lt; n) &#123; while (odd &lt; n &amp;&amp; A[odd] % 2 == 1) odd += 2; while (even &lt; n &amp;&amp; A[even] % 2 == 0) even += 2; if (odd &gt;= n || even &gt;= n) break; swap(A[odd], A[even]); odd += 2; even += 2; &#125; return A; &#125;&#125;; Leetcode 922 - Official Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 921. Minimum Add to Make Parentheses Valid（栈），及周赛（106）总结","slug":"2018-10-14-Leetcode-921-Minimum-Add-to-Make-Parentheses-Valid（栈）","date":"2018-10-14T15:23:44.000Z","updated":"2018-10-14T16:00:00.000Z","comments":true,"path":"post/leetcode-921-minimum-add-to-make-parentheses-valid-and-weekly-contest-106/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-921-minimum-add-to-make-parentheses-valid-and-weekly-contest-106/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-add-to-make-parentheses-valid/description/ 标记难度：Easy 提交次数：3/3 代码效率： 栈：4ms 计数器：0ms 题意 给定一个只由括号组成的字符串，问如果需要在字符串中添加括号使它变成合法的字符串，最少需要添加多少个括号？ 分析 这次比赛的排名是632 / 2700。（人好少。）排名很低的原因一是第三题罚时太多了（靠WA来debug毕竟不可取，还是要好好考虑corner case？），二是这次第四题非常简单，但我却不仅看错了题，暴力也没写对…… 这道题很简单，但还稍微有点意思。在何种情况下需要添加括号？如何打印出一种添加括号的方法？ 我的第一反应是直接统计左括号和右括号各自的数量，但这么做显然不可取，反例：))((。那么不妨采用我们一般对括号表达式进行思考的方式——栈——来考虑这个问题。在括号入栈的过程中，一个右括号总是和栈中最顶端的还没有配对的左括号配对；如果当前栈中是空的，则这个右括号没有被配对——可以直接在它的左边加上一个左括号；如果最后栈中还剩下一些左括号，则直接在字符串的右侧加上对应数量的右括号。 这个问题也可以简化到不用栈来解决。直接用一个计数器维护当前栈中尚未配对的左括号数量即可。[1] 代码 栈 12345678910111213class Solution &#123;public: int minAddToMakeValid(string S) &#123; stack&lt;char&gt; s; for (char ch: S) &#123; if (!s.empty() &amp;&amp; s.top() == '(' &amp;&amp; ch == ')') s.pop(); else s.push(ch); &#125; return s.size(); &#125;&#125;; 实际地添加括号 写了一个实际添加括号的程序，大概是对的吧。 1234567891011121314151617181920212223242526272829class Solution &#123;public: int minAddToMakeValid(string S) &#123; stack&lt;int&gt; s; vector&lt;int&gt; toInsBefore; int ans = 0; for (int i = 0; i &lt; S.size(); i++) &#123; if (S[i] == '(') s.push(i); else &#123; if (s.empty()) &#123; // 记录未配对右括号的位置 toInsBefore.push_back(i); ans++; &#125; else s.pop(); &#125; &#125; for (int i = toInsBefore.size() - 1; i &gt;= 0; i--) S = S.substr(0, toInsBefore[i]) + '(' + S.substr(toInsBefore[i], S.size() - toInsBefore[i]); for (int i = 0; i &lt; s.size(); i++) &#123; ans++; S += ')'; &#125; cout &lt;&lt; S &lt;&lt; endl; return ans; &#125;&#125;; 计数器 1234567891011121314class Solution &#123;public: int minAddToMakeValid(string S) &#123; int counter = 0, ans = 0; for (char ch: S) &#123; if (ch == '(') counter++; else &#123; if (counter &gt; 0) counter--; else ans++; &#125; &#125; return ans + counter; &#125;&#125;; rock’s solution - [Java] two one pass 7 liners - space O(n) and O(1), respectively ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 920. Number of Music Playlists（DP）","slug":"2018-10-12-Leetcode-920-Number-of-Music-Playlists（DP）","date":"2018-10-12T11:02:39.000Z","updated":"2018-10-14T02:59:00.000Z","comments":true,"path":"post/leetcode-920-number-of-music-playlists/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-920-number-of-music-playlists/","excerpt":"","text":"题目来源：https://leetcode.com/problems/number-of-music-playlists/description/ 标记难度：Hard 提交次数：2/2 代码效率： DP：75.46% DP (Optimized)：75.46% 题意 有N首不同的歌，共需要播放L次，要求： 每首歌至少被播放一次 每首歌被播放的间隔至少是K 求共有多少种播放方式。数据保证0 &lt;= K &lt; N &lt;= L &lt;= 100。 分析 比赛的时候我大胆地推测这道题是DP。然后就没了，还是不会写…… 动态规划 如果用DP来做，第一个问题是状态方程应该包含哪些变量。不妨先把状态方程设置成dp[n][l][k]。然后显然需要思考从哪些状态进行递推这个问题。我觉得之前我总会知道递归的状态的，但现在这好像是一个值得思考的问题。 dp[n-1][l][k]：比现在少一首歌，但播放列表长度仍然是l。如何把多出来的歌塞进播放列表中是一个问题。 dp[n][l-1][k]：和现在歌的数量相同，但播放列表长度是l-1。任何在[l-1-k, l-1]位置没有被播放过的歌都可以被再播一遍；而且这一区间内的歌必然是没有重复的。这大概是此题的一个重要性质：合法的播放列表中，任何长度为k的区间内的歌都是互不重复的。很好。所以答案+= dp[n][l-1][k] * (n - k)。 dp[n][l][k-1]：因为破坏了之前的性质，所以感到很难用这个方法来递推。 dp[n-1][l-1][k]：比现在少一首歌，播放列表长度也少一首。把新歌插入到播放列表的任何位置都可以（不会缩小任何两首相同的歌之间的间隔），因此答案+= dp[n-1][l-1][k] * (l + 1)。只需把新歌插入到播放列表的最后位置。这首歌可以是任意一首，因此答案+= dp[n-1][l-1][k] * n。[1] 结论是，我们需要考虑的子状态只包括dp[n][l-1][k]和dp[n-1][l-1][k]。由于题目中有N &lt;= L的要求，这一设置是合理的。同时，由于发现根本没有用到k，不妨把k去掉，得到dp[n][l-1]和dp[n-1][l-1]。 以及上面被划掉的部分说明我没有理解清楚此处DP到底意味着什么。DP的状态本身表示什么是很容易说明的：dp[n][l]表示长度为l且有n首不同的歌的播放列表的总数；而dp[n][l] += dp[n-1][l-1][k] * n表示的是，从当前的n首歌里任选一首删除，用n-1首歌组成长度为l-1的播放列表；最后再把选出来的这首歌放在播放列表最后。之所以不是把这首歌插入到播放列表的各个位置，是因为那样就会得到与其他歌重复的状态，因此需要加以限制。 数学+DP 这部分是题解提供的。说实话，我并没有太看懂题解……所以就不写了……[2] 代码 DP 1234567891011121314class Solution &#123;public: int numMusicPlaylists(int N, int L, int K) &#123; long long int f[N + 1][L + 1]; memset(f, 0, sizeof(f)); f[1][1] = 1; for (int i = 1; i &lt;= N; i++) for (int j = 1; j &lt;= L; j++) &#123; f[i][j] += f[i][j-1] * max(i - K, 0) + f[i-1][j-1] * i; f[i][j] %= 1000000007; &#125; return f[N][L]; &#125;&#125;; DP (Optimized) 显然上述代码还有很多可以优化的地方，包括但不限于[1:1]： 显然只有j &gt;= i时f[i][j]才有意义。 当i == K + 1时，意味着我们只能先播放K + 1首歌曲，然后按相同顺序继续播放同样的歌曲，因此总的可能性数量为i!。 当i == j时，歌曲数量和播放列表长度相同，不需要考虑K的问题，因此总的可能性数量也为i!。 可以根据上述内容对DP代码进行优化。（虽然结果好像也没快多少。） 123456789101112131415161718192021class Solution &#123;private: inline long long factorial(int x) &#123; long long int sum = 1; while (x) sum = (sum * x--) % 1000000007; return sum; &#125;public: int numMusicPlaylists(int N, int L, int K) &#123; long long int f[N + 1][L + 1]; for (int i = K + 1; i &lt;= N; i++) for (int j = i; j &lt;= L; j++) &#123; if (i == K + 1 || i == j) f[i][j] = factorial(i); else f[i][j] = (f[i][j-1] * (i - K) + f[i-1][j-1] * i) % 1000000007; &#125; return f[N][L]; &#125;&#125;; lee215’s DP Solution for Leetcode 920 ↩︎ ↩︎ Leetcode 920 Official Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 919. Complete Binary Tree Inserter（堆）","slug":"2018-10-11-Leetcode-919-Complete-Binary-Tree-Inserter（堆）","date":"2018-10-11T00:40:02.000Z","updated":"2018-10-14T01:33:00.000Z","comments":true,"path":"post/leetcode-919-complete-binary-tree-inserter/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-919-complete-binary-tree-inserter/","excerpt":"","text":"题目来源：https://leetcode.com/problems/complete-binary-tree-inserter/description/ 标记难度：Medium 提交次数：4/6 代码效率： vector：78.93% queue：48.93% 题意 给定一个完全二叉树，写一个向完全二叉树中插入元素的操作类。 分析 比赛的时候觉得这道题很水，随便写就好了。事实上确实差不多是这样的。 vector 既然是完全二叉树的插入，那么可以利用数组保存堆的思想。如果根在1处，则x的左孩子在2 * x处，右孩子在2 * x + 1处；x的父亲在floor(x / 2)处。于是直接用一个vector做就可以了。预处理花费O(N)时间（因为需要把树中当前的结点都插入）；插入花费O(1)时间。听起来还可以。 queue 这个方法来自[1]，和上一个解法差不多，都利用了完全二叉树只有最低一层可能不满，只有最低两层的结点可能只有&lt;2个子结点的特性： 用一个队列维护当前还没有获得两个叶子结点的TreeNode* 插入新结点时，尝试插入到队头的结点的左侧或右侧（左侧优先）；然后再把新结点插入队尾 如果队头的结点已经有了两个子结点，则把它弹出 不过我看不出题解里使用deque的意义何在…… 直接计算 通过阅读12ms的示例代码，我发现了一种比较神奇的解法：不把整棵树缓存下来，直接在树上计算下一个结点的父节点位置。[2] 这种做法的思路大致是这样的： 初始化：通过dfs计算结点数量counter 插入结点： 根据counter计算当前树中层数numRows 根据counter和numRows计算出当前结点的父结点是倒数第二层（或最后一层）的第几个结点 通过二分查找找出这个结点并插入 具体内容实在没有时间去写了。 代码 vector 其中初始化时用vector代替queue的trick来自[3]。 123456789101112131415161718192021222324252627282930class CBTInserter &#123;private: vector&lt;TreeNode*&gt; heap;public: CBTInserter(TreeNode* root) &#123; heap.push_back(nullptr); heap.push_back(root); for (int i = 1; i &lt; heap.size(); i++) &#123; TreeNode* x = heap[i]; if (heap[i]-&gt;left != nullptr) heap.push_back(heap[i]-&gt;left); if (heap[i]-&gt;right != nullptr) heap.push_back(heap[i]-&gt;right); &#125; &#125; int insert(int v) &#123; int n = heap.size(); TreeNode* x = new TreeNode(v); heap.push_back(x); int m = n / 2; if (n % 2 == 0) heap[m]-&gt;left = x; else heap[m]-&gt;right = x; return heap[m]-&gt;val; &#125; TreeNode* get_root() &#123; return heap[1]; &#125;&#125;; queue 123456789101112131415161718192021222324252627282930313233343536373839404142class CBTInserter &#123;private: queue&lt;TreeNode*&gt; q; TreeNode* root;public: CBTInserter(TreeNode* root) &#123; q.push(root); this-&gt;root = root; while (!q.empty()) &#123; TreeNode* p = q.front(); if (p-&gt;left != nullptr) &#123; q.push(p-&gt;left); if (p-&gt;right != nullptr) &#123; q.push(p-&gt;right); q.pop(); &#125; else break; &#125; else break; &#125; &#125; int insert(int v) &#123; TreeNode* p = q.front(); TreeNode* n = new TreeNode(v); if (p-&gt;left == nullptr) &#123; p-&gt;left = n; q.push(n); return p-&gt;val; &#125; p-&gt;right = n; q.push(n); q.pop(); return p-&gt;val; &#125; TreeNode* get_root() &#123; return root; &#125;&#125;; Official Solution for Leetcode 919 ↩︎ Leetcode 919: sample 12 ms submission ↩︎ lee215’s Solution for Leetcode 919: O(1) Insert ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Heap","slug":"alg-Heap","permalink":"https://zhanghuimeng.github.io/tags/alg-Heap/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 918. Maximum Sum Circular Subarray（动态规划）","slug":"2018-10-07-Leetcode-918-Maximum-Sum-Circular-Subarray（动态规划）","date":"2018-10-07T20:23:26.000Z","updated":"2018-10-11T00:31:26.000Z","comments":true,"path":"post/leetcode-918-maximum-sum-circular-subarray/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-918-maximum-sum-circular-subarray/","excerpt":"","text":"题目来源：https://leetcode.com/problems/maximum-sum-circular-subarray/description/ 标记难度：Medium 提交次数：4/6 代码效率： 前缀和+堆：356ms 半限定的拆分：32.68% 前缀和+双端队列：104ms 最大和+最小和：38.06% 题意 有一个循环数组，求非空子序列的最大可能值（子序列不能和自己重叠）。 分析 比赛的时候我没找到正解，WA了两次。然后匆匆想了一个我觉得能过的O(N * log(N))的算法交上去了。 算法是这样的，思路挺简单：把数组复制一份到后面（循环），得到B = A + A，然后计算B的前缀和数组P。遍历P，用一个堆（实际上是map，因为可能有重复元素，而且还要求最小值）维护P[max(i - N, 0)] ~ P[i-1]的前缀和，从中找出最小的（记为P[j]），就可以求出以i结尾的子序列的最大的和，为P[i] - P[j]（以及需要考虑i &lt; N时取整个前缀的情况）。最后取所有子序列的和的最大值即可。 前缀和+双端队列 我这个思路没什么太大的问题，但是用堆对前缀和进行维护实际上是不必要的—— 事实上，又遇到一道用栈求最大值一类的问题了，真是惊人…… 这次我们需要做的是用一个deque保存一系列index，它们对应的前缀和是从小到大递增的。当index = i时，如果deque.front() &lt; i - N，则将队头弹出。然后队头就是目前范围内的最小前缀和了。之后在队列非空且deque.back() &gt;= B[i]时不断弹出队尾。最后将i插入到队尾。[1] 我的第一个问题是将队头弹出之后队列是否会变空？答案是不会，因为i-1此时刚被插入队列，它是不会被弹出来的，所以队列不会为空。 第二个问题是这个算法为何正确。它和之前使用栈的想法很类似，差别是之前求的是每个元素左（右）侧比它大（小）的元素，现在求的是一个连续范围内的最小值。所以这个算法维护了一个以该连续范围的右界为结尾的且在连续范围内的严格递增的序列，序列开头处的值就是符合要求的最小值。但是怎么说明这样做的道理呢…… 还是题解里说得好：若i &lt; j且P[i] &gt;= P[j]，则i在此时无论如何都没有用处了。 半限定的拆分 在非循环的情况下，显然我们都会做这道题：令f[i]表示以i结尾的子序列的最大和，则f[i] = max(0, f[i-1]) + A[i]。在循环的情况下，仍然可以尝试这么做。令g[i]表示以i结尾的循环子序列的最大和（只计算循环的）；此时，g[i] = max(A[j: A.length-1] + A[0, i])，其中j &lt; i。由于我们规定了g[i]必须是一个循环子序列的和，因此可以把上式改写为g[i] = max(A[j: A.length-1]) + (A[0] + ... + A[i]), j &lt; i。 则此时可以开始递推了。令T[j] = A[j] + A[j+1] + ... + A[A.length-1]，R[j] = max(T[k]) (k &gt;= j)，则g[i] = R[i+1] + (A[0] + ... + A[i])。[1:1] 一个细节是，题解里写的实际上是g[i] = R[i+2] + (A[0] + ... + A[i])。我觉得这是因为使用R[i+1]时可能会得到整个数组（A[i+1] + ... + A[A.length-1] + A[0] + ... + A[i]），这是没有必要的；不过这好像也不会增加什么复杂度。 最大和+最小和 这是一种很妙的想法。题解里写了两个贪心算法的变种：sign变种和min变种，但我觉得它们本质上是差不多的。对于循环子序列A[0] + ... + A[i] + A[j] + ... + A[A.length-1]，可以把它写成sum(A) - (A[i+1] + ... + A[j-1])，也就意味着我们现在只需要求出一个和最小的子序列，然后用整个数列的和减去这个最小的和，就可以得到循环子序列的最大和了。（虽然其中大概包含了一些边界情况） 需要注意一种特殊情况：和最小的子序列是整个数组。这种情况只会发生在整个数组都是负数的时候，因此需要特判。题解里的做法要稍微更麻烦一些，我觉得没有必要。[1:2] 代码 前缀和+堆 12345678910111213141516171819202122232425262728class Solution &#123;public: int maxSubarraySumCircular(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); long long int p[2 * n]; long long int a[2 * n]; for (int i = 0; i &lt; n; i++) a[i] = a[i + n] = A[i]; p[0] = a[0]; for (int i = 1; i &lt; 2 * n; i++) p[i] = p[i - 1] + a[i]; map&lt;long long int, int&gt; m; long long int ans = a[0]; m[p[0]]++; for (int i = 1; i &lt; 2 * n; i++) &#123; if (i &gt;= n) &#123; m[p[i - n]]--; if (m[p[i - n]] == 0) m.erase(p[i - n]); &#125; long long int minVal = m.begin()-&gt;first; ans = max(ans, p[i] - minVal); if (i &lt; n) ans = max(ans, p[i]); m[p[i]]++; &#125; return ans; &#125;&#125;; 前缀和+双端队列 123456789101112131415161718192021222324class Solution &#123;public: int maxSubarraySumCircular(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); long long int p[2 * n + 1]; long long int a[2 * n + 1]; for (int i = 1; i &lt;= n; i++) a[i] = a[i + n] = A[i - 1]; p[0] = 0; for (int i = 1; i &lt;= 2 * n; i++) p[i] = p[i - 1] + a[i]; long long int ans = a[1]; deque&lt;long long int&gt; q; q.push_back(0); for (int i = 1; i &lt;= 2 * n; i++) &#123; while (q.front() &lt; i - n) q.pop_front(); ans = max(ans, p[i] - p[q.front()]); while (!q.empty() &amp;&amp; p[q.back()] &gt;= p[i]) q.pop_back(); q.push_back(i); &#125; return ans; &#125;&#125;; 半限定的拆分 12345678910111213141516171819202122232425262728class Solution &#123;public: int maxSubarraySumCircular(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); if (n == 1) return A[0]; // Don't forget the uncircular intervals! long long int p[n], t[n], f[n], ans = A[0]; f[0] = A[0]; for (int i = 1; i &lt; n; i++) &#123; f[i] = max(f[i-1], (long long int) 0) + A[i]; ans = max(ans, f[i]); &#125; // The uncircular intervals. p[0] = A[0]; for (int i = 1; i &lt; n; i++) p[i] = p[i - 1] + A[i]; t[n - 1] = A[n - 1]; long long int r = t[n - 1]; for (int i = n - 2; i &gt;= 0; i--) &#123; ans = max(ans, p[i] + r); t[i] = t[i + 1] + A[i]; r = max(r, t[i]); &#125; return ans; &#125;&#125;; 最大和+最小和 123456789101112131415161718192021222324class Solution &#123;public: int maxSubarraySumCircular(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); if (n == 1) return A[0]; // f: max sum; g: min sum; minSum: min of g long long int f[n], g[n], ans = A[0], minSum = A[0], sum = A[0]; f[0] = g[0] = A[0]; // not necessary - can directly test if ans &lt; 0 in the end. bool hasPos = A[0] &gt;= 0; for (int i = 1; i &lt; n; i++) &#123; sum += A[i]; hasPos = hasPos ? hasPos : A[i] &gt;= 0; f[i] = max(f[i-1], (long long int) 0) + A[i]; g[i] = min(g[i-1], (long long int) 0) + A[i]; ans = max(ans, f[i]); minSum = min(minSum, g[i]); &#125; if (!hasPos) return ans; return max(ans, sum - minSum); &#125;&#125;; Leetcode Solution - 918. Maximum Sum Circular Subarray ↩︎ ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 917. Reverse Only Letters（字符串），及周赛（105）总结","slug":"2018-10-07-Leetcode-917-Reverse-Only-Letters（字符串），及周赛（105）总结","date":"2018-10-07T12:21:36.000Z","updated":"2018-10-07T12:21:36.000Z","comments":true,"path":"post/leetcode-917-reverse-only-letters-and-weekly-contest-105/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-917-reverse-only-letters-and-weekly-contest-105/","excerpt":"","text":"题目来源：https://leetcode.com/problems/reverse-only-letters/description/ 标记难度：Easy 提交次数：2/2 代码效率： 双指针：0ms 栈：4ms 题意 给定字符串S，将S中的字母逆序排列，其他部分保持不变。 分析 这次的排名是270 / 3528。我觉得这次题目的难度排序是1 &lt; 3 &lt; 2 &lt; 4（为什么老有这种第3题比第2题简单的情况出现），而且第4题还比较简单（我感觉到是DP了，虽然不会做）。做出4道题的人一共67个（而且还真有做出来第4题而没做出第2题的人），比上次多一些。 本题显然很水。比赛时我的做法是直接用两个指针分别指向两侧的字母。另一种做法需要额外的空间，开一个栈，把字母顺序放进去再弹出。[1] 代码 双指针 12345678910111213141516171819class Solution &#123;private: bool isAlpha(char c) &#123; return ('A' &lt;= c &amp;&amp; c &lt;= 'Z') || ('a' &lt;= c &amp;&amp; c &lt;= 'z'); &#125;public: string reverseOnlyLetters(string S) &#123; int i = 0, j = S.length() - 1; while (i &lt; j) &#123; while (!isAlpha(S[i]) &amp;&amp; i &lt; j) i++; while (!isAlpha(S[j]) &amp;&amp; i &lt; j) j--; if (i &gt;= j) break; swap(S[i], S[j]); i++, j--; &#125; return S; &#125;&#125;; 栈 （非常简洁的写法） 1234567891011121314151617181920class Solution &#123;private: bool isAlpha(char c) &#123; return ('A' &lt;= c &amp;&amp; c &lt;= 'Z') || ('a' &lt;= c &amp;&amp; c &lt;= 'z'); &#125;public: string reverseOnlyLetters(string S) &#123; stack&lt;char&gt; s; for (char c: S) if (isAlpha(c)) s.push(c); for (char&amp; c: S) if (isAlpha(c)) &#123; c = s.top(); s.pop(); &#125; return S; &#125;&#125;; Leetcode 917 - Reverse Only Letters - Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 887. Super Egg Drop（动态规划）","slug":"2018-10-07-Leetcode-887-Super-Egg-Drop（动态规划）","date":"2018-10-07T10:50:56.000Z","updated":"2018-11-25T18:59:56.000Z","comments":true,"path":"post/leetcode-887-super-egg-drop/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-887-super-egg-drop/","excerpt":"","text":"题目来源：https://leetcode.com/problems/super-egg-drop/description/ 标记难度：Hard 提交次数：1/3 代码效率： 动态规划（plain）：TLE 动态规划（二分优化）：14.92% 题意 你有K个鸡蛋，它们从高度&gt;F的地方被丢下来时会破碎，但从高度&lt;=F的地方被丢下来时不会破碎。但是你不知道F的值。现有一栋高楼，高度N满足0 &lt;= F &lt;= N，请在这栋楼上通过丢鸡蛋的方式尝试确定F的值。问：对于任意F，至少需要丢多少次鸡蛋才能确定F的值？ 题意还是挺绕的。丢鸡蛋这一点我当时就想了很久也没明白……比如说，你只有一个鸡蛋：假如直接把它从高度为N的地方丢下来，鸡蛋有可能碎了，也可能没有碎。如果它没有碎，则可以确定F = N；否则只能知道F &lt; N，而且鸡蛋已经碎了，没有更多鸡蛋可以扔了，所以无法确定F。因此更合理的做法是，先把鸡蛋从1处扔下来，假如碎了则F = 0，结束；否则可知F &gt; 0，再把鸡蛋从2处扔下来，假如碎了则F = 1，否则可知F &gt; 1……以此类推。所以K = 1时需要的丢鸡蛋次数为N - 1。 因为只有一个鸡蛋，所以不能冒太大风险；假如有两个鸡蛋，就可以先把其中一个从N / 2处丢下来。假如鸡蛋碎了，则可以知道F &lt; N / 2；否则F &gt;= N / 2……以此类推。 分析 比赛的时候我好像尝试这样推导了一下：以两个鸡蛋的情况为例，如果进行二分式的扔法，就会出现这样的情形： 从N/2处丢下鸡蛋，鸡蛋碎了，于是之后只能从下往上逐层丢鸡蛋，需要约N/2次操作 从N/2处丢下鸡蛋，鸡蛋没碎，于是可以把这个鸡蛋再次从3/4*N层丢下去 如果鸡蛋碎了，则之后需要从N/2+1到3/4*N-1逐层丢鸡蛋，需要约N/4次操作 如果鸡蛋没碎，则可以把这个鸡蛋再次从7/8*N层丢下去 …… 可以看出，鸡蛋碎了的情况需要的迭代次数比较多，所以不应该二分，而应该偏分，鸡蛋可能碎掉的情况分配的层数少一点……比如三分？ 想到这里比赛就结束了…… 动态规划 事实上正解之一是动态规划。之前分析的时候并没有意识到这一点：丢下一个鸡蛋，它碎了/没碎之后，事实上当前的状态仍然可以用鸡蛋数目和总层数（如果鸡蛋碎了则层数上限减小，否则层数下限增大，但和从0开始的层数的情况仍然相同）来概括。于是我们就得到了一个子状态。 令f[n][k]表示用k个鸡蛋在n层中确定F至少需要的操作次数，则f[n][k] = 1 + min(max(f[i][k-1], f[n-i][k]))，且f[n][1] = n，f[0][k] = 0。这种做法的复杂度为O(N^2 * K)。[1] 然后就TLE了。（也对，N的范围是10000） 对于一个确定的k，显然f[n][k]随着n的增大而增大。（如果这从式子并不显然的话……那么显然如果鸡蛋不变，层数越多，所需的操作数就越多）。所以f[i][k-1]是随着i的增大而增大的，f[n-i][k]是随着i的增大而减小的。因此这两者的最大值是随着i先减小再增大的。所以可以通过二分查找找到这个点。这种做法的复杂度是`O(N*K*log(N))（注意边界条件）[2] 还有一种做法可以优化到O(KN)，但我不想管它了，毕竟这道题拖了有一个多月了，太累了…… 代码 普通的动态规划 123456789101112131415161718192021222324class Solution &#123;public: int superEggDrop(int K, int N) &#123; int f[N + 1][K + 1]; for (int i = 0; i &lt;= K; i++) &#123; f[0][i] = 0; // zero floor, no need to check f[1][i] = 1; // one floor, check once &#125; for (int i = 0; i &lt;= N; i++) &#123; f[i][1] = i; // one egg checks all floors f[i][0] = 0; // no egg to check &#125; for (int i = 2; i &lt;= N; i++) &#123; for (int j = 2; j &lt;= K; j++) &#123; f[i][j] = INT_MAX; for (int k = 1; k &lt; i; k++) &#123; f[i][j] = min(f[i][j], max(f[i - k][j], f[k - 1][j - 1]) + 1); &#125; &#125; &#125; return f[N][K]; &#125;&#125;; 二分优化的动态规划 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int superEggDrop(int K, int N) &#123; int f[N + 1][K + 1]; for (int i = 0; i &lt;= K; i++) &#123; f[0][i] = 0; // zero floor, no need to check f[1][i] = 1; // one floor, check once &#125; for (int i = 0; i &lt;= N; i++) &#123; f[i][1] = i; // one egg checks all floors f[i][0] = 0; // no egg to check &#125; for (int i = 2; i &lt;= N; i++) &#123; for (int j = 2; j &lt;= K; j++) &#123; f[i][j] = INT_MAX; // 注意边界条件 int left = 1, right = i; while (left + 1 &lt; right) &#123; int mid = (left + right) / 2; if (f[i - mid][j] &lt; f[mid - 1][j - 1]) right = mid; else if (f[i - mid][j] &gt; f[mid - 1][j - 1]) left = mid; else left = right = mid; &#125; f[i][j] = min(max(f[right - 1][j - 1], f[i - right][j]), max(f[left - 1][j - 1], f[i - left][j])) + 1; &#125; &#125; return f[N][K]; &#125;&#125;; Greatjian’s solution for Leetcode 887 - Python DP from kn^2 to knlogn to kn ↩︎ Leetcode’s Official Solution for Leetcode 887 ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"学习THUMT（2）：尝试训练一个小型模型（to be continued...）","slug":"2018-10-06-学习THUMT（2）","date":"2018-10-06T13:56:13.000Z","updated":"2018-11-28T21:39:00.000Z","comments":true,"path":"post/learn-thumt-2-small-model/","link":"","permalink":"https://zhanghuimeng.github.io/post/learn-thumt-2-small-model/","excerpt":"","text":"今天我决定照着UserManual里给出的方法训练一个小型的模型尝试一下，了解一下各个步骤都在做什么。 一些微小的问题 tensorflow-gpu 我首先尝试在自己的电脑上安装tensorflow-gpu。最后我虽然装上了，但却决定不用它了，因为我意识到我的这块普通显卡过于菜了（以至于nvidia-smi不能打印它的具体信息），这么做没什么太大的意义。 PyCharm和virtualenv 目前我的所有Python项目都是通过这两个东西运行的，看起来还不错；可是virtualenv存在一个问题，就是不容易卸载，或者说卸载包的时候可能会出一点问题——反正我卸载tensorflow-gpu再安装tensorflow之后，根本都找不到Module tensorflow了。但这大概不算什么大问题，因为网上的人都说[1]，“virtualenv is cheap”，如果把当前的环境搞乱了，直接删了新建一个就好。 virtualenv还有一个我之前没有想到的好处。它不止可以管理Python包，还可以管理环境变量。UserManual里要求在$PYTHONPATH里加上项目根路径，我一开始不太理解为什么，后来发现如果不加的话根本就找不到THUMT自己的包。我还以为是PyCharm没有定义好源文件夹的问题或者tensorflow挂了的问题呢。看来我对Python模块化和类编程根本就不是很熟悉…… 总之在virtualenv里可以在venv/bin/activate中增加以下命令来修改虚拟环境中的环境变量[2]： 12_OLD_PYTHONPATH=\"$PYTHONPATH\"export PYTHONPATH=\"/path/to/THUMT:$PYTHONPATH\" 然后在deactivate()函数中增加以下内容： 1export PYTHONPATH=\"$_OLD_PYTHONPATH\" 可以使用printenv PYTHONPATH以查看设置情况。 当然实际上应该写得更复杂一点，activate文件中本身就有设置和取消设置环境变量的例子，这里就先这样好了。 准备数据 语料 UserManual中使用的示例语料来自http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/，是经过预处理的语料。不过这些语料到底经历了怎样的预处理呢…… 被预处理完的corpus是这个样子的（取了前5个句子）： Deutsch English Europäische Kommission - Upcoming events European Commission - Upcoming events die Nachricht : the news : die Anmeldung zur Veranstaltung kann vorgenommen werden . registration for the event can be submitted . Hintergrund : the background : die folgen dem Vorbild der &amp;quot; Gemeindeversammlung &amp;quot; bzw. lokaler Bürgerforen , bei denen Vertreter der Politik sich mit Bürgerinnen und Bürgern über politische Fragen und anstehende Entscheidungen austauschen . the concept of builds on the model of &amp;quot; town hall meetings &amp;quot; or local fora during which politicians listen and debate with citizens about policies and decisions being taken . 被预处理完的测试数据是这个样子的： Deutsch English Gutach : noch mehr Sicherheit für Fußgänger Gutach : increased safety for pedestrians Sie stehen keine 100 Meter voneinander entfernt : am Dienstag ist in Gutach die neue B 33 @-@ Fußgängerampel am Dorfparkplatz in Betrieb genommen worden - in Sichtweite der älteren Rathausampel . they are not even 100 metres apart : on Tuesday , the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights . zwei Anlagen so nah beieinander : Absicht oder Schildbürgerstreich ? two sets of lights so close to one another : intentional or just a silly error ? diese Frage hat Gutachs Bürgermeister gestern klar beantwortet . yesterday , Gutacht &amp;apos;s Mayor gave a clear answer to this question . &amp;quot; die Rathausampel ist damals installiert worden , weil diese den Schulweg sichert &amp;quot; , erläuterte Eckert gestern . &amp;quot; at the time , the Town Hall traffic lights were installed because this was a school route , &amp;quot; explained Eckert yesterday . 至少可以看出有一部分符号被转义了（@-@），而且符号也进行了分词。 根据prepare.sh，训练数据经过了以下处理： normalize-punctuation：去除多余空白字符，将Unicode标点转义。 tokenizer：将句子tokenize。 clean-corpus-n：清理平行语料，删除空行、多余的空白字符和不合法的行。[3] train-truecaser和truecase：保持词语的大小写形式，只将句首的词的首字母转为小写。[4] 测试数据是从.sgm格式转换来的，所以前面多一个input-from-sgm，其他的处理都一样。 BPE 然后就是用rsennrich/subword-nmt中提供的脚本对原始语料进行BPE处理。此处我尝试对训练语料（单语大小约800M）跑了一下BPE，发现花了一个多小时，遂放弃，准备把其中一个测试集当做训练集来用。 以及现在subword-nmt这个仓库的使用方式已经有了一些变化，目前推荐的是pip install subword-nmt，然后直接通过包来调用脚本（而不是直接调用脚本）： 1subword-nmt learn-joint-bpe-and-vocab --input &#123;train_file&#125;.L1 &#123;train_file&#125;.L2 -s &#123;num_operations&#125; -o &#123;codes_file&#125; --write-vocabulary &#123;vocab_file&#125;.L1 &#123;vocab_file&#125;.L2 于是得到了BPE编码文件（其中&lt;/w&gt;应该表示的是词尾）： 2018.11.28 UPDATE：感谢评论区@ao ben指出，BPE编码文件中&lt;/w&gt;表达的应该是单词的结尾。阅读了一些代码[5]之后，我想这个文件可能从上到下表示了将词中的字母进行合并的顺序。 123456789101112#version: 0.2e n&lt;/w&gt;e ri nt he r&lt;/w&gt;c ha ne nu nth e&lt;/w&gt;... 和两种语料上的词汇表： 123456789101112, 3761. 2782die 2067der 1761und 1263&amp;quot; 1156in 1022@-@ 710das 667zu 645von 629... (Deutsch) 123456789101112the 4290, 3050. 2776of 1700to 1693a 1369in 1291and 1259&amp;quot; 1182@-@ 658is 615... (English) 然后用上述得到的BPE编码文件和词汇表对训练集、验证集、测试集的源语言一侧分别进行编码。以训练集为例，此时就得到了一堆这样的东西： Deutsch Deutsch (BPE) Gutach : noch mehr Sicherheit für Fußgänger G@@ u@@ t@@ a@@ c@@ h : noch mehr S@@ i@@ c@@ h@@ er@@ h@@ e@@ i@@ t für F@@ u@@ ß@@ g@@ ä@@ n@@ g@@ er Sie stehen keine 100 Meter voneinander entfernt : am Dienstag ist in Gutach die neue B 33 @-@ Fußgängerampel am Dorfparkplatz in Betrieb genommen worden - in Sichtweite der älteren Rathausampel . Sie s@@ t@@ e@@ h@@ en keine 1@@ 0@@ 0 M@@ e@@ t@@ er v@@ o@@ n@@ ein@@ an@@ der e@@ n@@ t@@ f@@ er@@ n@@ t : am D@@ i@@ e@@ n@@ s@@ t@@ a@@ g ist in G@@ u@@ t@@ a@@ c@@ h die n@@ e@@ u@@ e B 3@@ 3 @-@ F@@ u@@ ß@@ g@@ ä@@ n@@ g@@ er@@ a@@ m@@ p@@ e@@ l am D@@ o@@ r@@ f@@ p@@ a@@ r@@ k@@ p@@ l@@ a@@ t@@ z in B@@ e@@ t@@ r@@ i@@ e@@ b g@@ e@@ n@@ o@@ m@@ m@@ en worden - in S@@ i@@ c@@ h@@ t@@ w@@ e@@ i@@ te der ä@@ l@@ t@@ er@@ en R@@ a@@ t@@ h@@ a@@ u@@ s@@ a@@ m@@ p@@ e@@ l . zwei Anlagen so nah beieinander : Absicht oder Schildbürgerstreich ? zwei A@@ n@@ l@@ a@@ g@@ en so n@@ a@@ h b@@ e@@ i@@ ein@@ an@@ der : A@@ b@@ s@@ i@@ c@@ h@@ t oder S@@ c@@ h@@ i@@ l@@ d@@ b@@ ü@@ r@@ g@@ er@@ s@@ t@@ r@@ e@@ i@@ c@@ h ? diese Frage hat Gutachs Bürgermeister gestern klar beantwortet . diese F@@ r@@ a@@ g@@ e hat G@@ u@@ t@@ a@@ c@@ h@@ s B@@ ü@@ r@@ g@@ er@@ m@@ e@@ i@@ s@@ t@@ er ge@@ s@@ t@@ er@@ n k@@ l@@ a@@ r be@@ an@@ t@@ w@@ o@@ r@@ t@@ e@@ t . &amp;quot; die Rathausampel ist damals installiert worden , weil diese den Schulweg sichert &amp;quot; , erläuterte Eckert gestern . &amp;quot; die R@@ a@@ t@@ h@@ a@@ u@@ s@@ a@@ m@@ p@@ e@@ l ist d@@ a@@ m@@ als i@@ n@@ s@@ t@@ a@@ l@@ l@@ i@@ er@@ t worden , w@@ e@@ i@@ l diese den S@@ c@@ h@@ u@@ l@@ w@@ e@@ g s@@ i@@ c@@ h@@ er@@ t &amp;quot; , er@@ l@@ ä@@ u@@ t@@ er@@ te E@@ c@@ k@@ er@@ t ge@@ s@@ t@@ er@@ n . English English (BPE) Gutach : increased safety for pedestrians G@@ u@@ t@@ a@@ c@@ h : i@@ n@@ c@@ re@@ a@@ s@@ e@@ d s@@ a@@ f@@ e@@ t@@ y for p@@ e@@ d@@ e@@ s@@ t@@ r@@ i@@ a@@ n@@ s they are not even 100 metres apart : on Tuesday , the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights . they are not even 1@@ 0@@ 0 m@@ e@@ t@@ re@@ s a@@ p@@ a@@ r@@ t : on T@@ u@@ e@@ s@@ d@@ a@@ y , the new B 3@@ 3 p@@ e@@ d@@ e@@ s@@ t@@ r@@ i@@ an l@@ i@@ g@@ h@@ t@@ s in D@@ o@@ r@@ f@@ p@@ a@@ r@@ k@@ p@@ l@@ a@@ t@@ z in G@@ u@@ t@@ a@@ c@@ h b@@ e@@ c@@ a@@ m@@ e o@@ p@@ e@@ r@@ a@@ t@@ i@@ o@@ n@@ a@@ l - w@@ i@@ t@@ h@@ in v@@ i@@ e@@ w of the e@@ x@@ i@@ s@@ t@@ ing T@@ o@@ w@@ n H@@ all t@@ r@@ a@@ f@@ f@@ i@@ c l@@ i@@ g@@ h@@ t@@ s . two sets of lights so close to one another : intentional or just a silly error ? two s@@ e@@ t@@ s of l@@ i@@ g@@ h@@ t@@ s so c@@ l@@ o@@ s@@ e to one a@@ n@@ other : i@@ n@@ t@@ e@@ n@@ t@@ i@@ o@@ n@@ a@@ l or j@@ u@@ s@@ t a s@@ i@@ l@@ l@@ y e@@ r@@ r@@ o@@ r ? yesterday , Gutacht &amp;apos;s Mayor gave a clear answer to this question . y@@ e@@ s@@ t@@ e@@ r@@ d@@ a@@ y , G@@ u@@ t@@ a@@ c@@ h@@ t &amp;apos;s M@@ a@@ y@@ or g@@ a@@ v@@ e a c@@ l@@ e@@ a@@ r a@@ n@@ s@@ w@@ e@@ r to this q@@ u@@ e@@ s@@ t@@ i@@ on . &amp;quot; at the time , the Town Hall traffic lights were installed because this was a school route , &amp;quot; explained Eckert yesterday . &amp;quot; at the time , the T@@ o@@ w@@ n H@@ all t@@ r@@ a@@ f@@ f@@ i@@ c l@@ i@@ g@@ h@@ t@@ s were i@@ n@@ s@@ t@@ a@@ l@@ l@@ e@@ d because this was a s@@ c@@ h@@ o@@ o@@ l r@@ o@@ u@@ t@@ e , &amp;quot; e@@ x@@ p@@ l@@ a@@ i@@ n@@ e@@ d E@@ c@@ k@@ e@@ r@@ t y@@ e@@ s@@ t@@ e@@ r@@ d@@ a@@ y . 我猜@@指示的是词中间的分词。显然这不是一个正常的学习状况——因为学习的语料太少，词语出现频率不够，很多常见词都被切成字母了。我猜这将导致最后的测试结果不太像人类语言（如果还能跑出测试结果的话……）。不过可以看出，这个BPE还是学到了一些最常用的词汇的，比如德语的sie，am，ist，diese，den，英语的they，are，other，all等。 shuffle 据说这一步可以提高翻译质量（虽然我目前还不知道为什么）。我之前猜测可能和ensemble有关，不过这一点还需要思考一下。 生成NMT使用的词表 这一步的工作不需要用到之前生成的BPE操作和词表，而是由THUMT里的脚本直接从训练数据中再生成一次词表。我目前还不知道为什么要这么做——当然，这么做肯定没有问题，而且还有通用性。显然里面添加了一些控制字符。 1234567891011&lt;pad&gt;&lt;eos&gt;&lt;unk&gt;e@@i@@n@@s@@t@@a@@h@@... (Deutsch) 1234567891011&lt;pad&gt;&lt;eos&gt;&lt;unk&gt;e@@a@@i@@t@@o@@r@@n@@... (English) 训练 训练的时候主要有这样的一些参数： input：经过BPE和shuffle的训练数据（de+en） vocabulary：通过脚本从经过BPE处理的训练数据中提取的词表（de+en） model：使用的模型（目前使用的是推荐的transformer） validation：经过BPE的验证数据（de） references：经过BPE的验证数据（en） parameters：其他超参数 batch_size：每个batch训练多少个词 device_list：使用哪些显卡进行训练 train_steps：迭代次数 eval_steps：训练多少步输出一次在验证集上的BLEU值 keep_checkpoint_max：最多保留几个中间checkpoint keep_top_checkpoint_max：最多保留几个最佳checkpoint 目前我正在我的垃圾小电脑上用batch_size=400, train_steps=2000的参数训练（毕竟现在训练集只有25万个词），已经输出了两个checkpoint，但它似乎卡在计算模型在验证集上的BLEU值这一步上了……好像验证这一步的确是比较慢的，我打算明天再看到底是TensorFlow卡死了，还是单纯太慢了。 To be continued… UPDATE：跑了一晚上，终于验证出一个结果了。程序输出如下图： 123INFO:tensorflow:BLEU at step 2000: 0.001024INFO:tensorflow:Copying train/model.ckpt-2000 to train/eval/model.ckpt-2000INFO:tensorflow:Best score at step 2000: 0.001024 并在train/eval中保留了这个checkpoint。 （0.001，这个BLEU值还真是惊人的低呢……虽然训练过程只花了大约两个小时，验证花了可能得有10个小时……） 测试 下面就可以尝试用训练出的模型对测试集进行翻译了。使用的参数包括： models：模型 checkpoints：模型checkpoints位置，可以通过输入多个模型的checkpoints位置进行ensemble input：经过BPE的测试数据（de） output：翻译结果（en） vocabulary：通过脚本从经过BPE处理的训练数据中提取的词表（de+en），需要与训练使用的词表保持一致 parameters：其他超参数 垃圾小电脑大约需要1.5小时才能跑完一个batch，不知道一共有多少个batch…… To be continued… 2018.10.8 UPDATE：跑完了，一共94个batch。删除BPE分词之后，得到了这样的东西： Deutsch English English (Translated) Obama empfängt Netanyahu Obama receives Netanyahu &lt;unk&gt; Progen&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; das Verhältnis zwischen Obama und Netanyahu ist nicht gerade freundschaftlich . the relationship between Obama and Netanyahu is not exactly friendly . &lt;unk&gt; &lt;unk&gt; staff&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; die beiden wollten über die Umsetzung der internationalen Vereinbarung sowie über Teherans destabilisierende Maßnahmen im Nahen Osten sprechen . the two wanted to talk about the implementation of the international agreement and about Teheran &amp;apos;s destabilising activities in the Middle East . &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; bei der Begegnung soll es aber auch um den Konflikt mit den Palästinensern und die diskutierte Zwei @-@ Staaten @-@ Lösung gehen . the meeting was also planned to cover the conflict with the Palestinians and the disputed two state solution . &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; st&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; das Verhältnis zwischen Obama und Netanyahu ist seit Jahren gespannt . relations between Obama and Netanyahu have been strained for years . &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; st&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; 可以看出，这个模型根本什么都没翻译出来。考虑到BPE把词都切成字母了，这一点也可以想象得到。最后可以通过Moses里提供的脚本计算验证集的BLEU值： 1BLEU = 0.00, 0.0/0.0/0.0/0.0 (BP=1.000, ratio=5.679, hyp_len=372780, ref_len=65647) 虽然我猜BLEU值应该并没有低到严格为0，但是显然已经被四舍五入为0了。简直低破天际。 模型平均和集成 THUMT支持model averaging（把训练过程中生成的部分checkpoint进行平均）和model ensemble（对同一模型的不同训练结果进行ensemble）。以后有时间的话我要去读一下ensemble是怎么实现的。不过现在就不用这些功能了…… 可视化 TensorBoard 在训练过程中，train/文件夹下打印出了一个events.out.tfevents文件，可以用TensorBoard进行可视化。 batch_examples 从代码中可知，这个结点在trainer.py中通过调用record.py中的get_input_features函数生成，其中batch_examples函数大概是做了一个将输入数据按长度分块的工作，内部调用了tf.contrib.training.bucket_by_sequence_length函数。 embedding Transformer结点中显示在左下角的是embedding结点： source_embedding和target_embedding分别定义于transformer.py/encoding_graph和transformer.py/decoding_graph中，它们并不是Encoder和Decoder结点的一部分。至于bias……好吧，我目前还不知道这个bias是干什么的。 （不，我现在意识到了，之前的描述中为了简便起见忽略了所有bias项，但显然这些项还是得有的。） encoder 图中encoder的输入有两个：一个是dropout（adding_timing_signal -&gt; dropout），一个是attention_bias（SequenceMask -&gt; attention_bias）。我觉得数据应该是通过dropout输入的（因为按照Transformer的论文，数据是加了time signal之后输入到encoder的……），不过我现在只发现数据从batch_examples输入到SequenceMask了。 以及几乎所有结点都有一个叫create_train_op的输入，这个结点定义在optimize.py里，我猜测它是TensorFlow生成的后向图，用于对参数进行更新。 encoder的内部是这样的：6个layer连在一起，这一点倒是很清楚。 每一层内部都是self_attention加上feed_forward。 在self_attention这个部分中，主要就是multihead_attention进行dropout和layer-normalization。 在这个结点中，输入似乎首先被用于计算出q、k、v三个部分，然后再在q、k、v的计算中各自进行多个操作（所以只有3个split_heads结点……？），最后再通过combine_heads合并在一起。 decoder decoder的输入包括翻译后的数据（如果有的话）、bias和encoder的输出。 decoder内部也由6个layer组成，其中每一个layer的输入除了前一个layer的输入外，还有数据、bias和encoder的输出（大概是这样的）。 每个layer内部由self_attention、encdec_attention和feed_forward三部分组成，其中接收encoder输出的是encdec_attention。self_attention和encdec_attention的结构与encoder的self_attention结构基本相同，但是在q、k、v的计算上有一些差异。以及feed_forward中含有一个ffn_layer。 softmax decoder的输出通过softmax层得到概率。（大概是这样的） Relevance UserManual中提供了计算每个源句和翻译出来的目标句之间的relevance矩阵的工具。不过鉴于我这个结果的翻译质量，就先不去尝试了…… StackOverflow - How can I remove unused packages from virtualenv? ↩︎ StackOverflow - How do you set your pythonpath in an already-created virtualenv? ↩︎ Moses - Preparing Training Data ↩︎ Moses - Truecaser ↩︎ PLM’s blog - subword-units ↩︎","categories":[],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"THUMT","slug":"THUMT","permalink":"https://zhanghuimeng.github.io/tags/THUMT/"}]},{"title":"Leetcode 84. Largest Rectangle in Histogram（栈）","slug":"2018-10-06-Leetcode-84-Largest-Rectangle-in-Histogram（栈）","date":"2018-10-06T01:36:34.000Z","updated":"2018-10-06T01:36:34.000Z","comments":true,"path":"post/leetcode-84-largest-rectangle-in-histogram/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-84-largest-rectangle-in-histogram/","excerpt":"","text":"题目来源：https://leetcode.com/problems/largest-rectangle-in-histogram/description/ 标记难度：Hard 提交次数：1/3 代码效率： O(N^2)递推：超时 单栈：98.96% 题意 给定一个直方图的高度（或者说给定一排宽度都为1的矩形柱子的高度），找出图中包含的面积最大的矩形。 分析 显然可以有这样的直觉：所能找到的面积最大的矩形必定与某个矩形柱子的高度是相等的，否则它的高度必然小于它覆盖的所有柱子，因此高度还可以再升高，直到到达某个柱子的高度为止。因此问题可以转化为，对于每个柱子，它左边和右边各有多少个连续的柱子的高度不小于它？不妨记这两个值为left[i]和right[i]，则以第i个柱子为最大高度的矩形的面积就是(left[i] + right[i] + 1) * heights[i]。 我的第一个解法是错误的：试图直接通过前一个柱子的left[i-1]推导出下一个柱子的left[i]。显然这两者并不存在一个直接的推导关系，所以我WA了。 于是我立刻想出了第二种解法——用O(N^2)的复杂度直接计算left和right数组。题目里没给N的范围，不过我还是TLE了。 这时候我才想起来，我已经见过三道类似的题目了，它们分别是： Leetcode 901 Leetcode 739 Leetcode 907 它们所需要完成的任务是相似的：给定一个数组，为其中的每个数求出它左边/右边/both的第一个比它大/小的数的位置。这种算法我已经详细分析过了，所以现在不妨来比较一下这几道题的区别，特别是有重复数字时的边界问题的处理。下面用A表示数组： Leetcode 901：求左侧第一个&gt; A[i]的值。 Leetcode 739：求右侧第一个&gt; A[i]的值。 Leetcode 907：在问题的转换过程中需要自行确定边界： 计算“以A[i]为最小值的子序列的数量”之前，就需要考虑一个子序列中有多个最小值的情况怎么办。显然一个子序列只能被作为其中一个最小值所对应的子序列计算一次。所以问题是应该选择哪一个最小值作为“最小值”。显然比较方便的办法是取最左边或最右边的最小值。 如果取的是最左边的最小值，则对于每个值，需要求的是左侧第一个&lt;= A[i]的值，和右侧第一个&lt; A[i]的值； 反之，则需要求左侧第一个&lt; A[i]的值，和右侧第一个&lt;= A[i]的值。 Leetcode 84：求左侧第一个&lt; A[i]的值，和右侧第一个&lt; A[i]的值。 在Leetcode 907的分析中已经提到，有两种做法，一种是用两次迭代分别求左侧和右侧的值；另一种是直接用一次迭代。这种方法很聪明，但面临着一个问题：它无法实现左右两侧都严格不等或都不严格不等的情况。考虑用这一算法实现的907题，假如在栈中，A[i]将要被A[j]弹出了： 如果条件是A[i] &gt;= A[j]，则对于A[j]，它将找到左侧第一个&lt; A[j]的值，但对于A[i]，它找到的是右侧第一个&lt;= A[i]的值 如果条件是A[i] &gt; A[j]，则A[j]找到的是左侧第一个&lt;= A[j]的值，但A[i]找到的是右侧第一个&lt; A[i]的值 我想这是算法本身的限制。（也许可以改进，但我现在不太想思考了）所以严格来说，单栈算法对本题之前的模型是不太合适的。 但是我还是用了单栈的算法，因为可以把模型改一下。假如最大的矩形碰到了至少两个柱子的边界，说明对于这些柱子，它们都能计算得到对应的矩形面积（按照之前的算法）。那么只要保证其中至少一根柱子在计算的时候得到正确结果即可（其他的可以不管）。于是问题就转化成类似于907题的情况了。 代码 O(N^2)递推 123456789101112131415161718192021222324252627class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int n = heights.size(); if (n == 0) return 0; if (n == 1) return heights[0]; vector&lt;int&gt; sorted(heights); sort(sorted.begin(), sorted.end()); long long int f[n]; memset(f, 0, sizeof(f)); long long int ans = 0; // for each rectangle for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (sorted[j] &gt; heights[i]) f[j] = 0; else &#123; f[j]++; ans = max(ans, f[j] * sorted[j]); &#125; &#125; &#125; return ans; &#125;&#125;; 单栈 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; int n = heights.size(); if (n == 0) return 0; if (n == 1) return heights[0]; stack&lt;pair&lt;int, int&gt;&gt; s; // height, pos // Note: the left and right arrays are defined slightly differently // - They denote positions, not length (not a big deal though) long long int left[n], right[n], ans = 0; for (int i = 0; i &lt; n; i++) &#123; while (!s.empty() &amp;&amp; s.top().first &gt; heights[i]) &#123; right[s.top().second] = i; s.pop(); &#125; if (s.empty()) left[i] = -1; else left[i] = s.top().second; s.emplace(heights[i], i); &#125; while (!s.empty()) &#123; right[s.top().second] = n; s.pop(); &#125; for (int i = 0; i &lt; n; i++) ans = max(ans, (right[i] - left[i] - 1) * heights[i]); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Monotonic Stack","slug":"alg-Monotonic-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Monotonic-Stack/"}]},{"title":"USACO 1.4.2: Barn Repair（贪心）","slug":"2018-10-06-USACO-1-4-2-Barn-Repair（贪心）","date":"2018-10-06T01:19:53.000Z","updated":"2018-10-06T01:19:53.000Z","comments":true,"path":"post/usaco-1-4-2-barn-repair/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-2-barn-repair/","excerpt":"","text":"题意 见洛谷 P1209。 分析 这道题就是上回的文章里的例题，所以具体的算法内容和正确性就不再讲了。总之我是这样实现的： 统计所有空隙（同时排除两侧的空牛棚，因为它们显然不需要覆盖） 排序 根据木板的数量，从牛棚总数中依次减去最大的空隙 其中我没有注意到这一点：木板的数量可能会超过所有连续牛棚的数量，结果数组越界了，WA了一次。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*ID: zhanghu15TASK: barn1LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;bool occupied[205];int main() &#123; ofstream fout(\"barn1.out\"); ifstream fin(\"barn1.in\"); int M, S, C; fin &gt;&gt; M &gt;&gt; S &gt;&gt; C; for (int i = 0; i &lt; C; i++) &#123; int x; fin &gt;&gt; x; occupied[x] = true; &#125; int start = -1; int ans = S; vector&lt;int&gt; gaps; for (int i = 1; i &lt;= S; i++) &#123; if (start == -1 &amp;&amp; !occupied[i]) start = i; else if (start != -1 &amp;&amp; occupied[i]) &#123; if (start == 1) ans -= i - start; else gaps.push_back(i - start); start = -1; &#125; &#125; if (start != -1) ans -= S + 1 - start; // do the greedy (note that gaps can be exhausted...) sort(gaps.begin(), gaps.end()); for (int i = 0; i &lt; M - 1 &amp;&amp; i &lt; gaps.size(); i++) ans -= gaps[gaps.size() - i - 1]; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"学习THUMT（1）：UserManual和代码结构","slug":"2018-10-05-学习THUMT（1）","date":"2018-10-05T14:55:37.000Z","updated":"2018-10-05T14:55:37.000Z","comments":true,"path":"post/learn-thumt-1/","link":"","permalink":"https://zhanghuimeng.github.io/post/learn-thumt-1/","excerpt":"","text":"代码：THUMT 目录结构 目前thumt/文件夹下的目录结构是这样的： bin/ get_relevance.py：输入训练好的模型checkpoints、模型在测试数据上的输入和输出、词表，输出测试数据中每个句子及其翻译之间的关联矩阵。（似乎只对Transformer和RNNsearch模型有效）。 scorer.py：暂时不知道是做什么的。 trainer.py：用于训练模型，输入训练数据、词表、验证数据、参数，输出训练模型的checkpoints和在验证集上的得分。 translator.py：用训练好的模型对测试数据进行翻译，输入模型checkpoints、测试数据、词表，输出翻译结果。 data/ __init__.py：这是一个模块。 cache.py：从字义上看好像是存储feature用的，实际上看不懂。 dataset.py：输入训练和验证数据文件，将数据分成batch。 record.py：看起来和dataset.py有点像，仍然不知道是干什么的。 vocab.py：加载和处理词表。 interface/ __init__.py：这是一个模块。 model.py：表示NMT模型的抽象类NMTModel。 layers/ __init__.py：这是一个模块。 attention.py：Attention机制的实现。 nn.py：一些神经网络层的实现，包括linear和maxout。 rnn_cell.py：GRU的实现，以及一些wrapper。 models/ __init__.py：这是一个模块。 rnnsearch.py：RNNsearch模型的实现。 rnnsearch_lrp.py：LRP和RNNsearch模型的实现。 seq2seq.py：Seq2Seq模型的实现。 transformer.py：Transformer模型的实现。 transformer_lrq.py：LRP和Transformer模型的实现。 scripts/ build_vocab.py：通过输入的测试数据创建词表。 checkpoint_averaging.py：输入模型checkpoints，输出平均结果。 convert_old_model.py：看起来好像是用于把旧实现生成的模型转换成新模型的。 convert_vocab.py：不知道是干什么的。 input_converter.py：把输入转换成tf.Record格式。不知道有什么用。 shuffle_corpus.py：随机打乱训练数据。 visualize.py：对Transformer或RNNsearch输出的关联矩阵进行可视化。 utils/ __init__.py：这是一个模块。 bleu.py：BLEU值的计算。 common.py：看起来好像是一些用于推导形状的函数。 hooks.py：用于保存模型checkpoint。 inference.py：实现了Beam Search和不知道是什么的Inference。 lrp_utils.py：看名字可能和LRP有关，实际上好像有很多模型的实现，并不知道是干什么的。 optimize.py：不知道是干什么的。 parallel.py：看起来好像是用于多GPU训练的。 sampling.py：？ weight_ratio.py：？ __init__.py：这是一个模块。 训练过程 一般来说训练过程可以分成以下几个阶段： 准备数据 训练集、验证集、测试集语料 用训练集生成BPE操作和词典（大概？） 用上述BPE操作和词典对训练集、验证集和测试集的源语言部分分别进行处理 将训练集随机排序（shuffle_corpus.py） 通过训练集生成词表（build_vocab.py） 训练：输入训练集、验证集和词表，输出模型checkpoints、在验证集上得分最高的模型，以及模型在训练过程中在验证集上的评测结果 测试： 输入测试集、词表和模型checkpoints，输出翻译结果（translator.py），经过一定处理后可以得到BLEU分值 可以进行model averaging（checkpoint_averaging.py） 可以进行model ensemble（translator.py） 可视化：输入测试集、词表、模型checkpoints，输出模型在每个翻译句对上的关联矩阵（get_relevance.py，visualize.py） 明天我打算用比较少的数据在自己的电脑上试验一下。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://zhanghuimeng.github.io/tags/Machine-Learning/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"THUMT","slug":"THUMT","permalink":"https://zhanghuimeng.github.io/tags/THUMT/"}]},{"title":"USACO 1.4.1: Mixing Milk（贪心）","slug":"2018-10-05-USACO-1-4-1-Mixing-Milk（贪心）","date":"2018-10-05T03:12:25.000Z","updated":"2018-10-05T03:19:25.000Z","comments":true,"path":"post/usaco-1-4-1-mixing-milk/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-4-1-mixing-milk/","excerpt":"","text":"题意 见洛谷 P1208。 分析 典型的贪心问题，可以通过对最优解的exchange方法简单地证明，必然是按顺序选择价格从低到高的牛奶是最好的，否则总能找出更优的解。 这道题的Analysis中有很多人的讨论。因为题目对牛奶的价格做了限制（1000），所以可以利用这个来做一些优化。最开始好像有人打算用计数排序来进行优化，然后还写了个链表。很快就有人指出链表根本没有意义，因为价格相同的牛奶完全可以看做是一样的，直接存进一个大小为1000的数组中就行。总之这些优化还是挺有意思的。 代码 普通排序 12345678910111213141516171819202122232425262728293031323334353637383940/*ID: zhanghu15TASK: milkLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main() &#123; ofstream fout(\"milk.out\"); ifstream fin(\"milk.in\"); long long int N, M; fin &gt;&gt; N &gt;&gt; M; vector&lt;pair&lt;int, long long int&gt;&gt; milks; for (int i = 0; i &lt; M; i++) &#123; int P, A; fin &gt;&gt; P &gt;&gt; A; milks.emplace_back(P, A); &#125; sort(milks.begin(), milks.end()); long long int ans = 0; for (int i = 0; i &lt; milks.size(); i++) &#123; long long int c = min(N, milks[i].second); ans += c * milks[i].first; N -= c; if (N &lt;= 0) break; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125; 计数排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445/*ID: zhanghu15TASK: milkLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;long long int milkPrice[1005];int main() &#123; ofstream fout(\"milk.out\"); ifstream fin(\"milk.in\"); long long int N, M; fin &gt;&gt; N &gt;&gt; M; for (int i = 0; i &lt; M; i++) &#123; int P, A; fin &gt;&gt; P &gt;&gt; A; milkPrice[P] += A; &#125; // 1. 用计数排序来代替快排 // 2. 合并所有价格相同的牛奶 // 3. 直接进行遍历 long long int ans = 0; for (int i = 0; i &lt;= 1000; i++) &#123; if (N &gt;= milkPrice[i]) &#123; ans += milkPrice[i] * i; N -= milkPrice[i]; &#125; else &#123; ans += N * i; break; &#125; &#125; fout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"翻译：贪心算法（USACO）","slug":"2018-10-05-翻译：贪心算法（USACO）","date":"2018-10-05T00:35:59.000Z","updated":"2018-10-05T00:35:59.000Z","comments":true,"path":"post/greedy-algorithm-usaco-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/greedy-algorithm-usaco-translation/","excerpt":"","text":"之前我在USACO上的做题计划卡住了，主要是因为我想仔细阅读一下这篇文章，因为我觉得写得很好——结果因为各种原因卡了一个多月。 总之下面的翻译主要来自[1]，进行了一些小修改。 例题: 栅栏修理（1999 USACO Spring Open） 农场里有一排牛棚，其中的一些牛棚需要用木板遮盖起来。你最多可以使用N（1&lt;=N&lt;=50）块木板，其中每一块都可以遮盖任何数数量的连续的牛棚。请遮盖所有需要被遮盖的牛棚，而且使总的遮盖的牛棚的数量尽可能的少。 思路 贪心法的基本思想是用局部解构造全局解。和其它方法不同的是，贪心法在求解过程中只保留所找到的最优解。以上面这道题为例，为了构造N=5时的最优解，贪心法需要先找到N=4时的最优解，然后在此基础上进行修改，以得到N=5时的解。N=4时的所有其他解都不予考虑。 很显然，很多其他方法的基本思想都是用局部解构造全局解（大概包括回溯法和动态规划法，以及我现在都想不起来的很多很多算法，毕竟很难凭空造一个解出来）。只保留最优解就是贪心法速度快的原因（因为需要的解空间少）。以及在实际中（也就是不一定需要一个“正确”算法的时候），贪心法实际上不一定只会保留“the best solution”，而可能是若干个“best solutions”。昨天刚读的seq2seq里用到的Beam Search就是一个很好的例子。[2] 不过我感觉在竞赛算法中一般用不到这个策略…… 贪心法的特点是速度快，时间复杂度通常在O(N)和O(N^2)之间，不需要太多额外的内存。不幸的是，它们通常是不正确的。不过在贪心法确实正确的时候，它们通常很容易实现，且执行速度很快。 基本问题 贪心法通常将面临两个基本问题。 如何构造？ 怎样通过小规模的解构造更大规模的解呢？一般来说，这与问题本身有关。对于这道例题来说，通过4块板的解构造5块板的解的最显然的方法就是，选出一块木板，从中间去掉一段，这样就把一块木板变成了两块木板。你应该选择去掉所有木板中只包含不需要被遮盖的牛棚的最长的一段（这样就可以使得被遮盖的牛棚总数最少）。 将一段被遮盖的牛棚上遮盖的木板去除的方法是，把遮盖了这些牛棚的那块木板分成两块木板：一块遮盖了这一段之前的牛棚，另一块遮盖了这一段之后的牛棚。 是否正确？ 对编程者而言，最大的挑战来自这一事实：贪心法得到的解并不总是正确的。即使它们看起来好像在样例输入、随机输入，以及你能想到的任何情形下都是正确的，只要存在一种使贪心法发生错误的输入，评测样例中必然会包含至少一种（如果不是更多）该类型的输入。 （出题人的小心机……） 对于之前的例题，下面的内容证明了之前描述的贪心算法的正确性： 假设正确的解中里没有包含贪心算法移除的最长的一段木板留下的缺口，却包含了另外一段较小的缺口。通过把位于较小缺口两端的两块木板合并，并将跨越较长缺口的那块板分开，就可以得到一个与原解使用的木板数量相同，但覆盖的牛棚数量更少的新解。这个新的解更好，所以这个假设是错误的，我们总是应该选择移除最长的可以移除的一段木板。 如果正解中不包含这一个缺口，却包含另一个大小相同的缺口，使用同样的方法，可以得到一个与原解使用的木板数量相同，且覆盖的牛棚数量相同的解。新解与原解一样好，我们可以任选其一。 因此存在一个包含最大缺口的最优解，所以在每一步，总存在一个包含当前状态的最优解。因此，得到的解是最优的。 这是我比较喜欢的一个贪心法正确性证明的例子（虽然这里写得不是很严格）。这很显然是两种贪心法证明（exchange和stay ahead）中的exchange，其主要步骤为[3]： 用符号分别对贪心算法得到的解和最优解进行表示 将贪心解和最优解进行比较（假设两者不等），则可能 两者含有不同的元素（如上述证明中的不同的缺口） 两者元素顺序不同 对最优解中的元素进行修改，使得最优解更接近于贪心解，同时不比之前更差。继续进行修改，直到最优解与贪心解相同，这就证明了贪心解即最优解 总结 假如贪心法存在，可以用它。贪心法容易编写，调试方便，运行速度快，使用的内存少，这使得它在竞赛中不失为一个优秀算法。这里唯一没有提到的问题是它的正确性。如果贪心法能找到正确答案，就用它吧，但不要把时间浪费在试图把贪心算法应用于任何问题上。 （不过大部分情况下正确性是死结吧！） 其他例题 对三值序列排序（IOI 1996） 给定一个长度最大为1000的三值序列（只包含1、2和3），找出总数最小的能将该序列排序的交换操作的集合。 算法 序列由三个区域组成：第一个区域在排序后都是1，第二个区域在排序后都是2，第三个区域都是3。贪心算法尽量把位于区域二中的1和位于区域一中的2交换，把位于区域三中的1和位于区域一中的3交换，把位于区域三中的2和区域二中的3交换。将这些类型交换完后，剩余的不在正确区域的元素需要在某种意义上进行旋转。你可以通过首先把所有1交换到区域一中，再把所有2交换到区域二中完成最优排序。 事实上“旋转”的意思类似于置换，就像下面的证明中说的那样，三个数需要两次交换才能回到正确位置。 分析 显然，一次交换最多能将两个元素复位，所以所有的第一类交换操作都是最优的。而且，很显然不同的第一类操作交换的元素类型都是不同的，所以不同类型的操作之间没有“相互干渉”。这意味着交换的顺序对结果没有影响。完成所有第一类交换操作之后，最优的交换方法就是将不在正确位置的三个元素通过两次交换复位，这就是第二类交换操作将完成的（比如，所有的1都归位了，所有的2都在区域三，反之亦然，这可以进行交换）。 这似乎只是一个分析，而不是证明。（以及我没看懂他那个比如……）但是我还真的不知道该怎么证……目前的一个初步的想法是，假设一个最优的交换操作序列，证明它的一些比较好的性质（比如把一个元素归位之后就不会再动它了之类的），然后也用exchange的方法去做。 我刚才脑子一晕，还以为操作的总数应该等于逆序对的数量（不，那是冒泡排序）。实际上好像可以严格证明排序到底最少需要多少次swap操作。[4]所以可能不宜把这个题当做是一道贪心来证明。但是因为有重复元素，所以比较困难。 友好的硬币——一个反例（有删节） 给定一个新建立的国家（乳品共和国）的硬币面值和一些钱数，找出最小的和等于钱数的硬币集合。保证乳品共和国有1分硬币。 算法 找出最大的不大于目标值的硬币，将目标钱数减去该硬币，然后继续直到完成。 （错误的）分析 显然你绝不会想要拿一个面值更小的硬币，因为这意味着你需要拿更多的硬币以补上缺的部分，所以这个算法是正确的。 （大概没错的）分析 好吧，这个算法通常是正确的。事实上，对于美国硬币系统（1、5、10、25），这一算法总会输出最优解。但是，对于其他系统，如1、5、8、10和目标值13，贪心算法会拿一个10和三个1，总共为4个硬币；而实际上最优解是拿8和5。 这说明贪心算法还是很可能不对的。这个问题的正解大概是回溯法。 拓扑排序 给定一系列对象，以及一些顺序约束，如“A必须在B前面”，找出一个对象的顺序，满足全部约束。 算法 以对象为结点创建一个有向图，如果“A必须在B前面”，就从A到B创建一条边。以随机顺序遍历所有对象。每次你发现一个入度为0的的对象，就贪心地把它放在当前顺序序列的末尾，删除所有它的出边，然后对它（之前）的孩子结点执行相同的检查。如果算法遍历了所有对象，却没能把每个对象都放入顺序序列中，说明没有顺序能满足所有约束。 好吧，拓扑排序也是一种贪心算法。这个要证明起来还是比较容易的（而且，对于拓扑排序存在的情况，实际上没有“最优解”可言，都是可行解）：每找到一个入度为0的结点，说明它要么没有约束，要么所有约束都已经位于序列前面了，所以可以直接把它加入序列。这大概是一种类似于stay ahead[5]的方法。问题是怎么证明拓扑排序找不到序列的时候，拓扑序是不存在的。大概可以应用反证法。如果存在一个拓扑序列，则在每一步必然可以找到序列中的下一个结点，不可能找不到。 贪心算法简介 ↩︎ 谁能解释下seq2seq中的beam search算法过程? - 知乎 ↩︎ Greedy Exchange ↩︎ Minimum number of swaps required to sort an array ↩︎ Stays Ahead ↩︎","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 187. Repeated DNA Sequences（Hash）","slug":"2018-10-04-Leetcode-187-Repeated-DNA-Sequences（Hash）","date":"2018-10-04T00:55:57.000Z","updated":"2018-10-04T01:33:57.000Z","comments":true,"path":"post/leetcode-187-repeated-dna-qequences/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-187-repeated-dna-qequences/","excerpt":"","text":"题目来源：https://leetcode.com/problems/repeated-dna-sequences/description/ 标记难度：Medium 提交次数：2/3 代码效率： 普通的map：84.31% bitset+Rolling hash：99.74% 题意 有一个只包含ATGC的字符串序列，求其中全部长度为10的且出现了不止一次的序列。 分析 初步的想法 只要使用unordered_map作为Hash表，那就很简单了：只要依次遍历所有长度为10的字符串，然后把它们加入到unordered_map中，最后统计unordered_map中出现长度多于1次的序列即可。显然这个方法是可行的。 交上去之后我居然还写错了一次长度为10的子串的边界条件，所以wa了。 如何加速？ 上述做法存在几个显而易见的问题： 最后需要多遍历一次unordered_map，能否节省这一次遍历？ unordered_map&lt;string, int&gt;的速度是否太慢？ 是否存在对string的更好的hash方法？ 所以可以进行如下改进： 用两个Hash表来存储序列，一个存储的是所有出现过的序列，另一个只存储至少出现了两次的序列，这样就可以节省最后的一次遍历了。 改为采用Rolling Hash的方法滚动计算Hash值，并利用位运算进一步减少计算所需的时间。 由于对Hash值的范围进行了限定，因此可以改用其他的数据结构（如bitset）作为Hash表。 至于Rolling Hash如何和位运算结合起来，我见到的一种比较好的平衡了编写难度和运行时间的写法[1]是这样的： 把4个字符分别映射为0、1、2、3 对每一个新的序列计算Hash值时，先令hash = (hash &lt;&lt; 2) | charMap[ch] 显然hash的长度固定为20bit，其最大值为(1 &lt;&lt; 20) - 1（全为1），因此可以通过hash &amp;= (1 &lt;&lt; 20) - 1的方法来去掉最前面的项 此处使用的应该是Polynomial rolling hash，很类似于四进制的一种想法（也因此能保证hash函数是双射的）。 从中至少可以学到几点： 位运算是个很好用的东西（前提是没有写错） bitset在适当的时候可以拿来代替Hash表或者大数组，但一般来说并不是一个关键数据结构 代码 普通的map 123456789101112131415161718class Solution &#123;public: vector&lt;string&gt; findRepeatedDnaSequences(string s) &#123; int n = s.length(); unordered_map&lt;string, int&gt; mmap; vector&lt;string&gt; ans; for (int i = 0; i &lt;= n - 10; i++) &#123; string str = s.substr(i, 10); mmap[str]++; &#125; for (const auto&amp; k: mmap) &#123; if (k.second &gt; 1) ans.push_back(k.first); &#125; return ans; &#125;&#125;; bitset+Rolling hash 1234567891011121314151617181920212223242526272829303132333435363738// 参考了https://leetcode.com/submissions/detail/180202097/class Solution &#123;public: vector&lt;string&gt; findRepeatedDnaSequences(string s) &#123; int n = s.length(); if (n &lt; 11) return &#123;&#125;; // cheap mapping int charToInt[200]; charToInt['A'] = 0; charToInt['C'] = 1; charToInt['G'] = 2; charToInt['T'] = 3; const int MASK = (1 &lt;&lt; 20) - 1; int rhash = 0; for (int i = 0; i &lt; 9; i++) rhash = (rhash &lt;&lt; 2) | charToInt[s[i]]; // use bitset as hash table bitset&lt;(1 &lt;&lt; 20)&gt; onceSet; bitset&lt;(1 &lt;&lt; 20)&gt; twiceSet; vector&lt;string&gt; ans; for (int i = 9; i &lt; n; i++) &#123; rhash = (rhash &lt;&lt; 2) | charToInt[s[i]]; rhash &amp;= MASK; // 简化代码逻辑 if (twiceSet[rhash]) continue; if (onceSet[rhash]) &#123; ans.push_back(s.substr(i - 9, 10)); twiceSet.set(rhash); &#125; else onceSet.set(rhash); &#125; return ans; &#125;&#125;; sample 4 ms submission ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Bit Manipulation","slug":"alg-Bit-Manipulation","permalink":"https://zhanghuimeng.github.io/tags/alg-Bit-Manipulation/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"}]},{"title":"论文：Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation","slug":"2018-10-03-论文：Learning-Phrase-Representations-using-RNN-Encoder-Decoder-for-Statistical-Machine-Translation","date":"2018-10-03T14:15:32.000Z","updated":"2018-10-03T14:15:32.000Z","comments":true,"path":"post/learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation/","excerpt":"","text":"论文地址：https://arxiv.org/abs/1406.1078 这篇文章提出了RNN Encoder-Decoder架构，使得RNN能够处理序列数据的输入输出：先把序列数据encode成一个定长vector，再把它decode成另一个序列。有趣的一点是，这篇文章的题目里带了“SMT”这个词，说明它并不是一种纯NMT的方法——事实上论文里用它替代了现存的方法里给短语打分的部分。当然这种方法也是可以直接用于整句翻译的（On the Properties of Neural Machine Translation: Encoder-Decoder Approaches），但由于RNN的特性，使得在长句上表现不太好，最后又改进出了Attention方法。目前我还不知道这篇文章和Seq2Seq具体是什么关系。 2018.10.11 UPDATE：Seq2Seq和这篇文章提出的架构很类似，但是提高了长句翻译的表现（通过把句子倒过来的trick），一般说Seq2Seq架构的时候应该指的是那篇文章（至少我认为是这样）。本文的另一个重要贡献是LSTM的简化版，GRU单元。 简介 本文中提出了一种新的模型，称为RNN Encoder-Decoder，包括两个RNN。一个RNN（encoder）把符号序列编码成一个定长向量表示（fixed-length vector representation）；另一个RNN（decoder）把该表示解码成另一个符号序列。这两个RNN共同被训练，以最大化输出目标序列的概率。我们同时提出了一种新的隐藏层单元（hidden unit）。将该模型计算出的短语对条件概率作为现有SMT模型的额外特征之后，SMT的翻译结果提升了；且可以发现，该模型学到的短语中间表示在语义上和句法上都是有意义的。 RNN RNN是一个神经网络，它输入变长序列x=(x1,...,xT)\\mathbf{x} = (x_1, ..., x_T)x=(x1​,...,xT​)，内部有一个隐状态h\\mathbf{h}h，输出（可选）为y\\mathbf{y}y。在每个时刻ttt，RNN的隐状态h⟨t⟩\\mathbf{h}_{\\langle t \\rangle}h⟨t⟩​会被更新： h_⟨t⟩=f(h_⟨t−1⟩,xt)\\mathbf{h}\\_{\\langle t \\rangle} = f(\\mathbf{h}\\_{\\langle t - 1 \\rangle}, x_t) h_⟨t⟩=f(h_⟨t−1⟩,xt​) 其中fff是一个非线性激活函数，可能很简单，也可能很复杂（如LSTM）。 RNN可以通过被训练为预测序列中的下一个符号来学习序列的概率分布。在这种情况下，ttt时刻输出的就是概率分布p(xt∣xt−1,...,x1)p(x_t | x_{t-1}, ..., x_1)p(xt​∣xt−1​,...,x1​)。比如说，一个multinomial distribution（1-K编码）就可以用一个softmax激活函数输出（这里并没有看懂……）： p(xt,j=1∣xt−1,...,x1)=exp⁡(w_jh_⟨t⟩)∑j′=1Kexp⁡(w_j′h_⟨t⟩)p(x_{t, j} = 1 | x_{t-1}, ..., x_1) = \\frac{\\exp{(\\mathbf{w}\\_j\\mathbf{h}\\_{\\langle t \\rangle})}}{\\sum_{j&#x27;=1}^{K} \\exp{(\\mathbf{w}\\_{j&#x27;}\\mathbf{h}\\_{\\langle t \\rangle})}} p(xt,j​=1∣xt−1​,...,x1​)=∑j′=1K​exp(w_j′h_⟨t⟩)exp(w_jh_⟨t⟩)​ 其中j=1,...,Kj = 1, ..., Kj=1,...,K，wj\\mathbf{w}_jwj​是权重矩阵W\\mathbf{W}W的行。 现在就可以计算出序列x\\mathbf{x}x出现的概率了： p(x)=∏t=1Tp(xt∣xt−1,...,x1)p(\\mathbf{x}) = \\prod_{t=1}^T p(x_t | x_{t-1}, ..., x_1) p(x)=t=1∏T​p(xt​∣xt−1​,...,x1​) 通过这一学到的分布，生成一个新的序列的方法是显然的，逐步选择符号即可。 RNN Encoder-Decoder 之前已经说过了，RNN Encoder-Decoder是把一个变长序列编码为一个定长向量表示，再把这个表示解码为另一个变长序列的过程。从概率论的角度看（但是我不知道为什么要从概率论的角度看），这是学习两个变长序列之间的条件概率的方法： p(y1,...,yT′∣x1,...,xT)p(y_1, ..., y_{T&#x27;} | x_1, ..., x_T) p(y1​,...,yT′​∣x1​,...,xT​) Encoder Encoder是一个RNN，它顺序读入输入序列x\\mathbf{x}x，并逐步更新隐状态（和普通的RNN是一样的）： h_⟨t⟩=f(h_⟨t−1⟩,xt)\\mathbf{h}\\_{\\langle t \\rangle} = f(\\mathbf{h}\\_{\\langle t - 1 \\rangle}, x_t) h_⟨t⟩=f(h_⟨t−1⟩,xt​) 读到序列结尾（EOS）之后，RNN的隐状态就是整个输入序列对应的表示c\\mathbf{c}c。 Decoder Decoder也是一个RNN，它通过隐状态h_⟨t⟩\\mathbf{h}\\_{\\langle t \\rangle}h_⟨t⟩预测下一个符号yty_tyt​。不过，yty_tyt​和h_⟨t⟩\\mathbf{h}\\_{\\langle t \\rangle}h_⟨t⟩都依赖于yt−1y_{t-1}yt−1​和c\\mathbf{c}c，所以ttt时刻的隐状态为： h_⟨t⟩=f(h_⟨t−1⟩,yt−1,c)\\mathbf{h}\\_{\\langle t \\rangle} = f(\\mathbf{h}\\_{\\langle t - 1 \\rangle}, y_{t-1}, \\mathbf{c}) h_⟨t⟩=f(h_⟨t−1⟩,yt−1​,c) 相似地，下一个符号的条件分布就是（虽然不是很懂这是怎么相似出来的）： P(yt∣yt−1,yt−2,...,y1,c)=g(h_⟨t⟩,yt−1,c)P(y_t | y_{t-1}, y_{t-2}, ..., y_1, \\mathbf{c}) = g(\\mathbf{h}\\_{\\langle t \\rangle}, y_{t-1}, \\mathbf{c}) P(yt​∣yt−1​,yt−2​,...,y1​,c)=g(h_⟨t⟩,yt−1​,c) Encoder+Decoder Encoder和Decoder共同进行训练，以最大化conditional log-likelihood： max⁡θ1N∑n=1Nlog⁡pθ(yn∣xn)\\max_{\\mathbf{\\theta}} \\frac{1}{N} \\sum_{n=1}^N \\log{p_{\\mathbf{\\theta}}(\\mathbf{y}_n | \\mathbf{x}_n)} θmax​N1​n=1∑N​logpθ​(yn​∣xn​) 其中θ\\mathbf{\\theta}θ是模型参数，每个(xn,yn)(\\mathbf{x}_n, \\mathbf{y}_n)(xn​,yn​)都是训练集中的一个输入输出对。由于decoder的输出是可微分的， 因此可以通过基于梯度的算法来估计模型参数。 训练完RNN Encoder-Decoder之后，模型可以通过两种方式使用。一种是根据输入序列来生成输出序列。另一种是对给定的输入输出序列进行打分，分数就是概率pθ(y∣x)p_{\\mathbf{\\theta}}(\\mathbf{y} | \\mathbf{x})pθ​(y∣x)。 新的隐藏单元 这一单元的灵感来自LSTM，但是计算和实现都简单得多。图中zzz是update gate，用于控制当前隐状态是否需要被新的隐状态h~\\tilde{h}h~更新；rrr是reset gate，用于确定是否要丢弃上一个隐状态。 这个计算方法是否说明，是很多个隐藏单元一起更新和训练……但是为什么输入是个向量呢？大概是因为1-K表示法和Embedding？ 2018.10.11 UPDATE：用一般的术语来说，下列内容实际上说明的是“一个GRU cell中的一个unit的计算过程”，因此rjr_jrj​、zjz_jzj​和hj⟨t⟩h_j^{\\langle t \\rangle}hj⟨t⟩​都是标量。在本文中，layer=cell。 rjr_jrj​通过下式计算： rj=σ([Wrx]j+[U_rh_⟨t−1⟩]_j)r_j = \\sigma([\\mathbf{W}_r\\mathbf{x}]_j + [\\mathbf{U}\\_r \\mathbf{h}\\_{\\langle t-1 \\rangle}]\\_j) rj​=σ([Wr​x]j​+[U_rh_⟨t−1⟩]_j) 其中σ\\sigmaσ是Logistic Sigmoid函数，[.]j[.]_j[.]j​是向量的第jjj个元素，x\\mathbf{x}x是输入，h_⟨t−1⟩\\mathbf{h}\\_{\\langle t-1 \\rangle}h_⟨t−1⟩是上一个隐状态，Wr\\mathbf{W}_rWr​和U_r\\mathbf{U}\\_rU_r是学习到的权重矩阵。 zjz_jzj​类似地通过下式计算： zj=σ([Wzx]j+[U_zh_⟨t−1⟩]_j)z_j = \\sigma([\\mathbf{W}_z\\mathbf{x}]_j + [\\mathbf{U}\\_z \\mathbf{h}\\_{\\langle t-1 \\rangle}]\\_j) zj​=σ([Wz​x]j​+[U_zh_⟨t−1⟩]_j) 单元hjh_jhj​的实际激活状态通过下式计算： hj⟨t⟩=zjhj⟨t−1⟩+(1−zj)h~j⟨t⟩h_j^{\\langle t \\rangle} = z_j h_j^{\\langle t-1 \\rangle} + (1 - z_j) \\tilde{h}_j^{\\langle t \\rangle} hj⟨t⟩​=zj​hj⟨t−1⟩​+(1−zj​)h~j⟨t⟩​ 其中 h~j⟨t⟩=ϕ([Wx]_j+[U(r⊙h_⟨t−1⟩)]_j)\\tilde{h}_j^{\\langle t \\rangle} = \\phi([\\mathbf{W}\\mathbf{x}]\\_j + [\\mathbf{U}(\\mathbf{r} \\odot \\mathbf{h}\\_{\\langle t-1 \\rangle})]\\_j) h~j⟨t⟩​=ϕ([Wx]_j+[U(r⊙h_⟨t−1⟩)]_j) （虽然我看不懂这个式子是怎么使用rjr_jrj​的，以及它对激活状态有什么影响……）reset gate通过与h_⟨t−1⟩)\\mathbf{h}\\_{\\langle t-1 \\rangle})h_⟨t−1⟩)点乘对h~j⟨t⟩\\tilde{h}_j^{\\langle t \\rangle}h~j⟨t⟩​产生影响。 另一种对GRU的描述方式 SMT模型和RNN Encoder-Decoder的结合 传统的SMT系统的目标是对于源句e\\mathbf{e}e，找到一个使下式最大化的翻译f\\mathbf{f}f： p(f∣e)∝p(e∣f)p(f)p(\\mathbf{f} | \\mathbf{e}) \\propto p(\\mathbf{e} | \\mathbf{f}) p(\\mathbf{f}) p(f∣e)∝p(e∣f)p(f) 其中p(e∣f)p(\\mathbf{e} | \\mathbf{f})p(e∣f)称为翻译模型（translation model），p(f)p(\\mathbf{f})p(f)称为语言模型（language model）。 但在实际中，大部分SMT系统都把log⁡p(f∣e)\\log{p(\\mathbf{f} | \\mathbf{e})}logp(f∣e)做为一个log-linear模型，包括一些额外的feature和相应的权重： log⁡p(f∣e)=∑n=1Nwnfn(f,e)+log⁡Z(e)\\log{p(\\mathbf{f} | \\mathbf{e})} = \\sum_{n=1}^N w_n f_n(\\mathbf{f}, \\mathbf{e}) + \\log{Z(\\mathbf{e})} logp(f∣e)=n=1∑N​wn​fn​(f,e)+logZ(e) 其中fnf_nfn​是feature，wnw_nwn​是权重，Z(e)Z(\\mathbf{e})Z(e)是与权重无关的normalization constant。 在基于短语的SMT模型中，翻译模型p(e∣f)p(\\mathbf{e} | \\mathbf{f})p(e∣f)被分解为源句和目标句中短语匹配的概率。这一概率再一次被作为log-linear模型中的额外feature进行优化。 作者在一个短语对表中训练RNN Encoder-Decoder，并将得到的分数作为log-linear模型中的额外feature。目前的做法是把得到的短语对分数直接加入现有的短语对表中；事实上也可以直接用RNN Encoder-Decoder代替这个表，但这就意味着对于每个源短语，RNN Encoder-Decoder都需要生成一系列好的目标短语，因此需要进行很多采样，这太昂贵了。 实验 在WMT’14的En-Fr任务上进行了评测。对于每种语言都只保留了最常见的15000个词，将不常用的词标记为[UNK]。 实验中，RNN Encoder-Decoder的encoder和decoder各有1000个隐藏单元。每个输入符号x⟨t⟩x_{\\langle t \\rangle}x⟨t⟩​和隐藏单元之间的输入矩阵用两个低秩（100）矩阵来模拟，相当于学习了每个词的100维embedding。隐藏单元中的h~\\tilde{h}h~使用的是双曲余弦函数（hyperbolic tangent function）。decoder中隐状态到输出的计算使用的是一个深度神经网络，含有一个包含了500个maxout单元的中间层。 RNN Encoder-Decoder的权重初值都是通过对一个各向同性的均值为零的高斯分布采样得到的，其标准差为0.01。（但是另一种权重矩阵的初值不一样，而且我没看懂……） 通过Adadelta和随机梯度下降法进行训练，其中超参数为ϵ=10−6\\epsilon = 10^{-6}ϵ=10−6，ρ=0.95\\rho = 0.95ρ=0.95。每次更新时，从短语表中随机选出64个短语对。模型训练了大约3天。 因为CSLM和RNN Encoder-Decoder共同使用能进一步提高表现，说明这两种方法对结果的贡献并不相同。 除此之外，它学习到的word embedding矩阵也是有意义的。 （不过考虑到这就是Word Embedding的根本用途，这件事听起来就没有那么令人兴奋了……） 附录：RNN Encoder-Decoder的详细描述 令X=(x1,x2,...,xN)X = (\\mathbf{x}_1, \\mathbf{x}_2, ..., \\mathbf{x}_N)X=(x1​,x2​,...,xN​)表示源短语，Y=(y1,y2,...,yM)Y = (\\mathbf{y}_1, \\mathbf{y}_2, ..., \\mathbf{y}_M)Y=(y1​,y2​,...,yM​)。每个短语都是一系列KKK维的one-hot向量。 Encoder 源短语的每个词都被embed成了500维：e(xi)∈R500e(\\mathbf{x}_i) \\in \\mathbb{R}^{500}e(xi​)∈R500。 encoder的隐状态由1000个隐藏单元组成，其中每一个单元在ttt时刻的状态由下式计算： hj⟨t⟩=zjhj⟨t−1⟩+(1−zj)h~j⟨t⟩h_j^{\\langle t \\rangle} = z_j h_j^{\\langle t-1 \\rangle} + (1 - z_j) \\tilde{h}_j^{\\langle t \\rangle} hj⟨t⟩​=zj​hj⟨t−1⟩​+(1−zj​)h~j⟨t⟩​ 其中 h~j⟨t⟩=tanh⁡([We(xt)]_j+[U(r⊙h_⟨t−1⟩)]_j)\\tilde{h}_j^{\\langle t \\rangle} = \\tanh([\\mathbf{W}e(\\mathbf{x}_t)]\\_j + [\\mathbf{U}(\\mathbf{r} \\odot \\mathbf{h}\\_{\\langle t-1 \\rangle})]\\_j) h~j⟨t⟩​=tanh([We(xt​)]_j+[U(r⊙h_⟨t−1⟩)]_j) zj=σ([Wze(xt)]j+[U_zh_⟨t−1⟩]_j)z_j = \\sigma([\\mathbf{W}_z e(\\mathbf{x}_t)]_j + [\\mathbf{U}\\_z \\mathbf{h}\\_{\\langle t-1 \\rangle}]\\_j) zj​=σ([Wz​e(xt​)]j​+[U_zh_⟨t−1⟩]_j) rj=σ([Wre(xt)]j+[U_rh_⟨t−1⟩]_j)r_j = \\sigma([\\mathbf{W}_r e(\\mathbf{x}_t)]_j + [\\mathbf{U}\\_r \\mathbf{h}\\_{\\langle t-1 \\rangle}]\\_j) rj​=σ([Wr​e(xt​)]j​+[U_rh_⟨t−1⟩]_j) 其中σ\\sigmaσ是logistic sigmoid函数，⊙\\odot⊙是元素对应乘积。上式中忽略了偏移项。初始隐状态hj⟨0⟩=0h_j^{\\langle 0 \\rangle} = 0hj⟨0⟩​=0。 在隐状态计算完第NNN步之后，就可以得到源短语的表示c\\mathbf{c}c： c=tanh⁡Vh⟨N⟩\\mathbf{c} = \\tanh{\\mathbf{V}\\mathbf{h}^{\\langle N \\rangle}} c=tanhVh⟨N⟩ （但是V\\mathbf{V}V矩阵是哪里来的？也是需要学习的吗？） Decoder decoder通过下式对隐状态进行初始化： h′⟨0⟩=tanh⁡(V′c)\\mathbf{h&#x27;}^{\\langle 0 \\rangle} = \\tanh(\\mathbf{V&#x27;c}) h′⟨0⟩=tanh(V′c) （大概V′\\mathbf{V&#x27;}V′矩阵也是一个参数吧。当然和Encoder的参数不一样） decoder的隐藏单元在时刻ttt的隐状态通过下式计算： h′j⟨t⟩=z′jh′j⟨t−1⟩+(1−z′j)h′~j⟨t⟩{h&#x27;}_j^{\\langle t \\rangle} = {z&#x27;}_j {h&#x27;}_j^{\\langle t-1 \\rangle} + (1 - {z&#x27;}_j) \\tilde{h&#x27;}_j^{\\langle t \\rangle} h′j⟨t⟩​=z′j​h′j⟨t−1⟩​+(1−z′j​)h′~j⟨t⟩​ 其中 h′~_j⟨t⟩=tanh⁡([W′e(y_t−1)]_j+r′_j[U′h′_⟨t−1⟩+Cc]_j)\\tilde{h&#x27;}\\_j^{\\langle t \\rangle} = \\tanh([\\mathbf{W&#x27;}e(\\mathbf{y}\\_{t-1})]\\_j + r&#x27;\\_j [\\mathbf{U&#x27;}\\mathbf{h&#x27;}\\_{\\langle t-1 \\rangle} + \\mathbf{Cc}]\\_j) h′~_j⟨t⟩=tanh([W′e(y_t−1)]_j+r′_j[U′h′_⟨t−1⟩+Cc]_j) （我在上式的最后一项上加了个jjj。我觉得可能打错了，虽然更有可能是我看错了，不过也没有找到什么验证的方法。） z′_j=σ([W′ze(y_t−1)]j+[U′_zh′_⟨t−1⟩]_j+[C_zc]j){z&#x27;}\\_j = \\sigma([\\mathbf{W&#x27;}_z e(\\mathbf{y}\\_{t-1})]_j + [\\mathbf{U&#x27;}\\_z \\mathbf{h&#x27;}\\_{\\langle t-1 \\rangle}]\\_j + [\\mathbf{C}\\_z\\mathbf{c}]_j) z′_j=σ([W′z​e(y_t−1)]j​+[U′_zh′_⟨t−1⟩]_j+[C_zc]j​) r′_j=σ([W′re(y_t−1)]j+[U′_rh′_⟨t−1⟩]_j+[C_rc]j){r&#x27;}\\_j = \\sigma([\\mathbf{W&#x27;}_r e(\\mathbf{y}\\_{t-1})]_j + [\\mathbf{U&#x27;}\\_r \\mathbf{h&#x27;}\\_{\\langle t-1 \\rangle}]\\_j + [\\mathbf{C}\\_r\\mathbf{c}]_j) r′_j=σ([W′r​e(y_t−1)]j​+[U′_rh′_⟨t−1⟩]_j+[C_rc]j​) 其中e(y0)e(\\mathbf{y}_0)e(y0​)是一个全零向量。类似于encoder中的情况，e(y)e(\\mathbf{y})e(y)也是目标词的embedding。 decoder需要学习如何生成一个目标短语。在ttt时刻，decoder需要计算生成的词是第jjj个的概率： p(y_t,j=1∣y_t−1,...,y_1,X)=exp⁡(g_js_⟨t⟩)∑_j′=1Kexp⁡(g_j′s_⟨t⟩)p(y\\_{t,j} = 1 | \\mathbf{y}\\_{t-1}, ..., \\mathbf{y}\\_1, X) = \\frac{\\exp{(\\mathbf{g}\\_j \\mathbf{s}\\_{\\langle t \\rangle}})}{\\sum\\_{j&#x27;=1}^K \\exp{(\\mathbf{g}\\_{j&#x27;} \\mathbf{s}\\_{\\langle t \\rangle})}} p(y_t,j=1∣y_t−1,...,y_1,X)=∑_j′=1Kexp(g_j′s_⟨t⟩)exp(g_js_⟨t⟩)​ 其中s_⟨t⟩\\mathbf{s}\\_{\\langle t \\rangle}s_⟨t⟩的第iii个元素是 $$\\mathbf{s}_i^{\\langle t \\rangle} = \\max{{{s'}_{2i-1}^{\\langle t \\rangle}, {s'}_{2i}^{\\langle t \\rangle}}}$$ 且 $$\\mathbf{s'}^{\\langle t \\rangle} = \\mathbf{O}_h \\mathbf{h'}^{\\langle t \\rangle} + \\mathbf{O}_y \\mathbf{y}_{t-1} + \\mathbf{O}_c \\mathbf{c}$$ 简单来说，s_i⟨t⟩\\mathbf{s}\\_i^{\\langle t \\rangle}s_i⟨t⟩就是所谓的maxout单元。 （虽然我目前还不知道maxout是什么，以及这个g\\mathbf{g}g是怎么来的，以及这一堆到底是怎么算的……） 为了计算效率，我们使用两个矩阵的乘积作为输出权重矩阵G\\mathbf{G}G： G=G_lG_r\\mathbf{G} = \\mathbf{G}\\_l \\mathbf{G}\\_r G=G_lG_r 其中G_l∈RK×500\\mathbf{G}\\_l \\in \\mathrm{R}^{K \\times 500}G_l∈RK×500，G_r∈R500×1000\\mathbf{G}\\_r \\in \\mathrm{R}^{500 \\times 1000}G_r∈R500×1000。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://zhanghuimeng.github.io/tags/Machine-Learning/"},{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"}]},{"title":"论文：BLEU: a Method for Automatic Evaluation of Machine Translation (ACL2002)","slug":"2018-10-02-论文：BLEU-a-Method-for-Automatic-Evaluation-of-Machine-Translation-ACL2002","date":"2018-10-02T13:50:54.000Z","updated":"2018-10-02T13:50:54.000Z","comments":true,"path":"post/bleu-a-method-for-automatic-evaluation-of-machine-translation-acl2002/","link":"","permalink":"https://zhanghuimeng.github.io/post/bleu-a-method-for-automatic-evaluation-of-machine-translation-acl2002/","excerpt":"","text":"论文地址：https://www.aclweb.org/anthology/P02-1040.pdf 这篇文章大概是MT领域非常著名的一篇文章了，因为它提出了一种根据参考翻译为机器翻译质量打分的方法（BLEU值），直到现在还在被广泛使用。 基本思路 BLEU评价翻译水平的基本假设是这样的：机器翻译越接近人类翻译，机器翻译的质量就越高。因此，在这一前提下，需要量化机器翻译与人类翻译的相似程度。经过观察可以发现，一个较好的机器翻译和人工翻译中相同的词和短语比较多；因此可以通过比较机器翻译和人工翻译中相同n-gram的数量来评价一个机器翻译。因此令pnp_npn​表示改进的n-gram精度（modified n-gram precision）： pn=∑C∈Candidates∑n−gram∈CCountclip(n−gram)∑C′∈Candidates∑n−gram′∈C′Count(n−gram′)p_n = \\frac{\\sum_{C \\in {Candidates}} \\sum_{n-gram \\in C} Count_{clip}(n-gram)}{\\sum_{C&#x27; \\in {Candidates}} \\sum_{n-gram&#x27; \\in C&#x27;} Count(n-gram&#x27;)} pn​=∑C′∈Candidates​∑n−gram′∈C′​Count(n−gram′)∑C∈Candidates​∑n−gram∈C​Countclip​(n−gram)​ 其中Countclip(n−gram)Count_{clip}(n-gram)Countclip​(n−gram)的意思是，对于某一个在机器翻译结果中出现的n-gram，它被统计的数量不超过该n-gram在某一个参考翻译中出现的总数量。这样可以防止出现机器翻译大量重复参考翻译中出现的某个词，结果却会得到较高分数的情况。 此时可以看出，这一评分方法可以区分人类和机器翻译了，且n越大，得分的差异越大。 此时可以看出，这一评分方法也可以在较细粒度上区分人类和机器翻译。 改进：组合多种n-gram的得分 可以看出，n-gram分数大致随n的增加指数衰减，所以对pnp_npn​的对数做加权平均是比较好的。实验得出，取n≤4n \\leq 4n≤4时得到的评测结果最为接近。 改进：短句惩罚 很显然上面的做法已经惩罚了过长的句子和被使用太多次的词，但是并没有考虑到句子太短的情况。只考虑精度可能会使得短句得到非常高的分数。但是考虑召回率又可能会使得事情变得过于复杂。所以直接考虑机器翻译和参考翻译的长度。对于每个机器翻译得到的句子，在（可能有多个的）参考翻译中找到与它长度最为接近的句子，称其长度为最佳匹配长度（best match length）。然后计算出整体语料的机器翻译最佳匹配长度之和，称为rrr；令ccc是机器翻译结果的总长度，定义短句惩罚（brevity penalty）为 BP={1if:c&gt;re(1−r/c)if:c≤r\\text{BP} = \\begin{cases} 1 &amp; \\text{if} \\\\: c &gt; r\\\\\\\\ e^{(1 - r/c)} &amp; \\text{if} \\\\: c \\leq r \\end{cases} BP=⎩⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎧​1:c&gt;re(1−r/c):c≤r​ifif​ 将这个因子乘到BLEU分数上： BLEU=BP⋅exp⁡(∑n=1Nwnlog⁡pn)\\text{BLEU} = \\text{BP} \\cdot \\exp{(\\sum_{n=1}^{N} w_n \\log{p_n})} BLEU=BP⋅exp(n=1∑N​wn​logpn​) 即 log⁡BLEU=min⁡(1−rc,0)+∑n=1Nwnlog⁡pn\\log{\\text{BLEU}} = \\min{(1 - \\frac{r}{c}, 0)} + \\sum_{n=1}^{N} w_n \\log{p_n} logBLEU=min(1−cr​,0)+n=1∑N​wn​logpn​ 测试 在测试中，取N=4N = 4N=4，wn=1/Nw_n = 1/Nwn​=1/N（也就是直接平均）。 作者首先回答了这样几个问题： （不同机器/人类翻译）BLEU值的差异是可信的吗？ （不同机器/人类翻译）BLEU值的差异是稳定的吗？ BLEU值的方差是多少？ 作者找了500个句子，每个各有4个参考翻译，首先让机器/人类分别翻译500个句子，分别计算其BLEU值；然后把这500个句子分成20组，分组计算BLEU值，并计算出平均值和标准差，并对不同系统翻译的结果进行结对T检验。即使只随机留下每个句子的一个参考翻译，BLEU值的排序也没有改变。这说明BLEU值的差异是可信和稳定的，且方差不是很大。 之后作者比较了BLEU评测和人类评测（之前对人类评测也做了一个结对T检验，虽然我并不知道有什么用）的结果。 可以看出，BLEU值和单语言评测者的打分比较相近，和多语言评测者的打分差别比较大。这可能是因为BLEU值只考虑了翻译结果的流利度等因素，不像多语言评测者那样，会考虑更多的语义方面的问题。 总结 这个评价方法主要考虑的是翻译结果和参考翻译之间的相似程度，用比较简单的方法得到了与人类评价相似的结果。不过我的问题是： 单纯用n-gram计数的比较是否过于简单，没有考虑参考翻译和机器翻译之间语义比较的问题？ BLEU和单语言评测者比较接近大概是有原因的：这一评测方法完全依赖于参考翻译，完全没有管源句的结构之类的问题。不过我觉得只要能保证参考翻译是高质量的，这并不能说是一件坏事，这应该取决于MT的主要应用场景。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"https://zhanghuimeng.github.io/tags/Natural-Language-Processing/"},{"name":"Machine Translation","slug":"Machine-Translation","permalink":"https://zhanghuimeng.github.io/tags/Machine-Translation/"},{"name":"Paper","slug":"Paper","permalink":"https://zhanghuimeng.github.io/tags/Paper/"}]},{"title":"Raspberry Pi（1）：启动和远程访问","slug":"2018-10-01-Raspberry-Pi（1）：启动和远程访问","date":"2018-10-01T16:18:00.000Z","updated":"2018-10-01T16:49:00.000Z","comments":true,"path":"post/raspberry-pi-1-boot-and-remote-access/","link":"","permalink":"https://zhanghuimeng.github.io/post/raspberry-pi-1-boot-and-remote-access/","excerpt":"","text":"今年由于各种各样的原因选了《嵌入式系统》这门课，一部分原因是因为我小时候总觉得搞计算机的都应该会用这种开发板搞各种神奇的嵌入式开发。事实可能不是这样，不过这门课大概还挺有意思的，难度应该比OS和计原稍微小一点吧…… 套件包括： Raspberry Pi 3 Model B+一个，包括四个USB口、一个网线接口、一个microUSB电源接口、一个HDMI口和一个耳机（大概）接口，还有摄像头 32GB TF卡一个 USB读卡器一个 电源线一个 电源线转接头一个 第一次启动树莓派 首先需要把系统映像烧到TF卡里，可以使用Etcher或者Win32DiskImager。结果在这里我干了一件蠢事。我不小心在官网上下载了Raspberry Pi Desktop (for PC and Mac)，而不是用于树莓派自己的Raspbian。结果往TF卡上烧了几次，树莓派都没什么反应。至于“反应”……树莓派左下角有两个灯，“PWR”和“ACT”，分别表示是否通电和工作状态。正常工作状态下，PWR应该常亮。树莓派没有开关机按钮，它会在加电时直接自动启动。如果能够读取TF卡，则ACT会开始闪烁；否则ACT会保持不动。[1] 总之最后我终于发现自己下错镜像了。 第一次启动树莓派的时候必须要连接显示器和鼠标键盘，否则不能完成必要的设置。键盘和鼠标直接插USB就行；一般来说，需要一个VGA转HDMI转接头。 设置主要包括： 地点和时区 密码 Wifi 打开串口、Camera、SSH等开关 （好像没了） 其中，我开始的时候没有连上Wifi，不过也算是设置完了。 使用VNC Viewer远程访问树莓派 树莓派和电脑如何通过网络连接是一个比较大的问题。这次的推荐方法是把树莓派和电脑都连接到手机热点上，然后在电脑上用VNC Viewer远程访问树莓派。所以首先需要连接到手机热点。但是在这一步我又因为热点名称里有中文字符而踩了一点坑，最后只好改了手机的名称。[2] 通过在树莓派上执行ifconfig wlan0，可以知道树莓派在局域网内的地址。然后就可以在电脑端的VNCViewer上输入地址进行远程访问了。 不过我现在的问题是，这个地址是否会变化。重启了一次之后，发现暂时没有发生变化。不知道是为什么。还需要配置静态IP之类的吗？ STICKY: Is your Pi not booting? ↩︎ Raspberry Pi 3 can’t connect to iOS’ Personal Hotspot ↩︎","categories":[],"tags":[{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://zhanghuimeng.github.io/tags/Raspberry-Pi/"}]},{"title":"2018-09-30-Leetcode 913. Cat and Mouse（极大极小问题）","slug":"2018-09-30-Leetcode-913-Cat-and-Mouse（极大极小问题）","date":"2018-09-30T23:20:43.000Z","updated":"2018-10-01T21:45:00.000Z","comments":true,"path":"post/leetcode-913-cat-and-mouse/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-913-cat-and-mouse/","excerpt":"","text":"题目来源：https://leetcode.com/problems/cat-and-mouse/description/ 标记难度：Hard 提交次数：1/4 代码效率：12ms 题意 有一张无向图，包含最多50个结点。有两个玩家（Mouse和Cat）在图上，Mouse的起始位置是1，Cat的起始位置是2，0处有一个洞，Cat不能移动到0。Mouse和Cat在图上轮流移动，每次必须移动到与当前结点相邻的一个结点。 游戏有三种结束的可能： Cat和Mouse进入同一结点，则Cat胜利 Mouse进入0结点，则Mouse胜利 Cat和Mouse的位置和回合发生了重复，则平局 问：如果Cat和Mouse都以最优策略行动，最后的结果是什么？ 分析 这大概是我目前为止在Leetcode Contest里见过的最难的一道题…… 很显然，这道题是一个极大极小问题，可以把状态写成(mPos, cPos, turn)，然后建立一张状态之间的转移图，并给状态染色（胜、负、平局）。但问题是这个图里可能有圈（所以显然这不是一棵树），而且也因此存在平局的问题。题解里给出的解决方法类似于反过来的拓扑排序： 首先将那些颜色能够确定的状态（同时出度=0）入队，比如mPos = 0和mPos == cPos的那些 从队里取出一个状态，尝试对它的所有祖先状态进行染色。对于某个祖先状态： 如果已经被染色，则跳出 如果能够立即染色（比如祖先状态的turn == MOUSE且当前状态的颜色为MOUSE），则直接进行染色，并将该状态入队 如果不能立即染色，则记录祖先状态的出度-1；如果发现祖先状态的出度为0，说明该状态下的先手必然失败，也可以进行相应的染色并将该状态入队 最后输出(1, 2, MOUSE)的颜色。没有被染过色说明是平局。 以上的内容只是类似于拓扑排序，并不就是拓扑排序，因为我们可以在尚未访问完一个状态的所有子状态（即出度还不是0）时把它取出来，继续更新其他的结点。（我似乎因为这个原因踩了一些坑）[1] 但是，我觉得没有被染过色说明是平局不太好理解。虽然理论上是这样的。 除此之外，还有DP的方法，但是我暂时还不太理解。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495class Solution &#123; struct Tuple &#123; int mPos, cPos; int turn; Tuple(int m, int c, int t) &#123; mPos = m; cPos = c; turn = t; &#125; &#125;;public: int catMouseGame(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; const int MOUSE = 1, CAT = 2; int N = graph.size() - 1; int states[55][55][3]; // 1: mouse, 2: cat memset(states, 0, sizeof(states)); queue&lt;Tuple&gt; q; int outDegree[55][55][3]; memset(outDegree, 0, sizeof(outDegree)); // put the definite status to queue for (int i = 0; i &lt;= N; i++) &#123; for (int j = 0; j &lt;= N; j++) &#123; if (j == 0) continue; if (i == 0) &#123; states[i][j][MOUSE] = states[i][j][CAT] = MOUSE; q.emplace(i, j, MOUSE); q.emplace(i, j, CAT); continue; &#125; if (i == j) &#123; states[i][j][MOUSE] = states[i][j][CAT] = CAT; q.emplace(i, j, MOUSE); q.emplace(i, j, CAT); continue; &#125; outDegree[i][j][MOUSE] = graph[i].size(); // Note: Cat cannot go to 0 for (int x: graph[j]) if (x != 0) outDegree[i][j][CAT]++; &#125; &#125; while (!q.empty()) &#123; Tuple tuple = q.front(); q.pop(); int mPos = tuple.mPos, cPos = tuple.cPos, turn = tuple.turn; if (states[mPos][cPos][turn] == 0) continue; // find its parent node if (turn == MOUSE) &#123; for (int x: graph[cPos]) &#123; if (x == 0) continue; // Need this line if (states[mPos][x][CAT] != 0) continue; // When its color is defined, immediately add it to the queue if (states[mPos][cPos][turn] == CAT) &#123; states[mPos][x][CAT] = CAT; q.emplace(mPos, x, CAT); &#125; else &#123; outDegree[mPos][x][CAT]--; if (outDegree[mPos][x][CAT] == 0) &#123; states[mPos][x][CAT] = MOUSE; q.emplace(mPos, x, CAT); &#125; &#125; &#125; &#125; else &#123; for (int x: graph[mPos]) &#123; if (states[x][cPos][MOUSE] != 0) continue; if (states[mPos][cPos][turn] == MOUSE) &#123; states[x][cPos][MOUSE] = MOUSE; q.emplace(x, cPos, MOUSE); &#125; else &#123; outDegree[x][cPos][MOUSE]--; if (outDegree[x][cPos][MOUSE] == 0) &#123; states[x][cPos][MOUSE] = CAT; q.emplace(x, cPos, MOUSE); &#125; &#125; &#125; &#125; &#125; return states[1][2][MOUSE]; &#125;&#125;; Leetcode 913 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Minimax","slug":"alg-Minimax","permalink":"https://zhanghuimeng.github.io/tags/alg-Minimax/"}]},{"title":"Leetcode 916. Word Subsets（字符串）","slug":"2018-09-30-Leetcode-916-Word-Subsets（字符串）","date":"2018-09-30T21:18:40.000Z","updated":"2018-09-30T21:30:00.000Z","comments":true,"path":"post/leetcode-916-word-subsets/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-916-word-subsets/","excerpt":"","text":"题目来源：https://leetcode.com/problems/word-subsets/description/ 标记难度：Medium 提交次数：1/1 代码效率：176ms 题意 给定字符串数组A和B，如果字符串b中每个字符的出现次数都&lt;=该字符在a中的出现次数，则称b是a的子集。如果对于B中的每个字符串b，b都是a的子集，则称a为“universal”。问A中有多少个字符串是“universal”的。 分析 这道题也非常简单。如果a是“universal”的，说明 ∀b∈B,∀char,countchar(a)≥countchar(b)\\forall b \\in B, \\forall char, count_{char}(a) \\geq count_{char}(b) ∀b∈B,∀char,countchar​(a)≥countchar​(b) 即 ∀char,∀b∈B,countchar(a)≥countchar(b)\\forall char, \\forall b \\in B, count_{char}(a) \\geq count_{char}(b) ∀char,∀b∈B,countchar​(a)≥countchar​(b) ∀char,countchar(a)≥max⁡∀b∈Bcountchar(b)\\forall char, count_{char}(a) \\geq \\max_{\\forall b \\in B}{count_{char}(b)} ∀char,countchar​(a)≥∀b∈Bmax​countchar​(b) 只要a满足以上条件就可以了。[1] 代码 123456789101112131415161718192021222324252627282930class Solution &#123;public: vector&lt;string&gt; wordSubsets(vector&lt;string&gt;&amp; A, vector&lt;string&gt;&amp; B) &#123; int allb[26], b[26], a[26]; memset(allb, 0, sizeof(allb)); for (string bs: B) &#123; memset(b, 0, sizeof(b)); for (char ch: bs) b[ch - 'a']++; for (int i = 0; i &lt; 26; i++) allb[i] = max(allb[i], b[i]); &#125; vector&lt;string&gt; ans; for (string as: A) &#123; memset(a, 0, sizeof(a)); for (char ch: as) a[ch - 'a']++; bool ok = true; for (int i = 0; i &lt; 26; i++) if (a[i] &lt; allb[i]) &#123; ok = false; break; &#125; if (ok) ans.push_back(as); &#125; return ans; &#125;&#125;; Leetcode 916 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 915. Partition Array into Disjoint Intervals（数组）","slug":"2018-09-30-Leetcode-915-Partition-Array-into-Disjoint-Intervals（Array）","date":"2018-09-30T20:15:48.000Z","updated":"2018-09-30T21:03:00.000Z","comments":true,"path":"post/leetcode-915-partition-array-into-disjoint-intervals/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-915-partition-array-into-disjoint-intervals/","excerpt":"","text":"题目来源：https://leetcode.com/problems/partition-array-into-disjoint-intervals/description/ 标记难度：Medium 提交次数：2/3 代码效率： 3 Passes：28ms 1 Pass：28ms 题意 给定一个数组，要求将它分成left和right两半，满足： len(left) &gt; 0，len(right) &gt; 0 max(left) &lt;= min(right) left的长度最小 数据保证存在合法的分割方法，求left的最小长度。 分析 这道题还挺有意思的。 建立辅助数组 比赛的时候我用的就是这种方法，因为最好想。令maxn[i] = max(A[0], ..., A[i])，minn[i] = min(A[i], ..., A[n-1])，这两个数组可以分别通过一次遍历求得；然后再进行一次遍历，找出满足maxn[i] &lt;= minn[i + 1]的最小的i即可。时间复杂度和额外空间复杂度都是O(N)。 我在考虑怎么优化这个算法的时候思考了一下这两个数组的性质。显然maxn[i]是递增的，而minn[i]也是递增的，但增长速度不同，所以会出现一些maxn[i] &lt;= minn[i+1]的区间。我们要做的就是找到第一个这样的区间。但是这个东西似乎也没有很强的单调性…… 不建立辅助数组 很显然，因为要求len(left) &gt; 0，因此必然有max(left) &gt;= A[0]。然后从左向右进行扫描，记leftMax为已经确定需要包括在left数组中的数的最大值，j为当前已经确定的left数组的右边界，curMax为当前已经发现的最大值。对于下一个数A[i]： 如果A[i] &lt; leftMax，则它必须被包含在left中（否则right中将出现比left的最大值更小的数）。因此需要更新j = i，leftMax = curMax（因为left是连续的，所以之前已经发现过的最大值现在也必须包含于left中）。 如果leftMax &lt;= A[i] &lt;= curMax，则这个数有可能被包含在left中（如果右侧出现比leftMax更小的数），也有可能不需要（如果右侧没有出现这样的数）。所以暂时不作处理。 如果A[i] &gt; curMax，则这个数也不一定被包含在left中（和前一种情况同理）。更新curMax = A[i]。 最后的结果为j+1。[1] 以数组[5, 7, 3, 8, 6, 9, 10]为例。初始时，令leftMax = 5，curMax = 5，j = 0。 12345678910111213141516171819202122232425262728293031323334Initial State:leftMax = 5, curMax = 5, j = 05 7 3 8 6 9 10l - - - - - -i = 1: Update curMax to 7leftMax = 5, curMax = 7, j = 05 7 3 8 6 9 10l ^ - - - - -i = 2: Update leftMax to 7 and j to 2leftMax = 7, curMax = 7, j = 25 7 3 8 6 9 10l l l - - - -i = 3: Update curMax to 8leftMax = 7, curMax = 8, j = 25 7 3 8 6 9 10l l l ^ - - -i = 4: Update leftMax to 8, j to 4leftMax = 8, curMax = 8, j = 45 7 3 8 6 9 10l l l l l - -i = 5: Update curMax to 9leftMax = 8, curMax = 9, j = 45 7 3 8 6 9 10l l l l l ^ -i = 6: Update curMax to 10leftMax = 8, curMax = 10, j = 45 7 3 8 6 9 10l l l l l ^ ? 这一方法的时间复杂度仍然为O(N)，额外空间复杂度为O(1)。 更多 我花了一些时间，用于思考这个问题的复杂度能否降得更低。但我并不能想出来：我既不能很好地利用O(log(N))的最大值选择算法，也不能证明复杂度的下界是O(N)。所以反正就是想不出来。 代码 3 Passes 123456789101112131415161718192021222324class Solution &#123;public: int partitionDisjoint(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int maxn[n], minn[n]; for (int i = 0; i &lt; n; i++) &#123; if (i == 0 || A[i] &gt; maxn[i-1]) maxn[i] = A[i]; else maxn[i] = maxn[i - 1]; &#125; for (int i = n - 1; i &gt;= 0; i--) &#123; if (i == n - 1 || A[i] &lt; minn[i+1]) minn[i] = A[i]; else minn[i] = minn[i + 1]; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; if (maxn[i] &lt;= minn[i+1]) return i + 1; &#125; return -1; &#125;&#125;; 1 Pass 12345678910111213141516class Solution &#123;public: int partitionDisjoint(vector&lt;int&gt;&amp; A) &#123; int leftMax = A[0], curMax = A[0], j = 0; for (int i = 1; i &lt; A.size(); i++) &#123; if (A[i] &lt; leftMax) &#123; j = i; leftMax = curMax; &#125; else if (A[i] &gt; curMax) &#123; curMax = A[i]; &#125; &#125; return j + 1; &#125;&#125;; 这一想法的灵感来自Different Thinking - Intuitive Explanation ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 914. X of a Kind in a Deck of Cards（数学），及周赛（104）总结","slug":"2018-09-30-Leetcode-914-X-of-a-Kind-in-a-Deck-of-Cards（数学）","date":"2018-09-30T19:45:13.000Z","updated":"2018-09-30T19:45:13.000Z","comments":true,"path":"post/leetcode-914-x-of-a-kind-in-a-deck-of-dards-and-contest-104/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-914-x-of-a-kind-in-a-deck-of-dards-and-contest-104/","excerpt":"","text":"题目来源：https://leetcode.com/problems/x-of-a-kind-in-a-deck-of-cards/description/ 标记难度：Easy 提交次数：1/1 代码效率：12ms 题意 给定若干个元素，问每种元素的数量的最大公约数。 分析 这次比赛时我正在上《信号处理原理》。所以就随便写了一下。前三题过于水了，一共花了不到20分钟……然后我觉得第四题应该要用对抗搜索，就直接上课了，没去管它。后来我发现我居然是51 / 3579名，4道题都做出来的一共41个人，而做出来三道题的超过了1000个人。所以这是一次拼手速的比赛。 直接用hash表统计元素数量加gcd算法就好了，这道题真的水…… 代码 1234567891011121314151617181920212223242526class Solution &#123;private: int gcd(int x, int y) &#123; if (x % y == 0) return y; return gcd(y, x % y); &#125;public: bool hasGroupsSizeX(vector&lt;int&gt;&amp; deck) &#123; int h[10005]; memset(h, 0, sizeof(h)); for (int d: deck) h[d]++; int g = -1; for (int i = 0; i &lt; 10000; i++) &#123; if (g == 1) break; if (h[i] &gt; 0) &#123; if (g == -1) g = h[i]; else g = gcd(h[i], g); &#125; &#125; return g &gt; 1; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"读书笔记：《深入理解TensorFlow》第2章：TensorFlow环境准备","slug":"2018-09-25-读书笔记：《深入理解TensorFlow》第2章：TensorFlow环境准备","date":"2018-09-25T02:06:08.000Z","updated":"2018-09-25T02:06:08.000Z","comments":true,"path":"post/reading-report-tensorflow-in-depth-ch-2-prepare-for-tensorflow-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/reading-report-tensorflow-in-depth-ch-2-prepare-for-tensorflow-summary/","excerpt":"","text":"书：深入理解TensorFlow架构设计与实现原理 本章主要介绍了TensorFlow的安装方法和基本结构。基本结构里大部分内容我也不是很明白…… TensorFlow的五种安装方法 用包管理工具Anacoda安装 用原生pip安装 用virtualenv安装 自己下载源码进行编译并得到whl包 用docker运行含有TensorFlow二进制包的容器 如果需要使用GPU版本的TensorFlow，则需要安装CUDA、cuDNN和libcupti-dev开发库。（因为这些是TensorFlow的外部依赖项。） 我是用virtualenv安装的。本来打算用原生pip，但PyCharm自动提供virtualenv环境，那就直接这么装好了。 TensorFlow的几种重要依赖项 Bazel：TensorFlow软件构建 Protocol Buffers数据结构序列化工具和gRPC通信库：TensorFlow的进程间通信机制，以及Serving等周边组件的交互机制所依赖的框架 Eigen线性代数计算库：主要用于在CPU和OpenCL GPU设备上实现TensorFlow的计算类操作 CUDA统一计算设备架构：用于并行计算（是不受Bazel管理的外部依赖项） 源代码结构 根目录 根目录是一个Bazel项目的工作空间，包含了TensorFlow的所有源代码、Bazel构建规则文件，以及一些辅助脚本。 tensorflow/：TensorFlow项目自身的源代码 third_party/：部分第三方源代码以及针对第三方项目的Bazel构建规则文件 tools/：Bazel构建过程所需的环境配置脚本 utils/：现已删除 tensorflow目录 这一目录下的源文件几乎实现了TensorFlow的全部功能，同时体现了TensorFlow的整体模块布局。 c/：C语言应用层API，亦作为C、C++以外的其他语言应用层API的实现基础 cc/：C++语言应用层API compiler/：XLA（Accelerated Linear Algebra）编译优化组件的源代码。 contrib/：社区托管的第三方贡献组件 core/：TensorFlow核心运行时库的源代码，主要使用C++语言实现 doc_src/：TensorFlow软件文档（即TensorFlow官方网站文档）的Markdown源代码 examples/：TensorFlow应用开发示例代码 g3doc/：旧的文档目录，已弃用 go/：Go语言应用层API java/：Java语言应用层API python/：Python语言应用层API security/：显然写书的时候还没有这个文件夹 stream_executor/：StreamExecutor库的源代码，主要使用C++语言实现，用于管理CUDA GPU上的计算。 tensorboard/：TensorBoard组件的源代码，主要使用Python语言实现，用于深度学习过程可视化；现已移入单独仓库tensorboard中 tools/：TensorFlow构建和运行时使用的工具程序或脚本 BUILD：Bazel构建规则文件，用于构建TensorFlow核心运行时库等组件 tensorflow.bzl：Bazel构建过程所需的辅助脚本，主要用于定义TensorFlow特有的构建规则 workspace.bzl：Bazel构建过程所需的辅助脚本，主要用于定义外部依赖项的下载规则 tensorflow/core目录 api_def/：显然写书的时候还没有这个文件夹 common_runtime/：核心库的公共运行时源代码，实现了TensorFlow数据流图计算的主要逻辑 debug/：用于核心库调试的组件 distributed_runtime/：核心库的分布式运行时源代码，实现了TensorFlow分布式运行模式的主要逻辑 example/：使用Protocol Buffers创建自定义数据结构并访问序列化文件的示例代码 framework/：核心库的框架性组件，包含TensorFlow编程框架中主要抽象的C++或Protocol Buffers定义 graph/：数据流图相关抽象和工具类的源代码 grappler/：Grappler优化器（一种基于硬件使用成本分析的数据流图优化器）的源代码 kernels/：数据流图操作（Op）针对各类计算设备实现的核函数源代码 lib/：公共基础库，涉及通用数据结构、常用算法的实现，以及多种图形、音频格式的访问接口类 ops/：数据流图操作的接口定义源代码 platform/：用于访问特定操作系统或云服务接口的平台相关代码 protobuf/：数据流图基本抽象以外的序列化数据结构的Protocol Buffers源代码，例如gRPC接口定义 public/：对应用层可见的公开接口的头文件 user_ops/：用于存放用户自行开发的数据流图操作，包含一组示例代码 util/：核心库内部使用的多种实用工具类或函数的集合，例如用于解析命令行参数和访问环境变量的工具 tensorflow/python目录 autograph/：？ client/：TensorFlow主-从模型中的客户端组件，主要包括会话抽象，用于维护数据流图计算的生命周期 compat/：？ data/：？ debug/：用于Python应用程序调试的组件 distribute/：？ eager/：？ estimator/：各类模型评价器（estimator） feature_column/：特征列（feature column）组件 framework/：Python API的框架型组件，包含TensorFlow编程框架中主要抽象的Python语言定义。 grappler/：Grappler优化器的Python语言接口。 keras/：？ kernel_tests/：数据流图操作的单元测试代码，有助于用户学习各种操作的使用方法。 layers/：预置的神经网络模型层（layer）组件 lib/：公共基础库，涉及专用数据结构访问和文件系统I/O等。 ops/：数据流图操作的Python语言接口 platform/：用于访问特定操作系统或云服务接口的平台相关代码 profiler/：？ saved_model/：用于访问TensorFlow通用模型序列化格式（SavedModel）的组件 summary/：用于生成TensorFlow事件汇总文件（summary）的组件，以便在TensorFlow中可视化计算过程。 tools/：若干可独立运行的Python脚本工具，涉及访问和优化模型文件等功能。 training/：与模型训练相关的组件，例如各类优化器（optimizer）、模型保存器（saver）等。 user_ops/：用于存放用户自行开发的数据流图操作的Python语言接口。 util/：用于存放用户自行开发的数据流图操作的Python语言接口 build_defs.bzl：Bazel构建过程所需的辅助脚本，主要用于定义Python API特有的构建规则。 pywrap_tensorflow.py：间接封装核心库通过C API导出的函数，以便在Python API内部调用核心库的功能。 tensorflow.i：对接C API的SWIG接口描述文件，用于在软件构建时为Python API生成核心层的动态链接库。 TensorFlow的安装目录 使用二进制包安装TensorFlow时，pip会将python文件、动态链接库和必要的依赖项复制到当前Python环境的site-packages或dist-packages目录中。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://zhanghuimeng.github.io/tags/TensorFlow/"}]},{"title":"读书笔记：《深度学习》第1章：引言","slug":"2018-09-24-读书笔记：《深度学习》第1章：引言","date":"2018-09-24T16:22:31.000Z","updated":"2018-09-24T19:56:31.000Z","comments":true,"path":"post/reading-report-deep-learning-chapter-1-introduction/","link":"","permalink":"https://zhanghuimeng.github.io/post/reading-report-deep-learning-chapter-1-introduction/","excerpt":"","text":"书：Deep Learning 这本书的引言内容还是相当丰富的，里面谈到了很多有趣的问题。作者首先对深度学习的基本概念做了解释。对AI来说，能够形式化描述的问题是容易解决的，而对人类来说更直觉性的问题不易解决。深度学习（deep learning）让计算机能够从经验中学习，并通过层次化概念的形式来理解世界，通过构建较简单概念的方法来学习复杂概念。由于概念的层次很多，我们称之为深度学习。 下面是深度学习产生的动机。之前有一些AI项目尝试过用形式语言描述现实世界的知识，但都不是很成功；这说明AI系统需要具备从原始数据中提取模式，即自己获取知识的能力：这一能力被称为机器学习（machine learning）。这些简单的机器学习算法的表现在很大程度上依赖于它们获得的数据的表示（representation），表示的每条信息称为一个特征（feature）。但是对很多任务来说，找到合适的特征是很难的。 对这一问题的解决方法之一是，不仅仅学习从表示到输出的映射，也学习表示本身。这一方法被称为表示学习（representation learning）。学习到的表示通常比直接设计表示的表现更好。这也使得AI系统能迅速适应新的任务。 在设计特征或用于学习特征的算法的时候，我们的目标通常是将解释变化因素的特征（或数据的概念和抽象）相互分开。但很多因素会同时影响每一个数据，所以直接提取这些抽象因素是很难的。而深度学习通过其他较简单的表示来表达复杂表示，解决了表示学习中的这一核心问题。 刚才说的是，深度学习让计算机通过较简单的概念构建复杂的概念。对深度学习的另一种解释是，“深度”使得电脑能够学习一个多步程序。每一层表示都可以被看成是电脑的内存在并行执行完一系列指令后的内存状态。 目前主要的两种度量模型深度的方式： 计算流程图中的最长路径 概念描述图的深度 总的来说，深度学习是一种机器学习，是一种能够使计算机系统从经验和数据中得到提高的技术。 According to the authors of this book, machine learning is the only viable approach to building AI systems that can operate in complicated, real-world environments. 1.1 本书面向的读者 正在学习深度学习的学生 缺乏统计背景的软件工程师 1.2 深度学习的历史潮流 几个关键趋势： 有很长的历史，曾经有很多名字，这反应了不同的哲学视角 训练数据量越多，深度学习的用处就越大 计算机软硬件水平提高后，深度学习的模型也变大了 深度学习解决的问题的复杂性和准确度都在不断提高 1.2.1 神经网络的众多名称和命运变迁 1940-1960：控制论（cybernetics） 1980-1990：联结主义（connectionsim） 2006-：深度学习 控制论，神经科学和现代深度学习 最早的一些学习算法模拟的是生物学习。例子包括包括简单线性模型、McCulloch-Pitts神经元和随机梯度下降法。由于线性模型有很多局限性，这导致批评者对受生物学启发的学习产生了抵触。 这种深度学习的神经科学（生物学）视角主要受到以下两点的启发： 大脑具有智慧，所以创造人工智能的直接方法就是对大脑进行逆向工程 这些学习模型除了能够解决工程问题外，还能为理解大脑提供一些帮助 这些想法目前仍有意义，但深度学习已经超越了这一视角，而是采用学习多层次组合这一原理。目前神经科学仍是深度学习研究者灵感的重要来源，但已经不再是这个领域重要的部分了。主要问题是我们目前没有足够的关于大脑的知识。 神经科学已经通过实验表明，哺乳动物的大脑可以使用单一算法解决很多不同任务，这说明了单一深度学习算法能够解决不同任务的理由；但我们对生物的实际学习算法还没有什么了解。现在大部分神经网络的基础是整流线性单元（rectified linear unit），这一单元受到了实际神经元的启发，但和实际神经元的功能并不完全相同。 以及，深度学习的目标不是理解大脑如何在算法层面上工作，那是计算神经科学。 联结主义，认知科学 联结主义来自认知科学，它的基本思想是，把很多简单的计算单元连接在一起，就可以获得智能。这场运动为今天的深度学习留下了很多关键概念： 分布式表示（distributed representation）：系统的每一个输入都应该由多个特征表示，且每个特征都应该和多个输入的表示相关。（见15章） 反向传播算法（back-propagation algorithm） 长短期记忆（long short-term memory，LSTM）网络 到1990年代中期，神经网络的进展放缓，而核方法和图模型开始有较好的结果，这使得神经网络的受欢迎程度降低了。 “深度学习” 在2006年，研究发现，贪婪逐层预训练（greedy layer-wise pretraining）方法可以用于有效地训练各种神经网络，并能够系统地帮助提高在测试样例上的泛化能力。“深度学习”这一术语强调，研究者现在可以训练比以往深得多的神经网络了，并说明了“深度”的理论意义。 1.2.2 越来越大的数据量 调整一个深度学习算法，使它获得良好的性能是需要一些技巧的。但是，当训练数据增加，训练所需的技巧就减少了。在大数据时代，机器学习变得简单多了。 在2016年，一个粗略的经验法则是，一个监督深度学习算法在每类数据有5000个标注样本时可以达到较好的表现，在数据集总的大小至少为1000万时可以达到或超过人类的表现。 1.2.3 越来越大的模型 联结主义认为，当很多神经元一起工作的时候，动物会变得聪明。事实上，生物神经元的连接并不是非常稠密；我们的机器学习模型每个神经元的连接数量已经和哺乳动物大脑在同一个数量级上了。但神经网络的总神经元数量仍然很小，目前比青蛙的神经系统还要更简单。 1.2.4 越来越高的准确度、复杂性和对现实的影响 深度学习在对象识别、语音识别、行人检测和图像分割等领域都取得了较大的成功。神经网络可以解决的问题的复杂性也提高了，比如机器翻译。 深度学习还在强化学习中进行了拓展。强化学习（reinforcement learning）：一个自主的智能体在没有人类操作员的指导下，自己通过试错来学习执行一项任务。 深度学习已被用于许多顶级技术公司；它所使用的软件也在不断发展。 深度学习也为其他学科提供了帮助。神经科学家可以从对象识别的卷积神经网络中学习到一个图像处理的模型。而且深度学习可以帮助别的学科处理大量数据，并给出有用的预测。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://zhanghuimeng.github.io/tags/Deep-Learning/"}]},{"title":"Leetcode 911. Online Election（BST）","slug":"2018-09-23-Leetcode-911-Online-Election（BST）","date":"2018-09-23T15:47:44.000Z","updated":"2018-09-23T16:46:44.000Z","comments":true,"path":"post/leetcode-911-online-election/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-911-online-election/","excerpt":"","text":"题目来源：https://leetcode.com/problems/online-election/description/ 标记难度：Medium 提交次数：2/4 代码效率： 使用BST进行离线计算：248ms 线性扫描：384ms 二维链表：396ms 题意 给定N个时间点，在times[i]时刻，就有一个人投票给person[i]。对于若干个时刻t，请给出t时刻领先的人。 分析 这道题的设计好像不是很适合在线方法，所以我觉得离线还是比较合适的。 BST+二分查找 我比赛的时候用了一种相当之麻烦的方法——仍然是用优先队列的思想，在TreeSet中存储(person, votes, recency)的元组，然后在每个有人投票的时间点，更新TreeSet，并找出当前领先的人，保存下来；之后在查询的时候进行二分查找。这种方法的复杂度大约是O(N * log(N) + M * log(N))（假定M是查询的总次数）。 线性扫描+二分查找 事实上找出各个时刻领先的人并不需要这么麻烦。事实上persons和times数组都是已经排好序的了。因此，可以用一个map来维护每个人的票数，然后在每个时刻更新被投票的人的票数，并判断当前领先的人是否会变成这个人。如果不变的话，完全可以忽略这个时间点。这种方法的复杂度大约是O(N + M * log(N))。[1] 二维链表 我感觉这是一种特别神奇的做法……简单来说，我觉得可以维护一个vector&lt;vector&lt;pair&lt;int, int&gt;&gt;，其中外层vector的含义是，所有投的是某人的第i票的选票；内层vector按时间顺序存储了每张选票的(person, time)。用题目中的例子来描述一下： 12345678910111213[0,1,1,0,0,1,0],[0,5,10,15,20,25,30]+------+ +---+ +---+ +---+ +---+| Head |----| 1 |------| 2 |------| 3 |------| 4 | count+------+ +-+-+ +-+-+ +-+-+ +---+ | | | | +-+-+ -+-+-+- -+-+-+- -+-+-+- | |0,0| |1, 10| |0, 20| |0, 30| | +-+-+ -+-+-+- -+-+-+- -+-+-+- | Most recent | | | | +-+-+ -+-+-+- -+-+-+- | |1,5| |0, 15| |1, 25| | +-+-+ -+-+-+- -+-+-+- v 然后很显然，每个外层vector的第一个元素都是递增的，每个内层vector自己也是递增的。对于每个时间点，我们可以首先对外层vector进行二分查找，然后再在内层进行二分查找。整体复杂度是O(N + M * log(N)^2)。[2] 以及，我觉得这种做法有些像Leetcode 460中给出的HashMap+List方法。 代码 BST 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class TopVotedCandidate &#123;private: vector&lt;pair&lt;int, int&gt;&gt; timesOfVote; // time, vote vector&lt;int&gt; times; vector&lt;int&gt; leaders; int N; struct VotedPerson &#123; int person; int recency; int votes; VotedPerson(int p, int r, int v) &#123; person = p; recency = r; votes = v; &#125; friend bool operator &lt; (const VotedPerson&amp; p1, const VotedPerson&amp; p2) &#123; if (p1.votes != p2.votes) return p1.votes &gt; p2.votes; return p1.recency &gt; p2.recency; &#125; friend bool operator == (const VotedPerson&amp; p1, const VotedPerson&amp; p2) &#123; return p1.person == p2.person &amp;&amp; p1.recency == p2.recency &amp;&amp; p1.votes == p2.votes; &#125; &#125;;public: TopVotedCandidate(vector&lt;int&gt; persons, vector&lt;int&gt; times) &#123; N = persons.size(); for (int i = 0; i &lt; N; i++) &#123; timesOfVote.emplace_back(times[i], persons[i]); &#125; sort(timesOfVote.begin(), timesOfVote.end()); unordered_map&lt;int, int&gt; recMap; // person to recency unordered_map&lt;int, int&gt; voteMap; // person to vote set&lt;VotedPerson&gt; treeSet; for (int i = 0; i &lt; N; i++) &#123; int person = timesOfVote[i].second; int time = timesOfVote[i].first; int recency = recMap[person]; int votes = voteMap[person]; auto it = treeSet.find(VotedPerson(person, recency, votes)); if (it != treeSet.end()) treeSet.erase(it); recMap[person] = recency = i; voteMap[person]++; votes++; treeSet.insert(VotedPerson(person, recency, votes)); this-&gt;times.push_back(time); this-&gt;leaders.push_back(treeSet.begin()-&gt;person); &#125; &#125; int q(int t) &#123; auto it = upper_bound(times.begin(), times.end(), t); it--; return leaders[it - times.begin()]; &#125;&#125;; 线性扫描 12345678910111213141516171819202122232425class TopVotedCandidate &#123;private: vector&lt;int&gt; leader; vector&lt;int&gt; ctimes;public: TopVotedCandidate(vector&lt;int&gt; persons, vector&lt;int&gt; times) &#123; unordered_map&lt;int, int&gt; voteMap; int curLeader = -1, curLeadVotes = -1; for (int i = 0; i &lt; persons.size(); i++) &#123; voteMap[persons[i]]++; if (voteMap[persons[i]] &gt;= curLeadVotes) &#123; curLeadVotes = voteMap[persons[i]]; curLeader = persons[i]; leader.push_back(curLeader); ctimes.push_back(times[i]); &#125; &#125; &#125; int q(int t) &#123; auto it = upper_bound(ctimes.begin(), ctimes.end(), t); return leader[it - ctimes.begin() - 1]; &#125;&#125;; 二维链表 12345678910111213141516171819202122232425262728293031323334353637383940class TopVotedCandidate &#123;private: vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; bucket; // (time, person)public: TopVotedCandidate(vector&lt;int&gt; persons, vector&lt;int&gt; times) &#123; unordered_map&lt;int, int&gt; voteMap; for (int i = 0; i &lt; persons.size(); i++) &#123; voteMap[persons[i]]++; int c = voteMap[persons[i]]; while (bucket.size() &lt; c) bucket.push_back(vector&lt;pair&lt;int, int&gt;&gt;()); bucket[c-1].emplace_back(times[i], persons[i]); &#125; &#125; int q(int t) &#123; int l = 0, r = bucket.size(); // upper_bound, then -1 while (l &lt; r) &#123; int mid = l + (r - l) / 2; if (bucket[mid][0].first &lt;= t) l = mid + 1; else r = mid; &#125; int i = l - 1; l = 0, r = bucket[i].size(); while (l &lt; r) &#123; int mid = l + (r - l) / 2; if (bucket[i][mid].first &lt;= t) l = mid + 1; else r = mid; &#125; int j = l - 1; if (j &lt; 0) j = 0; return bucket[i][j].second; &#125;&#125;; [C++/Java/Python] Binary Search in Times ↩︎ 911. Online Election, Approach 2: Precomputed Answer + Binary Search ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 910. Smallest Range II（数学）","slug":"2018-09-23-Leetcode-910-Smallest-Range-II（数学）","date":"2018-09-23T14:58:14.000Z","updated":"2018-09-23T15:23:00.000Z","comments":true,"path":"post/leetcode-910-smallest-range-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-910-smallest-range-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/smallest-range-ii/description/ 标记难度：Medium 提交次数：1/1 代码效率：36ms 题意 给定整数数组A，对于每个A[i]，令B[i] = A[i] + K or - K。问数组B中最大值和最小值之差的最小可能值。 分析 在比赛的时候我居然完全没有想到可以把A先排序这回事…… 不妨先把所有元素排序并减去K。这样，原问题就转化为，需要选出一部分元素加上2*K，另一部分元素不变。显然，为了缩小最大值和最小值的差值，应该选择较小的元素加上2*K。 可以证明，需要加上2*K的元素是数组中从左侧（最小的元素）开始的连续元素。这一点可以这样说明： 假如最优解中有至少一个元素增加了2*K（B[i] = A[i] + 2*K），且它的左侧有一个不变的元素（B[j] = A[j]），那么由于A[j] &lt; A[i]，令B[j] = A[j] + 2*K不会使B数组的最大值变化，但却有可能使B数组的最小值增大，情况不会变的更糟； 假如最优解中有至少一个元素不变（B[i] = A[i]），且它的右侧有一个增加了2*K的元素（B[j] = A[j] + 2*K），那么由于A[j] &gt; A[i]，令B[j] = A[j]不会使B数组的最小值变化，但却有可能使B数组的最大值减小，情况也不会变的更糟 综上，总存在一个只有从左侧开始的连续元素才加了2*K的最优解。我觉得这个证明的思路很像贪心；这大概也可以算是一种贪心算法？[1] 所以我们可以把元素扫描一遍，对于每个元素，计算“当它是增加的最末一个元素”时的差值，并在这些差值里求最小值。对于A[i]，这个差值为max(A[N-1], A[i] + 2*K) - min(A[i+1], A[0] + 2*K)。 代码 123456789101112class Solution &#123;public: int smallestRangeII(vector&lt;int&gt;&amp; A, int K) &#123; sort(A.begin(), A.end()); int N = A.size(); int res = A[N-1] - A[0]; for (int i = 0; i &lt; N - 1; i++) &#123; res = min(res, max(A[N-1], A[i] + 2*K) - min(A[i+1], A[0] + 2*K)); &#125; return res; &#125;&#125;; Nice proof by veihbisd ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 909. Snakes and Ladders（BFS）","slug":"2018-09-23-Leetcode-909-Snakes-and-Ladders（BFS）","date":"2018-09-23T14:10:33.000Z","updated":"2018-09-23T14:10:33.000Z","comments":true,"path":"post/leetcode-909-snakes-and-ladders/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-909-snakes-and-ladders/","excerpt":"","text":"题目来源：https://leetcode.com/problems/snakes-and-ladders/description/ 标记难度：Medium 提交次数：2/3 代码效率： 比赛时的BFS：32ms 优化过的BFS：16ms 题意 一个变种的BFS题。简单来说，就是可以以某种方式在棋盘上向前走1~6个格子；如果走到的格子中的值不是-1，则可以跳到该值对应的格子。 分析 数据量很小，所以不论怎么处理坐标问题都能做。但是在这个问题中，visited数组就不能那么简单地定义了。走到一个格子之后继续尝试向前走，和中途跳过这个格子显然是不一样的。所以我定义了两种visited数组，分别处理两种情况。不过题解里好像就没有管中途跳过这种情况了，只记录了实际走过的格子。 我中间因为没有处理好visited数组的问题MLE了一次，说明必须要处理这个问题，否则会出现循环跳的情况。 仔细想了一下，我觉得处理中途跳过的情形的数组确实没什么用，因为下一个要跳到的格子是确定的。以及实时计算格子对应的坐标其实也是比较简单的，不过我更喜欢不想那么多，直接全部存起来……[1] 代码 比赛时的BFS 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Solution &#123; struct Pair &#123; int x, y; // 事实上没什么必要 int boardNum; int steps; Pair(int num, int x1, int y1, int s) &#123; boardNum = num; x = x1; y = y1; steps = s; &#125; &#125;;public: int snakesAndLadders(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; int N = board.size(); map&lt;int, pair&lt;int, int&gt;&gt; numToCoordMap; map&lt;pair&lt;int, int&gt;, int&gt; coordToNumMap; bool startFrom = true; int cnt = 1; for (int i = N - 1; i &gt;= 0; i--) &#123; if (startFrom) &#123; for (int j = 0; j &lt; N; j++) &#123; numToCoordMap[cnt] = make_pair(i, j); coordToNumMap[make_pair(i, j)] = cnt; cnt++; &#125; &#125; else for (int j = N - 1; j &gt;= 0; j--) &#123; numToCoordMap[cnt] = make_pair(i, j); coordToNumMap[make_pair(i, j)] = cnt; cnt++; &#125; startFrom = !startFrom; &#125; queue&lt;Pair&gt; q; bool visited[N*N + 1], jumped[N*N + 1]; memset(visited, 0, sizeof(visited)); memset(jumped, 0, sizeof(jumped)); q.emplace(1, N-1, 0, 0); visited[1] = true; while (!q.empty()) &#123; Pair p = q.front(); q.pop(); if (p.boardNum == N * N) return p.steps; for (int i = 1; i &lt;= 6; i++) &#123; if (p.boardNum + i &gt; N * N) break; // jumped[x]: this point has been jumped through // visited[x]: this point has been x+1...x+6 int next = p.boardNum + i; if (jumped[next]) continue; pair&lt;int, int&gt; nc = numToCoordMap[next]; if (board[nc.first][nc.second] != -1) &#123; jumped[next] = true; next = board[nc.first][nc.second]; if (visited[next]) continue; nc = numToCoordMap[next]; visited[next] = true; &#125; else jumped[next] = true; q.emplace(next, nc.first, nc.second, p.steps + 1); &#125; &#125; return -1; &#125;&#125;; 优化过的BFS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class Solution &#123; struct Pair &#123; int x, y; int boardNum; int steps; Pair(int num, int x1, int y1, int s) &#123; boardNum = num; x = x1; y = y1; steps = s; &#125; &#125;;public: int snakesAndLadders(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; int N = board.size(); // 分别存储number-&gt;坐标和坐标-&gt;number的映射 // 虽然可以即时计算，但我觉得这样比较直观好写…… vector&lt;pair&lt;int, int&gt;&gt; numberToCord; vector&lt;vector&lt;int&gt;&gt; cordToNumber(N, vector&lt;int&gt;(N, 0)); bool startFrom = true; numberToCord.emplace_back(-1, -1); // board number starts from 1 int cnt = 1; for (int i = N - 1; i &gt;= 0; i--) &#123; if (startFrom) for (int j = 0; j &lt; N; j++) &#123; numberToCord.emplace_back(i, j); cordToNumber[i][j] = cnt++; &#125; else for (int j = N - 1; j &gt;= 0; j--) &#123; numberToCord.emplace_back(i, j); cordToNumber[i][j] = cnt++; &#125; startFrom = !startFrom; &#125; // number和坐标表示存储一种即可 queue&lt;pair&lt;int, int&gt;&gt; q; // (boardNum, steps) bool visited[N*N + 1], jumped[N*N + 1]; memset(visited, 0, sizeof(visited)); memset(jumped, 0, sizeof(jumped)); q.emplace(1, 0); visited[1] = true; while (!q.empty()) &#123; pair&lt;int, int&gt; p = q.front(); q.pop(); int curNum = p.first, curStep = p.second; if (curNum == N * N) return curStep; for (int i = 1; i &lt;= 6 &amp;&amp; curNum + i &lt;= N*N; i++) &#123; // jumped[x]: this point has been jumped through // visited[x]: this point has been x+1...x+6 int nextNum = curNum + i; // 事实上jumped没什么用。即使不维护这个访问数组，从当前nextNum // 所能跳到的格子是确定的，所以下一步就可以确定是否已经访问过那个格子了。 if (jumped[nextNum]) continue; int nx = numberToCord[nextNum].first, ny = numberToCord[nextNum].second; if (board[nx][ny] != -1) &#123; jumped[nextNum] = true; nextNum = board[nx][ny]; if (visited[nextNum]) continue; visited[nextNum] = true; &#125; else jumped[nextNum] = true; q.emplace(nextNum, curStep + 1); &#125; &#125; return -1; &#125;&#125;; Leetcode 909 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 908. Smallest Range I，及周赛（103）总结","slug":"2018-09-23-Leetcode-908-Smallest-Range-I，及周赛（103）总结","date":"2018-09-23T13:48:27.000Z","updated":"2018-09-23T14:03:00.000Z","comments":true,"path":"post/leetcode-908-smallest-range-i-and-weekly-contest-103/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-908-smallest-range-i-and-weekly-contest-103/","excerpt":"","text":"题目来源：https://leetcode.com/problems/smallest-range-i/description/ 标记难度：Easy 提交次数：2/4 代码效率：24ms 题意 给定整数数组A，对于每个A[i]，可以选择任意-K &lt;= x &lt;= K，令B[i] = A[i] + x。问数组B中最大值和最小值之差的最小可能值。 分析 这次比赛我获得了180 / 4160的名次，是最近一段时间以来最高的一次了。我猜想这是因为这次的题目整体难度非常简单，居然有三道Medium的缘故。而且，很神奇的是，我是先做完第2题，第4题，最后几分钟才做完第1题的，因为我开始时觉得第1题和第3题都特别难……当然事实证明它们还是比较简单的。 思路非常简单：如果max(A) - min(A) &lt;= 2*K，则可以通过上述方式将所有A中的数都变成相等的，如min(A) + (max(A) - min(A)) / 2；而如果max(A) - min(A) &gt; 2*K，则显然差值的最小值是max(A) - min(A) - 2*K。对于数组中的各个值，可以分别进行以下操作： 如果A[i] &lt;= min(A) + K，则B[i] = A[i] + K 如果A[i] &gt;= max(A) - K，则B[i] = A[i] - K 如果min(A) + K &lt; A[i] &lt; max(A) - K，则B[i] = A[i] 此时所有B[i]都位于[min(A) + K, max(A) - K]区间内了。[1] 代码 123456789101112class Solution &#123;public: int smallestRangeI(vector&lt;int&gt;&amp; A, int K) &#123; int maxn = A[0], minn = A[0]; for (int i = 0; i &lt; A.size(); i++) &#123; maxn = max(maxn, A[i]); minn = min(minn, A[i]); &#125; if (maxn - minn &gt; 2 * K) return maxn - minn - 2 * K; else return 0; &#125;&#125;; Leetcode 908 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 903. Valid Permutations for DI Sequence（DP）","slug":"2018-09-23-Leetcode-903-Valid-Permutations-for-DI-Sequence（DP）","date":"2018-09-23T11:41:02.000Z","updated":"2018-09-23T19:19:00.000Z","comments":true,"path":"post/leetcode-903-valid-permutations-for-di-sequence/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-903-valid-permutations-for-di-sequence/","excerpt":"","text":"题目来源：https://leetcode.com/problems/valid-permutations-for-di-sequence/description/ 标记难度：Hard 提交次数：2/3 代码效率： O(N^2) DP：79.78% O(N^3) DP：14.07% 题意 给定n，求所有数字满足一定上升和下降规律的n的排列。 分析 比赛的时候看到这道题，我心里是十分懵逼的，觉得应当用搜索的方法去做，但又感觉复杂度太高，即使剪枝也很离谱。显然，我根本没有怎么接触过这个类型的题。所以比赛之后我仍然很懵逼。 事实上这是一道动态规划题。但是递推的方式并不好想。令dp[i][j]表示长度为i且结尾为j的符合DI序列的排列数量。（在这里，长度为i也就意味着，是从1到i的数字的排列。）下一个问题是如何进行递推。如果我们之前已经得到了一个1~i的排列，如何把j合理地添加进去，使得这个排列变成1~i+1的排列，仍然满足原有的DI序列，且结尾是j？ 这个想法无疑十分巧妙：把比j更大的数都加上1，然后把j附在排列的最后。这样就可以得到一个仍然合法且合理的排列了。[1] 如果DI序列当前的值为D，则dp[i][j] = dp[i-1][j] + ... + dp[i-1][N]；如果当前的值为I，则dp[i][j] = dp[i-1][1] + ... + dp[i-1][j-1]。 如果不进行优化，则这是一个O(N^3)的算法。但是实际上可以非常迅速地用前缀和数组的方法加以改进，这样就变成了一个O(N^2)的算法。[2] 除此之外，还有一种比较好的思考方法：先构思一种自顶向下的回溯法，再把这种方法逐渐转换为DP。不过具体内容我不是很想看了。[3] 最后一个有趣的问题是：是否对于任何DI序列，都存在合法的排列？我觉得可以用和动态规划类似的方法进行推导。令函数f(str)表示DI序列str所对应的所有可能末尾元素的集合。 当str.length = 1时，显然f(&quot;D&quot;) = {1}, f(&quot;I&quot;) = {2}，集合均非空 当str.length = N, N &gt;= 2时，对于某一str，由归纳假设，有f(str[0:-1])非空。 当str[-1] = 'I'时，从f(str[0:-1])中任取元素，直接将N附在该元素对应的排列后，即可构造出新的合法排列 当str[-1] = 'D'时，从f(str[0:-1])中任取元素，记该元素为j，将对应排列中&gt;= j的元素均增加1，并把j附在排列最后，即可构造出新的合法排列 所以对于任意长度的任意DI序列，f(str)都不为空，得证。 代码 O(N^3) DP 1234567891011121314151617181920212223242526class Solution &#123;public: int numPermsDISequence(string S) &#123; int N = S.length() + 1; long long MOD = 1000000007; long long int dp[N+1][N+1]; // length i, ends with j memset(dp, 0, sizeof(dp)); dp[1][1] = 1; long long int ans = 0; for (int i = 2; i &lt;= N; i++) &#123; for (int j = 1; j &lt;= i; j++) &#123; if (S[i-2] == 'D') &#123; for (int k = j; k &lt;= N; k++) dp[i][j] = (dp[i][j] + dp[i-1][k]) % MOD; &#125; else &#123; for (int k = 1; k &lt; j; k++) dp[i][j] = (dp[i][j] + dp[i-1][k]) % MOD; &#125; if (i == N) ans = (ans + dp[i][j]) % MOD; &#125; &#125; return ans; &#125;&#125;; O(N^2) DP 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int numPermsDISequence(string S) &#123; int N = S.length() + 1; long long MOD = 1000000007; long long int dp[N+1][N+1]; // length i, ends with j long long int g[N+1][N+1]; memset(dp, 0, sizeof(dp)); memset(g, 0, sizeof(g)); dp[1][1] = 1; for (int i = 1; i &lt;= N; i++) g[1][i] = g[1][i-1] + dp[1][i]; long long int ans = 0; for (int i = 2; i &lt;= N; i++) &#123; for (int j = 1; j &lt;= i; j++) &#123; if (S[i-2] == 'D') &#123; // [j, N] dp[i][j] = (g[i-1][N] - g[i-1][j-1] + MOD) % MOD; // beware of mod subtraction... &#125; else &#123; // [1, j-1] dp[i][j] = g[i-1][j-1] % MOD; &#125; if (i == N) ans = (ans + dp[i][j]) % MOD; &#125; for (int j = 1; j &lt;= N; j++) g[i][j] = (g[i][j-1] + dp[i][j]) % MOD; &#125; return ans; &#125;&#125;; [Visualization] Key to the DP solution: imagine cutting a piece of paper and separating the halves ↩︎ Share my O(N^3) =&gt; O(N^2) C++ DP solution. Including the thoughts of improvement. ↩︎ Top-down with Memo -&gt; Bottom-up DP -&gt; N^3 DP -&gt; N^2 DP -&gt; O(N) space ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 404. Sum of Left Leaves（树）","slug":"2018-09-23-Leetcode-404-Sum-of-Left-Leaves（树）","date":"2018-09-23T11:32:32.000Z","updated":"2018-09-23T11:38:00.000Z","comments":true,"path":"post/leetcode-404-sum-of-left-leaves/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-404-sum-of-left-leaves/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sum-of-left-leaves/description/ 标记难度：Easy 提交次数：1/1 代码效率：1.40% 题意 给定一棵二叉树，计算树中所有左侧叶结点的值之和。 分析 水题…… 当然，仍然至少有三种策略：递归DFS，用栈模拟DFS，以及BFS。我在代码中明确给出了left和right的标记，用来识别当前结点是父结点的左子结点还是右子结点；当然，这并不是必要的。[1] 代码 123456789101112131415class Solution &#123; int dfs(TreeNode* root, bool isLeft) &#123; if (root == nullptr) return 0; if (root-&gt;left == nullptr &amp;&amp; root-&gt;right == nullptr) &#123; if (isLeft) return root-&gt;val; return 0; &#125; return dfs(root-&gt;left, true) + dfs(root-&gt;right, false); &#125;public: int sumOfLeftLeaves(TreeNode* root) &#123; return dfs(root, false); &#125;&#125;; Java iterative and recursive solutions ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"}]},{"title":"机器学习速成课程（1）：构建一个简单的线性模型","slug":"2018-09-21-机器学习速成课程（1）：构建一个简单的线性模型","date":"2018-09-21T19:19:02.000Z","updated":"2018-09-22T17:01:00.000Z","comments":true,"path":"post/machine-learning-crash-course-1-construct-a-simple-linear-model/","link":"","permalink":"https://zhanghuimeng.github.io/post/machine-learning-crash-course-1-construct-a-simple-linear-model/","excerpt":"","text":"课：机器学习速成课程 课程内容 基本概念 首先介绍了监督式机器学习的概念并给出了一些定义。 标签：我们要预测的事物（简单线性回归中的y变量） 特征：表示数据的方式，用于描述数据的输入变量。 样本：数据的特定实例，分为有标签和无标签两类。 创建模型即从数据中学习规律的过程。 模型生命周期的两个阶段： 训练：创建模型，让模型逐渐学习特征与标签之间的关系 推断：将训练后的模型应用于无标签样本 模型的一种分类方法： 回归模型：预测连续值 分类模型：预测离散值 然后介绍了关于线性回归模型（和通用模型）的一些基本概念。线性回归模型用一条直线对样本的标签进行推断，即 y=wx+by = wx + b y=wx+b 损失：对单个样本而言模型预测的准确程度。 给定样本的L2L_2L2​损失（平方误差）：(观察值−预测值)2(\\text{观察值} - \\text{预测值})^2(观察值−预测值)2 数据集上的L2L_2L2​损失：L2loss=∑(x,y)∈D(y−prediction(x))2L_2 loss = \\sum_{(x, y) \\in D} (y - prediction(x))^2L2​loss=∑(x,y)∈D​(y−prediction(x))2 均方误差（MSE，Mean Squared Error）：每个样本的平均平方损失 在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。 减少损失 下一个问题就是如何选择合适的模型参数以减小误差。 常用的方法是，通过计算梯度获得与模型参数相关的误差函数的导数，并沿着梯度指出的方向前进。这可以视为一种迭代法。 迭代法有几个需要考虑的问题。一个问题是沿着这一方向需要前进多少，这被称为学习速率（learning rate）。这是一个超参数。我们需要找到一个合适的学习速率，使得梯度下降过程高效收敛，但又不会高到使该过程永远无法收敛。 另一个问题是起始的位置。对于凸形问题，任意起始位置都是可取的；但很多问题（如神经网络）并不是凸形问题。它们有很多可能的极小值，其中一些比其他更优。 最后一个问题是如何计算梯度。为了得到正确的梯度方向，需要对数据集中所有样本的梯度进行计算。但是一般来说样本量太大，这样计算复杂度太高。所以可以转而计算小型样本的梯度，有两种方法： 随机梯度下降法（SGD，Stochastic Gradient Descent）：每次只抽取一个样本计算梯度。这一方法最终会收敛，但可能速度太慢，且过程比较杂乱 小批量梯度下降法（small batch SGD）：每批包含10-1000个样本，可以减少杂乱的过程 训练模型是一个迭代的过程：将特征输入当前的模型，返回一个预测作为输出，计算输出的损失，生成新的参数值。当总体损失不再变化或变化极其缓慢时，我们称模型收敛。 梯度是偏导数的矢量，具有两个特征：方向和大小。梯度指向函数增长速度最快的方向，负梯度指向函数下降速度最快的方向。 梯度下降法用梯度乘以一个称为学习速率（步长）的标量，以确定下一个点的位置。如果学习速率过小，则会花费过长的学习时间；否则可能无法收敛。合适的学习速率取决于损失函数的平坦程度。 理想的学习速率： 一维空间：理想学习速率是1/f(x)′′1 / f(x)&#x27;&#x27;1/f(x)′′ 二维或多维空间：理想学习速率是1 / Hessian矩阵 广义凸函数：很难确定 编码练习：使用LinearRegressor构建模型 我参照first_steps_with_tensor_flow.ipynb中的内容在本地写了一遍并运行了一下。 我大概从这一过程中学到了： PyCharm的安装和使用，以及venv虚拟环境的使用 用Estimator API构建和训练模型的基本步骤： 定义optimizer和feature_columns 定义数据输入函数 用数据输入函数对模型进行若干步训练 用预测数据输入函数对模型进行测试 pandas.Dataframe的基本使用方法和它与numpy如何联合使用 用describe、直方图等方法观察数据的分布，寻找离群值 用matplotlib.pyplot对数据特征和训练过程中的RMSE变化进行可视化表示 下一个问题是如何调整超参数。简单来说，不同超参数的效果取决于数据。因此没有必须遵循的规则，需要对自己的数据进行测试。不过，仍然有一些经验法则： 训练误差应该稳步减小；开始时急剧减小，最终应随着训练收敛达到平稳状态。 如果训练没有收敛，尝试运行更长的时间。 如果训练误差减小速度过慢，则提高学习速率可能有助于加快其减小速度。 但有时如果学习速率过高，训练误差的减小速度反而会变慢。 如果训练误差变化很大，尝试降低学习速率。 较低的学习速率和较大的步数/较大的批量大小通常是不错的组合 批量大小过小也会导致不稳定情况。不妨先尝试100或1000等较大的值，然后逐渐减小值的大小，直到出现性能降低的情况。 以及在代码中： steps：指训练迭代的总次数。一步计算一批样本产生的损失，然后使用该值修改模型的权重一次。 batch size：是指单步的样本数量（随机选择）。例如，SGD的批量大小为1。 总被训练样本数 = batch size * steps periods：控制报告的粒度。例如，如果periods设为7且steps设为70，则练习将每10步（共输出7次）输出一次损失值。 每period被训练的样本数 = batch size * steps / periods 我随便调了几组参数。我觉得目前这不是重点，所以就不写了。 完整代码见learnTensorFlow/first_linear_regression/first_steps.py。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://zhanghuimeng.github.io/tags/Machine-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://zhanghuimeng.github.io/tags/TensorFlow/"}]},{"title":"读书笔记：《深入理解TensorFlow》第1章：TensorFlow系统概述","slug":"2018-09-18-读书笔记：《深入理解TensorFlow》第1章：TensorFlow系统概述","date":"2018-09-18T01:01:45.000Z","updated":"2018-09-18T01:23:00.000Z","comments":true,"path":"post/reading-report-tensorflow-in-depth-ch-1-tensorflow-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/reading-report-tensorflow-in-depth-ch-1-tensorflow-summary/","excerpt":"","text":"书：深入理解TensorFlow架构设计与实现原理 本章对TensorFlow进行了一些非常基本的介绍，主要包括以下内容： TensorFlow的发展过程和优缺点 TensorFlow的设计目标和独特性 TensorFlow的基本架构 由于我现在对TensorFlow其实还没有太多的了解，前两部分我只是粗略地看了一下。 TensorFlow的发展过程和优缺点 TensorFlow是Google出的。其他发展过程略。 TensorFlow的优点： • 线性代数编译器XLA；可针对不同软硬件环境优化配置 • 框架设计通用：提供高层封装API和底层元素API • 支持生产环境部署 • 语言接口丰富：核心层是C++，应用层使用SWIG等技术封装 • 端云协同计算 以及丰富的算子库和教学资料。 TensorFlow的缺点： API太丰富，太灵活，学习成本过高。 需要进行一些特殊配置才能使TensorFlow达到最高性能。 TensorFlow的设计目标和独特性 TensorFlow的设计目标：面向多种应用场景和编程范式、支持异构计算平台、具备优异性能与可伸缩性的通用人工智能引擎。 TensorFlow的独特性： 灵活性 端云协同计算 高性能的基础平台软件 （上述内容我看不太懂，因为没有什么了解。） TensorFlow的基本架构 一般来说，平台设计模式有两种主要形态： 库模式：平台层软件以静态或动态开发库形式存在，应用层开发者需要编写程序调用这些软件；程序入口和整体流程控制权把握在开发者手中 框架模式：平台层软件以可执行文件的形式存在，并以前端交互式程序或后端守护进程方式独立运行。应用层开发者需要遵守接口约束，开发子程序。程序入口和整体流程控制权由框架把握。 TensorFlow采用的是库模式。 上图中的“TensorFlow运行时核心库”就是平时所说的TensorFlow库。这个库是C++编写的，主要分为以下三个层次： 公共运行时：实现了数据流图计算的基本逻辑 分布式运行时：实现了数据流图的跨进程协同计算逻辑 算子核函数：包含图上具体操作结点的算法实现代码 在运行时核心库之上是API层，它对用户屏蔽了核心库的动态链接逻辑。 运行时核心库的底层依赖包括计算库和通信库，其中有些是外部组件（如Eigen），有些是内部集成（如StreamExecutor）。","categories":[],"tags":[{"name":"Reading Report","slug":"Reading-Report","permalink":"https://zhanghuimeng.github.io/tags/Reading-Report/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://zhanghuimeng.github.io/tags/TensorFlow/"}]},{"title":"Leetcode 906. Super Palindromes（数学）","slug":"2018-09-16-Leetcode-906-Super-Palindromes（数学）","date":"2018-09-16T21:42:38.000Z","updated":"2018-09-19T18:11:00.000Z","comments":true,"path":"post/leetcode-906-super-palindromes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-906-super-palindromes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/super-palindromes/description/ 标记难度：Hard 提交次数：1/1 代码效率： 穷举法：552ms 构造法：4ms（82.91%） 题意 统计[L, R]区间内“超级回文数”的个数。“超级回文数”的定义是，它是一个回文数，且也是一个回文数的平方。保证L &lt;= R &lt;= 10^18。 分析 穷举法 显然，一个事实是，我们可以通过穷举[1, 10^9]内的回文数并判断其平方是否为回文数，来穷举[1, 10^18]内的超级回文数。而且，通过回文数的特性，我们可以通过穷举[1, 10^4.5]内的数并把它反过来拼成一个回文数（当然有两种拼法）来穷举[1, 10^9]内的回文数。所以我们得到了一个O(U^0.25) (U = upper limit)的算法。[1] 构造法 很快就可以发现，超级回文数是相当稀疏的，在[1, 10^18]的范围内，总共只有70个。（OEIS A002779中收录了平方回文数的数列，但似乎还并没有“超级回文数”。）所以这就导向了一种采用构造法的可能性，可以大大降低时间复杂度。 123456789101112131, 4, 9, 121, 484, 10201, 12321, 14641, 40804, 44944, 1002001, 1234321, 4008004,100020001, 102030201, 104060401, 121242121, 123454321, 125686521, 400080004,404090404, 10000200001, 10221412201, 12102420121, 12345654321, 40000800004,1000002000001, 1002003002001, 1004006004001, 1020304030201, 1022325232201,1024348434201, 1210024200121, 1212225222121, 1214428244121, 1232346432321,1234567654321, 4000008000004, 4004009004004, 100000020000001, 100220141022001,102012040210201, 102234363432201, 121000242000121, 121242363242121, 123212464212321,123456787654321, 400000080000004, 10000000200000001, 10002000300020001,10004000600040001, 10020210401202001, 10022212521222001, 10024214841242001,10201020402010201, 10203040504030201, 10205060806050201, 10221432623412201,10223454745432201, 12100002420000121, 12102202520220121, 12104402820440121,12122232623222121, 12124434743442121, 12321024642012321, 12323244744232321,12343456865434321, 12345678987654321, 40000000800000004, 40004000900040004 从上面的列表中可以发现，所有超级回文数的长度都是奇数。这并不是巧合。证明如下：假设A = a^2，且A和a都是回文数。显然，只有在a * a时首位发生进位的情况下，A的长度才有可能变成偶数。为了使首位发生进位，需要a的首位&gt;= 3。 假定a = a[n-1] a[n-2] a[n-3] ... a[0]，则a * a的竖式可以表示为： 123456 a[n-1] a[n-2] a[n-3] ... a[n-1] a[n-2] a[n-3] ... ×-------------------------------------------------- a[n-1]*a[n-2] a[n-2]*a[n-3] ... a[n-1]*a[n-1] a[n-1]*a[n-2] ... 当a[n-1] = 2时，即使[n-2] = 9，2*a[n-1]*a[n-2]加上进位最大只可能为45，计算出的第一位最大为8，不会发生进位。所以要求a[n-1] &gt;= 3。 下面可以根据a[n-1]分类讨论： 当a[n-1] = 3时，A的前两位必在10和15之间；但由于a是回文数，因此a的末位也为3，此时A的末位必为9，所以A不是回文数 当a[n-1] = 4时，A的前两位必在16和24之间；但由于a是回文数，因此a的末位也为4，此时A的末位必为6，所以A不是回文数 当a[n-1] = 5时，A的前两位必在25和35之间；但由于a是回文数，因此a的末位也为5，此时A的末位必为5，所以A不是回文数 当a[n-1] = 6时，A的前两位必在36和48之间；但由于a是回文数，因此a的末位也为6，此时A的末位必为6，所以A不是回文数 当a[n-1] = 7时，A的前两位必在49和63之间；但由于a是回文数，因此a的末位也为7，此时A的末位必为9，所以A不是回文数 当a[n-1] = 8时，A的前两位必在64和80之间；但由于a是回文数，因此a的末位也为8，此时A的末位必为4，所以A不是回文数 当a[n-1] = 9时，A的前两位必在81和99之间；但由于a是回文数，因此a的末位也为9，此时A的末位必为1，所以A不是回文数 假定a的长度为n，则A的长度必为2*n - 1。此时，由于a * a的首位（即使加上进位也）不会进位，说明a * a的末位也必然不会进位（因为a是回文数）；所以A的倒数第二位没有被进位；又由于A是回文数，所以A的正数第二位也没有被进位。以此类推，可以用数学归纳法证明，回文数a * a能产生超级回文数，当且仅当a * a的过程中没有发生过任何进位。[2] 此时，我们可以开始尝试枚举&lt;= 10^9且不会发生进位的所有回文数。由于要求每一位都不能进位，显然回文数的数字只能包括{0, 1, 2, 3}。所以我们仍然可以采取类似于之前的枚举的方法：枚举回文数的一半（最大5位），然后扩展出回文数的下一半。而且，在这一情况下，我们可以尝试直接推导乘法应有的计算结果。 对于扩展出奇数长度的回文数的情形： 1234567891011121314n = 9,a = a[8] a[7] a[6] a[5] a[4] a[3] a[2] a[1] a[0] = a[0] a[1] a[2] a[3] a[4] a[3] a[2] a[1] a[0]A[0] = a[0]^2A[1] = 2*a[0]*a[1]A[2] = 2*a[0]*a[2] + a[1]^2A[3] = 2*a[0]*a[3] + 2*a[1]*a[2]A[4] = 2*a[0]*a[4] + 2*a[1]*a[3] + a[2]^2A[5] = 2*a[0]*a[3] + 2*a[1]*a[4] + 2*a[2]*a[3]A[6] = 2*a[0]*a[2] + 2*a[1]*a[4] + 2*a[2]*a[4] + a[3]^2A[7] = 2*a[0]*a[1] + 2*a[1]*a[3] + 2*a[2]*a[3] + 2*a[3]*a[4]A[8] = 2*a[0]^2 + 2*a[1]^2 + 2*a[2]^2 + 2*a[3]^2 + a[4]^2... 显然A[8]是其中最大的数位。 对于扩展出偶数长度的回文数的情形： 123456789101112131415n = 10,a = a[9] a[8] a[7] a[6] a[5] a[4] a[3] a[2] a[1] a[0] = a[0] a[1] a[2] a[3] a[4] a[4] a[3] a[2] a[1] a[0]A[0] = a[0]^2A[1] = 2*a[0]*a[1]A[2] = 2*a[0]*a[2] + a[1]^2A[3] = 2*a[0]*a[3] + 2*a[1]*a[2]A[4] = 2*a[0]*a[4] + 2*a[1]*a[3] + a[2]^2A[5] = 2*a[0]*a[5] + 2*a[1]*a[4] + 2*a[2]*a[3]A[6] = 2*a[0]*a[3] + 2*a[1]*a[4] + 2*a[2]*a[4] + a[3]^2A[7] = 2*a[0]*a[2] + 2*a[1]*a[3] + 2*a[2]*a[4] + 2*a[3]*a[4]A[8] = 2*a[0]*a[1] + 2*a[1]*a[2] + 2*a[2]*a[3] + 2*a[3]*a[4] + a[4]^2A[9] = 2*a[0]*a[0] + 2*a[1]*a[1] + 2*a[2]*a[2] + 2*a[3]*a[3] + 2*a[4]*a[4]... 显然A[9]是其中最大的数位。 这样我们就可以直接判断这个最大的数位是否会发生进位了。 然后复杂度分析我实在没看懂……[3] 代码 穷举法 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;private: bool isPalindrome(long long x) &#123; string str = to_string(x); int n = str.length(); for (int i = 0; i &lt; n - i - 1; i++) if (str[i] != str[n - i - 1]) return false; return true; &#125; long long stol(string str) &#123; long long x = 0; for (char ch: str) x = x * 10 + ch - '0'; return x; &#125;public: int superpalindromesInRange(string L, string R) &#123; int ans = 0; long long l = stol(L), r = stol(R); // 31623约为10^4.5 for (long long i = 1; i &lt;= 31623; i++) &#123; // 按拼成的回文数的长度的奇偶性分出的两种算法 for (int j = 0; j &lt;= 1; j++) &#123; string str = to_string(i); int n = str.length(); for (int i = n - j - 1; i &gt;= 0; i--) str += str[i]; long long p1 = stol(str); long long p2 = p1 * p1; if (l &lt;= p2 &amp;&amp; p2 &lt;= r &amp;&amp; isPalindrome(p2)) &#123; ans++; // cout &lt;&lt; p1 &lt;&lt; ' ' &lt;&lt; p2 &lt;&lt; endl; &#125; &#125; &#125; return ans; &#125;&#125;; 构造法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class Solution &#123; bool isPalindrome(long long x) &#123; string str = to_string(x); int n = str.length(); for (int i = 0; i &lt; n - i - 1; i++) if (str[i] != str[n - i - 1]) return false; return true; &#125; long long stol(string str) &#123; long long x = 0; for (char ch: str) x = x * 10 + ch - '0'; return x; &#125;public: int superpalindromesInRange(string L, string R) &#123; int sum = 0; long long l = stol(L), r = stol(R); for (int a0 = 0; a0 &lt;= 3; a0++) &#123; for (int a1 = 0; a1 &lt;= 3; a1++) &#123; for (int a2 = 0; a2 &lt;= 3; a2++) &#123; for (int a3 = 0; a3 &lt;= 3; a3++) &#123; for (int a4 = 0; a4 &lt;= 3; a4++) &#123; // 回文数a长度为奇数 if (2*a0*a0 + 2*a1*a1 + 2*a2*a2 + 2*a3*a3 + a4*a4 &lt; 10) &#123; string str = to_string(a0) + to_string(a1) + to_string(a2) + to_string(a3) + to_string(a4); int left = stoi(str); if (left != 0) &#123; // 这一转换是为了消除前导0 string numStr = str = to_string(left); reverse(numStr.begin(), numStr.end()); numStr = str.substr(0, str.length() - 1) + numStr; long long num = stol(numStr); num = num * num; if (l &lt;= num &amp;&amp; num &lt;= r &amp;&amp; isPalindrome(num)) sum++; &#125; &#125; // 回文数a长度为偶数 if (2*a0*a0 + 2*a1*a1 + 2*a2*a2 + 2*a3*a3 + 2*a4*a4 &lt; 10) &#123; string str = to_string(a0) + to_string(a1) + to_string(a2) + to_string(a3) + to_string(a4); int left = stoi(str); if (left != 0) &#123; string numStr = str = to_string(left); reverse(numStr.begin(), numStr.end()); numStr = str + numStr; long long num = stol(numStr); num = num * num; if (l &lt;= num &amp;&amp; num &lt;= r &amp;&amp; isPalindrome(num)) sum++; &#125; &#125; &#125; &#125; &#125; &#125; &#125; return sum; &#125;&#125;; Leetcode 905 Solution ↩︎ Explanation For the Math behind Generating All Super Palindromes ↩︎ Python O(4^5) solution. No cheating. Generate all super-palindromes directly. ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 907. Sum of Subarray Minimums（栈）","slug":"2018-09-16-Leetcode-907-Sum-of-Subarray-Minimums（栈）","date":"2018-09-16T16:35:21.000Z","updated":"2018-09-16T18:11:00.000Z","comments":true,"path":"post/leetcode-907-sum-of-subarray-minimums/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-907-sum-of-subarray-minimums/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sum-of-subarray-minimums/description/ 标记难度：Medium 提交次数：3/5 代码效率： BST：304ms 2 Stacks：60ms 1 Stack：84ms 题意 给定正整数数组A，求出A中所有连续子序列的最小值之和mod (10^9 + 7)。 分析 比赛后再看到题解时，我的内心是震惊的。没错，这道题又是一道和Leetcode 901一样的题。比赛期间我使用了原来想到的那种O(n * log(n))的BST方法，完全没有意识到这道题和前一晚上学习的题解的相似性。于是我对自己的学习情况表示了深切的怀疑。 显然一种较好的思路是，对于A中的每一个值A[i]，寻找以它为最小值的子序列的数量。也就是说，我们需要寻找A[i]左侧第一个比它大的值的位置，以及右侧第一个比它大的值的位置。然后就可以计算对应的子序列的数量了。 显然这个寻找的过程和刚才说到的题是一样的，因此就不多写了。[1] 这个过程可以简化为使用一个栈。对于被某个数从栈中弹出的数而言，它右侧第一个比它小的数就是这个数。所以我们可以对所有被弹出的数得到左侧的区间范围和右侧的区间范围。我觉得这是一种非常聪明的做法。[2] 代码 BST 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: int sumSubarrayMins(vector&lt;int&gt;&amp; A) &#123; vector&lt;pair&lt;int, int&gt;&gt; loc; int n = A.size(); for (int i = 0; i &lt; n; i++) loc.emplace_back(A[i], i); sort(loc.begin(), loc.end()); set&lt;int&gt; locSet; long long int sum = 0; for (int i = 0; i &lt; n; i++) &#123; int index = loc[i].second; long long int val = loc[i].first; int left = 0; int right = 0; auto it = locSet.lower_bound(index); if (it != locSet.begin()) &#123; --it; left = index - *it - 1; &#125; else left = index; it = locSet.upper_bound(index); if (it != locSet.end()) &#123; right = *it - index - 1; &#125; else right = n - index - 1; sum += val * (left + 1) * (right + 1) % 1000000007; sum %= 1000000007; locSet.insert(index); &#125; return sum; &#125;&#125;; 2 Stacks 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: int sumSubarrayMins(vector&lt;int&gt;&amp; A) &#123; stack&lt;pair&lt;int, int&gt;&gt; leftStack, rightStack; int n = A.size(); int left[n], right[n]; leftStack.emplace(-1, -1); // val, idx for (int i = 0; i &lt; n; i++) &#123; while (!leftStack.empty() &amp;&amp; leftStack.top().first &gt;= A[i]) leftStack.pop(); if (leftStack.top().second == -1) left[i] = i; else left[i] = i - leftStack.top().second - 1; leftStack.emplace(A[i], i); &#125; rightStack.emplace(-1, -1); for (int i = n - 1; i &gt;= 0; i--) &#123; // 对于leftStack，此处写的是&gt;= // 这意味着对于同一子序列中有多个最小元素的情况， // 我们选择把这种情况的值最右侧的最小元素中计算。 // （防止重复计算） while (!rightStack.empty() &amp;&amp; rightStack.top().first &gt; A[i]) rightStack.pop(); if (rightStack.top().second == -1) right[i] = n - i - 1; else right[i] = rightStack.top().second - i - 1; rightStack.emplace(A[i], i); &#125; long long int sum = 0; for (int i = 0; i &lt; n; i++) &#123; sum += (left[i] + 1) * (right[i] + 1) * (long long int) A[i] % 1000000007; sum %= 1000000007; &#125; return sum; &#125;&#125;; 1 Stack 123456789101112131415161718192021222324252627282930class Solution &#123;public: int sumSubarrayMins(vector&lt;int&gt;&amp; A) &#123; stack&lt;pair&lt;int, int&gt;&gt; s; // (ele, idx) long long int sum = 0; int n = A.size(); for (int i = 0; i &lt;= n; i++) &#123; // 我经常想不清楚这个地方的符号。不过，当A[i] &gt; 已有元素时， // 并不会影响那些元素作为最小值。这样想比较容易。 if (s.empty() || i &lt; n &amp;&amp; s.top().first &lt;= A[i]) s.emplace(A[i], i); else &#123; while (!s.empty() &amp;&amp; (i == n || s.top().first &gt; A[i])) &#123; int val = s.top().first; int idx = s.top().second; s.pop(); int left, right; if (s.empty()) left = idx; else left = idx - s.top().second - 1; right = i - idx - 1; sum += (long long) (left + 1) * (right + 1) * val % 1000000007; sum %= 1000000007; &#125; s.emplace(A[i], i); &#125; &#125; return sum; &#125;&#125;; [C++/Java/Python] Stack Solution ↩︎ One stack solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Monotonic Stack","slug":"alg-Monotonic-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Monotonic-Stack/"}]},{"title":"Leetcode 904. Fruit Into Baskets","slug":"2018-09-16-Leetcode-904-Fruit-Into-Baskets","date":"2018-09-16T15:37:53.000Z","updated":"2018-09-16T16:19:00.000Z","comments":true,"path":"post/leetcode-904-fruit-into-baskets/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-904-fruit-into-baskets/","excerpt":"","text":"题目来源：https://leetcode.com/problems/fruit-into-baskets/description/ 标记难度：Medium 提交次数：2/2 代码效率： 分块扫描：148ms 滑动窗口：192ms 题意 给定数组tree，求其中最长的只包含两种元素的连续子序列的长度。 分析 分块扫描 比赛的时候我就是这么写的。 首先显然可以把这个数组按连续相同的元素分块。这样，相邻的两块所表示的元素必然就是不同的了。然后再考虑怎么求这种子序列。 以样例中的序列[3,3,3,1,2,1,1,2,3,3,4]为例，分块之后，即可得到 1[(3, 3), (1, 1), (2, 1), (1, 2), (2, 1), (3, 2), (4, 1)] 首先尝试从(3, 3)开始寻找最长子序列。显然我们能够找到的是[(3, 3), (1, 1)]。此时下一个块对应的元素必然既不是3也不是1（或者也可能没有下一个块）。一个事实是，如果从这个最长子序列中的任意非最后一个元素开始寻找最长子序列，都必然会结束在当前的最后一个元素。所以下一次搜寻只需从当前最长子序列的最后一个元素开始。 于是之后从(1, 1)开始寻找，找到了[(1, 1), (2, 1), (1, 2), (2, 1)]；再从(2, 1)开始寻找，找到了[(2, 1), (3, 2)]；从(3, 2)开始寻找，找到了[(3, 2), (4, 1)]；最后找到了[(4, 1)]。其中最长的子序列是从(1, 1)开始的。 滑动窗口 看了题解之后，我反而觉得这种想法更容易想。简单来说，令opt(j)表示以j结尾的最长合法子序列的首位坐标，则显然opt(j)是随j单调递增的。也就是说，[opt(j), j]形成了一个滑动窗口。 因此我们可以在遍历j的同时维护滑动窗口中各元素的数量，当元素种类超过2时，则将窗口下沿向前滑，并相应地删除元素，直到元素种类回到2。[1] 代码 分块扫描 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public: int totalFruit(vector&lt;int&gt;&amp; tree) &#123; // 分块 vector&lt;pair&lt;int, int&gt;&gt; subs; // cnt, ele int cnt = 0; for (int i = 0; i &lt; tree.size(); i++) &#123; if (i != 0 &amp;&amp; tree[i - 1] != tree[i]) &#123; subs.emplace_back(cnt, tree[i - 1]); cnt = 0; &#125; cnt++; &#125; if (cnt != 0) subs.emplace_back(cnt, tree.back()); // 进行扫描 // eleSet中存储的是当前找到的元素 unordered_set&lt;int&gt; eleSet; int i = 0; int curSum = 0; int ans = -1; while (i &lt; subs.size()) &#123; while (i &lt; subs.size() &amp;&amp; eleSet.size() &lt;= 2) &#123; int cnt = subs[i].first; int ele = subs[i].second; if (eleSet.find(ele) == eleSet.end() &amp;&amp; eleSet.size() == 2) break; if (eleSet.find(ele) == eleSet.end()) eleSet.insert(ele); curSum += cnt; i++; &#125; ans = max(ans, curSum); curSum = 0; eleSet.clear(); // 如果扫描已经完成则不再回退 if (i &gt;= subs.size()) break; // 回退1，重新开始扫描 i--; &#125; return ans; &#125;&#125;; 滑动窗口 123456789101112131415161718192021class Solution &#123;public: int totalFruit(vector&lt;int&gt;&amp; tree) &#123; int start = 0; // 窗口前沿 unordered_map&lt;int, int&gt; cntMap; int maxn = -1; // 遍历窗口后沿 for (int i = 0; i &lt; tree.size(); i++) &#123; cntMap[tree[i]]++; // 维护窗口中元素种类 while (cntMap.size() &gt; 2) &#123; cntMap[tree[start]]--; if (cntMap[tree[start]] == 0) cntMap.erase(tree[start]); start++; &#125; maxn = max(maxn, i - start + 1); &#125; return maxn; &#125;&#125;; Leetcode 904 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 905. Sort Array By Parity，及周赛（102）总结","slug":"2018-09-16-Leetcode-905-Sort-Array-By-Parity，及周赛（102）总结","date":"2018-09-16T11:48:00.000Z","updated":"2018-09-16T15:27:00.000Z","comments":true,"path":"post/leetcode-905-sort-array-by-parity-and-weekly-contest-102/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-905-sort-array-by-parity-and-weekly-contest-102/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sort-array-by-parity/description/ 标记难度：Easy 提交次数：3/3 代码效率： 平凡的遍历：44ms 平凡的排序：36ms 不平凡的双指针：28ms 题意 给定整数数组A，要求将A中元素重排，使得所有偶数元素在前，奇数元素在后。 分析 这次比赛的题目整体又比较简单。所以我的排名又变高了，变成了271 / 4385（最近几次比赛人好像越来越多了，是错觉吗？）。做出来三道题；最后一题我也想出了几乎正确的做法，就是懒得写了。 一种平凡的做法：两次遍历 比赛的时候我就是这么写的。新开一个vector，先遍历A一次，把偶数元素都插入到里面；再遍历A一次，这次只插入奇数元素。时间复杂度是O(n)，额外空间复杂度是O(n)。 另一种平凡的做法：重写排序比较器 好吧，这种做法倒也没有那么平凡。重写一个排序的比较器，使得偶数都小于奇数，而偶数之间都相等。然后就可以直接把A排序了。时间复杂度是O(n * log(n))，额外空间复杂度是O(1)。[1] 不太平凡的做法：双指针 仍然和快排的想法是类似的。不过我的代码里似乎仍然写了太多的特判，还是这份代码比较好。[2] 代码 遍历 12345678910111213class Solution &#123;public: vector&lt;int&gt; sortArrayByParity(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; ans; for (int x: A) if (x % 2 == 0) ans.push_back(x); for (int x: A) if (x % 2 != 0) ans.push_back(x); return ans; &#125;&#125;; 排序 再一次回到了如何使用自己的比较器进行std::sort的这个问题中。此时你不止需要一个函数，还需要一个函数对象，把这个函数放到重载的()运算符中。[3] 12345678910111213141516class Solution &#123;private: struct &#123; bool operator()(const int&amp; x, const int&amp; y) const &#123; return x % 2 &lt; y % 2; &#125; &#125; Cmp;public: vector&lt;int&gt; sortArrayByParity(vector&lt;int&gt;&amp; A) &#123; // https://en.cppreference.com/w/cpp/algorithm/sort sort(A.begin(), A.end(), Cmp); return A; &#125;&#125;; 双指针 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; sortArrayByParity(vector&lt;int&gt;&amp; A) &#123; int i = 0, j = 0; int n = A.size(); while (i &lt; n &amp;&amp; A[i] % 2 == 0) i++; j = i; while (j &lt; n &amp;&amp; A[j] % 2 != 0) j++; while (i &lt; n &amp;&amp; j &lt; n) &#123; swap(A[i], A[j]); while (i &lt; n &amp;&amp; A[i] % 2 == 0) i++; while (j &lt; n &amp;&amp; A[j] % 2 != 0) j++; &#125; return A; &#125;&#125;; Leetcode 905 Solution ↩︎ [C++/Java] In Place Swap ↩︎ Cpp Reference: std::sort ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 902. Numbers At Most N Given Digit Set（DP）","slug":"2018-09-16-Leetcode-902-Numbers-At-Most-N-Given-Digit-Set（DP）","date":"2018-09-16T00:16:06.000Z","updated":"2018-09-16T11:44:00.000Z","comments":true,"path":"post/leetcode-902-numbers-at-most-n-given-digit-set/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-902-numbers-at-most-n-given-digit-set/","excerpt":"","text":"题目来源：https://leetcode.com/problems/numbers-at-most-n-given-digit-set/description/ 标记难度：Hard 提交次数：1/1 代码效率： 递推：47.81% 数学：100.00% 题意 给定数字集合D（即D是集合{'1','2','3','4','5','6','7','8','9'}的子集）和正整数N，问用这些数字共能组成多少&lt;=N的数。 分析 我想，第一个问题是，这到底是一个统计问题，还是一个计算问题。考虑到N的范围，显然不能直接遍历所有数进行统计，而是需要进行某种程度的计算。也许会涉及到组合数。（虽然事实是没有） 第二个问题是正着做还是反着做——计算只包含这些数字的数的个数，还是计算不只包含这些数字的数的个数？显然我比赛的时候完全没有想清楚这一点，但就这道题来说，大概计算包含更简单一点。 最后一个问题是怎么算。显然我比赛的时候懵逼了，没想出来。“包含X数字的数”也许不算是一种常见的题型，但用非统计的方法计算在某个范围内符合某条件的数的数量似乎还挺常见的（如Leetcode 866）。但我觉得这些题目之间的共性并不大。 递推方法 如何寻找&lt;=N的合法的数？显然可以根据数的长度进行分类讨论。[1]对于长度小于len(N)的那些，显然D中数字的任意组合均是合法的（这一点我之前居然没有意识到……）；对于长度和len(N)相等的那些，则需要分类讨论： 如果该数首位比N的首位小，则之后的数字可以任意组合；如果该数首位和N的首位相等（当然前提是N的首位也是一个合法数字），则需要继续讨论第2位 如果该数第2位比N的第2位小，则之后的数字可以任意组合；如果该数第2位和N的第2位相等（当然前提是N的第2位也是一个合法数字），则需要继续讨论第3位 以此类推…… 于是我们就得到了一个递推算法：令f[i]表示&lt;= N[i:]的数的数量（i从1开始编号），则 1f[i] = (number of digits &lt; N[i]) * (D.size)^(len - i) + (N[i] in D) * f[i + 1] 且最终的结果为 1f[1] + (D.size)^(len - 1) + (D.size)^(len - 2) + ... + D.size 数学方法 这是一种很神奇的方法。我们不妨把D中的数字看成是一种新的进位表示。比如，当D = {1, 3, 5}时，就可以把[11, 13, 51, 53]这类的数写成[11, 12, 31, 32]。如果能够知道&lt;= N的最大的这种进位表示，就可以直接计算合法的数的数量了。所以剩下的问题就是怎么找到这个进位表示。 一种方法是根据N的位，从高位到低位分别进行讨论。令B表示所需的进位表示，1 &lt;= B[i] &lt;= D.size, 1 &lt;= i &lt;= len(N)： 如果N[i] in D &amp;&amp; N[i] = D[j]，则B[i] = j 如果N[i] &gt; min(D)，则B[i] = lower_bound(D, N[i])，B[i+1:] = len(D)，结束 如果N[i] &lt; min(D)，则B[i] = 0，并对之前的数执行类似于退位的操作，B[i+1:] = len(D)，结束 其他情况是比较显然的。一个需要退位的例子：D = {2, 4, 6, 8}，N = 41265 B[1] = 2, &quot;4&quot; B[2] = 0；执行退位操作后，B[1] = 1, B[2] = 4, B[3:5] = 4, &quot;28888&quot; 找到这个进位表示之后就可以直接计算出比它小的数的数量了。事实上这种表示方法类似于Leetcode 171，同样没有0的位置。[1:1] 代码 递推 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;private: // 递归快速幂 long long quickpow(long long a, int x) &#123; if (x == 0) return 1; long long int b = quickpow(a, x &gt;&gt; 1); return x % 2 == 0 ? b * b : b * b * a; &#125;public: int atMostNGivenDigitSet(vector&lt;string&gt;&amp; D, int N) &#123; bool valid[10]; memset(valid, 0, sizeof(valid)); for (string str: D) valid[str[0] - '0'] = true; int x = 0; for (int i = 0; i &lt; 10; i++) if (valid[i]) x++; // 递推过程 long long int f = 1; int digits = 0; while (N &gt; 0) &#123; if (!valid[N % 10]) f = 0; int y = 0; for (int i = 0; i &lt; N % 10; i++) if (valid[i]) y++; f += y * quickpow(x, digits); N /= 10; digits++; &#125; for (int i = 1; i &lt; digits; i++) f += quickpow(x, i); return f; &#125;&#125;; 数学 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution &#123;public: int atMostNGivenDigitSet(vector&lt;string&gt;&amp; D, int N) &#123; vector&lt;int&gt; digits; while (N &gt; 0) &#123; digits.push_back(N % 10); N /= 10; &#125; reverse(digits.begin(), digits.end()); vector&lt;int&gt; digSet; for (string str: D) digSet.push_back(stoi(str)); int n = digits.size(); int B = D.size(); vector&lt;int&gt; b(n, 0); for (int i = 0; i &lt; digits.size(); i++) &#123; int k; // 本来用的是set，后来我实在搞不明白lower_bound和distance那套理论了 // 反正数据量比较小…… for (k = 0; k &lt; digSet.size(); k++) if (digits[i] &lt; digSet[k]) break; // digit[i] &lt; min(D) if (k == 0) &#123; b[i] = 0; // 退位 for (int j = i; j &gt; 0; j--) &#123; if (b[j] == 0) &#123; b[j-1]--; b[j] = B; &#125; else break; &#125; for (int j = i + 1; j &lt; n; j++) b[j] = B; break; &#125; // digit[i] &gt; min(D) with no match else if (digSet[k - 1] &lt; digits[i]) &#123; b[i] = k; for (int j = i + 1; j &lt; n; j++) b[j] = B; break; &#125; // find match else if (digSet[k - 1] == digits[i]) b[i] = k; &#125; long long int cnt = 0; for (int d: b) &#123; cnt = cnt * B + d; &#125; return cnt; &#125;&#125;; Leetcode 902 Solution ↩︎ ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Recursive","slug":"alg-Recursive","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursive/"}]},{"title":"Leetcode 739. Daily Temperatures（栈）","slug":"2018-09-15-Leetcode-739-Daily-Temperatures（栈）","date":"2018-09-15T20:09:27.000Z","updated":"2018-09-17T02:09:00.000Z","comments":true,"path":"post/leetcode-739-daily-temperatures/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-739-daily-temperatures/","excerpt":"","text":"题目来源：https://leetcode.com/problems/daily-temperatures/description/ 标记难度：Medium 提交次数：3/6 代码效率： 排序+BST：14.41% 栈：58.54% 暴力：48.92% 题意 和Leetcode 901差不多，不过顺序正好相反。 分析 因为是几乎一样的所以没什么好分析的。但是在这道题中，因为数据范围比较小（[30, 100]），所以可以从右往左扫描，维护每个温度出现的最左侧的位置，然后对当前的温度，遍历比它高的所有温度，找出其中位于最左侧的。这大概是一种暴力算法吧。[1] 代码 离线算法：排序+BST 虽然写了计数排序，但这个算法仍然超时了。一般来说，30000规模的数据用O(n * log(n))的算法没有什么太大的问题，此处不知道是因为用的STL太多了，Leetcode太面向对象了，还是Leetcode的评测机太渣了。既然如此，纯递归的算法更没有写的必要…… 2018.9.16 UPDATE：我错怪Leetcode了，实际上是我自己没用对set.lower_bound，结果变成了O(n^2)的算法。现在这个算法是能过的了…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;private: struct Pair &#123; int val; int index; Pair(int v, int i) &#123; val = v; index = i; &#125; friend bool operator &lt; (const Pair&amp; x, const Pair&amp; y) &#123; if (x.val != y.val) return x.val &lt; y.val; return x.index &gt; y.index; &#125; &#125;; void bucketSort(vector&lt;Pair&gt;&amp; a) &#123; list&lt;Pair&gt; bucket[105]; for (int i = 0; i &lt; a.size(); i++) &#123; bucket[a[i].val].push_front(a[i]); &#125; int n = 0; for (int i = 30; i &lt;= 100; i++) &#123; for (auto j = bucket[i].begin(); j != bucket[i].end(); j++)&#123; a[n++] = *j; &#125; &#125; &#125;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) &#123; vector&lt;Pair&gt; loc; int n = temperatures.size(); vector&lt;int&gt; ans(n); for (int i = 0; i &lt; n; i++) &#123; loc.emplace_back(temperatures[i], i); &#125; // sort(loc.begin(), loc.end()); bucketSort(loc); set&lt;int&gt; indSet; for (int i = n - 1; i &gt;= 0; i--) &#123; // auto it = lower_bound(indSet.begin(), indSet.end(), loc[i].index); // 上面那个写法是错误的，因为std::lower_bound函数并不知道set的内部结构 // 下面使用std::set::lower_bound才是正确的 auto it = indSet.lower_bound(loc[i].index); if (it == indSet.end()) ans[loc[i].index] = 0; else ans[loc[i].index] = *it - loc[i].index; indSet.insert(loc[i].index); &#125; return ans; &#125;&#125;; 在线算法：栈 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) &#123; stack&lt;pair&lt;int, int&gt;&gt; s; int n = temperatures.size(); vector&lt;int&gt; ans(n); s.emplace(1000, -1); // 一个哨兵 for (int i = n - 1; i &gt;= 0; i--) &#123; while (!s.empty() &amp;&amp; s.top().first &lt;= temperatures[i]) s.pop(); if (s.top().second == -1) ans[i] = 0; else ans[i] = s.top().second - i; s.emplace(temperatures[i], i); &#125; return ans; &#125;&#125;; 在线算法：暴力 如果要求在线，数据从右向左提供，则显然暴力算法是可以在线的。 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) &#123; int n = temperatures.size(); int lastIdx[105]; vector&lt;int&gt; ans(n, 0); for (int i = 0; i &lt; 105; i++) lastIdx[i] = n; for (int i = n - 1; i &gt;= 0; i--) &#123; int minn = n; for (int j = temperatures[i] + 1; j &lt;= 100; j++) minn = min(minn, lastIdx[j]); if (minn == n) ans[i] = 0; else ans[i] = minn - i; lastIdx[temperatures[i]] = i; &#125; return ans; &#125;&#125;; Leetcode 739 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Monotonic Stack","slug":"alg-Monotonic-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Monotonic-Stack/"}]},{"title":"Leetcode 901. Online Stock Span（栈）","slug":"2018-09-15-Leetcode-901-Online-Stock-Span（栈）","date":"2018-09-15T16:51:36.000Z","updated":"2018-09-15T20:57:00.000Z","comments":true,"path":"post/leetcode-901-online-stock-span/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-901-online-stock-span/","excerpt":"","text":"题目来源：https://leetcode.com/problems/online-stock-span/description/ 标记难度：Medium 提交次数：1/1 代码效率：19.81% 题意 给定一个整数数组，为每一个数求出以它为结尾的满足这一条件的连续子数组的最大长度：其余的数都比它更小。 分析 比赛的时候显然我没有做出来这道题，心态崩了。我大概是想出了一个合理的离线方法，但这道题强制要求在线。我当时只能想出O(n^2)的暴力在线方法，没看出来什么递推的方法简化时间复杂度。或者说我就没见过这个类型的题目…… 离线算法1：排序 如果这道题是离线的话，我想出了这样一种做法： 首先把所有数和它们原来的index进行排序 然后按数值大小遍历所有数，并维护一棵存放index的BST；对于每个数，在该BST中查找自己的index的前驱，前驱和自己的index之间的距离（有相同数值时需要特殊处理）；最后把自己的index插入树中 时间复杂度是O(n * log(n))。 离线算法2：递归 事实上通过仔细观察是可以进行一定程度的递推的。这一点我觉得题解就写得不错。假定当前的数组是这样的： 12array = [11, 3, 9, 5, 6, 4]len = [ 1, 1, 2, 1, 2, 1] 对于下一个元素x： 如果x &lt; last，则len[x] = 1 如果x == last，则len[x] = len[last] + 1 如果x &gt; last，则需要在前面的元素中找到比x大的最后一个元素。不过，因为x &gt; last，所以需要找到的元素必然也比last更大。所以对于每一个元素，只有前面比它更大的元素在递推中才有意义。 但是这么想还不够好，因为显然元素的大小可能是随机的，对于不同的元素，“前面比它更大的元素”这个集合在动态变化，并不能直接进行递推。 再重新观察一下上面的例子，查看一下每个元素覆盖的具体子序列： 1234567array = [ 11, 3 , 9 , 5 , 6 , 4 ]Element 11 +Element 3 +Element 9 + +Element 5 +Element 6 + +Element 4 + 一个有趣的问题是，可以试图从这些元素中选择出一部分，使得它们各自的子序列恰好可以拼成这个完整的数组。选择的方法是，先选出数组中最大的数，再选出数组中在这个数之后最大的数，再选出在这个数之后最大的数……直到选到最后一个数。在这个例子中，选出的就是11, 9, 6, 4。它们对应的子序列的长度就是到前一个数的距离。 那么在选出来的数中间的那些数怎么办呢？事实上，这个时候我们已经得到了一个子问题的结构。通过上述选择过程可以看出，夹在选出来的数中间的数必然比两边的数小，也就是说它们的子序列长度和周围的数没有任何关系。 但这仍然是一个离线算法，而且时间复杂度也很成问题。 在线算法：栈 事实上我刚才写了那么多字，主要是为了试图解释这个算法为何是合理的——因为我看到题解的时候，实在是不知道为什么能这么做。不过现在我觉得我已经可以给出一个合理的答案了。刚才已经得到了一个子问题的结构。虽然看起来好像一次选择可能会把数组划分成好几个子问题（事实上也是这样），但实际上并没有把这个问题递归化的必要——因为分割前的元素的结果不依赖于子问题的结果，对吧。所以只要能合理地划分子问题，就可以用任意合理的顺序来解决子问题——比如顺序解决。 我想，栈的作用就是这样的。在加入每个元素之前，把比它小的元素都弹出来。此时栈中实际上顺序保存了一些子问题的元素。（我发现很难描述到底保存了哪些元素……）弹出的过程相当于解决了当前层次的所有子问题。题解中只说“关注递增的元素”，但并没有解释怎么关注递增的元素这个问题。[1] PS. 这道题和Leetcode 739基本上是一样的，看来我还是见得少了。 2018.9.16 UPDATE：通过今天的比赛题Leetcode 907，我意识到了一个问题，这个算法比我想象得要更强一些。对于被某个数从栈中弹出的数而言，它右侧第一个比它大的数就是这个数。所以一个方向的一次使用栈的操作可以同时解决两侧的问题。 代码 只实现了在线算法（显然只能这样）。 在线算法：栈 1234567891011121314151617class StockSpanner &#123;private: stack&lt;pair&lt;int, int&gt;&gt; s;public: StockSpanner() &#123; &#125; int next(int price) &#123; int sum = 1; while (!s.empty() &amp;&amp; s.top().first &lt;= price) &#123; sum += s.top().second; s.pop(); &#125; s.emplace(price, sum); return sum; &#125;&#125;; Leetcode 901 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"},{"name":"alg:Monotonic Stack","slug":"alg-Monotonic-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Monotonic-Stack/"}]},{"title":"About Translating Paul Simon's Lyrics","slug":"2018-09-13-About-Translating-Paul-Simon-s-Lyrics","date":"2018-09-13T14:36:22.000Z","updated":"2018-09-13T21:28:00.000Z","comments":true,"path":"post/about-translating-paul-simon-s-lyrics/","link":"","permalink":"https://zhanghuimeng.github.io/post/about-translating-paul-simon-s-lyrics/","excerpt":"","text":"It seems that English is the universal language for Business, Science, Entertainment and (to some extent) even Literature now. Maybe it is not immediately obvious to many native English speakers that, how big the advantage they have over other language speakers - especially the languages not belonging to the Indo-European Family (that means their monther tongues are less similar to English). As far as I am concerned, it is still quite hard for an average Chinese undergraduate to understand serious English content (I mean, things like The Economist or The New Yorker…), let alone literature works or modern poems. (Yeah, I am camparing Simon’s lyrics to modern poems. And I know there are simpler works like Charlotte’s Web, but here I mean books like Pride and Prejudice.) What’s more, only less than ten percent of Chinese polulation has gone to university. (According to a recent statistic) So, as a result, translation has been thriving here in China, especially after the Internet came into being. All kinds of fun materials - films, news, songs, jokes, twitters, reddits, quoras, and so on - are in English. And the GFW makes the segregating situation worse. (Sorry to tell you that, your whole blog is blocked in China. That’s because blogspot is a google service. Or I think more Chinese fans would come here and try to grab some song meanings.) So some people with good English skills (and good “wall-climbing” skills shh…) would translate the things they are interested in and “carry these materials back inside the walls”. (Here by “the wall”, I mean the GFW, or the language barrier, or both.) So it goes with song lyrics translation. The most popular music software here, Netease Cloud Music (this software is quite like Spotify, but I think it cannot be accessed out of China…), has special settings for “Foreign Language Songs”: users can upload the Chinese translation of the original lyrics. If an English song has no Chinese translation, then very few people would bother to listen to it, because they won’t be able to know what the song is talking about. So, if you like a song very much, but it has no translation, the best thing you can do for it is to translate the lyrics. Well, I think I’ve said quite enough for the general “translation”. Now let’s talk about translations for Paul Simon’s lyrics. In China, Simon’s most famous songs are Scarborough Fair and The Sound of Silence. Everyone knows about these two songs (while most of them having no idea about S &amp; G, or Simon’s other works). So there are many versions of lyric translation for these two songs. One of the most creative ones is this Scarborough Fair translation, paraphrasing the ballad into an very old Chinese poetry style, The Classic of Poetry style: Lyric Translation Are you going to Scarborough Fair 問爾所之，是否如適 Parsely sage rosemary and thyme 蕙蘭芫荽，郁郁香芷 Remember me to one who lives there 彼方淑女，憑君寄辭 She once was a true love of mine 伊人曾在，與我相知 However I prefer a more literal translation than this free one. One of the problems is that, I think the original words are modern English (or something very close), but the translation is in Classic Chinese. As of other songs, I’ll give some translations that I quite like as an example. However, they might not be perfect. Here is a translation of April Come She Will by 灾难艺术家小魏 (It seems that he makes music himself!): Lyric Translation April come she will 四月，她将到来 When streams are ripe and swelled with rain; 溪流如同佳酿，雨水融入其中 May, she will stay 五月，她将停歇 Resting in my arms again 于我怀中休憩 June, she′ll change her tune, 六月，她将唱起新的歌谣 In restless walks she′ll prowl the night; 在无眠的夜里隐匿行踪 July, she will fly 七月，她将翱翔 And give no warning to her flight. 展翅高飞毫无顾虑 August, die she must, 八月，她必须消逝 The autumn winds blow chilly and cold; 秋风飕飕寒冷刺骨 September I′ll remember. 九月，我将怀念 A love once new has now grown old. 曾经鲜活如今苍白的爱情 And here is a translation of Bookends Theme (Reprise) by 无为世界: Lyric Translation Time it was (No translation provided for this line) And what a time it was 多么易逝的时光 It was a time of innocence 那是一段天真无邪的时光 A time of confidences 也是自信满满的时光 Long ago, it must be 一定发生在很久以前 I have a photograph 我保留着一张照片 Preserve your memories 封存了你的所有记忆 They’re all that’s left you 这些记忆只为你而留 However, till now, most of Simon’s songs still lack translation. And I have to admit that some of the translation online now are not so good, maybe mine included… but I’ll do my best. Yes, I have been translating the rest songs - but my time is limited, and sometimes translating his lyrics is really a headache. Take Diamonds On the Soles of Her Shoes as an example - it has all the problems, foreign words, vague meanings… As for the non-English words, I just translate them out to plain Chinese and put a footnote down there saying “the original text of that line is in Zulu”, something like that. But the vagueness and wordplays are the real problem. Should I take “diamonds” as real diamonds, or just diamonds shapes on soles? Although I think Simon means “real” dimonds, I can’t just deny the latter interpretion. I want to convey the multiple ways of understanding through my translation, but sometimes it is quite beyond my ability. Another problem is cultural barrier. For example, in The Teacher, however I translate the line “Whose words were like the tablets of stone”, almost no Chinese reader can relate that to the Bible story. They might have never heard about Moses, at least not familiar with him. And I feel that directly pointing out the similarity of “The Teacher” and Moses in the translation is not a good idea. Recently I have got some new ideas. I might have expected too much from the translations… Some of the work should belong to comments, reviews or analysises. So maybe now on I’ll continue to translate these lyrics, and write some thing about the song as well as translating. And it would be easy to conclude from above that, most of my (and almost all the other) English lyric translations are never intended for singing along. They are intended for the listener to read while listening to the song so they can understand what the song is singing about. Yeah, I have considered that kind of thing. It would be great if I can sing my own Chinese version of lyrics. But It’s really, really hard. I had composed more “singable” versions, but every time after thinking about the nature of these translations, I always choose the more “readable” and “faithful” versions. Well, I am not a professional translator, at least not yet. I think the best solutions I have seen so far are translations for Schubert’s lieder, like this translation for Heidenröslein. But since the original language is German, I won’t discuss these songs further now. But most musicians are not professional translators either. So they choose a different way: using the original song’s music arrangement (of course buying the rights first), and singing their own Chinese lyric. These Chinese lyrics can be completely unrelated to the original lyrics. Some of the most popular songs of this kind are: 彩虹的微笑, adapted from It’s So Easy! 恋人未满, adapted from Brown Eyes 独领风骚, adapted from Who Let the Dogs Out … And yes, there exists a similar arrangement for Simon’s song Mother and Child Reunion. It’s called 制水歌 (“The Song of Water Restriction” in English) by 許冠傑. He sings in Cantonese (a dialect of Chinese), not Mandarin (the standard Chinese), a dialect that I am not really familiar with. In case you should be interested in his lyric, I have made up a loose English version of that. Cantonese lyric English Lyric 又制水真正受气 The authorities are restricting the use of water again, and I feel like a doormat 又制水的确系无谓 The authorities are restricting the use of water again, but I can do nothing about that 又制水今晚点冲凉 The authorities are restricting the use of water again, I can’t take a shower tonight 成晚要干煎真撞鬼 Ah heck, I’m gonna feel sizzling all night OH!真苦透呀老友 听朝早Ｄ起身 Oh! Life’s so hard, my dear friend. I shall get up earlier next morning 搵定水桶半打 装多Ｄ水乜都假 And snatch half a dozen water buckets. Though I can get more water in this way, it’s still not enough 水紧真真冇修 I really realy can do nothing about the water shortage 快搵多Ｄ水啦老友 My dear friend, don’t hesitate to grab more water 莫水真阴功 请保重 We are so pitiful without water, please take care 又制水 夜街你都无谓去 The authorities are restricting the use of water again, I don’t feel like going to the night market now 又制水 拍拖都冇话厘味 The authorities are restricting the use of water again, even the dating couples are stinking 又制水 妹佢怕我周身一阵除 The authorities are restricting the use of water again, my girlfriend thinks that I lack hygiene 成晚要干煎真正悲 It feels so sad that I’m gonna sizzle all night 又制水真正真冇乐趣 The authorities are restricting the use of water again, it ain’t no fun living 又制水的确系无谓 The authorities are restricting the use of water again, but I can do nothing about that 又制水今晚点冲凉 The authorities are restricting the use of water again, I can’t take a shower tonight 成晚要干煎真撞鬼 Ah heck, I’m gonna feel sizzling all night","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"Paul Simon","slug":"Paul-Simon","permalink":"https://zhanghuimeng.github.io/tags/Paul-Simon/"}]},{"title":"Leetcode 900. RLE Iterator，及周赛（101）总结","slug":"2018-09-10-Leetcode-900-RLE-Iterator，及周赛（101）总结","date":"2018-09-10T16:55:42.000Z","updated":"2018-09-10T18:38:00.000Z","comments":true,"path":"post/leetcode-900-rle-iterator-and-weekly-contest-101/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-900-rle-iterator-and-weekly-contest-101/","excerpt":"","text":"题目来源：https://leetcode.com/problems/rle-iterator/description/ 标记难度：Easy 提交次数：2/4 代码效率： 复杂的做法：4ms 简单的做法：4ms 题意 给定一个数组的游程编码（run-length encoding），写一个它的迭代器，支持操作： int next(int n)：删除数组中的前n个元素，返回最后一个被删除的元素；如果数组已经被删光了，则返回-1。 分析 这次比赛出了一点incident，开始时Leetcode自己崩了，进不了比赛，看不了题。所以比赛最后延长了15分钟。而且比赛期间我的心态不是很好，所以一共只做出来一道Easy，剩下的两道Medium都没做出来。不过说实话我觉得这次的题难度稍微高了一点啊…… 总之排名是1331 / 4937。（这次第一又是uwi。） 我自己的思路倒是很简单：把原来的游程编码拆成两个数组（len和val），然后再开一个新的数组acum，acum[i] = len[0] + len[1] + ... + len[i]；用m记录当前已经删除了多少个数。对于每一次next(n)的操作，令m += n，然后找到这样的i，使得len[i-1] &lt; m &lt;= len[i]，如果找到则返回val[i]，否则返回-1。 听起来不是很难，结果我WA了两次。第一次是因为m爆int了。第二次居然是因为之前都忘了把curIdx的初值置零了…… 但一个事实是，其实不需要额外的O(N)空间。只需用变量i记录当前还没被删光的第一个元素的位置，以及q记录这个元素已经被消耗了多少个。对于每一次next(n)的操作，若q + n &lt;= A[i+1]，说明应返回当前元素，且q += n；否则消耗所有当前元素（n -= A[i+1] - q; q = 0; i += 2;）并继续寻找。这个做法有一个好处，不会爆int。[1] 代码 复杂的做法 123456789101112131415161718192021222324252627282930313233343536class RLEIterator &#123;private: vector&lt;long long int&gt; len; vector&lt;long long int&gt; val; vector&lt;long long int&gt; acum; int N; long long int m; int curIdx;public: RLEIterator(vector&lt;int&gt; A) &#123; if (A.size() &gt; 0) &#123; for (int i = 0; i &lt; A.size(); i += 2) &#123; if (A[i] == 0) continue; len.push_back(A[i]); val.push_back(A[i+1]); if (acum.size() &gt; 0) acum.push_back(acum.back() + A[i]); else acum.push_back(A[i]); &#125; N = len.size(); &#125; else &#123; N = 0; &#125; m = 0; curIdx = 0; &#125; int next(int n) &#123; m += n; if (curIdx &gt;= N) return -1; while (curIdx &lt; N &amp;&amp; acum[curIdx] &lt; m) curIdx++; if (curIdx &gt;= N) return -1; return val[curIdx]; &#125;&#125;; 简单的做法 123456789101112131415161718192021222324class RLEIterator &#123;private: int q; int i; vector&lt;int&gt; A;public: RLEIterator(vector&lt;int&gt; A) &#123; i = q = 0; this-&gt;A = A; &#125; int next(int n) &#123; if (i &gt;= A.size()) return -1; while (i &lt; A.size() &amp;&amp; A[i] - q &lt; n) &#123; n -= A[i] - q; q = 0; i += 2; &#125; if (i &gt;= A.size()) return -1; q += n; return A[i + 1]; &#125;&#125;; Leetcode 900 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"软院2016考研机试模拟赛C. 软小宣的比赛","slug":"2018-09-10-软院2016考研机试模拟赛C-软小宣的比赛","date":"2018-09-10T15:50:09.000Z","updated":"2018-09-10T15:56:09.000Z","comments":true,"path":"post/thuss-2016-postgraduate-entrance-exam-simulation-c-contest/","link":"","permalink":"https://zhanghuimeng.github.io/post/thuss-2016-postgraduate-entrance-exam-simulation-c-contest/","excerpt":"","text":"题目来源：http://ac.ssast.org/contest/2/problem/7（需要清华内网） 提交次数：1/1 题意 将[1, N]范围内的数字以某种随机的方式排列并形成一个字符串，从中删除一个字符。给定删除后的字符串和N，请输出被删除的字符。（1 &lt;= N &lt;= 100000） 分析 很简单的一道题。输入N之后把[1, N]范围内的数字的字符数量都统计一下，然后和字符串里各字符的数量比较一下就可以了。但是，这里的问题是，字符串大概会有多长。因为N的最大长度是6，所以字符串长度的上界应该是600000。虽然这个界可能比较大，但肯定不应该是100000……比赛的时候因此丢掉了若干分。 代码 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;char str[600005];int h[10];int main() &#123; ios_base::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); int n; cin &gt;&gt; n; cin &gt;&gt; str; for (int i = 1; i &lt;= n; i++) &#123; int x = i; while (x &gt; 0) &#123; h[x % 10]++; x /= 10; &#125; &#125; int m = strlen(str); for (int i = 0; i &lt; m; i++) h[str[i] - '0']--; for (int i = 0; i &lt; 10; i++) &#123; if (h[i] &gt; 0) &#123; cout &lt;&lt; i &lt;&lt; endl; break; &#125; &#125; return 0;&#125;","categories":[],"tags":[]},{"title":"软院2016考研机试模拟赛B. XDD找素数（数学）","slug":"2018-09-10-软院2016考研机试模拟赛B-XDD找素数（数学）","date":"2018-09-10T14:12:29.000Z","updated":"2018-09-10T15:44:29.000Z","comments":true,"path":"post/thuss-2016-postgraduate-entrance-exam-simulation-b-prime/","link":"","permalink":"https://zhanghuimeng.github.io/post/thuss-2016-postgraduate-entrance-exam-simulation-b-prime/","excerpt":"","text":"题目来源：http://ac.ssast.org/contest/2/problem/6（需要清华内网） 提交次数：1/2 题意 输入n，输出[2, n]区间内的素数总数。（2 &lt;= n &lt;= 2 * 10^7） 分析 比赛的时候我心想，这不是很简单的暴力题么……我相信肯定可以开一个10^7左右的bool数组的。于是我就写完了，写过之后测了一下最大的数据（20000000），发现也没有超过1秒，于是就这样了。 这道题至少有两个正解，埃式筛法（Sieve of Eratosthenes）和欧拉筛法（Euler’s Sieve）。[1] 埃式筛法 最简单的筛法之一，思路非常简单。 12345678define array isPrime[n + 1] // 令数组isPrime表示一个数是否为素数for i from 1 to n isPrime[i] = true // 起始时假定所有数都是素数for i from 2 to n // 如果不需要打印所有素数，此处结束条件可以是n / i（或者说sqrt(n)） if (isPrime[i]) // 找到了一个素数；筛除所有这个素数的倍数 for j from 2 to n / i // 从i开始可以降低复杂度 isPrime[i * j] = false 算法空间复杂度是O(n)O(n)O(n)，时间复杂度是O(nlog⁡log⁡n)O(n\\log{\\log{n}})O(nloglogn)，接近于线性。当然，一个问题是，这个时间复杂度是怎么算出来的。显然，对于每个素数p，内层的for循环至多运行了n / p次。由于[2] ∑p≤n1p=O(log⁡log⁡n)\\sum_{p \\leq n} \\frac{1}{p} = O(\\log{\\log{n}}) p≤n∑​p1​=O(loglogn) 因此总的时间复杂度是O(nlog⁡log⁡n)O(n\\log{\\log{n}})O(nloglogn)。 下一个问题是，如果外层循环的结束条件改成n\\sqrt{n}n​，并不会改变这个界。虽然此时我们只访问了比n\\sqrt{n}n​小的素数，但是对于每个素数p，内层的for循环仍然至多运行了n / p次。此时 ∑p≤nnp=n⋅O(log⁡log⁡n)=n⋅O(log⁡(0.5log⁡n))=n⋅O(log⁡0.5+log⁡log⁡n)=n⋅O(log⁡log⁡n)\\sum_{p \\leq \\sqrt{n}} \\frac{n}{p} = n \\cdot O(\\log{\\log{\\sqrt{n}}}) = n \\cdot O(\\log{(0.5 \\log{n})}) = n \\cdot O(\\log{0.5} + \\log{\\log{n}}) = n \\cdot O(\\log{\\log{n}}) p≤n​∑​pn​=n⋅O(loglogn​)=n⋅O(log(0.5logn))=n⋅O(log0.5+loglogn)=n⋅O(loglogn) 最后一个问题是，如果再把内层循环的起始条件改成i，这个算法的时间复杂度上界能否更紧一些。此时和式变成了 ∑p≤n(np−p)=n⋅∑p≤n1p−∑p≤np\\sum_{p \\leq \\sqrt{n}} ( \\frac{n}{p} - p) = n \\cdot \\sum_{p \\leq \\sqrt{n}} \\frac{1}{p} - \\sum_{p \\leq \\sqrt{n}} p p≤n​∑​(pn​−p)=n⋅p≤n​∑​p1​−p≤n​∑​p 欧拉筛法 从上面的例子可以看出，log⁡log⁡n\\log{\\log{n}}loglogn这个函数已经相当接近于线性了，不过我们仍然可以把埃式筛法改得更好一些，使它的时间复杂度变成O(n)O(n)O(n)。对于埃式筛法，显然一个合数可能被不止一个素数筛掉，如12，可能会被2和3筛掉两遍，这就增加了复杂度。如果我们通过某些方法，使得每个合数只会被它最小的质因子筛掉一遍，复杂度就可以降低到O(n)O(n)O(n)了。 我们考查任何一个数nnn，假设其最小质因子为mmm，那么小于等于mmm的质数与nnn相乘，会得到一个更大的合数，且其最小质因数为与nnn相乘的那个素数。此时该合数可以直接从表中删除，因为其刚好满足之前的合数删除的定义。 12345678910111213141516define array isPrime[n + 1] // 令数组isPrime表示一个数是否为素数define array prime[n + 1] // 存储已经找到的素数int m = 0 // 找到的素数个数for i from 1 to n isPrime[i] = true // 起始时假定所有数都是素数for i from 2 to n if (isPrime[i]) prime[m] = i m += 1 for j from 0 to m-1 if (i * prime[j] &gt; n) break isPrime[i * prime[j]] = false // prime[j]是&lt;=i的最小素因子的素数 if (i % prime[j] == 0) break // 如果prime[j]已经是i的最小素因子了，结束 上述代码里有一个我起初没有注意到的问题。我们需要允许与i的最小素因子相等的素数与i相乘的结果被筛掉，否则我们就无法筛掉任何含有素数的比1更高的次幂的数了。[3] 代码 埃式筛法 123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;bool isPrime[20000005];int main() &#123; int n; cin &gt;&gt; n; memset(isPrime, 1, sizeof(isPrime)); isPrime[1] = false; int cnt = 0; for (int i = 2; i &lt;= n; i++) &#123; if (isPrime[i]) &#123; cnt++; // 注意溢出 for (long long int k = i; k * i &lt;= n; k++) isPrime[k * i] = false; &#125; &#125; cout &lt;&lt; cnt &lt;&lt; endl; return 0;&#125; 欧拉筛法 123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;typedef long long int LL;bool isPrime[20000005];LL prime[2000005];int main() &#123; LL n, m; cin &gt;&gt; n; m = 0; memset(isPrime, 1, sizeof(isPrime)); for (LL i = 2; i &lt;= n; i++) &#123; if (isPrime[i]) prime[m++] = i; for (LL j = 0; j &lt; m &amp;&amp; i * prime[j] &lt;= n; j++) &#123; isPrime[i * prime[j]] = false; if (i % prime[j] == 0) break; &#125; &#125; cout &lt;&lt; m &lt;&lt; endl; return 0;&#125; Sieve of Eratosthenes ↩︎ What is the sum of the reciprocal of primes? (Yes, it diverges) ↩︎ 上述描述参考了XDD找素数——题解（仍然需要内网） ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"软院2016考研机试模拟赛A. 小w的耳机（DP）","slug":"2018-09-09-软院2016考研机试模拟赛A-小w的耳机（DP）","date":"2018-09-09T15:42:18.000Z","updated":"2018-09-10T13:51:00.000Z","comments":true,"path":"post/thuss-2016-postgraduate-entrance-exam-simulation-a-earphone/","link":"","permalink":"https://zhanghuimeng.github.io/post/thuss-2016-postgraduate-entrance-exam-simulation-a-earphone/","excerpt":"","text":"题目来源：http://ac.ssast.org/contest/2/problem/5（需要清华内网） 提交次数：1/2 题意 有一个n * n的网格，定义一条合法路径是从左上角到右下角且只向右和向下走的路径。每个格子有一定的权值。问从左上到右下的三条路径所覆盖的格子的总权值最大是多少？（权值不重复计算） 分析 比赛的时候我看到这是第一题，就很慌张。后来发现这是三道题里最难的一道。我开始时想到了复杂度较高的DP方法，后来简化了一下，就交上去了。结果比赛之后发现只得了70分，因为我看错数据范围了，应该开2 * n的数组，我只开了n。 我想出来的第一种DP做法是这样的：令f[x1][y1][x2][y2][x3][y3]表示第一条路径到达(x1, y1)，第二条路径到达(x2, y2)，第三条路径到达(x3, y3)时的最大权值和。此时的问题是怎么写状态转移方程。很显然，每次只选择若干条路径前进是一种不太合理的做法，既然三条路径的长度是相同的，不妨令每次每条路径都要前进。此时可以这样进行状态转移： 初始条件：f[0][0][0][0][0][0] = a[0][0]（这是显然的） 转移：f[x1][y1][x2][y2][x3][y3] = max(f[x1 - dx[i1]][y1 - dy[i1]][x2 - dx[i2]][y2 - dx[i2]][x3 - dx[i3]][y3 - dy[i3]]) + value，其中dx[2] = {0, 1}，dy[2] = {1, 0}，i = 0表示该路径上一步是向右走的，i = 1表示该路径上一步是向下走的，value表示(x1, y1), (x2, y2), (x3, y3)覆盖的格子的总权值和。 答案：f[n-1][n-1][n-1] 这个方法的问题是空间复杂度太高（O(n^6)）。 通过之前的观察，我们可以发现，这个方法里的状态是比较冗余的：既然每条路径当前走过的总长度都是相同的，不妨这样设计状态：令f[m][x1][x2][x3]表示三条路径都走了m，第一条路径到达(x1, m - x1)，第二条路径到达(x2, m - x2)，第三条路径到达(x3, m - x3)时的最大权值和。 初始条件：f[0][0][0][0] = a[0][0] 转移：f[m][x1][x2][x3] = max(f[m - 1][x1 - dx[i1]][x2 - dx[i2]][x3 - dx[i3]]) + value 答案：max(f[2(n-1)][i][j][k]) 这种方法的空间复杂度降低到了O(n^4)。 当然，上述两种方法都要注意边界条件。[1] 代码 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;typedef long long int LL;int n;LL g[55][55];LL f[105][55][55][55];int main() &#123; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; n; j++) cin &gt;&gt; g[i][j]; // 共需走2(n-1)步 // f[m][x1][x2][x3]：当都走了m步，且1向下走了x1步，2向下走了x2步，3向下走了x3步时的最大的和 LL maxSum = -1; f[0][0][0][0] = g[0][0]; for (int m = 1; m &lt;= 2 * (n-1); m++) &#123; for (int i = 0; i &lt;= min(m, n-1); i++) &#123; for (int j = 0; j &lt;= min(m, n-1); j++) &#123; for (int k = 0; k &lt;= min(m, n-1); k++) &#123; f[m][i][j][k] = 0; for (int i1 = max(0, i-1); i1 &lt;= min(i, m-1); i1++) for (int j1 = max(0, j-1); j1 &lt;= min(j, m-1); j1++) for (int k1 = max(0, k-1); k1 &lt;= min(k, m-1); k1++) f[m][i][j][k] = max(f[m][i][j][k], f[m-1][i1][j1][k1]); f[m][i][j][k] += g[i][m - i] + g[j][m - j] + g[k][m - k]; if (i == j) f[m][i][j][k] -= g[i][m-i]; if (i == k) f[m][i][j][k] -= g[i][m-i]; if (j == k) f[m][i][j][k] -= g[k][m-k]; if (i == j &amp;&amp; j == k) f[m][i][j][k] += g[i][m-i]; if (m == 2 * (n-1)) maxSum = max(maxSum, f[m][i][j][k]); &#125; &#125; &#125; &#125; cout &lt;&lt; maxSum &lt;&lt; endl; return 0;&#125; 上述描述参考了《小w的耳机》解题报告（仍然需要内网） ↩︎","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"}]},{"title":"宁静祷文（Serenity Prayer）翻译","slug":"2018-09-08-宁静祷文（Serenity-Prayer）翻译","date":"2018-09-08T23:46:19.000Z","updated":"2018-09-09T01:25:00.000Z","comments":true,"path":"post/serenity-prayer-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/serenity-prayer-translation/","excerpt":"","text":"宁静祷文（Serenity Prayer）是神学家莱因霍尔德·尼布尔所作的一篇祷告，最初通过尼布尔的讲道和教会团体传播，后来因嗜酒者无名会（Alcoholics Anonymous）等组织将其用于十二步项目（Twelve-step program）而广为流传。 最常见的版本 God, give me grace to accept with serenity the things that cannot be changed, Courage to change the things which should be changed, and the Wisdom to distinguish the one from the other. Living one day at a time, Enjoying one moment at a time, Accepting hardship as a pathway to peace, Taking, as Jesus did, This sinful world as it is, Not as I would have it, Trusting that You will make all things right, If I surrender to Your will, So that I may be reasonably happy in this life, And supremely happy with You forever in the next. Amen.[1] 原文 翻译 God, give me grace to accept with serenity 上帝，请赐我恩典，以宁静之心 the things that cannot be changed, 接受那些无法改变的， Courage to change the things 以勇气 which should be changed, 改变那些应当改变的， and the Wisdom to distinguish 并以智慧 the one from the other. 分辨两者之差异。 Living one day at a time, 每日只活在每日的生活里， Enjoying one moment at a time, 每时只享受当下的这一刻， Accepting hardship as a pathway to peace, 接纳困苦为通向平安之路， Taking, as Jesus did, 效法耶稣， This sinful world as it is, 接受这罪恶世界的本相， Not as I would have it, 而非只看见心中的愿景， Trusting that You will make all things right, 坚信你必将万事安排妥帖， If I surrender to Your will, 若我顺从你的意志， So that I may be reasonably happy in this life, 我将在此生得到适度的欢欣， And supremely happy with You forever in the next. 并于彼世在你身边享受永久的喜乐。 Amen. 阿门。 上述翻译参考了[2]和[3]。 另一版本 在这一版本中，祷文中增加了“责任”，并且尝试在这种主动的责任感和深刻的接纳感之间进行平衡。这里的祷文形式是“祝福”（“May I …”），但很容易修改为“祈祷”（“God grant me the …”）。当然上一个版本也是这样的。[4] May I take deep responsibility for all the consequence of my actions, both intentional and unintentional. May I take deep responsibility for my emotional states. May I take deep responsibility for everything I control and everything over which I have some sort of influence. May I accept complete surrender in all those aspects of life in which I have absolutely no control or influence. May I cultivate tremendous trust and acceptance wherever my control and influence end. May I relax into the deep vulnerability of human life. And between what I control and what I do not, what I influence and what I do not, may I have the wisdom, the courage, and the insight to know the difference. 原文 翻译 May I take deep responsibility for all the consequence of my actions, both intentional and unintentional. 愿我为自己行为的一切后果真正负责，无论是有意的还是无意的。 May I take deep responsibility for my emotional states. 愿我为自身的情绪状态真正负责。 May I take deep responsibility for everything I control and everything over which I have some sort of influence. 愿我为自己可控的一切真正负责，以及那些我能够施加一定影响的。 May I accept complete surrender in all those aspects of life in which I have absolutely no control or influence. 愿我彻底顺从于我完全无法控制和影响的一切。 May I cultivate tremendous trust and acceptance wherever my control and influence end. 在我无法控制和影响之处，愿我培育出无穷的信任和接纳。 May I relax into the deep vulnerability of human life. 愿我轻松地接受人类生命深切的脆弱。 And between what I control and what I do not, what I influence and what I do not, may I have the wisdom, the courage, and the insight to know the difference. 在我能够控制和不能之间，能够影响和不能之间，愿我有智慧、勇气和洞见分辨其区别。 Serenity Prayer ↩︎ 寧靜禱告 Serenity Prayer ↩︎ The Serenity Prayer 宁静之祷 ↩︎ The Serenity Prayer ↩︎","categories":[],"tags":[{"name":"Counseling","slug":"Counseling","permalink":"https://zhanghuimeng.github.io/tags/Counseling/"},{"name":"Psychology","slug":"Psychology","permalink":"https://zhanghuimeng.github.io/tags/Psychology/"}]},{"title":"Codeforces 1038D. Slime（贪心）","slug":"2018-09-08-Codeforces-1038D-Slime（贪心）","date":"2018-09-08T16:09:35.000Z","updated":"2018-09-08T16:56:00.000Z","comments":true,"path":"post/codeforces-1038d-slime/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1038d-slime/","excerpt":"","text":"题目来源：http://codeforces.com/contest/1038/problem/D 提交次数：1/2 题意 给定一个长度为n的数组，可以将数组内任意两个相邻的数x和y合并，合并结果是x - y。问将数组中的数全部合并为一个数之后，得到的数的最大值。 分析 比赛的时候我没有做这个题。后来看了看题解，发现实际上非常简单。 我们不妨对数组中的元素a[i]做这样的标记：如果在最后的和里，它是被加上的，则令sign[i] = &quot;+&quot;；如果是被减去的，则令sign[i] = &quot;-&quot;。比如： 12[1, 2, -1]sum = 2 - 1 - (-1) = 2 则将元素标记为 1sign = [&quot;-&quot;, &quot;+&quot;, &quot;-&quot;] 一个事实是，当a.length &gt;= 2时，sign数组中非全&quot;-&quot;和非全&quot;+&quot;的任何组合都是可以得到的，也就是说，几乎所有加减组合都是可以实现的。对于任一符合上述要求的组合，可以给出一个粗略的构造方法： 从数组中选出一个&quot;+&quot;，使得它的左右两边至少各有一个&quot;-&quot;；或者这个数在边上，左边或右边是空的，另一边有至少一个&quot;-&quot;的数。此时数组看起来是这样的： 1&quot;+1&quot; &quot;+2&quot; &quot;-3&quot; &quot;-4&quot; &quot;+5&quot; &quot;+6&quot;* &quot;+7&quot; &quot;-8&quot; &quot;-9&quot; 对于所有的&quot;-&quot;的数，令它“吸收”（也就是减去并合并）所有左右两边的连续的&quot;+&quot;的数（当然，不要重复“吸收”同一个数）。次数数组看起来是这样的： 1(&quot;-3&quot; - &quot;+1&quot; - &quot;+2&quot;) (&quot;-4&quot; - &quot;+5&quot;) &quot;+6&quot;* (&quot;-8&quot; - &quot;+7&quot;) &quot;-9&quot; 此时，令之前选出来的&quot;+&quot;吸收剩下所有的数，于是我们得到： 12&quot;+6&quot;* - (&quot;-3&quot; - &quot;+1&quot; - &quot;+2&quot;) - (&quot;-4&quot; - &quot;+5&quot;) - (&quot;-8&quot; - &quot;+7&quot;) - &quot;-9&quot;= &quot;+6&quot;* - &quot;-3&quot; + &quot;+1&quot; + &quot;+2&quot; - &quot;-4&quot; + &quot;+5&quot; - &quot;-8&quot; + &quot;+7&quot; - &quot;-9&quot; 显然我们此时已经构造出了这样的和。[1] 以及我们可以通过数学归纳法证明为什么全&quot;+&quot;和全&quot;-&quot;的组合不可能实现。对于任何一个通过加减得到的数，其中必然包含至少一个被减去的a[i]和一个被加上的a[j]。在第一次加减的时候，我们会得到a[j] - a[i]。这之后，无论这个数是减去别的数（a[j] - a[i]），还是被别的数减去（a[i] - a[j]），得到的结果中仍然至少包含一个被减去的数和一个被加上的数。 此时就很容易得出最终的算法了。令sum表示数组中所有元素绝对值的和，则： 如果数组长度为1，则ans = a[1]（显然此时不可能进行任何合并和组合。我在这里WA了一次） 如果数组元素全为正，则ans = sum - 2 * minValue（minValue在最后的结果中是减去的，其他数都是加上的） 如果数组元素全为负，则ans = sum + 2 * maxValue（maxValue在最后的结果中是加上的，其他数都是减去的） 如果数组元素有正有负，则ans = sum（令正数被加上，负数被减去即可） 代码 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;int n, a[500005];int main() &#123; ios_base::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); cin &gt;&gt; n; cin &gt;&gt; a[0]; // 然而这是一个特判 if (n == 1) &#123; cout &lt;&lt; a[0] &lt;&lt; endl; return 0; &#125; long long int sum = abs(a[0]); int maxn = a[0], minn = a[0], hasPos = a[0] &gt; 0, hasNeg = a[0] &lt; 0; for (int i = 1; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; maxn = max(maxn, a[i]); minn = min(minn, a[i]); hasPos = hasPos ? hasPos : a[i] &gt; 0; hasNeg = hasNeg ? hasNeg : a[i] &lt; 0; sum += abs(a[i]); &#125; if (hasPos &amp;&amp; !hasNeg) sum -= 2 * minn; else if (!hasPos &amp;&amp; hasNeg) sum += 2 * maxn; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125; 这一构造方法参考了MahmoudAlio’s Comment ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1038C. Gambling（贪心）","slug":"2018-09-08-Codeforces-1038C-Gambling（贪心）","date":"2018-09-08T10:29:01.000Z","updated":"2018-09-08T11:31:00.000Z","comments":true,"path":"post/codeforces-1038c-gambling/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1038c-gambling/","excerpt":"","text":"题目来源：http://codeforces.com/contest/1038/problem/C 提交次数：1/1 题意 有两个玩家A和B，他们各有一个长度相等的数组a和b，A和B轮流进行以下操作之一： 从自己的数组中删除一个数，将这个数加到自己的sum中； 从对方的数组中删除一个数 每个人的目标都是最大化自己的sum和对方的sum的差（不是绝对值）。问如果两人都以最优策略行动，sum_A - sum_B会是多少？ 分析 这道题看起来有点像博弈论的问题，但实际上关系好像没有那么大，和贪心关系更大一些。或者说，每个人的最优策略都是贪心策略。 令sum_A' = sum(a[1]/2 + ... + a[n]/2)，sum_B' = sum(b[1]/2 + ... + b[n]/2)，将a和b转换成： 12a&apos; = &#123;a[1]/2, ..., a[n]/2&#125;b&apos; = &#123;b[1]/2, ..., b[n]/2&#125; 此时，若玩家A选择a'中的元素（不妨设为a[1]）并删除，则sum_A' += a[1]/2；若玩家A选择b'中的元素（不妨设为b[1]）并删除，则sum_B' -= b[1]/2。当A和B的操作删除完所有元素之后，sum_A'和sum_B'就会变成合法的sum结果。显然，无论A选择的是a'还是b'中的元素，sum_A' - sum_B'都会同样增加该元素的值（a[1]/2或b[1]/2）。这说明对于某个玩家，选择A中的元素和B中的元素本质上是相同的。所以最优解就是不断选择a和b中最大的元素并删除（不管元素是不是自己的）。[1] 我感觉这不是一个严格的证明。虽然这确实说明了对于每个玩家当前的最优（贪心）策略是什么，但并没有回答最优子结构的问题。不过我猜这个问题的答案是显然的。 代码 123456789101112131415161718192021222324252627282930313233343536373839// 因为上述等价性，实际上把两个数组放在一起排序也是合理的，但看起来好像麻烦一些// https://codeforces.com/contest/1038/submission/42562135#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int a[2][100005];int main() &#123; ios_base::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); int n, m[2]; long long int sum[2]; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) cin &gt;&gt; a[0][i]; for (int i = 0; i &lt; n; i++) cin &gt;&gt; a[1][i]; sort(a[0], a[0] + n); sort(a[1], a[1] + n); m[0] = m[1] = n - 1; sum[0] = sum[1] = 0; while (m[0] &gt;= 0 || m[1] &gt;= 0) &#123; for (int i = 0; i &lt;= 1; i++) &#123; int j = (i + 1) % 2; if (m[i] &lt; 0) &#123; if (m[j] &lt; 0) break; m[j]--; &#125; else &#123; if (m[j] &lt; 0) sum[i] += a[i][m[i]--]; else &#123; if (a[i][m[i]] &lt; a[j][m[j]]) m[j]--; else sum[i] += a[i][m[i]--]; &#125; &#125; &#125; &#125; cout &lt;&lt; sum[0] - sum[1] &lt;&lt; endl; return 0;&#125; MahmoudAlio’s Excellent Comment on Editorial ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1038B. Non-Coprime Partition（数学）","slug":"2018-09-07-Codeforces-1038B-Non-Coprime-Partition（数学）","date":"2018-09-07T21:51:49.000Z","updated":"2018-09-08T10:15:00.000Z","comments":true,"path":"post/codeforces-1038b-non-coprime-partition/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1038b-non-coprime-partition/","excerpt":"","text":"题目来源：http://codeforces.com/contest/1038/problem/B 提交次数：1/2 题意 给定正整数n，要求将1到n的数分成两个各自非空的集合S1和S2，且gcd(sum(S1), sum(S2)) &gt; 1。任意合法的解均可接受。 分析 这道题是个水题。但我一开始根本就没看清输出要求（要先输出集合的大小，再输出集合中的元素），所以WA了一次。 很显然有很多种分法，所以一个直觉是，对于一般的n，必然存在一组合法的解。由于1 + 2 + ... + n = n*(n+1) / 2，不妨这样构造： 当n = 1, 2时，显然没有合法的分法。 当n为大于1的奇数时，n必然是n*(n+1) / 2的约数，那么不妨把n分成一组（S1），其他数分成另一组，此时sum(S2) = 1 + 2 + ... + (n-1) = (n-1)*n / 2，gcd(sum(S1), sum(S2)) = n。 当n为大于2的偶数时，n / 2必然是n*(n+1) / 2的约数，那么不妨把n / 2分为一组，其他数分为另一组，同理可得此时gcd(sum(S1), sum(S2)) = n / 2。 代码 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;int main() &#123; int n; cin &gt;&gt; n; if (n &lt;= 2) &#123; cout &lt;&lt; \"No\" &lt;&lt; endl; return 0; &#125; if (n % 2 == 1) &#123; cout &lt;&lt; \"Yes\" &lt;&lt; endl &lt;&lt; 1 &lt;&lt; ' ' &lt;&lt; n &lt;&lt; endl; cout &lt;&lt; n - 1; for (int i = 1; i &lt; n; i++) cout &lt;&lt; ' ' &lt;&lt; i; cout &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; \"Yes\" &lt;&lt; endl &lt;&lt; 1 &lt;&lt; ' ' &lt;&lt; n / 2 &lt;&lt; endl; cout &lt;&lt; n - 1; for (int i = 1; i &lt;= n; i++) if (i != n / 2) cout &lt;&lt; ' ' &lt;&lt; i; cout &lt;&lt; endl; &#125; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Codeforces 1038A. Equality（贪心），及比赛（Codeforces Round #508 Div. 2）总结","slug":"2018-09-07-Codeforces-1038A-Equality（贪心），及比赛（Codeforces-Round-508-Div-2）总结","date":"2018-09-07T21:22:32.000Z","updated":"2018-09-07T21:40:32.000Z","comments":true,"path":"post/codeforces-1038a-equality-and-contest-codeforces-round-508-div-2/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1038a-equality-and-contest-codeforces-round-508-div-2/","excerpt":"","text":"题目来源：http://codeforces.com/contest/1038/problem/A 提交次数：1/1 题意 给定一个长度为n的字符串s，其中只包含前k个大写字母。定义一个“好”的子序列为其中这k个字母的出现频率都相等的子序列，问s的“好”的子序列的最大长度是多少。 分析 这次一共有6个题。前3题都很水；后3题也相对比较简单（当然还是有点难度的，但仍然比之前的比赛更简单一些）。做（水）完前3题之后（大概花了半个小时），我发现第5题的形式之前曾经见过（SGU 101，模型的抽象方法是一样的，但那道题要求把欧拉路算出来，我还没做），大概能做出来，于是决定写上一番。 写了一个小时之后，我交了，结果挂在了pretest 26上。我百思不得其解（过了25个test呢，而且估计也不是因为数据量大才挂的），也不知道该怎么debug，最后就没去管它了。 后来比赛结束之后我看了好久不同的人的各种题解，终于理解我挂哪了，这是一个比较微妙的错误，的确是有个细节没有想清楚。 这次的排名是1486 / 7631，Rating增加了4。（虽然我其实不知道CF现在的Rating是怎么算的。） 这道题显然非常水。只需要找到这k个字母中出现次数最少的字母，然后必然可以构造出字母出现频率相等且最大的子序列，返回k乘以最小出现次数就可以了。 代码 12345678910111213141516#include &lt;iostream&gt;using namespace std;char a[100005];int h[26];int main() &#123; int n, k; cin &gt;&gt; n &gt;&gt; k; cin &gt;&gt; a; for (int i = 0; i &lt; n; i++) h[a[i] - 'A']++; int minn = h[0]; for (int i = 0; i &lt; k; i++) minn = min(minn, h[i]); cout &lt;&lt; minn * k &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1040A. Palindrome Dance（贪心），及比赛（Codeforces Round #507 Div. 2）总结","slug":"2018-09-06-Codeforces-1040A-Palindrome-Dance（贪心），及比赛（Codeforces-Round-507）总结","date":"2018-09-06T21:33:19.000Z","updated":"2018-09-06T21:45:00.000Z","comments":true,"path":"post/codeforces-1040a-palindrome-dance-and-contest-codeforces-round-507/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1040a-palindrome-dance-and-contest-codeforces-round-507/","excerpt":"","text":"题目来源：http://codeforces.com/contest/1040/problem/A 提交次数：1/1 题意 给定n个排成一行的舞蹈者，他们会穿黑色和白色的舞蹈服，其中只有一些人已经买了舞蹈服，一些人还没有。白色舞蹈服价格为a，黑色舞蹈服价格为b。问是否可能给还没有买舞蹈服的人安排服装，使得这n个人舞蹈服装的颜色是左右对称的；如果可能的话，服装的最低总价格是多少。 分析 这次一共有5个题，我只做出来两个，第三题还交了一次错的，结果居然得了353 / 6242名，Rating增加了106，现在Div2这么水的吗？如果Rating不幸升高到了1700以上，我是不是只能去Div1了（然后一题飘过）？ 显然是比较简单的一个回文数类型的题。对于0 &lt;= i &lt;= n / 2，考虑第i和第n - i - 1个人的舞蹈服的颜色： 首先注意i == n - i - 1的情况，如果颜色没有确定，则取价格较低的颜色 如果衣服颜色均已确定，则需要判断颜色是否相同，如果不同，输出-1 如果有一人确定，另一人不确定，则将不确定的人的颜色取为确定的人的颜色 如果两人衣服颜色都不确定，则将两人颜色都取为价格较低的颜色 没了。 代码 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int color[25];int main() &#123; int n, pay[2], minn; cin &gt;&gt; n &gt;&gt; pay[0] &gt;&gt; pay[1]; minn = min(pay[0], pay[1]); for (int i = 0; i &lt; n; i++) cin &gt;&gt; color[i]; int sum = 0; for (int i = 0; i &lt;= n - i - 1; i++) &#123; if (i == n - i - 1) &#123; if (color[i] == 2) sum += minn; break; &#125; if (color[i] != 2 &amp;&amp; color[n - i - 1] == 2) sum += pay[color[i]]; else if (color[i] == 2 &amp;&amp; color[n - i - 1] != 2) sum += pay[color[n - i - 1]]; else if (color[i] == 2 &amp;&amp; color[n - i - 1] == 2) sum += 2 * minn; else if (color[i] != 2 &amp;&amp; color[n - i - 1] != 2) &#123; if (color[i] != color[n - i - 1]) &#123; cout &lt;&lt; -1 &lt;&lt; endl; return 0; &#125; &#125; &#125; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"歌词翻译：No Roses No Skies, by Have Heart (Album: Songs to Scream at the Sun)","slug":"2018-09-06-歌词翻译：No-Roses-No-Skies-by-Have-Heart-Album-Songs-to-Scream-at-the-Sun","date":"2018-09-06T19:26:35.000Z","updated":"2018-09-09T14:22:00.000Z","comments":true,"path":"post/no-roses-no-skies-by-have-heart-album-songs-to-scream-at-the-sun-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/no-roses-no-skies-by-have-heart-album-songs-to-scream-at-the-sun-lyric-translation/","excerpt":"","text":"歌词和翻译 歌词 翻译 She’s a song unsung 她是一首无名的歌 She’s the wild orchid in your ugly swamp 她是一朵开放在肮脏沼泽里的野兰花 She’s a song unsung 她是一首无名的歌 And the only white walls of her mind know what the song sounds like 只有她脑海四周的白墙听过那首歌的声音 The pills, the pills 那些药片，那些药片 And Dr.’s promises just ain’t doing the trick 医生的许诺总是不灵 Cause the arm’s of nothing she falls asleep in 能让她睡下的臂弯也毫无用处 Can still bring the razor to the wrist 那仍然没有阻止刀片划破手腕 The tv screens, the magazines 那些电视屏幕，那些杂志 Scream at you like the dogs of hell 如地狱犬一般向你咆哮 Advertising and advising you to be 推销给你，推荐你变成 Anyone, anyone but your-beautiful-self 任何人，任何人，只除了美好的你自己 Prince charming never brought you flowers 白马王子从未为你带来花束 Just a loveless lifetime all alone 只有独自一人的无爱人生 No roses for you, just unknocked doors 没有一朵玫瑰献给你，只有无人敲响的门 And the deafening silence of your phone 和电话震耳欲聋的寂静 So block your ears, close your eyes 那就堵住耳朵，闭上眼睛 Remember that you’re a golden soul fallen from the 记住，你有一颗金子般的灵魂 Boring, heartless, Hollywood herd of lies that they call: 你从大堆冷酷无聊的好莱坞谎言中坠落，他们称其为： B e a u t i f u l 美 丽 的 With no shoulder, no hand, no body, no man, no door 没有肩膀，没有手，没有身体，没有男人，没有门 No heart to let you: 没有心让你（依靠）： t h e s u n c a n t a k e t o o l o n g 太 阳 花 太 长 时 间 来 t o e n d t h e e n d l e s s n i g h t 结 束 这 无 尽 的 夜 了 I hear you, I feel you, I bleed with you 我听见你了，我与你同感，我们共同战斗 When our hearts begin to scream: 我们的心开始尖叫： t h i s l i f e c a n f e e l t o o l o n g 这 人 生 太 过 漫 长 了 But at night you’re dancing through the pain 但当你在痛苦的夜里翩翩起舞 Even when you’re the only one 即使你独自一人 No rose, no sky as full of beauty as the girl who dies 没有玫瑰，没有天空能比得上那女孩的美 But rises with every morning’s sun 她死去，又在每天清晨日出时复活 Alone 独自一人 She dances alone 她独自起舞 Alone - so beautiful 独自一人——她如此美丽 Alone - her own romance 独自一人——她自己的浪漫传奇 Alone - Lady Lazaru’s Life – Sustaining Dance 独自一人——拉撒路小姐的维系生命之舞 一些诠释 这首歌令我感到很感动，因为： 和歌中的主人公很有同感。 很显然，这首歌的主题在硬核里比较罕见。 在这首歌中，“you”和“she”指向的是同一人，一位女孩。她很痛苦，也许患上了抑郁症，医生为她开了药，但并没有效果；尝试寻求爱情也没有效果。（这里的问题是如何理解“Cause the arm’s of nothing she falls asleep in”一句。有人认为这句的意思是“她找不到能够让她安眠的臂弯”[1]；但我觉得不是，应该是“即使找到了也没用”。而且不同的歌词版本的断句不同，有的在in之前断句，有的在之后。） 媒体（“The tv screens, the magazines”）为她（或者说是所有女性）呈现了一种“女性应有的样子”，声称那是美丽的，并期望她变成那样（也许这就是她的痛苦的来源）。我想，歌词中不断重复的和爱情相关的意象（“Prince charming”、“flowers”、“roses”）也和这种社会建构相关。社会为女性定义了一种标准的美丽的模式，并告诉她们，只要符合了这种模式，就可以得到相应奖赏，比如浪漫的爱情，并且不再孤独（“doors”、“phone”）。但叙事者想告诉她，她本来的样子就是美丽的（“your-beautiful-self”）。她并不需要浪漫爱情来缓解自己的孤独，叙事者能够和她感同身受；她也不需要去迎合社会关于“美丽”的标准（“Boring, heartless, Hollywood herd of lies”），她和痛苦抗争的过程本身就是美丽的（“Alone - so beautiful”）。 我非常喜欢最后一句里的拉撒路这个意象，非常惊艳，也为这首歌赋予了更多诠释的可能性。 8 “But Rabbi,” they said, “a short while ago the Jews there tried to stone you, and yet you are going back?” 9 Jesus answered, “Are there not twelve hours of daylight? Anyone who walks in the daytime will not stumble, for they see by this world’s light. 10 It is when a person walks at night that they stumble, for they have no light.” 11 After he had said this, he went on to tell them, “Our friend Lazarus has fallen asleep; but I am going there to wake him up.” … 25 Jesus said to her, “I am the resurrection and the life. The one who believes in me will live, even though they die; 26 and whoever lives by believing in me will never die. Do you believe this?” 27 “Yes, Lord,” she replied, “I believe that you are the Messiah, the Son of God, who is to come into the world.” … 43 When he had said this, Jesus called in a loud voice, “Lazarus, come out!” 44 The dead man came out, his hands and feet wrapped with strips of linen, and a cloth around his face.[2] 让拉撒路小姐在清晨时又重新获得生活的勇气的不再是耶稣，而是她自己。即使人在黑夜行路容易跌倒，毕竟白日仍然有十二个小时，白日总会来的。 有人说这首歌是Patrick Flynn写给自己的姐妹的。我也不知道这是不是真的。[3] 2018.9.8 UPDATE：把“Prince charming”的翻译修正成了“白马王子”。以及，我是有意把“No roses for you”翻译成“没有一朵玫瑰献给你”的，这句话让我想起A Rose For Emily（《献给爱米丽的一朵玫瑰花》）以及其中的故事。这个题目大概的意思是这样的：福克纳说，他怜悯经历了一场巨大的悲剧的爱米丽小姐，这朵玫瑰是他向她的致意。[4] 2019.2.3 UPDATE：最后稍微修改了一些措辞，上传到网易云音乐上了。 xTEVINJAYx comment ↩︎ John 11 ↩︎ General Comment ↩︎ A Rose for Emily ↩︎","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Have Heart","slug":"artist-Have-Heart","permalink":"https://zhanghuimeng.github.io/tags/artist-Have-Heart/"}]},{"title":"Leetcode 460. LFU Cache（STL）","slug":"2018-09-05-Leetcode-460-LFU-Cache（STL）","date":"2018-09-05T18:57:45.000Z","updated":"2018-09-06T15:37:00.000Z","comments":true,"path":"post/leetcode-460-lfu-cache/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-460-lfu-cache/","excerpt":"","text":"题目来源：https://leetcode.com/problems/merge-two-sorted-lists/description/ 标记难度：Easy 提交次数：4/9 代码效率： map O(n)：3.13% HashMap + list O(1)：45.28% TreeSet + map O(log(n))：23.78% 简单版map + list O(1)：11.36% 题意 实现LFU缓存。 分析 map O(n) 这是我想出来的第一种做法：用三个map分别记录每个key对应的值（valueMap）、访问次数（freqMap）和最近访问时间（recentMap）。 get(int key)：在valueMap中查找key对应的值，然后更新freqMap和recentMap。 put(int key, int value)： 如果不需要换出，则直接更新三个map中维护的值 如果需要换出，则遍历当前的所有key，从中找出访问频率最小的最不频繁访问的元素，把它换出，再插入新元素 这种做法显然不是很聪明。 HashMap + list O(1) 这是一种相对比较复杂的方法，原理是这样的[1]： 1234567891011121314Increasing frequencies----------------------------------&gt;+------+ +---+ +---+ +---+| Head |----| 1 |----| 5 |----| 9 | Frequencies+------+ +-+-+ +-+-+ +-+-+ | | | +-+-+ +-+-+ +-+-+ | |2,3| |4,3| |6,2| | +-+-+ +-+-+ +-+-+ | Most recent | | | +-+-+ +-+-+ | key,value pairs |1,2| |7,9| | +---+ +---+ v 作者在代码中维护了两个数据结构： unordered_map&lt;int, pair&lt;list&lt;LRUNode&gt;::iterator, list&lt;pair&lt;int, int&gt;&gt;::iterator&gt;&gt; kv_：存放每个key对应的桶的头结点，以及key在桶中对应的具体结点 list&lt;LRUNode&gt; cache_：所有桶组成的链表；其中LRUNode = (int freq, list&lt;pair&lt;int, int&gt;&gt; vals)，表示频率freq的key组成的链表，其中pair的第一项表示key，第二项表示value。 具体实现的核心是三个成员函数： promote(int key, int val)：找到key对应的桶的头结点i和key在桶中对应的结点j，以及下一个频率对应的桶k，在有必要的情况下取出j-&gt;second；然后从i中删除j，把i插入到k的最末端。 evict()：找到频率最小的桶i，以及位于桶头部的访问最不频繁的结点j，然后从i和kv_中删除j insert(int key, int val)：找到频率最小的桶i，如果i对应的频率不是1，则在cahce_头部插入一个新的桶，对应的频率为1；最后在该桶的末端插入(key, val)。 利用上述函数很容易实现get和put，我就不写了。 我的实现方法则比较复杂。维护4个map和一个list： unordered_map&lt;int, int&gt; valMap：存放key和value的对应关系 unordered_map&lt;int, int&gt; freqMap：存放key和访问频率的对应关系 unordered_map&lt;int, list&lt;list&lt;int&gt;&gt;::iterator&gt; headMap：存放访问频率和桶的对应关系 unordered_map&lt;int, list&lt;int&gt;::iterator&gt; nodeMap：存放key和桶中结点的对应关系 list&lt;list&lt;int&gt;&gt; buckets：桶 实现了一个更新函数touch(int key)，主要功能是将key的访问频率+1，即把key从headMap[freqMap[key]]对应的桶中删除，放入headMap[freqMap[key] + 1]对应的桶中，并更新各map之间的关系。 get(int key)：在valMap中查找key，如果key不存在则返回-1；如果存在则执行touch(key)，然后返回valMap[key]。 put(int key, int value)： 如果key已经存在，则执行touch(key)，并更新valMap。 如果key不存在且需要换出，则在buckets中找到当前对应频率值最低的桶，将桶中最末一个元素删除，并更新其他map。 最后将（还不存在的）key插入访问频率1对应的桶中，更新其他map。 TreeSet + map O(log(n)) 上一种方法实在是太繁琐了，于是我又发现了另一种利用TreeSet（或者说优先队列）的方法。[2] 维护一个集合treeSet（对C++来说，用priority_queue有一些缺陷，所以此处实际上用的是set），其中的元素是(frequency, recency, key) unordered_map&lt;int, int&gt; valMap，用于存储key到value的对应关系。 unordered_map&lt;int, (frequency, recency, key)&gt; keyMap，用于存储key到freq和recency的对应关系。 实现一种touch(int key)操作：在treeSet中删除当前的keyMap[key]，更新key的访问频率（keyMap[key].frequency++），并将更新后的keyMap[key]重新插入到treeSet中。 get(int key)：在valMap中查找key，如果找不到则返回-1；否则执行touch(key)。 put(int key, int value)： 如果key已经存在，则执行touch(key)。 如果key不存在且需要换出，则通过treeSet-&gt;begin()找到当前的LFUkey，从treeSet和其他map中删除该key对应的元素。 最后，令keyMap[key] = (1, curTime, key)，valMap[key] = value，将keyMap[key]插入到treeSet中。 由于treeSet中按值查找、删除和插入的复杂度都是O(log(n))，所以这种方法的时间复杂度是O(log(n))，比之前的方法稍微高一点，不过写起来方便多了。 以及，随便说一下C中鸡肋一般的priority_queue。事实上，像这道题中这样的需求——插入元素、寻找最小元素、删除最小元素、元素下滤（显然对元素的操作只会使frequency和recency增加）——是很适合堆的。然而C中并没有为priority_queue提供修改其中元素的接口，如果想要实现，大概只能自己继承这个类然后重写。Java中的PriorityQueue倒是有remove接口，但时间复杂度是O(n)。那还不如用set（Java中的TreeSet）和运算符重载算了。 不过我之前从未想过，set可以实现和priority_queue类似的功能这回事，而且时间复杂度差不多。嗯，只是差不多而已，此处又想起了邓公的话： 由上可见，上滤调整过程中交换操作的累计次数，不致超过全堆的高度⌊log⁡2(n)⌋\\lfloor \\log_2{(n)} \\rfloor⌊log2​(n)⌋。 而在向量中， 每次交换操作只需常数时间，故上滤调整乃至整个词条插入算法整体的时间复杂度，均为O(log⁡n)O(\\log{n})O(logn)。这也是从一个方面，兑现了10.1节末尾就优先级队列性能所做的承诺。 当然，不难通过构造实例说明，新词条有时的确需要一直上滤至堆顶。然而实际上，此类最坏情况通常极为罕见。以常规的随机分布而言，新词条平均需要爬升的高度，要远远低于直觉的估计（习题[10-6]）。[3] 不过，我觉得在这道题的语境下，优先队列的上滤过程恐怕没有那么大的优势（因为插入的新元素的frequency必然为1，因此很可能会上升到堆中比较高的位置），下滤过程倒可能有类似的效果（因为下滤时作为排序的第一关键字的frequency只增加了1，因此很可能不需要下降很多层）。 简单版map + list O(1) 这是最简单的一种方法了。本质上也是利用桶排序，但是这种方法利用了一个我们之前都没有注意到的事实：插入新key时，它的frequency必然是1。因此我们并不需要一个有序集或一个链表来维护最小的访问频率，因为在删除一个访问频率最小的结点之后，插入的新结点的频率（1）必然是现在的最小频率。这样，我们就可以用一个unordered_map&lt;int, list&lt;int&gt;&gt;来存储访问频率和桶的对应的关系了。 其余的想法和第一种桶排序是非常类似的。具体内容看代码和注释好了。 有一件很有趣的事情。在这种方法中，我仍然需要维护一个unordered_map&lt;int, list&lt;int&gt;::iterator&gt; iterMap，用于从桶中删除元素；但是Java里有一个比较神奇的东西，叫LinkedHashSet，同时实现了链表和哈希表的特性，所以Java代码会看起来好看一点。[4]不过也许它内部也就是把一个HashSet&lt;Type, ListNode&gt;和一个ListNode&lt;Type&gt;这样拼起来的。 代码 map O(n) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class LFUCache &#123;private: unordered_map&lt;int, int&gt; valueMap; unordered_map&lt;int, int&gt; freqMap; unordered_map&lt;int, int&gt; recentMap; int time; int cap; int num;public: LFUCache(int capacity) &#123; time = 0; num = 0; cap = capacity; &#125; int get(int key) &#123; auto i = valueMap.find(key); if (i == valueMap.end()) return -1; recentMap[key] = time; freqMap[key]++; time++; return i-&gt;second; &#125; void put(int key, int value) &#123; // 这是一个不容易注意到的corner case // 虽然毫无意义。 if (cap == 0) return; if (valueMap.find(key) != valueMap.end()) &#123; valueMap[key] = value; freqMap[key]++; recentMap[key] = time; time++; return; &#125; if (num &gt;= cap) &#123; // find LFU int minKey = -1, minFreq, minRec; // 遍历所有的key，找到其中freq和recent最小的 for (auto const&amp; i: freqMap) &#123; int freq = i.second; int recent = recentMap[i.first]; if (minKey == -1 || freq &lt; minFreq || (freq == minFreq &amp;&amp; recent &lt; minRec)) &#123; minKey = i.first; minFreq = freq; minRec = recent; &#125; &#125; // cout &lt;&lt; minKey &lt;&lt; ' ' &lt;&lt; minFreq &lt;&lt; ' ' &lt;&lt; minRec &lt;&lt; endl; valueMap.erase(minKey); freqMap.erase(minKey); recentMap.erase(minKey); num--; &#125; valueMap[key] = value; freqMap[key]++; recentMap[key] = time; num++; time++; return; &#125;&#125;; HashMap + list O(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class LFUCache &#123;private: unordered_map&lt;int, int&gt; valMap; // key --&gt; value unordered_map&lt;int, int&gt; freqMap; // key --&gt; frequence unordered_map&lt;int, list&lt;list&lt;int&gt;&gt;::iterator&gt; headMap; // frequence --&gt; bucket head unordered_map&lt;int, list&lt;int&gt;::iterator&gt; nodeMap; // key --&gt; node in list list&lt;list&lt;int&gt;&gt; buckets; // buckets int cap; int num; /* increase the frequence of @key */ void touch(int key) &#123; int freq = freqMap[key]; auto head = headMap[freq]; // head of the bucket containing key auto node = nodeMap[key]; // the list node containing key head-&gt;erase(node); // delete the key from this bucket // find new bucket head auto newHead = head; if (headMap.find(freq + 1) != headMap.end()) newHead = headMap[freq + 1]; else &#123; // Note: that's \"insert before\" for C++ buckets.insert(head, list&lt;int&gt;()); newHead--; &#125; // insert the key into another bucket // put the most recent values in the front newHead-&gt;push_front(key); // delete empty bucket (for convenience of finding LFU) if (head-&gt;empty()) &#123; buckets.erase(head); headMap.erase(freq); &#125; // update the maps freqMap[key]++; headMap[freq + 1] = newHead; nodeMap[key] = newHead-&gt;begin(); &#125;public: LFUCache(int capacity) &#123; cap = capacity; num = 0; &#125; int get(int key) &#123; if (valMap.find(key) == valMap.end()) return -1; touch(key); // update frequence return valMap[key]; &#125; void put(int key, int value) &#123; if (cap == 0) return; // Only update value if (valMap.find(key) != valMap.end()) &#123; valMap[key] = value; touch(key); return; &#125; // Need to evict a LFU key-value pair if (num &gt;= cap) &#123; // find the head of the bucket of minimum frequency auto head = buckets.end(); head--; // find least visited key of this frequency and delete it int evict = head-&gt;back(); head-&gt;pop_back(); int freq = freqMap[evict]; // if this bucket becomes empty, then delete it if (head-&gt;empty()) &#123; headMap.erase(freq); buckets.pop_back(); &#125; // delete the evicted key valMap.erase(evict); freqMap.erase(evict); nodeMap.erase(evict); num--; &#125; // find the head of frequency 1 if (headMap.find(1) == headMap.end()) &#123; buckets.push_back(list&lt;int&gt;()); auto head = buckets.end(); head--; headMap[1] = head; &#125; // insert new key at the front of list auto head = headMap[1]; head-&gt;push_front(key); nodeMap[key] = head-&gt;begin(); valMap[key] = value; freqMap[key] = 1; num++; &#125;&#125;; TreeSet + map O(log(n)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class LFUCache &#123;private: struct Tuple &#123; int key; int freq; int recent; Tuple() &#123;&#125; Tuple(int x, int y, int z): key(x), freq(y), recent(z) &#123;&#125; // For ordered set friend bool operator &lt; (const Tuple&amp; a, const Tuple&amp; b) &#123; if (a.freq != b.freq) return a.freq &lt; b.freq; return a.recent &lt; b.recent; &#125; friend bool operator == (const Tuple&amp; a, const Tuple&amp; b) &#123; return a.key==b.key &amp;&amp; a.freq==b.freq &amp;&amp; a.recent==b.recent; &#125; &#125;; unordered_map&lt;int, int&gt; valMap; unordered_map&lt;int, Tuple&gt; keyMap; set&lt;Tuple&gt; treeSet; int num; int cap; int time;public: LFUCache(int capacity) &#123; num = 0; time = 0; cap = capacity; &#125; int get(int key) &#123; if (valMap.find(key) == valMap.end()) return -1; // Erase old Tuple and insert new one treeSet.erase(keyMap[key]); keyMap[key].freq++; keyMap[key].recent = time; treeSet.insert(keyMap[key]); time++; return valMap[key]; &#125; void put(int key, int value) &#123; if (cap &lt;= 0) return; if (valMap.find(key) != valMap.end()) &#123; treeSet.erase(keyMap[key]); keyMap[key].freq++; keyMap[key].recent = time; valMap[key] = value; treeSet.insert(keyMap[key]); &#125; else &#123; if (num &gt;= cap) &#123; // Find LFU (ordered set head) auto iter = treeSet.begin(); int evict = iter-&gt;key; treeSet.erase(iter); valMap.erase(evict); keyMap.erase(evict); num--; &#125; keyMap[key] = Tuple(key, 1, time); treeSet.insert(keyMap[key]); valMap[key] = value; num++; &#125; time++; &#125;&#125;; 简单版map + list O(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class LFUCache &#123;private: unordered_map&lt;int, int&gt; valMap; unordered_map&lt;int, int&gt; freqMap; unordered_map&lt;int, list&lt;int&gt;::iterator&gt; iterMap; unordered_map&lt;int, list&lt;int&gt;&gt; bucketMap; int minFreq; int cap; int num; // visit @key void touch(int key) &#123; int freq = freqMap[key]; auto iter = iterMap[key]; bucketMap[freq].erase(iter); // erase key from old bucket if (freq == minFreq &amp;&amp; bucketMap[freq].empty()) // update minFreq minFreq++; bucketMap[freq + 1].push_front(key); // insert key to new bucket iterMap[key] = bucketMap[freq + 1].begin(); freqMap[key]++; &#125;public: LFUCache(int capacity) &#123; cap = capacity; num = 0; minFreq = 1; &#125; int get(int key) &#123; if (freqMap.find(key) == freqMap.end()) return -1; touch(key); return valMap[key]; &#125; void put(int key, int value) &#123; if (cap == 0) return; if (freqMap.find(key) != freqMap.end()) &#123; valMap[key] = value; touch(key); return; &#125; if (num &gt;= cap) &#123; int evict = bucketMap[minFreq].back(); // find LFU // delete LFU bucketMap[minFreq].pop_back(); valMap.erase(evict); freqMap.erase(evict); iterMap.erase(evict); num--; &#125; // because the freq of new key is 1, minFreq will certainly become 1 minFreq = 1; bucketMap[1].push_front(key); valMap[key] = value; freqMap[key] = 1; iterMap[key] = bucketMap[1].begin(); num++; &#125;&#125;; C++ list with hashmap with explanation ↩︎ Java solution using PriorityQueue, with detailed explanation ↩︎ 《数据结构(C++语言版)》（第三版） P290，清华大学出版社，2013.9 ↩︎ JAVA O(1) very easy solution using 3 HashMaps and LinkedHashSet ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"},{"name":"alg:Linked List","slug":"alg-Linked-List","permalink":"https://zhanghuimeng.github.io/tags/alg-Linked-List/"},{"name":"alg:Priority Queue","slug":"alg-Priority-Queue","permalink":"https://zhanghuimeng.github.io/tags/alg-Priority-Queue/"}]},{"title":"Leetcode 232. Implement Queue using Stacks（栈和队列）","slug":"2018-09-05-Leetcode-232-Implement-Queue-using-Stacks（栈和队列）","date":"2018-09-05T15:30:06.000Z","updated":"2018-09-05T16:54:00.000Z","comments":true,"path":"post/leetcode-232-implement-queue-using-stacks/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-232-implement-queue-using-stacks/","excerpt":"","text":"题目来源：https://leetcode.com/problems/implement-queue-using-stacks/description/ 标记难度：Easy 提交次数：3/3 代码效率： 我的做法（两个栈）：100.00% 稍微好一点的双栈版本：100.00% 平摊O(1)的双栈版本：100.00% 题意 用栈实现队列。 分析 这道题和Leetcode 225正好对应。不过，栈和队列相比，只有一个出口，所以解法也少一种。 法1：我的做法 我的做法特别简单直接明了，用一个栈（s1）模拟队列（栈顶表示队尾，栈底表示队头），另一个栈（s2）作为临时存储空间。 push(x)：直接把x放入s1栈顶，时间复杂度为O(1)。 pop()：把s1中的元素逐个弹出并插入到s2中，直到得到位于s1栈底的队头元素；然后把s2中的元素再逐个弹出，放回s1中，时间复杂度是O(n)（因为这里的数据结构是栈，所以临时存储会改变元素的顺序，按照这种思路，只能把元素再重新放回去了）。 peek()：和pop()的过程基本相同，但不删除队头元素，时间复杂度为O(n)。 empty()：返回s1.empty()，时间复杂度为O(1)。 这种做法虽然不算很错，但显然不是一种很聪明的办法：因为栈只有一端是开口的，我还把队头放在不开的那一头，所以pop()和peek()都要花费O(n)的时间，相当离谱。 法2：较少的时间复杂度 这种做法的思路和上一种做法很相似，也是用一个栈（s1）模拟队列，另一个栈（s2）作为临时存储空间；主要的区别是，此时用栈顶表示队头，栈底表示队尾。[1] push(x)：把s1中的元素逐个弹出并插入到s2中，把x插入s1中，最后再把s2中的元素再逐个弹出，放回s1中。时间复杂度是O(n)。 pop()：直接从s1栈顶弹出元素，时间复杂度是O(1)。 peek()：返回s1栈顶元素，时间复杂度是O(1)。 empty()：返回s1.empty()，时间复杂度是O(1)。 法3：平摊O(1)复杂度 这种做法大约是法1的改进版。可以发现，在法1里，进行pop()的过程中，元素在s2中排成了正确的顺序，队头在栈顶。那我们不妨就把这些元素留在s1里面。并且用front变量维护s1栈顶元素。 push(x)：直接把x放入s1栈顶，维护front，时间复杂度是O(1)。 pop()：如果s2为空，则把s1中的元素逐个弹出并插入到s2中；从s2中弹出栈顶元素。显然，单次时间复杂度最坏可能是O(n)，但并不是每次都需要花这么多时间；事实上，每个元素只会进入s1一次，然后再进入s2一次，所以整体的时间复杂度只有O(1)；平摊到每次操作上，就是O(1)。 peek()：如果s2不为空，则返回s2栈顶元素；否则返回front。时间复杂度为O(1)。 empty()：返回s1.empty() &amp;&amp; s2.empty()。时间复杂度是O(1)。 以及，我感觉用栈模拟链表再模拟队列的做法应该也是可行的，不过既然以及有了平摊O(1)的方法，似乎没有这个必要了。 代码 法1 1234567891011121314151617181920212223242526272829303132333435363738394041424344class MyQueue &#123;private: stack&lt;int&gt; s1, s2;public: MyQueue() &#123; &#125; void push(int x) &#123; s1.push(x); &#125; int pop() &#123; while (!s1.empty()) &#123; s2.push(s1.top()); s1.pop(); &#125; int x = s2.top(); s2.pop(); while (!s2.empty()) &#123; s1.push(s2.top()); s2.pop(); &#125; return x; &#125; int peek() &#123; while (!s1.empty()) &#123; s2.push(s1.top()); s1.pop(); &#125; int x = s2.top(); while (!s2.empty()) &#123; s1.push(s2.top()); s2.pop(); &#125; return x; &#125; bool empty() &#123; return s1.empty(); &#125;&#125;; 法2 12345678910111213141516171819202122232425262728293031323334class MyQueue &#123;private: stack&lt;int&gt; s1, s2;public: MyQueue() &#123; &#125; void push(int x) &#123; while (!s1.empty()) &#123; s2.push(s1.top()); s1.pop(); &#125; s1.push(x); while (!s2.empty()) &#123; s1.push(s2.top()); s2.pop(); &#125; &#125; int pop() &#123; int x = s1.top(); s1.pop(); return x; &#125; int peek() &#123; return s1.top(); &#125; bool empty() &#123; return s1.empty(); &#125;&#125;; 法3 12345678910111213141516171819202122232425262728293031323334353637383940class MyQueue &#123;private: stack&lt;int&gt; s1, s2;public: MyQueue() &#123; &#125; void push(int x) &#123; s1.push(x); &#125; int pop() &#123; if (s2.empty()) &#123; while (!s1.empty()) &#123; s2.push(s1.top()); s1.pop(); &#125; &#125; int x = s2.top(); s2.pop(); return x; &#125; // 我觉得不维护front变量，而把peek写成和pop类似的形式并不会改变整体的平摊时间复杂度 // 但是可能会增加peek的访问时间 int peek() &#123; if (s2.empty()) &#123; while (!s1.empty()) &#123; s2.push(s1.top()); s1.pop(); &#125; &#125; return s2.top(); &#125; bool empty() &#123; return s1.empty() &amp;&amp; s2.empty(); &#125;&#125;; 232. Implement Queue using Stacks（本文中的图片都来自这里） ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Queue","slug":"alg-Queue","permalink":"https://zhanghuimeng.github.io/tags/alg-Queue/"}]},{"title":"Leetcode 513. Find Bottom Left Tree Value（BFS）","slug":"2018-09-05-Leetcode-513-Find-Bottom-Left-Tree-Value（BFS）","date":"2018-09-05T15:13:38.000Z","updated":"2018-09-05T15:27:00.000Z","comments":true,"path":"post/leetcode-513-find-bottom-left-tree-value/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-513-find-bottom-left-tree-value/","excerpt":"","text":"题目来源：https://leetcode.com/problems/find-bottom-left-tree-value/description/ 标记难度：Medium 提交次数：1/1 代码效率：98.56% 题意 给定一棵二叉树，找到最底层最靠左的结点的值。 分析 这道题看起来像是Leetcode 199的反过来的超简化版，因为只需要最底层的最左边的结点。我是用BFS直接做的——逐层访问，记录每层最左侧的结点，最后找到最底层最左侧的结点——不过这个思路可以再简化一些：对于每一层都从右往左访问，这样我们就不需要记录每层最左侧的结点，只需要返回最后一个访问的结点就可以了。[1] 代码 123456789101112131415161718192021222324252627class Solution &#123;public: int findBottomLeftValue(TreeNode* root) &#123; queue&lt;TreeNode*&gt; q; TreeNode* bottomLeft = nullptr; q.push(root); while (!q.empty()) &#123; TreeNode* left = nullptr; // 这个代码实际上复用了Leetcode 199的BFS代码 // 同理，仍然可以不新开一个queue的 queue&lt;TreeNode*&gt; q2; while (!q.empty()) &#123; TreeNode* x = q.front(); q.pop(); if (left == nullptr) left = x; if (x-&gt;left != nullptr) q2.push(x-&gt;left); if (x-&gt;right != nullptr) q2.push(x-&gt;right); &#125; q = q2; bottomLeft = left; &#125; return bottomLeft-&gt;val; &#125;&#125;; Right-to-Left BFS (Python + Java) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 199. Binary Tree Right Side View（BFS）","slug":"2018-09-05-Leetcode-199-Binary-Tree-Right-Side-View（BFS）","date":"2018-09-05T14:56:00.000Z","updated":"2018-09-05T14:38:36.000Z","comments":true,"path":"post/leetcode-199-binary-tree-right-side-view/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-199-binary-tree-right-side-view/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-tree-right-side-view/description/ 标记难度：Medium 提交次数：2/2 代码效率： BFS：100.00% DFS：100.00% 题意 给定一棵二叉树，求每一层最右侧的结点的值。 分析 显然，一种最直接的想法是用BFS对树进行分层遍历，然后就可以立刻得出每一层最右侧的结点的值了。 另一种方法和Leetcode 102的其中一种解题思路很像：使用DFS，然后按照深度把结点放到对应的层里面。但此处的问题是，每一层只需要放最右侧的结点。解决这一问题的方法是，访问子树时，先访问右子结点，再访问左子结点，这样每一层最先被访问到的结点都是最右侧的结点，我们只要在该层为空时才插入结点就可以了。[1] 代码 BFS 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;int&gt; rightSideView(TreeNode* root) &#123; if (root == NULL) return &#123;&#125;; queue&lt;TreeNode*&gt; q; vector&lt;int&gt; rightSide; q.push(root); while (!q.empty()) &#123; int right = -1; // 此处新开了一个队列作为记录，事实上没有必要 // 只要记录本层结点的个数就可以了 queue&lt;TreeNode*&gt; q2; while (!q.empty()) &#123; TreeNode* x = q.front(); q.pop(); right = x-&gt;val; if (x-&gt;left != nullptr) q2.push(x-&gt;left); if (x-&gt;right != nullptr) q2.push(x-&gt;right); &#125; q = q2; rightSide.push_back(right); &#125; return rightSide; &#125;&#125;; DFS 1234567891011121314151617class Solution &#123;private: void dfs(TreeNode* root, int depth, vector&lt;int&gt;&amp; views) &#123; if (root == nullptr) return; // 事实上写的时候是自顶向下的，所以是逐渐push_back if (depth &gt;= views.size()) views.push_back(root-&gt;val); dfs(root-&gt;right, depth+1, views); dfs(root-&gt;left, depth+1, views); &#125;public: vector&lt;int&gt; rightSideView(TreeNode* root) &#123; vector&lt;int&gt; views; dfs(root, 0, views); return views; &#125;&#125;; Simple C++ solution (BTW: I like clean codes) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 111. Minimum Depth of Binary Tree（BFS）","slug":"2018-09-05-Leetcode-111-Minimum-Depth-of-Binary-Tree（BFS）","date":"2018-09-05T11:03:12.000Z","updated":"2018-09-05T11:17:00.000Z","comments":true,"path":"post/leetcode-111-minimum-depth-of-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-111-minimum-depth-of-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-depth-of-binary-tree/description/ 标记难度：Easy 提交次数：2/2 代码效率： BFS：100.00% 递推：100.00% 题意 找出二叉树中深度最小的结点的深度。 分析 显然用BFS可以做，DFS也可以。另一种可能的做法是递推，从子结点的最小深度推出当前子树的最小深度。[1]事实上，我现在觉得，递推是把代码写得简短且不需要额外函数的一种好方法。 代码 BFS 123456789101112131415161718class Solution &#123;public: int minDepth(TreeNode* root) &#123; if (root == nullptr) return 0; queue&lt;pair&lt;int, TreeNode*&gt;&gt; q; q.emplace(1, root); while (!q.empty()) &#123; TreeNode* x = q.front().second; int depth = q.front().first; q.pop(); if (x-&gt;left == nullptr &amp;&amp; x-&gt;right == nullptr) return depth; if (x-&gt;left != nullptr) q.emplace(depth+1, x-&gt;left); // 居然写成了root…… if (x-&gt;right != nullptr) q.emplace(depth+1, x-&gt;right); &#125; return -1; &#125;&#125;; 递推 123456789101112class Solution &#123;public: int minDepth(TreeNode* root) &#123; if (root == nullptr) return 0; int L = minDepth(root-&gt;left), R = minDepth(root-&gt;right); // 如果L,R&gt;0，说明两棵子树都不为空，最浅的叶结点可能在两棵子树中，所以取min // 如果L,R中至少有一个数为0，说明至少有一棵子树为空，最浅的叶结点只能在另一棵子树中，所以取max // 如果L==R==0，说明root就是叶结点，这种情况包含在上一种里 // 因为是子树所以深度要+1 return 1 + ((L &gt; 0 &amp;&amp; R &gt; 0) ? min(L, R) : max(L, R)); &#125;&#125;; 3 lines in Every Language ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 107. Binary Tree Level Order Traversal II（BFS）","slug":"2018-09-04-Leetcode-107-Binary-Tree-Level-Order-Traversal-II（BFS）","date":"2018-09-04T21:38:15.000Z","updated":"2018-09-05T00:35:00.000Z","comments":true,"path":"post/leetcode-107-binary-tree-level-order-traversal-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-107-binary-tree-level-order-traversal-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-tree-level-order-traversal-ii/description/ 标记难度：Easy 提交次数：3/3 代码效率： 递推：0.00% reverse：98.33% 两次DFS：98.33% 题意 返回一棵二叉树自底向上的层次遍历。 分析 这次我用上了Leetcode 429里面的那种递推法。[1]令leftLevels表示当前结点左子树的自底向上层次遍历结果，rightLevels表示当前结点左子树的自底向上层次遍历结果。显然，左右两侧的深度不同，所以我们需要把它们“自顶向下”合并。以leftLevels.size &gt; rightLevels的情形为例： 12345678910111213n1 = leftLevels.size, n2 = rightLevels.sizeleftLevels[0] --&gt; levels[0]leftLevels[1] --&gt; levels[1] . . . . . .leftLevels[n1-n2] + rightLevels[0] --&gt; levels[n1-n2]leftLevels[n1-n2+1] + rightLevels[1] --&gt; levels[n1-n2+1] . . . . . . . . .leftLevels[n1-1] + rightLevels[n2-1] --&gt; levels[n1-1] 当然，我们都知道，最简单的一种方法就是做一次普通的层次遍历，然后把整个vector倒转过来。不过这种解法就很平凡了。[2] 另一种不那么平凡的方法是，首先进行一次DFS，得到树的深度；然后再进行一次DFS，此时我们就可以得到结点在层次遍历中应有的位置，然后直接把结点插入对应的vector中即可。 一个很有趣的问题是，如果vector能够以O(1)时间在头部插入的话，这个问题和正向层次遍历就是正好对偶的了。对于Java用户，他们的函数返回值是List&lt;List&lt;int&gt;&gt;，因此可以通过LinkedList达到一种比较好的效果。[3] 代码 递推 1234567891011121314151617181920class Solution &#123; public: vector&lt;vector&lt;int&gt;&gt; levelOrderBottom(TreeNode* root) &#123; if (root == nullptr) return &#123;&#125;; vector&lt;vector&lt;int&gt;&gt; leftLevels = levelOrderBottom(root-&gt;left); vector&lt;vector&lt;int&gt;&gt; rightLevels = levelOrderBottom(root-&gt;right); int n1 = leftLevels.size(), n2 = rightLevels.size(), n = max(n1, n2); vector&lt;vector&lt;int&gt;&gt; levels(n + 1, vector&lt;int&gt;()); // i表示从数组末端开始的距离，也即对应的层相对root的深度 // 这样表示是因为数组是末端对齐的 for (int i = n; i &gt; 0; i--) &#123; if (n1 - i &gt;= 0) levels[n - i].insert(levels[n - i].end(), leftLevels[n1 - i].begin(), leftLevels[n1 - i].end()); if (n2 - i &gt;= 0) levels[n - i].insert(levels[n - i].end(), rightLevels[n2 - i].begin(), rightLevels[n2 - i].end()); &#125; levels[n].push_back(root-&gt;val); return levels; &#125;&#125;; reverse 12345678910111213141516171819class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; levels; void dfs(TreeNode* root, int depth) &#123; if (root == NULL) return; if (levels.size() &lt;= depth) levels.push_back(&#123;&#125;); levels[depth].push_back(root-&gt;val); dfs(root-&gt;left, depth+1); dfs(root-&gt;right, depth+1); &#125;public: vector&lt;vector&lt;int&gt;&gt; levelOrderBottom(TreeNode* root) &#123; dfs(root, 0); reverse(levels.begin(), levels.end()); return levels; &#125;&#125;; 两次DFS 12345678910111213141516171819202122232425262728class Solution &#123;private: int maxDepth; void getMaxDepth(TreeNode* root, int depth) &#123; if (root == nullptr) return; maxDepth = max(maxDepth, depth); getMaxDepth(root-&gt;left, depth+1); getMaxDepth(root-&gt;right, depth+1); &#125; void dfs(TreeNode* root, int depth, vector&lt;vector&lt;int&gt;&gt;&amp; levels) &#123; if (root == nullptr) return; levels[maxDepth - depth].push_back(root-&gt;val); dfs(root-&gt;left, depth+1, levels); dfs(root-&gt;right, depth+1, levels); &#125;public: vector&lt;vector&lt;int&gt;&gt; levelOrderBottom(TreeNode* root) &#123; maxDepth = -1; getMaxDepth(root, 0); vector&lt;vector&lt;int&gt;&gt; levels(maxDepth+1, vector&lt;int&gt;()); dfs(root, 0, levels); return levels; &#125;&#125;; Easy to understand, recursive solution based on DFS (44 ms, beats 98.67%) ↩︎ C++ 4ms solution! ↩︎ Simple Java solution with LinkedList. ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-firth Search","slug":"alg-Breadth-firth-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-firth-Search/"}]},{"title":"Leetcode 637. Average of Levels in Binary Tree（BFS）","slug":"2018-09-04-Leetcode-637-Average-of-Levels-in-Binary-Tree（BFS）","date":"2018-09-04T20:19:14.000Z","updated":"2018-09-04T20:27:00.000Z","comments":true,"path":"post/leetcode-637-average-of-levels-in-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-637-average-of-levels-in-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/average-of-levels-in-binary-tree/description/ 标记难度：Easy 提交次数：1/2 代码效率：99.60% 题意 计算一棵二叉树每层结点的平均值。 分析 这道题和Leetcode 102差不多，不过那道题是层次遍历，这道题是求每层的平均值。具体做法也差不多，至少可以通过BFS和DFS两种做法完成层次遍历。 不过我又被long long int卡了一次，我真是非常容易忘记这一点。 代码 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;double&gt; averageOfLevels(TreeNode* root) &#123; if (root == nullptr) return &#123;&#125;; vector&lt;double&gt; averages; queue&lt;TreeNode*&gt; q; q.push(root); while (!q.empty()) &#123; // [2147483647,2147483647,2147483647] int size = q.size(); long long int sum = 0; for (int i = 0; i &lt; size; i++) &#123; TreeNode* x = q.front(); q.pop(); sum += x-&gt;val; if (x-&gt;left != nullptr) q.push(x-&gt;left); if (x-&gt;right != nullptr) q.push(x-&gt;right); &#125; averages.push_back((double) sum / size); &#125; return averages; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 102. Binary Tree Level Order Traversal（BFS）","slug":"2018-09-04-Leetcode-102-Binary-Tree-Level-Order-Traversal（BFS）","date":"2018-09-04T19:30:24.000Z","updated":"2018-09-04T20:04:00.000Z","comments":true,"path":"post/leetcode-102-binary-tree-level-order-traversal/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-102-binary-tree-level-order-traversal/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-tree-level-order-traversal/description/ 标记难度：Medium 提交次数：2/2 代码效率： 未优化的DFS：0.00% 优化过的DFS：98.83% 题意 返回一棵二叉树的层次遍历结果。不同层要分开。 分析 这道题和Leetcode 429差不多，那道题是多叉树遍历，这道题是二叉树遍历，似乎还更简单一些。我参考其中DFS的解法写了一份代码，结果很慢，后来我意识到，vector之间的拷贝可能花了太多时间，还不如记录当前结点的深度，然后直接把结点的值放到对应的层里面，于是就快了很多。[1] 代码 未优化的DFS 12345678910111213141516171819class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; if (root == NULL) return &#123;&#125;; vector&lt;vector&lt;int&gt;&gt; level; level.push_back(&#123;root-&gt;val&#125;); vector&lt;TreeNode*&gt; children = &#123;root-&gt;left, root-&gt;right&#125;; for (TreeNode* ch: children) &#123; vector&lt;vector&lt;int&gt;&gt; chLevel = levelOrder(ch); for (int i = 0; i &lt; chLevel.size(); i++) &#123; if (i + 1 &lt; level.size()) level[i + 1].insert(level[i + 1].end(), chLevel[i].begin(), chLevel[i].end()); else level.push_back(chLevel[i]); &#125; &#125; return level; &#125;&#125;; 优化的DFS 12345678910111213141516171819202122class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; levels; // just put the node value in levels[depth] void dfs(TreeNode* root, int depth) &#123; if (root == NULL) return; if (depth &lt; levels.size()) levels[depth].push_back(root-&gt;val); else levels.push_back(&#123;root-&gt;val&#125;); dfs(root-&gt;left, depth+1); dfs(root-&gt;right, depth+1); &#125;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; dfs(root, 0); return levels; &#125;&#125;; Java Solution using DFS ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Leetcode 429. N-ary Tree Level Order Traversal（BFS）","slug":"2018-09-04-Leetcode-429-N-ary-Tree-Level-Order-Traversal（BFS）","date":"2018-09-04T18:49:53.000Z","updated":"2018-09-04T19:46:00.000Z","comments":true,"path":"post/leetcode-429-n-ary-tree-level-order-traversal/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-429-n-ary-tree-level-order-traversal/","excerpt":"","text":"题目来源：https://leetcode.com/problems/n-ary-tree-level-order-traversal/description/ 标记难度：Easy 提交次数：2/3 代码效率： 未优化的BFS：5.07% DFS：36.95% 不同的DFS写法：10.52% 题意 返回一棵多叉树的层次遍历结果。不同层要分开。 分析 直接BFS即可。不过我感觉我有点傻，每一层都新开了一个队列；事实上不需要，只要记录当前层的结点个数就足以判断何时这一层结束了。[1]中间WA了一次，是因为对于空结点应该返回[]，而非[[]]。（我似乎经常在这一点上犯错。） 另一种相对比较神奇的做法是用DFS。此时的核心问题是不同的子结点返回的层次遍历结果的合并：显然，子结点的层次遍历结果总是比当前结点正好低一层。令r = levelOrder(root-&gt;child)，ret表示当前结点的层次遍历结果。显然，r[0]应该与ret[1]合并，r[1]应该与ret[2]合并，以此类推。[2] 看了Java Solution using DFS之后，我重写了一份看起来会跑得更快的DFS，但事实上并没有。 以及，从上述代码里我学习了把一个vector里的内容（而不是整个vector）插入到别的vector里的正确方法[3]： 123// 在 pos 前插入来自范围 [first, last) 的元素。template&lt; class InputIt &gt;void insert( iterator pos, InputIt first, InputIt last); 代码 未优化的BFS 1234567891011121314151617181920212223242526272829303132333435363738394041/*// Definition for a Node.class Node &#123;public: int val = NULL; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(Node* root) &#123; if (root == NULL) return &#123;&#125;; vector&lt;vector&lt;int&gt;&gt; levelOrder; queue&lt;Node*&gt; q1; q1.push(root); while (!q1.empty()) &#123; vector&lt;int&gt; level; queue&lt;Node*&gt; q2; while (!q1.empty()) &#123; Node* x = q1.front(); q1.pop(); level.push_back(x-&gt;val); for (Node* c: x-&gt;children) q2.push(c); &#125; q1 = q2; levelOrder.push_back(level); &#125; return levelOrder; &#125;&#125;; DFS 123456789101112131415161718192021222324252627282930313233/*// Definition for a Node.class Node &#123;public: int val = NULL; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(Node* root) &#123; if (root == NULL) return &#123;&#125;; vector&lt;vector&lt;int&gt;&gt; level; level.push_back(&#123;root-&gt;val&#125;); for (Node* child: root-&gt;children) &#123; vector&lt;vector&lt;int&gt;&gt; chLevel = levelOrder(child); for (int i = 0; i &lt; chLevel.size(); i++) &#123; if (i &lt; level.size() - 1) level[i + 1].insert(level[i + 1].end(), chLevel[i].begin(), chLevel[i].end()); else level.push_back(chLevel[i]); &#125; &#125; return level; &#125;&#125;; 另一种DFS写法 12345678910111213141516171819202122232425262728293031323334/*// Definition for a Node.class Node &#123;public: int val = NULL; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125;&#125;;*/class Solution &#123;private: void dfs(Node* root, int depth, vector&lt;vector&lt;int&gt;&gt;&amp; levels) &#123; if (root == NULL) return; if (depth &lt; levels.size()) levels[depth].push_back(root-&gt;val); else levels.push_back(&#123;root-&gt;val&#125;); for (Node* ch: root-&gt;children) dfs(ch, depth+1, levels); &#125;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(Node* root) &#123; vector&lt;vector&lt;int&gt;&gt; levels; dfs(root, 0, levels); return levels; &#125;&#125;; Basic C++ solution using queue. Super easy for beginners. ↩︎ Easy to understand, recursive solution based on DFS (44 ms, beats 98.67%) ↩︎ std::vector::insert ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Breadth-firth Search","slug":"alg-Breadth-firth-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-firth-Search/"}]},{"title":"Leetcode 146. LRU Cache（链表+map）","slug":"2018-09-04-Leetcode-146-LRU-Cache（链表-map）","date":"2018-09-04T15:14:43.000Z","updated":"2018-09-04T16:00:00.000Z","comments":true,"path":"post/leetcode-146-lru-cache/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-146-lru-cache/","excerpt":"","text":"题目来源：https://leetcode.com/problems/merge-two-sorted-lists/description/ 标记难度：Hard 提交次数：1/1 代码效率： 手写链表+map：92.93% list+map：33.54% 题意 实现一个LRU缓存的功能。 分析 这个问题的标准答案显然是： 用一个map&lt;int, int&gt;维护(key, value)对 用一个双向链表维护访问顺序 用一个map&lt;int, Node*&gt;查询key在链表中对应的结点 然后具体操作是： 查询：在map&lt;int, int&gt;中查询有没有这个key，如果找到了，则在map&lt;int, Node*&gt;中找到它对应的Node*，在链表中把它的位置移到链表最前面 插入： 如果不需要删除旧结点，则新建一个Node*，把它插入到链表最前面；维护map&lt;int, int&gt;和map&lt;int, Node*&gt; 如果需要删除旧结点，则把链表最末端的Node*取出来并删掉，得到对应的key，在两个map中删除对应元素；然后再插入新结点 手写一个双向链表并不难，不过更好的方法是利用std::list，我之前从未用过。list满足链表的一般性质，也就是迭代器只会因为删除而失效，不会因为其他原因失效。[1] 代码 手写list 一个事实是，在使用了哨兵结点head和tail之后，在deleteNode、insertBefore和insertAfter函数中，其实都不需要检查空结点了。[2] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class LRUCache &#123;private: struct Node &#123; int key; Node* prev; Node* next; Node(int k) &#123; key = k; prev = next = nullptr; &#125; &#125;; void deleteNode(Node* node) &#123; Node* prev = node-&gt;prev; Node* next = node-&gt;next; if (prev != nullptr) prev-&gt;next = next; if (next != nullptr) next-&gt;prev = prev; &#125; void insertBefore(Node* node, Node* i) &#123; Node* prev = node-&gt;prev; if (prev != nullptr) prev-&gt;next = i; i-&gt;prev = prev; i-&gt;next = node; node-&gt;prev = i; &#125; void insertAfter(Node* node, Node* i) &#123; Node* next = node-&gt;next; if (next != nullptr) next-&gt;prev = i; i-&gt;prev = node; i-&gt;next = next; node-&gt;next = i; &#125; void moveToFront(Node* node) &#123; deleteNode(node); insertAfter(head, node); &#125; int capacity; int num; unordered_map&lt;int, int&gt; valMap; unordered_map&lt;int, Node*&gt; nodeMap; Node* head; Node* tail;public: LRUCache(int capacity) &#123; this-&gt;capacity = capacity; num = 0; head = new Node(-1); tail = new Node(-1); head-&gt;next = tail; tail-&gt;prev = head; &#125; int get(int key) &#123; auto i = valMap.find(key); if (i == valMap.end()) return -1; moveToFront(nodeMap[key]); return i-&gt;second; &#125; void put(int key, int value) &#123; if (valMap.find(key) != valMap.end()) &#123; valMap[key] = value; moveToFront(nodeMap[key]); &#125; else &#123; if (num &lt; capacity) &#123; Node* node = new Node(key); nodeMap[key] = node; valMap[key] = value; insertAfter(head, node); num++; &#125; else &#123; // evict out a least used one Node* node = tail-&gt;prev; deleteNode(node); nodeMap.erase(node-&gt;key); valMap.erase(node-&gt;key); node-&gt;key = key; nodeMap[key] = node; valMap[key] = value; insertAfter(head, node); &#125; &#125; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache obj = new LRUCache(capacity); * int param_1 = obj.get(key); * obj.put(key,value); */ STL list 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class LRUCache &#123;private: int capacity; int num; unordered_map&lt;int, int&gt; valMap; unordered_map&lt;int, list&lt;int&gt;::iterator&gt; posMap; list&lt;int&gt; orderList; void moveToFront(int key) &#123; orderList.erase(posMap[key]); orderList.push_front(key); posMap[key] = orderList.begin(); &#125;public: LRUCache(int capacity) &#123; this-&gt;capacity = capacity; num = 0; &#125; int get(int key) &#123; auto i = valMap.find(key); if (i == valMap.end()) return -1; moveToFront(key); return i-&gt;second; &#125; void put(int key, int value) &#123; if (valMap.find(key) != valMap.end()) &#123; valMap[key] = value; moveToFront(key); &#125; else &#123; if (num &lt; capacity) &#123; valMap[key] = value; orderList.push_front(key); posMap[key] = orderList.begin(); num++; &#125; else &#123; // evict out a least used one int evict = orderList.back(); orderList.pop_back(); valMap.erase(evict); posMap.erase(evict); valMap[key] = value; orderList.push_front(key); posMap[key] = orderList.begin(); &#125; &#125; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache obj = new LRUCache(capacity); * int param_1 = obj.get(key); * obj.put(key,value); */ C++11 code 74ms - Hash table + List ↩︎ Hashtable + Double linked list (with a touch of pseudo nodes) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Linked List","slug":"alg-Linked-List","permalink":"https://zhanghuimeng.github.io/tags/alg-Linked-List/"}]},{"title":"Codeforces 1037D. Valid BFS?（BFS）","slug":"2018-09-03-Codeforces-1037D-Valid-BFS-（BFS）","date":"2018-09-03T18:59:19.000Z","updated":"2018-09-03T21:17:00.000Z","comments":true,"path":"post/codeforces-1037d-valid-bfs/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1037d-valid-bfs/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1037/problem/D 提交次数：2/3 题意 给定一棵结点编号从1到n的无根树，以及一个BFS序列，问该BFS序列是否为合法的树的BFS序列。保证BFS算法必从结点1开始，但BFS序列的第一个结点未必是1。 分析 比赛的时候我想了一种模拟的算法，经过一定的debug之后过了pretest，但后来在大数据量下超时了。 模拟算法 我的模拟算法很简单： 对每个结点，记录它是否已被访问（visited[x]）、已被访问的邻居个数（count[x]），以及总邻居个数（degree[x]） 用一个队列维护已被访问，但是邻居尚未都被访问的结点 验证BFS序列的第一个结点为1，visited[1] = true，并将1入队 顺序枚举BFS序列的其他结点y： 验证visited[y] == false 将队列中满足count[x] == degree[x]的结点全部弹出，直到得到第一个还有邻居未被访问的结点x 验证y是x的邻居 count[x]++，count[y] = 1（因为y的邻居x已经被访问过了），并将y入队 问题是如何验证y是x的邻居。如果直接在邻接表中顺序查找，则在最坏情况下（1有n-1个孩子）上述算法的复杂度是O(n^2)，对于n = 200000的数据显然是过不了的。所以要把邻接表排序，然后用二分查找在里面寻找元素，这样复杂度在最坏情况下也降低到了O(n * log(n))。 构造算法 题解[1]中给出了另一种构造算法： 将每个结点的邻居按它们在BFS序列中出现的顺序排序 按上述排序之后的顺序进行一次BFS 比较两次BFS得到的结点序列是否相同 这种做法的正确性在于，事实上，决定BFS结果的是访问每个结点的子结点的顺序，而这一访问顺序和在BFS中出现的顺序显然是相同的。[2] 排序的时间复杂度最坏是O(n * log(n))，BFS的时间是O(n)，总时间复杂度和上一种差不多，但写出来的代码比上一种简洁很多。 代码 模拟算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;int main() &#123; int n, x, y; cin &gt;&gt; n; vector&lt;vector&lt;int&gt;&gt; graph(n + 1, vector&lt;int&gt;()); int bfs[n + 1]; int marked[n + 1]; bool visited[n + 1]; queue&lt;int&gt; q; for (int i = 1; i &lt; n; i++) &#123; scanf(\"%d %d\", &amp;x, &amp;y); graph[x].push_back(y); graph[y].push_back(x); &#125; // 邻接表排序 for (int i = 1; i &lt;= n; i++) sort(graph[i].begin(), graph[i].end()); for (int i = 0; i &lt; n; i++) scanf(\"%d\", &amp;bfs[i]); if (bfs[0] != 1) &#123; cout &lt;&lt; \"No\" &lt;&lt; endl; return 0; &#125; memset(marked, 0, sizeof(marked)); memset(visited, 0, sizeof(visited)); visited[1] = true; q.push(1); bool ok = true; for (int i = 1; i &lt; n; i++) &#123; int x; if (q.empty()) &#123; ok = false; break; &#125; while (!q.empty()) &#123; x = q.front(); if (marked[x] == graph[x].size()) q.pop(); else break; &#125; int y = bfs[i]; if (visited[y]) &#123; ok = false; break; &#125; visited[y] = true; // 寻找孩子结点 auto idx = lower_bound(graph[x].begin(), graph[x].end(), y); if (idx == graph[x].end() || *idx != y) &#123; ok = false; break; &#125; marked[x]++; marked[y] = 1; q.push(y); &#125; if (!ok) cout &lt;&lt; \"No\" &lt;&lt; endl; else cout &lt;&lt; \"Yes\" &lt;&lt; endl; return 0;&#125; 构造算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 参考：https://codeforces.com/contest/1037/submission/42406857#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;vector&lt;int&gt; adj[200005];int bfs[200005];int ans[200005];int pos[200005];bool visited[200005];int cmp(int x, int y) &#123; return pos[x] &lt; pos[y];&#125;int main() &#123; int n, x, y; ios_base::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); cin &gt;&gt; n; for (int i = 1; i &lt; n; i++) &#123; cin &gt;&gt; x &gt;&gt; y; adj[x].push_back(y); adj[y].push_back(x); &#125; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; bfs[i]; pos[bfs[i]] = i; &#125; // 按结点出现顺序为邻接表排序 for (int i = 1; i &lt;= n; i++) sort(adj[i].begin(), adj[i].end(), cmp); // 普通的BFS int m = 0; queue&lt;int&gt; q; visited[1] = true; q.push(1); ans[m++] = 1; while (!q.empty()) &#123; int x = q.front(); q.pop(); for (int child: adj[x]) if (!visited[child]) &#123; visited[child] = true; ans[m++] = child; q.push(child); &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if (ans[i] != bfs[i]) &#123; cout &lt;&lt; \"No\" &lt;&lt; endl; return 0; &#125; &#125; cout &lt;&lt; \"Yes\" &lt;&lt; endl; return 0;&#125; Manthan, Codefest’18, IIT (BHU) Editorial ↩︎ 官方代码 ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Breadth-first Search","slug":"alg-Breadth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Breadth-first-Search/"}]},{"title":"Codeforces 1037C. Equalize（贪心）","slug":"2018-09-03-Codeforces-1037C-Equalize（贪心）","date":"2018-09-03T18:34:42.000Z","updated":"2018-09-03T18:45:00.000Z","comments":true,"path":"post/codeforces-1037c-equalize/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1037c-equalize/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1037/problem/C 提交次数：1/2 题意 给定两个长度相同的只含有0和1的串a和串b，可以对a进行下列两种操作之一： 交换i和j处的位，代价为|i - j| 将一位翻转，代价为1 问对a执行操作使它变成b的最小代价是多少。 分析 这道题足够简单，所以很快一遍过了。 很显然交换位的代价太大了，只有当两个需要交换的位相邻的时候，代价才比分别翻转这两个位小。所以我就先扫描了一遍a，将所有适合交换的相邻（这两位不同，且与b中对应位都不同）交换，然后再扫描一遍，翻转所有不同的位。 当然事实上扫描一遍就够了。[1]顺序考虑每一位： 如果这一位和下一位可以交换，sum++，直接跳过下一位 如果不能交换，翻转这一位，sum++ 以及，从题解里发现了加速ostream的方法，即取消和stdio的同步： 1ios_base::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); 代码 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;char a[1000005];char b[1000005];int main() &#123; int n; scanf(\"%d\", &amp;n); scanf(\"%s\", a); scanf(\"%s\", b); int sum = 0; for (int i = 1; i &lt; n; i++) &#123; if (a[i-1] != b[i-1] &amp;&amp; a[i] != b[i] &amp;&amp; a[i-1] != a[i]) &#123; swap(a[i], a[i-1]); sum++; &#125; &#125; for (int i = 0; i &lt; n; i++) if (a[i] != b[i]) sum++; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125; https://codeforces.com/contest/1037/submission/42406848 ↩︎","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1037B. Reach Median（贪心）","slug":"2018-09-03-Codeforces-1037B-Reach-Median（贪心）","date":"2018-09-03T16:36:25.000Z","updated":"2018-09-03T16:51:00.000Z","comments":true,"path":"post/codeforces-1037-b-reach-median/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1037-b-reach-median/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1037/problem/B 提交次数：1/2 题意 给定n（保证n为奇数）个正数和s，要求修改这些数的数值，使得这n个数的中位数是s，问数值变化的绝对值总和最小是多少。 分析 比赛的时候我自以为想出了正确的思路，然后交上去了，结果连pretest都没过。一个小时之后，我突然灵光一闪：原题可没有保证输出的数据范围，也没要求取模。于是我把int改成long long int，重新交上去了，这回就过了。 首先把数组排个序，然后就可以得到现在的中位数了，记为mid。如果mid == s，那么不用做任何改变。但如果mid != s，通过一些修改，把当前的mid变成s，仍然是最好的方法。若mid &lt; s，则把mid改成s，并把所有满足mid &lt;= x &lt; s的x也改成s，保证现在的mid仍为中位数；若mid &gt; s，则把mid改成s，并把所有满足s &lt; x &lt;= mid的x也改成s，保证现在的mid仍为中位数。 代码 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;int a[200000], n, s;int main() &#123; scanf(\"%d %d\", &amp;n, &amp;s); for (int i = 0; i &lt; n; i++) scanf(\"%d\", &amp;a[i]); sort(a, a + n); // 实际上不需要显式地计算lower和upper，遍历一遍即可 // 甚至只遍历半遍也可以，因为两侧是对称的 // 参考标答： // https://codeforces.com/contest/1037/submission/42406891 int lower = lower_bound(a, a + n, s) - a; int upper = upper_bound(a, a + n, s) - a; int mid = n / 2; // [lower, upper) long long int sum = 0; if (lower &lt;= mid &amp;&amp; mid &lt; upper) &#123; sum = 0; &#125; else if (mid &lt; lower) &#123; for (int i = mid; i &lt; lower; i++) sum += s - a[i]; &#125; else &#123; for (int i = upper; i &lt;= mid; i++) sum += a[i] - s; &#125; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Codeforces 1037A. Packets（数学），及比赛（Codefest 18）总结","slug":"2018-09-03-Codeforces-1037A-Packets（数学），及比赛（Codefest-18）总结","date":"2018-09-03T16:14:53.000Z","updated":"2018-09-03T16:33:00.000Z","comments":true,"path":"post/codeforces-1037a-packets-and-contest-codefest-18/","link":"","permalink":"https://zhanghuimeng.github.io/post/codeforces-1037a-packets-and-contest-codefest-18/","excerpt":"","text":"题目来源：https://codeforces.com/contest/1037/problem/A 提交次数：1/1 题意 给定n枚一元硬币，要求把硬币分成若干包，使得任意1 &lt;= x &lt;= n的钱数都可以用这些硬币包表示出来。问硬币包的最小数量。 分析 这次比赛一共有8道题，其中大概前4题是比较简单的。比赛的时候我过了前4题的pretest，后来第4题没过全部的测试点，因为超时了。最后我的排名是2219 / 7396，rating增加了1，从1500变成了1501。（。。。） 这次暂时还没有时间和心情体验Hack机制。 从直觉上来说，显然用二进制的方式来构造硬币包比较好。所以不妨找到最大的的kkk，满足1+2+...+2k≤n1 + 2 + ... + 2^k \\leq n1+2+...+2k≤n。这样，这kkk个硬币包就可以表示[1,2k+1−1][1, 2^{k+1} - 1][1,2k+1−1]范围内的所有数了。然后把剩下的所有硬币打包成大小为n−2k+1+1n - 2^{k+1} + 1n−2k+1+1的包。这样，[2k+1,n][2^{k+1}, n][2k+1,n]范围内的数就可以用刚才剩下的那个包+二进制硬币包来表示了。 不知道如何证明这个方法是最优的，虽然直觉上就是这样。 代码 1234567891011121314151617#include &lt;iostream&gt;using namespace std;int main() &#123; int n; cin &gt;&gt; n; int i = 1, cnt = 0; while (n != 0) &#123; if (i &gt; n) break; n -= i; cnt++; i *= 2; &#125; if (n != 0) cnt++; cout &lt;&lt; cnt &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"https://zhanghuimeng.github.io/tags/Codeforces/"},{"name":"Codeforces Contest","slug":"Codeforces-Contest","permalink":"https://zhanghuimeng.github.io/tags/Codeforces-Contest/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 662. Maximum Width of Binary Tree（树）","slug":"2018-09-03-Leetcode-662-Maximum-Width-of-Binary-Tree（树）","date":"2018-09-03T14:47:02.000Z","updated":"2018-09-03T15:28:00.000Z","comments":true,"path":"post/leetcode-662-maximum-width-of-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-662-maximum-width-of-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/maximum-width-of-binary-tree/description/ 标记难度：Medium 提交次数：2/3 代码效率：100.00% 题意 计算二叉树的最大宽度。“宽度”指的是，把树中所有空的位置都用null填上，填成一棵完全二叉树之后，树上同层的两个非空结点之间的最大距离。题目保证答案在32位有符号整数范围内。 分析 很显然，这个要求和二叉树的数组表示很相似，所以可以为每个结点计算一个pos：根结点的pos = 1，每个结点的左子结点的left.pos = pos*2 + 1，右子结点的right.pos = pos*2 + 2。然后用DFS或BFS统计每一层的最小和最大pos，记录最大的宽度。 这个方法看起来很好，但是有一点微小的问题，就是数据范围。看到题目里的保证之后，我就自以为聪明地把pos都换成long long int类型的了，觉得这样就能保证结果不溢出了。结果仍然有一个点没过，因为这个测试点长这个样子： 1[0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,null,0,... 也就是一条很长的不断向右延伸的链。在这种情况下，pos连long long int都会溢出，变成负数。 后来我修改了一下代码的写法，过了这个测试点，但我感觉还可能会有更极端的情形出现。一种更好的做法可能是重设每一层的pos。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: struct Node &#123; TreeNode* treeNode; int depth; long long int pos; Node(TreeNode* x, int d, int p): treeNode(x), depth(d), pos(p) &#123; &#125; &#125;;public: int widthOfBinaryTree(TreeNode* root) &#123; if (root == NULL) return 0; queue&lt;Node&gt; q; q.push(Node(root, 0, 1)); int curDepth = 0; long long int ans = -1; while (!q.empty()) &#123; long long int left = -1, right = -1; while (!q.empty() &amp;&amp; q.front().depth == curDepth) &#123; Node node = q.front(); q.pop(); if (left == -1) left = node.pos; right = node.pos; // 重设本层的pos // node.pos -= left - 1; if (node.treeNode-&gt;left != NULL) q.push(Node(node.treeNode-&gt;left, curDepth+1, node.pos*2+1)); if (node.treeNode-&gt;right != NULL) q.push(Node(node.treeNode-&gt;right, curDepth+1, node.pos*2+2)); &#125; // 居然爆long long了 // cout &lt;&lt; left &lt;&lt; ' ' &lt;&lt; right &lt;&lt; endl; ans = max(ans, right - left + 1); curDepth++; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"}]},{"title":"Leetcode 865. Smallest Subtree with all the Deepest Nodes（递推）","slug":"2018-09-03-Leetcode-865-Smallest-Subtree-with-all-the-Deepest-Nodes（递推）","date":"2018-09-03T13:43:06.000Z","updated":"2018-09-03T14:39:06.000Z","comments":true,"path":"post/leetcode-865-smallest-subtree-with-all-the-deepest-nodes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-865-smallest-subtree-with-all-the-deepest-nodes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/smallest-subtree-with-all-the-deepest-nodes/description/ 标记难度：Medium 提交次数：3/3 代码效率： 两遍递归：61.92% 一遍递归：64.44% 题意 找出包含了树中所有深度最大的结点的最深的子树。 分析 一种简单的思路是，首先通过一遍深度优先搜索找出所有深度最大的结点的个数，然后再通过一遍深度优先搜索，计算左右子树中深度最大的结点的总个数，如果已经包含了所有最深的结点，则当前结点符合要求。因为是DFS，所以找到的第一个结点就是深度最大的子树的根。 但事实上我们可以通过递推的方法只进行一遍DFS。令f(root) = (depth, deepestTreeNode)，其中depth表示在以root为根的子树中最深的结点的深度，deepestTreeNode表示在该子树中，包含了所有最深的结点的最深的子树。然后就可以递推了： f(root.left).depth &gt; f(root.right).depth时，说明最深的结点在左子树中，f(root) = (f(root.left).depth+1, f(root.left).deepestTreeNode) f(root.left).depth &lt; f(root.right).depth时，说明最深的结点在右子树中，f(root) = (f(root.right).depth+1, f(root.right).deepestTreeNode) f(root.left).depth = f(root.right).depth时，说明两棵子树中都有最深的结点，f(root) = (f(root.left).depth+1, root) 最后返回的结果是f(root).deepestTreeNode。[1] 值得注意的是，在上述解法中，是以root为根计算深度的，而非绝对深度；当然用相对整棵树的绝对深度去做也可以，具体代码差不多，就不再列出了。 代码 两遍递归 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int maxDepth; int maxNum; void findMaxDepth(TreeNode* root, int depth) &#123; if (root == NULL) return; if (depth == maxDepth) maxNum++; else if (depth &gt; maxDepth) &#123; maxDepth = depth; maxNum = 1; &#125; findMaxDepth(root-&gt;left, depth + 1); findMaxDepth(root-&gt;right, depth + 1); &#125; TreeNode* father; int maxDepthNum(TreeNode* root, int depth) &#123; if (root == NULL) return 0; int sum = maxDepthNum(root-&gt;left, depth + 1) + maxDepthNum(root-&gt;right, depth + 1); if (father != NULL) return 0; if (depth == maxDepth) sum++; if (sum == maxNum) father = root; return sum; &#125;public: TreeNode* subtreeWithAllDeepest(TreeNode* root) &#123; maxDepth = 0; maxNum = 0; findMaxDepth(root, 0); // cout &lt;&lt; maxDepth &lt;&lt; ' ' &lt;&lt; maxNum &lt;&lt; endl; father = NULL; maxDepthNum(root, 0); return father; &#125;&#125;; 一遍递归 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123; // depth, deepestTree typedef pair&lt;int, TreeNode*&gt; Node;private: Node dfs(TreeNode* root) &#123; if (root == NULL) return &#123;0, NULL&#125;; Node leftNode(dfs(root-&gt;left)); Node rightNode(dfs(root-&gt;right)); if (leftNode.first &lt; rightNode.first) return &#123;rightNode.first+1, rightNode.second&#125;; if (leftNode.first &gt; rightNode.first) return &#123;leftNode.first+1, leftNode.second&#125;; return &#123;leftNode.first+1, root&#125;; &#125;public: TreeNode* subtreeWithAllDeepest(TreeNode* root) &#123; Node node(dfs(root)); return node.second; &#125;&#125;; One pass ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"},{"name":"alg:Recursion","slug":"alg-Recursion","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursion/"}]},{"title":"SGU 123. The sum","slug":"2018-09-03-SGU-123-The-sum","date":"2018-09-03T00:40:49.000Z","updated":"2018-09-03T13:37:00.000Z","comments":true,"path":"post/sgu-123-the-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/sgu-123-the-sum/","excerpt":"","text":"题目来源：http://codeforces.com/problemsets/acmsguru/problem/99999/123 提交次数：2/2 题意 求斐波那契数列前K项的和（0&lt;K&lt;41）。 分析 对于这个数量级的K，直接计算就可以了。当然，还有一些更快速的算法： 利用矩阵快速幂算法，可以用O(log(K))的复杂度求FnF_nFn​ 利用Binet公式：Fn=(1+52)n−(1−52)n5F_n = \\frac{(\\frac{1 + \\sqrt{5}}{2})^n - (\\frac{1 - \\sqrt{5}}{2})^n}{\\sqrt{5}}Fn​=5​(21+5​​)n−(21−5​​)n​，不过考虑到计算精度等问题，可能不是很好 求和事实上也是有公式的：∑i=1nFi=F(n+2)−1\\sum_{i=1}^{n} F_i = F(n+2) - 1∑i=1n​Fi​=F(n+2)−1 公式的推导过程如下[1]： 12345678F(n) = F(n+2) - F(n+1)F(n-1) = F(n+1) - F(n). . .. . .. . .F(1) = F(3) - F(2)------------------------------------------sum = F(n+2) - F(2) .... adding all equations 这样求和的时间复杂度也可以降低到O(log(n))。 代码 枚举版本 12345678910111213141516#include &lt;iostream&gt;using namespace std;int main() &#123; int k; cin &gt;&gt; k; int s = 0; int f1 = 0, f2 = 1; for (int i = 0; i &lt; k; i++) &#123; s += f2; int tmp = f1; f1 = f2; f2 += tmp; &#125; cout &lt;&lt; s &lt;&lt; endl; return 0;&#125; 快速幂版本 写这个代码的过程中，我再次深刻体会到了这一点：在非必要的情况下，尽量不要使用C的指针、析构函数、拷贝构造函数、运算符重载等特性，这是在玩火。（也许用C开发大型程序对我来说本身就是玩火。） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;struct Matrix &#123; int n, m; long long int a[10][10]; Matrix(int x, int y) &#123; n = x; m = y; memset(a, 0, sizeof(a)); &#125; friend Matrix operator * (const Matrix&amp; m1, const Matrix&amp; m2) &#123; int nn = m1.n, mm = m2.m; Matrix m3(nn, mm); for (int i = 0; i &lt; nn; i++) for (int j = 0; j &lt; m1.m; j++) for (int k = 0; k &lt; mm; k++) m3.a[i][k] += m1.a[i][j] * m2.a[j][k]; return m3; &#125; friend ostream&amp; operator &lt;&lt; (ostream&amp; out, const Matrix&amp; m1) &#123; for (int i = 0; i &lt; m1.n; i++) &#123; for (int j = 0; j &lt; m1.m; j++) out &lt;&lt; m1.a[i][j] &lt;&lt; ' '; out &lt;&lt; endl; &#125; return out; &#125;&#125;;int main() &#123; int K; cin &gt;&gt; K; Matrix power(2, 2), basic(2, 2), f(2, 1); power.a[0][1] = power.a[1][0] = power.a[1][1] = 1; basic.a[0][0] = basic.a[1][1] = 1; f.a[1][0] = 1; K++; int i = 1; while (i &lt;= K) &#123; if ((i &amp; K) != 0) basic = basic * power; i &lt;&lt;= 1; power = power * power; &#125; f = basic * f; cout &lt;&lt; f.a[1][0] - 1 &lt;&lt; endl; return 0;&#125; What is the sum of n terms of a Fibonacci series? ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"SGU","slug":"SGU","permalink":"https://zhanghuimeng.github.io/tags/SGU/"}]},{"title":"Leetcode 394. Decode String（栈）","slug":"2018-09-02-Leetcode-394-Decode-String（栈）","date":"2018-09-02T20:25:12.000Z","updated":"2018-09-02T21:49:00.000Z","comments":true,"path":"post/leetcode-394-decode-string/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-394-decode-string/","excerpt":"","text":"题目来源：https://leetcode.com/problems/decode-string/description/ 标记难度：Medium 提交次数：1/1 代码效率： 递归版本：100.00% 栈版本：100.00% 正则表达式版本：0.00% 题意 给定一个形如&quot;3[a2[c]]&quot;的字符串，要求将其展开为accaccacc格式。 分析 递归寻找[]中间的字符串，将其递归展开后，将返回的字符串重复规定的次数。大致就是这么一个思路。我觉得需要注意的细节包括： 注意一些不需要递归展开的部分 注意字符串操作中的边界 用递归的方法相当于用栈。也许用栈直接做会更直接和节省时间一些。[1] 另一种神奇的做法是用正则表达式，直接找出形如cnt[str]的字符串并展开。[2]我尝试用C++写了一下，发现效率比较低，但这种想法是很妙的。 代码 递归版本 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;private: bool isDigit(char x) &#123; return '0' &lt;= x &amp;&amp; x &lt;= '9'; &#125;public: string decodeString(string s) &#123; if (s.length() == 0) return \"\"; int leftBrackets = 0, rightBrackets = 0, k = 0, start = -1, end = -1; string startStr, multStr, addStr; int i = 0, n = s.length(); while (!isDigit(s[i]) &amp;&amp; s[i] != '[' &amp;&amp; i &lt; n) i++; if (i &gt;= n) return s; startStr = s.substr(0, i); while (isDigit(s[i]) &amp;&amp; i &lt; n) &#123; k = k * 10 + s[i] - '0'; i++; &#125; start = i; while ((leftBrackets == 0 || leftBrackets != rightBrackets) &amp;&amp; i &lt; n) &#123; if (s[i] == '[') leftBrackets++; if (s[i] == ']') rightBrackets++; i++; &#125; end = i - 1; // cout &lt;&lt; \"s=\" &lt;&lt; s &lt;&lt; \" k=\" &lt;&lt; k &lt;&lt; \" startStr=\" &lt;&lt; startStr &lt;&lt; \" start=\" &lt;&lt; start &lt;&lt; \" end=\" &lt;&lt; end &lt;&lt; endl; multStr = s.substr(start + 1, end - start - 1); addStr = s.substr(i, n - i); multStr = decodeString(multStr); addStr = decodeString(addStr); string str(startStr); for (int i = 0; i &lt; k; i++) str += multStr; str += addStr; return str; &#125;&#125;; 栈版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123;public: string decodeString(string s) &#123; // 把这两个栈分开的思路不错 stack&lt;int&gt; cntStack; stack&lt;string&gt; strStack; int cnt = 0; string str; for (char ch: s) &#123; if ('0' &lt;= ch &amp;&amp; ch &lt;= '9') &#123; cnt = cnt * 10 + ch - '0'; // 把之前不在重复范围内的字符串入栈 if (str.length() != 0) &#123; strStack.push(str); str = \"\"; &#125; &#125; else if (ch == '[') &#123; cntStack.push(cnt); cnt = 0; strStack.push(\"[\"); // 需要了解右括号对应的范围 &#125; else if (ch == ']') &#123; // 把范围内的字符串都弹出来，可能有不止一块 while (true) &#123; if (strStack.top() == \"[\") &#123; strStack.pop(); break; &#125; str = strStack.top() + str; strStack.pop(); &#125; cnt = cntStack.top(); cntStack.pop(); string rep; for (int i = 0; i &lt; cnt; i++) rep += str; cnt = 0; str = \"\"; strStack.push(rep); &#125; else str += ch; &#125; while (!strStack.empty()) &#123; str = strStack.top() + str; strStack.pop(); &#125; return str; &#125;&#125;; 正则表达式版本 12345678910111213141516class Solution &#123;public: string decodeString(string s) &#123; smatch m; regex r(\"(\\\\d+)\\\\[([^\\\\[^\\\\]]*)\\\\]\"); while (regex_search(s, m, r)) &#123; int cnt = stoi(m.format(\"$1\")); string str = m.format(\"$2\"); string rep; for (int i = 0; i &lt; cnt; i++) rep += str; s = m.prefix().str() + rep + m.suffix().str(); &#125; return s; &#125;&#125;; Simple Java Solution using Stack ↩︎ 3 lines Python, 2 lines Ruby, regular expression ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Recursive","slug":"alg-Recursive","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursive/"}]},{"title":"Leetcode 899. Orderly Queue","slug":"2018-09-02-Leetcode-899-Orderly-Queue","date":"2018-09-02T17:41:14.000Z","updated":"2018-09-02T20:17:00.000Z","comments":true,"path":"post/leetcode-899-orderly-queue/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-899-orderly-queue/","excerpt":"","text":"题目来源：https://leetcode.com/problems/orderly-queue/description/ 标记难度：Hard 提交次数：1/1 代码效率：4ms 题意 给定一个字符串和正整数K，可以对该字符串进行任意次下列操作：将字符串的前K的字符之一移动到字符串最后。求上述操作所能得到的字典序最小的字符串。 分析 在比赛的时候我尝试做了一下这道题，感觉暴力应该时间复杂度太高，贪心或者动态规划的方法一时又想不出来。我尝试手动模拟一个长度为5的字符串的暴力结果（K=2），但没有模拟完。 其实暴力的做法对于一些较小的数据是有用的，用处不在于解题，而在于观察结果。[1] 如果真的把所有的结果都列出来了（虽然对于长度为5的字符串，5!=120，还是太大了，不适合手动模拟），就会发现，K=2时，这种操作可以得到字母的所有可能排列。事实上，当K&gt;=2时，上述移动操作相当于可以任意交换字符串中相邻的两个字母，也就是相当于冒泡排序。所以K&gt;=2时，只需将字符串排序即可。K=1时，可以将字符串循环枚举一遍。[2] 代码 123456789101112131415class Solution &#123;public: string orderlyQueue(string S, int K) &#123; if (K &gt; 1) &#123; sort(S.begin(), S.end()); return S; &#125; set&lt;string&gt; smallSet; for (int i = 0; i &lt; S.length(); i++) &#123; smallSet.insert(S); S = S.substr(1, S.length() - 1) + S[0]; &#125; return *smallSet.begin(); &#125;&#125;; Leetcode 899 Solution ↩︎ K&gt;1 is bubblesort ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"}]},{"title":"Leetcode 898. Bitwise ORs of Subarrays（DP）","slug":"2018-09-02-Leetcode-898-Bitwise-ORs-of-Subarrays（DP）","date":"2018-09-02T15:32:33.000Z","updated":"2018-09-02T16:19:00.000Z","comments":true,"path":"post/leetcode-898-bitwise-ors-of-subarrays/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-898-bitwise-ors-of-subarrays/","excerpt":"","text":"题目来源：https://leetcode.com/problems/bitwise-ors-of-subarrays/description/ 标记难度：Medium 提交次数：1/2 代码效率： 暴力：过不了 优化过的暴力：796ms 题意 给定一个正整数数组，求其中（连续）子序列的或总共有多少种可能取值。 分析 我也不知道这道题做了多久，总之首先就看错题了（把“或”看成了“异或”），做出来是不太可能的了。其次当时Leetcode服务器大概比较爆炸，平均5分钟才能运行一次。 记数组为A，显然我们的目标就是求出所有or(i, j) = A[i] | ... | A[j] (i &lt;= j)的可能取值。如果直接暴力计算，则复杂度为O(N^3)。一个显而易见的优化是，对于当前的j，我们可以维护一个数组，其中保存了所有以j结尾的子序列的取值；or(0, j), or(1, j), ..., or(j, j)的值；对于j+1，我们可以通过这些值递推出所有以j+1结尾的子序列的取值：or(0, j+1)=or(0, j)|A[j+1], or(1, j+1)=or(1, j)|A[j+1], ... or(j, j+1)=or(j, j)|A[j+1], or(j+1, j+1)=A[j+1]。于是复杂度降低到O(N^2)。 （也许我可以推导到这一步，但是后来我信心丧失直接去看题解了） 然后是一个信仰之跃：我们要利用一下或操作的性质，在一个或和中不断或上新的数值，其二进制表示中1的数量不会减少。刚才维护的子序列除了能够递推之外，还满足一个很好的性质：or(0, j) = or(1, j) | A[0] = ... = or(j, j) | A[0] | A[1] | .. | A[j-1]；因此，cnt1(or(0, j)) &gt;= cnt1(or(1, j)) &gt;= ... &gt;= cnt1(or(j, j))，且同一位置上的1出现后就不会消失。而题目给定了0 &lt;= A[i] &lt;= 10^9，所以这些数的二进制位最多只有30个。 这也就说明，以j结尾的所有子序列的或和的取值最多只有30种。 所以只需把上述保存以j结尾的子序列的或和的数组改成HashSet，然后维护这个HashSet中的值，就可以得到O(30N)的复杂度。 （上述内容基本参考的都是[1]。） 代码 暴力 过了八十多个测试点中的七十多个，果然O(N^2)暴力还是不可取。 123456789101112131415161718class Solution &#123;public: int subarrayBitwiseORs(vector&lt;int&gt;&amp; A) &#123; int n = A.size(); int ends[n + 1]; unordered_set&lt;int&gt; allSet; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; i; j++) ends[j] |= A[i]; ends[i] = A[i]; for (int j = 0; j &lt;= i; j++) allSet.insert(ends[j]); &#125; return allSet.size(); &#125;&#125;; 优化过的暴力 123456789101112131415161718class Solution &#123;public: int subarrayBitwiseORs(vector&lt;int&gt;&amp; A) &#123; unordered_set&lt;int&gt; sums; unordered_set&lt;int&gt; all; int n = A.size(); sums.insert(0); for (int i = 0; i &lt; n; i++) &#123; unordered_set&lt;int&gt; sums2 = &#123;A[i]&#125;; for (const auto&amp; j: sums) sums2.insert(j | A[i]); for (const auto&amp; j: sums2) all.insert(j); sums = sums2; &#125; return all.size(); &#125;&#125;; O(30N) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Bit Manipulation","slug":"alg-Bit-Manipulation","permalink":"https://zhanghuimeng.github.io/tags/alg-Bit-Manipulation/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 897. Increasing Order Search Tree（树的遍历）","slug":"2018-09-02-Leetcode-897-Increasing-Order-Search-Tree（树的遍历）","date":"2018-09-02T14:28:25.000Z","updated":"2018-09-02T15:27:00.000Z","comments":true,"path":"post/leetcode-897-increasing-order-search-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-897-increasing-order-search-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/increasing-order-search-tree/description/ 标记难度：Easy 提交次数：3/6 代码效率： 中序遍历（未优化）：68ms 中序遍历+额外空间：60ms 优化的中序遍历：44ms 题意 给定一棵二叉树，要求把原来的树按照中序遍历的顺序重新组织，拉成一条长链，第一个结点在树根，下一个结点是它的右孩子，以此类推。 分析 这道题写了二十多分钟，错了三次，心态崩了。题目描述原来给的是一棵二叉搜索树，于是我就直接把结点全都保存下来，排了个序，然后重新接起来。如果原来的树是BST，那么中序遍历就相当于是排序，这么做没有什么问题，只是复杂度高点而已。但事实上并不是，所以在心态崩坏中错了三次，最后自己悟出来了可能的原因，交了个看上去像是旋转的方法上去。 很显然可以使用链表之类的数据结构把中序遍历的结点顺序保存下来，然后再重新连接结点，时间复杂度是O(N)，额外空间复杂度是O(N)。 除此之外，一种简单的方法是在递归中序遍历的基础上修改一下。先递归修改左子树，然后把左子树的最右侧的结点连到当前的根上，然后递归修改右子树，把当前的根的右子树设为递归得到的新子树。我比赛的时候是这么写的，当时自以为是一种“旋转”；但这和一般所说的BST的“旋转”相差有点远，何况这也不是个BST。 上述做法的时间复杂度为O(N^2)，因为在最坏情况下（整棵树完全是一个向左延伸的链）枚举左子树最右侧结点的平摊复杂度大致是O(N/2)，需要枚举O(N)次。 可以通过一些方法改善这一复杂度，比如在递归修改左子树的时候，把根节点也作为参数传递过去，然后在递归结束时，把根节点连到合适的位置上。[1] 代码 中序遍历（未优化） 比赛的时候脑补出来的代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* rotate(TreeNode* root) &#123; if (root == NULL) return NULL; if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) return root; TreeNode* newRoot = root; if (root-&gt;left != NULL) &#123; newRoot = rotate(root-&gt;left); TreeNode* p = newRoot; while (p-&gt;right != NULL) &#123; p = p-&gt;right; &#125; p-&gt;right = root; root-&gt;left = NULL; &#125; if (root-&gt;right != NULL) &#123; root-&gt;right = rotate(root-&gt;right); &#125; return newRoot; &#125; void dfs(TreeNode* root) &#123; if (root == NULL) return; dfs(root-&gt;left); cout &lt;&lt; root-&gt;val &lt;&lt; endl; dfs(root-&gt;right); &#125;public: TreeNode* increasingBST(TreeNode* root) &#123; if (root == NULL) return NULL; return rotate(root); &#125;&#125;; 中序遍历+额外空间 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: vector&lt;TreeNode*&gt; inOrder; void traverse(TreeNode* root) &#123; if (root == NULL) return; traverse(root-&gt;left); inOrder.push_back(root); traverse(root-&gt;right); &#125;public: TreeNode* increasingBST(TreeNode* root) &#123; traverse(root); root = NULL; TreeNode* last = NULL; for (TreeNode* x: inOrder) &#123; x-&gt;left = x-&gt;right = NULL; if (root == NULL) &#123; root = last = x; &#125; else &#123; last-&gt;right = x; last = x; &#125; &#125; return root; &#125;&#125;; 优化的中序遍历 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: TreeNode* traverse(TreeNode* root, TreeNode* tail) &#123; if (root == NULL) return NULL; TreeNode* newRoot = root; if (root-&gt;right != NULL) root-&gt;right = traverse(root-&gt;right, tail); else root-&gt;right = tail; if (root-&gt;left != NULL) &#123; newRoot = traverse(root-&gt;left, root); root-&gt;left = NULL; &#125; return newRoot; &#125;public: TreeNode* increasingBST(TreeNode* root) &#123; return traverse(root, NULL); &#125;&#125;; 上面是我的代码。如果把递归的截止条件下移一层，规整一下，会变得非常好看（但思路可能更不好理解），就像下面这份代码一样： 123456789// author: lee215// https://leetcode.com/problems/increasing-order-search-tree/discuss/165885/C++JavaPython-Self-Explained-5-line-O(N)TreeNode* increasingBST(TreeNode* root, TreeNode* tail = NULL) &#123; if (!root) return tail; TreeNode* res = increasingBST(root-&gt;left, root); root-&gt;left = NULL; root-&gt;right = increasingBST(root-&gt;right, tail); return res;&#125; Self-Explained, 5-line, O(N) ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:In-Order Traversal","slug":"alg-In-Order-Traversal","permalink":"https://zhanghuimeng.github.io/tags/alg-In-Order-Traversal/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 896. Monotonic Array，及周赛（100）总结","slug":"2018-09-02-Leetcode-896-Monotonic-Array，及周赛（100）总结","date":"2018-09-02T14:16:06.000Z","updated":"2018-09-02T14:24:00.000Z","comments":true,"path":"post/leetcode-896-monotonic-array-and-weekly-contest-100/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-896-monotonic-array-and-weekly-contest-100/","excerpt":"","text":"题目来源：https://leetcode.com/problems/monotonic-array/description/ 标记难度：Easy 提交次数：1/1 代码效率：96ms 题意 判断一个数组是否是递增或递减的。 分析 这次比赛的排名继续稳步下降（1393 / 4008），我意识到我可能只能稳定做出Easy来，难一点的Medium就做不出来了。当然事实上有的时候也许Hard还会简单一点。比赛时第二题的题目描述出了问题，导致我心态很崩，并在上面花了很长时间和很多罚时。然后还看错了第三题的题面。最后一题本来有希望推导出来，但是没有时间了。 反正这道题只写了3分钟，还行吧。 水题，水到难以分类（Array……？），直接扫描两遍分别判断递增和递减就可以了。当然也可以压缩为一遍，但没有什么本质区别。 代码 123456789101112131415161718192021222324class Solution &#123;public: bool isMonotonic(vector&lt;int&gt;&amp; A) &#123; if (A.size() &lt;= 1) return true; bool mono = true; for (int i = 1; i &lt; A.size(); i++) &#123; if (A[i] &lt; A[i - 1]) &#123; mono = false; break; &#125; &#125; if (mono) return true; mono = true; for (int i = 1; i &lt; A.size(); i++) &#123; if (A[i] &gt; A[i - 1]) &#123; mono = false; break; &#125; &#125; return mono; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"SGU 546. Ternary Password（贪心）","slug":"2018-09-01-SGU-546-Ternary-Password（贪心）","date":"2018-09-01T23:58:38.000Z","updated":"2018-09-02T00:20:00.000Z","comments":true,"path":"post/sgu-546-ternary-password/","link":"","permalink":"https://zhanghuimeng.github.io/post/sgu-546-ternary-password/","excerpt":"","text":"题目来源：http://codeforces.com/problemsets/acmsguru/problem/99999/546 提交次数：2/3 题意 给定一个只包含0，1，2三种字符的字符串，长度为n（1 &lt;= n &lt;= 200）；要求通过替换操作修改字符串，使得0的个数为a，1的个数为b（0 &lt;= a,b &lt;= 200）。输出最少的替换次数和任意替换后的合法字符串，如无法完成要求，输出-1。 分析 这道题还比较简单。 通过替换操作修改字符串实际上相当于可以把字符串完全换掉一遍，所以无法完成要求，只可能是a + b &gt; n的情况。 然后很显然可以贪心。只要给定了a和b，事实上替换的方向和数量就都确定了：如果0当前的数量比a多，那么其中必然有一部分0需要被替换掉，而被替换的这些0可以是当前字符串中所有0的任意子集，所以不妨替换最靠前的那些。进行一次操作之后，得到的必然仍是一个最优子问题。 进行实际替换的操作过程大概是一个贪心，不过这道题的确定性显然比一般所说的“贪心”问题更强。比如说，替换次数就可以直接计算出来：changeTimes * 2 = abs(a-count('0')) + abs(b-count('1')) + abs(n-a-b-count('2'))。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;using namespace std;char p[205];int main() &#123; int n, a, b; int actNum[3], expNum[3]; cin &gt;&gt; n &gt;&gt; a &gt;&gt; b; cin &gt;&gt; p; memset(actNum, 0, sizeof(actNum)); expNum[0] = a; expNum[1] = b; expNum[2] = n - a - b; if (a &lt; 0 || b &lt; 0 || a + b &gt; n) &#123; cout &lt;&lt; -1 &lt;&lt; endl; return 0; &#125; for (int i = 0; i &lt; n; i++) actNum[p[i] - '0']++; // int changed = 0; int changed = (abs(actNum[0]-expNum[0]) + abs(actNum[1]-expNum[1]) + abs(actNum[2]-expNum[2])) / 2; for (int i = 0; i &lt; n; i++) &#123; int x = p[i] - '0'; if (actNum[x] &gt; expNum[x]) &#123; for (int j = 0; j &lt; 3; j++) if (j != x &amp;&amp; actNum[j] &lt; expNum[j]) &#123; p[i] = j + '0'; actNum[j]++; actNum[x]--; // changed++; break; &#125; &#125; &#125; cout &lt;&lt; changed &lt;&lt; endl &lt;&lt; p &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"SGU","slug":"SGU","permalink":"https://zhanghuimeng.github.io/tags/SGU/"}]},{"title":"Leetcode 682. Baseball Game（栈）","slug":"2018-09-01-Leetcode-682-Baseball-Game（栈）","date":"2018-09-01T17:49:24.000Z","updated":"2018-09-01T19:49:00.000Z","comments":true,"path":"post/leetcode-682-baseball-game/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-682-baseball-game/","excerpt":"","text":"题目来源：https://leetcode.com/problems/baseball-game/description/ 标记难度：Easy 提交次数：1/1 代码效率：96.89% 题意 对一个栈中的元素进行以下几种操作： 入栈一个元素 把栈顶前两个元素的和入栈 把栈顶元素的2倍入栈 弹出一个元素 求最后栈中所有元素的和。 分析 简单的栈操作。不过题目描述有点莫名其妙，获得了很多差评…… 代码 12345678910111213141516171819202122232425262728class Solution &#123;public: int calPoints(vector&lt;string&gt;&amp; ops) &#123; vector&lt;int&gt; rounds; int n = 0, sum = 0; for (string op: ops) &#123; if (op == \"+\") &#123; rounds.push_back(rounds[n-1] + rounds[n-2]); n++; &#125; else if (op == \"C\") &#123; rounds.pop_back(); n--; &#125; else if (op == \"D\") &#123; rounds.push_back(rounds[n-1] * 2); n++; &#125; else &#123; rounds.push_back(stoi(op)); n++; &#125; &#125; for (int i = 0; i &lt; n; i++) sum += rounds[i]; return sum; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"}]},{"title":"Leetcode 701. Insert into a Binary Search Tree（BST）","slug":"2018-09-01-Leetcode-701-Insert-into-a-Binary-Search-Tree（BST）","date":"2018-09-01T16:31:34.000Z","updated":"2018-09-01T16:34:00.000Z","comments":true,"path":"post/leetcode-701-insert-into-a-binary-search-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-701-insert-into-a-binary-search-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/insert-into-a-binary-search-tree/description/ 标记难度：Easy 提交次数：1/1 代码效率：15.50% 题意 在二叉搜索树中插入元素。 分析 感觉和Leetcode 700是同一系列的题目。同样直接插入就可以了。 代码 12345678910111213141516171819202122232425262728293031323334/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* insertIntoBST(TreeNode* root, int val) &#123; if (root == NULL) return new TreeNode(val); TreeNode* p = root; while (p != NULL) &#123; if (val &lt; p-&gt;val) &#123; if (p-&gt;left == NULL) &#123; p-&gt;left = new TreeNode(val); break; &#125; p = p-&gt;left; &#125; else &#123; if (p-&gt;right == NULL) &#123; p-&gt;right = new TreeNode(val); break; &#125; p = p-&gt;right; &#125; &#125; return root; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"}]},{"title":"Leetcode 700. Search in a Binary Search Tree（BST）","slug":"2018-09-01-Leetcode-700-Search-in-a-Binary-Search-Tree（BST）","date":"2018-09-01T16:25:39.000Z","updated":"2018-09-01T16:29:00.000Z","comments":true,"path":"post/leetcode-700-search-in-a-binary-search-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-700-search-in-a-binary-search-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/search-in-a-binary-search-tree/description/ 标记难度：Easy 提交次数：1/1 代码效率：14.34% 题意 在二叉搜索树中查找元素。 分析 水题。直接按BST的性质查找就可以了。 代码 123456789101112131415161718192021222324/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* searchBST(TreeNode* root, int val) &#123; TreeNode* p = root; while (p != NULL) &#123; if (p-&gt;val == val) break; if (val &lt; p-&gt;val) p = p-&gt;left; else p = p-&gt;right; &#125; return p; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"}]},{"title":"Leetcode 687. Longest Univalue Path（递推）","slug":"2018-09-01-Leetcode-687-Longest-Univalue-Path（递推）","date":"2018-09-01T16:19:14.000Z","updated":"2018-09-01T16:23:00.000Z","comments":true,"path":"post/leetcode-687-longest-univalue-path/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-687-longest-univalue-path/","excerpt":"","text":"题目来源：https://leetcode.com/problems/longest-univalue-path/description/ 标记难度：Easy 提交次数：1/1 代码效率：39.40% 题意 给定一棵二叉树，找到树上满足下列条件的最长的路径：路径中每个结点的值都是相同的。 分析 这道题和Leetcode 124基本是一样的，只是递推条件换成了路径中的结点是否相等。不过我也是很不理解，怎么那道题是Hard，这道题就变成Easy了。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int maxLength; // number, length pair&lt;int, int&gt; dfs(TreeNode* root) &#123; if (root == NULL) return &#123;-1, -1&#125;; pair&lt;int, int&gt; leftPair = dfs(root-&gt;left); pair&lt;int, int&gt; rightPair = dfs(root-&gt;right); int length = 1; if (leftPair.second != -1 &amp;&amp; leftPair.first == root-&gt;val) length = max(leftPair.second + 1, length); if (rightPair.second != -1 &amp;&amp; rightPair.first == root-&gt;val) length = max(rightPair.second + 1, length); int sum = length; if (leftPair.second != -1 &amp;&amp; leftPair.first == root-&gt;val &amp;&amp; rightPair.second != -1 &amp;&amp; rightPair.first == root-&gt;val) length = max(leftPair.second + rightPair.second + 1, length); maxLength = max(length, maxLength); return &#123;root-&gt;val, sum&#125;; &#125;public: int longestUnivaluePath(TreeNode* root) &#123; if (root == NULL) return 0; maxLength = -1; dfs(root); return maxLength - 1; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Recursion","slug":"alg-Recursion","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursion/"}]},{"title":"歌词翻译：If I Give My Soul, by Johnny Cash (Album: Unearthed)","slug":"2018-09-01-歌词翻译：If-I-Give-My-Soul-by-Johnny-Cash-Album-Unearthed","date":"2018-09-01T14:00:10.000Z","updated":"2018-09-06T19:12:00.000Z","comments":true,"path":"post/if-i-give-my-soul-by-johnny-cash-album-unearthed-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/if-i-give-my-soul-by-johnny-cash-album-unearthed-lyric-translation/","excerpt":"","text":"歌词 翻译 (Get off stage, Cash. OK?) （从台上下去，卡什。好吗？） Down a dangerous road, I have come to where I’m standing 走过一条危险的道路，我终于来到此地 With a heavy heart and my hat clutched in my hand 心情沉重，脱下帽子攥在手里 Such a foolish man, God ain’t known no greater sinner 上帝定未见过比我更加罪孽深重的愚蠢之人 I have come in search of Jesus, hoping He will understand 我前来寻找耶稣，希望祂愿意谅解我 If I give my soul, will He clean these clothes I’m wearin? 如果我献出灵魂，祂愿洗净我身穿的衣服吗？ If I give my soul, will He put new boots on my feet? 如果我献出灵魂，祂愿为我换上新的靴子吗？ If I bow my head and beg God for His forgiveness 如果我低下头颅，向上帝祈求原谅 Will He breathe new life within me and bring her back to me? 祂愿在我体内注入新的生命，把她还给我吗？ I had a woman once, she was kind and she was gentle 我曾拥有一个女人，她又善良又温柔 Had a child by me, who grew up to be a man 和我生下一个孩子，他已经长大成人 I had a steady job, 'til I started into drinking 我曾有一份稳定的工作，直到我染上酒瘾 Then I started making music travelin’ with the devil’s band 然后我开始创作音乐，和魔鬼的乐队四处旅行 Oh the years went by like a mighty rush of eagles 时光流逝，如老鹰俯冲般飞快 Our dreams and plans were all scattered in the wind 我们的梦想和计划都散落在风中 And it’s a lonesome life, when you lose the ones you live for 当你失去那些最重要的人，生命变得如此孤独 If I make my peace with Jesus will they take me back again? 如果我与耶稣和好，他们愿重新接受我吗？ If I give my soul, will he stop my hands from shaking? 如果我献出灵魂，祂愿让我的双手不再发颤吗？ If I give my soul, will my son love me again? 如果我献出灵魂，我的儿子愿意重新爱我吗？ If I give my soul, and she knows I really mean it? 如果我献出灵魂，她也明白我已幡然悔悟？ If I give my soul to Jesus will she take me back again? 如果我把灵魂献给耶稣，她愿意重新接受我吗？ If I give my soul, will He clean these clothes I’m wearin? 如果我献出灵魂，祂愿洗净我身穿的衣服吗？ If I give my soul, will He put new boots on my feet? 如果我献出灵魂，祂愿为我换上新的靴子吗？ If I bow my head and beg God for His forgiveness 如果我低下头颅，向上帝祈求原谅 Will He breathe new breath within me and bring her back to me? 祂愿在我体内注入新的生命，把她还给我吗？ 一些问题： 我开始时把“will”统统理解为将来时助动词，然后翻译成“会”；后来又通读了一遍歌词，主人公对自己犯下的错误能否被原谅实际上是极其没有信心的（而且，从事实上来说，即使他的亲人愿意和他重新团聚，老年也是不可逆转的），所以我更倾向于把“will”理解为愿意，有种祈求他们回心转意的感觉。 我拿不定主意，把“He”翻译成“他”还是“祂”。 翻译成“他”的理由： 和合本里对“He”和“His”的处理都是翻译成“他”。 “祂”看起来太像是港台翻译了。 这首歌里把上帝和耶稣混用，涉及到一些称呼的问题。[1] 翻译成“祂”的理由： 方便分辨人称。 看起来很厉害。 不知道“devil’s band”里的“devil”是语气词（见鬼的乐队）还是形容词（魔鬼的乐队）。另一个问题是，歌里的主人公到底在多大程度上是卡什自己。查了查他的生平之后，我感觉，这个人和卡什很像，但并不就是他。 2018.9.6：我最后还是决定翻译成“祂”了。然后我把歌词重新修改了一下，并上传到了网易云上。 聖經中的「祂」和「他」 ↩︎","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Johnny Cash","slug":"artist-Johnny-Cash","permalink":"https://zhanghuimeng.github.io/tags/artist-Johnny-Cash/"}]},{"title":"Leetcode 225. Implement Stack using Queues（栈和队列）","slug":"2018-09-01-Leetcode-225-Implement-Stack-using-Queues（栈和队列）","date":"2018-09-01T11:22:24.000Z","updated":"2018-09-05T16:20:00.000Z","comments":true,"path":"post/leetcode-225-implement-stack-using-queues/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-225-implement-stack-using-queues/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-search-tree-iterator/description/ 标记难度：Easy 提交次数：4/4 代码效率： 方法1：2个队列：100.00% 方法2：2个队列：100.00% 方法3：1个队列：100.00% 方法4：用队列模拟链表：100.00% 题意 只通过队列实现栈。 分析 方法1：使用两个队列 我的第一反应就是弄两个队列，push(x)的时候， 把x放到第一个队列的队尾；pop()的时候，把第一个队列里的元素依次弹出再插入到第二个队列里，直到把最末一个元素弹出来，然后交换这两个队列。在这种实现下，push(x)的复杂度是O(1)，pop()的复杂度是O(n)。 方法2：仍然是两个队列 另一种类似的思路也是使用两个队列，push(x)的时候，把x放入第二个队列的队尾（此时第二个队列为空），然后把第一个队列里的元素依次弹出，插入到第二个队列中，最后交换两个队列；pop()的时候直接弹出第一个队列的队头。在这种实现下，push(x)的复杂度是O(n)，pop()的复杂度是O(1)，元素在队列中的顺序正好和上一种做法相反。 另一个问题是，还有top()和pop()两种操作需要实现，第一种做法的top()操作也是O(n)的（因为栈顶元素在队尾，所以不得不全都重新移动一遍），所以可能第二种做法比较好。 方法3：只使用一个队列 一种更简单的方法是只用一个队列，push(x)的时候，先把x放到队尾，然后把x前面的元素全都弹出，依次插入到x后面；pop()的时候，直接弹出队头。这种方法的复杂度和方法2是相同的。[1] 方法4：用队列模拟链表 这是StephanPochmann提出的一种很有创意的方法。简单来说，就是用一个队列表示链表中的一项，队列中一共两个元素，第一个元素是数值，第二个元素是链表指针。然后就可以用链表来表示栈了。在这种做法中，插入和删除都是O(1)的。[2] 代码 方法1（2个队列） 12345678910111213141516171819202122232425262728293031323334353637class MyStack &#123;private: queue&lt;int&gt; q[2]; int cur;public: MyStack() &#123; cur = 0; &#125; void push(int x) &#123; q[cur].push(x); &#125; int pop() &#123; int x; while (!q[cur].empty()) &#123; x = q[cur].front(); q[cur].pop(); if (q[cur].empty()) break; q[(cur + 1) % 2].push(x); &#125; cur = (cur + 1) % 2; return x; &#125; int top() &#123; int x = pop(); push(x); return x; &#125; bool empty() &#123; return q[cur].empty(); &#125;&#125;; 方法2（2个队列） 123456789101112131415161718192021222324252627282930313233class MyStack &#123;private: queue&lt;int&gt; q[2]; int cur;public: MyStack() &#123; cur = 0; &#125; void push(int x) &#123; q[(cur + 1) % 2].push(x); while (!q[cur].empty()) &#123; q[(cur + 1) % 2].push(q[cur].front()); q[cur].pop(); &#125; cur = (cur + 1) % 2; &#125; int pop() &#123; int x = q[cur].front(); q[cur].pop(); return x; &#125; int top() &#123; return q[cur].front(); &#125; bool empty() &#123; return q[cur].empty(); &#125;&#125;; 方法3：1个队列 12345678910111213141516171819202122232425262728293031class MyStack &#123;private: queue&lt;int&gt; q;public: MyStack() &#123; &#125; void push(int x) &#123; q.push(x); for (int i = 0; i &lt; q.size() - 1; i++) &#123; q.push(q.front()); q.pop(); &#125; &#125; int pop() &#123; int x = q.front(); q.pop(); return x; &#125; int top() &#123; return q.front(); &#125; bool empty() &#123; return q.empty(); &#125;&#125;; 方法4：用队列模拟链表 1234567891011121314151617181920212223242526272829303132333435363738394041class MyStack &#123;private: queue&lt;void*&gt;* head;public: MyStack() &#123; head = NULL; &#125; /** Push element x onto stack. */ void push(int x) &#123; queue&lt;void*&gt;* newNode = new queue&lt;void*&gt;(); int* val = new int(x); newNode-&gt;push((void*) val); newNode-&gt;push((void*) head); head = newNode; &#125; int pop() &#123; int* val = (int*) head-&gt;front(); head-&gt;pop(); queue&lt;void*&gt;* newHead = (queue&lt;void*&gt;*) head-&gt;front(); head-&gt;pop(); int x = *val; delete val; delete head; head = newHead; return x; &#125; int top() &#123; int* val = (int*) head-&gt;front(); int x = *val; return x; &#125; bool empty() &#123; return head == NULL; &#125;&#125;; Leetcode 255 Solution ↩︎ O(1) purely with queues ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Queue","slug":"alg-Queue","permalink":"https://zhanghuimeng.github.io/tags/alg-Queue/"}]},{"title":"Leetcode 168. Excel Sheet Column Title（进制转换）","slug":"2018-09-01-Leetcode-168-Excel-Sheet-Column-Title（进制转换）","date":"2018-09-01T10:30:59.000Z","updated":"2018-09-01T10:40:00.000Z","comments":true,"path":"post/leetcode-168-excel-sheet-column-title/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-168-excel-sheet-column-title/","excerpt":"","text":"题目来源：https://leetcode.com/problems/excel-sheet-column-title/description/ 标记难度：Easy 提交次数：1/1 代码效率：100.00% 题意 把数字转换成Excel的列标题（形如A，AB，AZ……）。 分析 这道题刚好和Leetcode 171是相反的。就像之前分析的那样，这并不是一个严格的进制转换问题，所以也不能直接按照普通进制转换的方法去做。 于是我就把刚才的递推式拿过来取了个逆： 123number = number*26 + ch-&apos;A&apos; + 1=&gt;ch = (number - 1) % 26 + &apos;A&apos; 另一种方法[1]是进行观察： 123456A 1 AA 26+ 1 BA 2×26+ 1 ... ZA 26×26+ 1 AAA 1×26²+1×26+ 1B 2 AB 26+ 2 BB 2×26+ 2 ... ZB 26×26+ 2 AAB 1×26²+1×26+ 2. . .. ..... .. ....... ... .. ........ ... .............. . .. ..... .. ....... ... .. ........ ... .............. . .. ..... .. ....... ... .. ........ ... .............Z 26 AZ 26+26 BZ 2×26+26 ... ZZ 26×26+26 AAZ 1×26²+1×26+26 通过观察可以发现，由于数字代表的值的范围是1-26，所以直接模26会导致Z消失；因此可以先-1再模26，然后就可以把得到的0-25的数字映射到A-Z的范围内了。 代码 1234567891011121314class Solution &#123;public: string convertToTitle(int n) &#123; if (n &lt;= 0) return \"\"; string ans; while (n &gt; 0) &#123; n--; ans = (char) (n % 26 + 'A') + ans; n /= 26; &#125; return ans; &#125;&#125;; Python solution with explanation ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 124. Binary Tree Maximum Path Sum（递推）","slug":"2018-08-31-Leetcode-124-Binary-Tree-Maximum-Path-Sum（递推）","date":"2018-08-31T18:56:09.000Z","updated":"2018-08-31T19:18:09.000Z","comments":true,"path":"post/leetcode-124-binary-tree-maximum-path-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-124-binary-tree-maximum-path-sum/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-tree-maximum-path-sum/description/ 标记难度：Hard 提交次数：2/3 代码效率： 不太简洁的版本：98.55% 比较简洁的版本：98.57% 题意 给定一棵非空二叉树，求树上所有路径中结点总和的最大值。 分析 这是一道比较简单的递推题。对于一棵有根树，显然树上的每一条路径都有一个深度最小的结点，所以这种做法可以覆盖到所有的路径。对于树上的每一个结点x，计算从x开始向下延伸的路径的最大结点总和，记为maxDown(x)；显然，这一总和只有3种可能性，取的是其中的最大值： x.val + maxDown(x.left)（如果左子树存在；此时路径向左子树延伸） x.val + maxDown(x.right)（如果右子树存在；此时路径向右子树延伸） x.val（因为负数结点值的存在，可能不如不延长路径；此时路径上只有x一个点） 通过DFS的方法可以比较方便地推出maxDown(x)。接下来的问题是，树上的路径除了向下延伸之外，还有另外一类，就是从某个结点开始，既向左也向右延伸。（之前忘了这种情况所以WA了一次。）因此需要另外计算maxSum(x) = max(maxDown(x), x.val + maxDown(x.left) + maxDown(x.right))。答案就是树上所有结点中maxSum的最大值。 代码 我的不太简洁的代码 这个代码对边界情况考虑得并不好，有更简洁也更好的写法。 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int maxn; int dfs(TreeNode* root) &#123; if (root == NULL) return -1000000000; int leftSum = dfs(root-&gt;left); int rightSum = dfs(root-&gt;right); int endSum = max(leftSum + root-&gt;val, rightSum + root-&gt;val); endSum = max(endSum, root-&gt;val); int sum = endSum; endSum = max(endSum, leftSum + rightSum + root-&gt;val); maxn = max(endSum, maxn); return sum; &#125;public: int maxPathSum(TreeNode* root) &#123; if (root == NULL) return 0; maxn = root-&gt;val; dfs(root); return maxn; &#125;&#125;; 比较简洁的代码 参考了Simple O(n) algorithm with one traversal through the tree的写法。 12345678910111213141516171819202122232425262728293031323334/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int maxn; int dfs(TreeNode* root) &#123; if (root == NULL) return 0; int leftSum = dfs(root-&gt;left); int rightSum = dfs(root-&gt;right); if (leftSum &lt; 0) leftSum = 0; if (rightSum &lt; 0) rightSum = 0; maxn = max(maxn, max(max(leftSum, rightSum) + root-&gt;val, leftSum + rightSum + root-&gt;val)); return max(leftSum, rightSum) + root-&gt;val; &#125;public: int maxPathSum(TreeNode* root) &#123; if (root == NULL) return 0; maxn = root-&gt;val; dfs(root); return maxn; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Recursion","slug":"alg-Recursion","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursion/"}]},{"title":"Leetcode 129. Sum Root to Leaf Numbers（枚举）","slug":"2018-08-31-Leetcode-129-Sum-Root-to-Leaf-Numbers（枚举）","date":"2018-08-31T15:24:07.000Z","updated":"2018-08-31T15:29:07.000Z","comments":true,"path":"post/leetcode-129-sum-root-to-leaf-numbers/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-129-sum-root-to-leaf-numbers/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sum-root-to-leaf-numbers/description/ 标记难度：Medium 提交次数：1/1 代码效率：100.00% 题意 给定一棵二叉树，树上的每个结点都是一个0-9的数位，问所有从根到叶结点的路径代表的数字之和。 分析 这个题和Leetcode 112差不多（我很好奇，为啥那道题就是Easy，这道就变Medium了），主要区别是没有剪枝的必要了，因为是求所有数字的和。题解区里也没看见什么特别惊人的做法。 代码 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int sum; void dfs(TreeNode* root, int num) &#123; if (root == NULL) return; num = num * 10 + root-&gt;val; if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; sum += num; return; &#125; dfs(root-&gt;left, num); dfs(root-&gt;right, num); &#125;public: int sumNumbers(TreeNode* root) &#123; sum = 0; dfs(root, 0); return sum; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"Tree","slug":"Tree","permalink":"https://zhanghuimeng.github.io/tags/Tree/"},{"name":"Depth-first Search","slug":"Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/Depth-first-Search/"}]},{"title":"Leetcode 112. Path Sum（枚举）","slug":"2018-08-31-Leetcode-112-Path-Sum（枚举）","date":"2018-08-31T14:33:54.000Z","updated":"2018-08-31T14:46:00.000Z","comments":true,"path":"post/leetcode-112-path-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-112-path-sum/","excerpt":"","text":"题目来源：https://leetcode.com/problems/path-sum/description/ 标记难度：Easy 提交次数：1/4 代码效率：5.68% 题意 给定一棵二叉树和一个数sum，问这棵二叉树上是否存在一条从根到叶结点的路径，这条路径上的结点之和为sum。 分析 这道题的思路很简单：既然对这棵树没有什么其他的规定，那就只能枚举所有路径了。通过DFS进行搜索，复杂度应该是O(n)。 结果我竟然错了3次……真叫人头大。 第一次错是因为对[] 0的输入给出了true的返回值，特判没做好。当然这份代码本来也不对。（就这样还过了101个测试点。）于是特判了一下。 第二次错是因为根本没有判断当前结点是否为叶结点，就用求和结果和sum相比较了。于是判断了一下。 第三次错是因为改了判断方式后求和结果搞错了，忘了把根节点的值加上去了。改完后终于对了…… 这可真叫人头大。这的确是道水题，但我可能把题目想得太复杂了，代码也不够简洁——答案里有些C++代码只有3行[1]（虽然可能为了简洁牺牲了一些效率，比如不能剪枝；不过把问题转化一下之后写法是变得简单了）。 代码 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: bool found; int sum; void dfs(TreeNode* root, int curSum) &#123; if (found) return; if (root == NULL) return; // cout &lt;&lt; root &lt;&lt; ' ' &lt;&lt; root-&gt;left &lt;&lt; ' ' &lt;&lt; root-&gt;right &lt;&lt;' ' &lt;&lt; curSum &lt;&lt; endl; if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; if (curSum + root-&gt;val == sum) found = true; return; &#125; dfs(root-&gt;left, curSum + root-&gt;val); dfs(root-&gt;right, curSum + root-&gt;val); &#125;public: bool hasPathSum(TreeNode* root, int sum) &#123; found = false; this-&gt;sum = sum; dfs(root, 0); return found; &#125;&#125;; 3 lines of c++ solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Depth-first Search","slug":"alg-Depth-first-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Depth-first-Search/"}]},{"title":"Leetcode 171. Excel Sheet Column Number（进制转换）","slug":"2018-08-31-Leetcode-171-Excel-Sheet-Column-Number（进制转换）","date":"2018-08-31T10:27:42.000Z","updated":"2018-08-31T10:33:42.000Z","comments":true,"path":"post/leetcode-171-excel-sheet-column-number/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-171-excel-sheet-column-number/","excerpt":"","text":"题目来源：https://leetcode.com/problems/excel-sheet-column-number/description/ 标记难度：Easy 提交次数：1/1 代码效率：7.82% 题意 把Excel的列标题（形如A，AB，AZ……）转换成数字。 分析 是个水题。就当26进制去转换就行了。但实际上这并不是26进制，只是看起来很像而已：因为没有0的位置，用Z而非A0表示26。 代码 12345678910class Solution &#123;public: int titleToNumber(string s) &#123; int ans = 0; for (char ch: s) &#123; ans = ans * 26 + ch - 'A' + 1; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 894. All Possible Full Binary Trees（递归）","slug":"2018-08-31-Leetcode-894-All-Possible-Full-Binary-Trees（递归）","date":"2018-08-31T09:37:52.000Z","updated":"2018-08-31T10:08:52.000Z","comments":true,"path":"post/leetcode-894-all-possible-full-binary-trees/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-894-all-possible-full-binary-trees/","excerpt":"","text":"题目来源：https://leetcode.com/problems/maximum-frequency-stack/description/ 标记难度：Medium 提交次数：1/1 代码效率：77.64% 题意 返回所有结点总数为N的完全二叉树。 分析 这是周赛（99）的第三题。比赛的时候我大概花了一个小时在这道题上，但是并没有做出来。我企图用一遍DFS完成所有的枚举任务，但事实上，如果不明确给定左子树和右子树的结点数目，是无法正常进行枚举的。直到最后我也没想出来怎么正常地枚举，于是我就挂了。 事实上这道题有非常明显的子问题结构，但我比赛的时候对这一点毫无知觉。显然，对于完全二叉树的每一个结点，要么它是一个叶结点，要么它的左右子树都是完全二叉树。而且显然完全二叉树的结点数目必然是奇数。于是我们可以通过递归解决这个问题：对于要求的结点总数N，枚举所有可能的左子树结点数（i，奇数）以及对应的右子树结点数（N - i - 1），然后把生成的子树拼在一起，得到所有可能的拼法。可以将N对应的所有树存起来，减少迭代的次数。 以及，令N=2k+1N = 2k + 1N=2k+1，则NNN个结点的不同构满二叉树的总数为卡特兰数Ck=1k+1(2kk)C_k = \\frac{1}{k+1} \\binom{2k}{k}Ck​=k+11​(k2k​)。从上述迭代公式应该是可以用数学归纳法证明的。[1] 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: unordered_map&lt;int, vector&lt;TreeNode*&gt;&gt; cache; void generate(int n) &#123; if (n &lt;= 0 || n % 2 == 0) return; if (cache.find(n) != cache.end()) return; if (n == 1) &#123; TreeNode* root = new TreeNode(0); cache[1].push_back(root); return; &#125; for (int leftNum = 1; leftNum &lt;= n - 1; leftNum += 2) &#123; generate(leftNum); generate(n - 1 - leftNum); for (TreeNode* ltree: cache[leftNum]) for (TreeNode* rtree: cache[n - 1 - leftNum]) &#123; TreeNode* root = new TreeNode(0); root-&gt;left = copy(ltree); root-&gt;right = copy(rtree); cache[n].push_back(root); &#125; &#125; &#125; TreeNode* copy(TreeNode* root) &#123; if (root == NULL) return NULL; TreeNode* newRoot = new TreeNode(0); newRoot-&gt;left = copy(root-&gt;left); newRoot-&gt;right = copy(root-&gt;right); return newRoot; &#125;public: vector&lt;TreeNode*&gt; allPossibleFBT(int N) &#123; generate(N); return cache[N]; &#125;&#125;; Leetcode 894 Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:Recursion","slug":"alg-Recursion","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursion/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 895. Maximum Frequency Stack（STL）","slug":"2018-08-30-Leetcode-895-Maximum-Frequency-Stack（STL）","date":"2018-08-30T15:48:06.000Z","updated":"2018-08-30T19:29:06.000Z","comments":true,"path":"post/leetcode-895-maximum-frequency-stack/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-895-maximum-frequency-stack/","excerpt":"","text":"题目来源：https://leetcode.com/problems/maximum-frequency-stack/description/ 标记难度：Hard 提交次数：2/3 代码效率： map+heap：41.40% vector+stack+map：66.98% 题意 实现一种名为freqStack的数据结构，提供以下两种功能： push(int x)：将整数x入栈 pop()：删除并返回栈中出现次数最多的元素；如果有平局，则删除最靠近栈顶的元素。 单个测试样例中每种操作的数量均不会超过10000。 分析 这是周赛（99）的第四题。比赛的时候我一直在死磕第三题，所以没有时间做这道题，但是后来我发现这道题还挺简单的，花了不到半个小时就做出来了。 map+heap 我感觉题意中有一个地方说得不够清楚，不过在之后的例子中解决了这种模糊性：对于出现次数最多的那些元素，我们删除的是最靠近栈顶的一个。 我的做法是这样的： 使用一个map&lt;int, int&gt;记录每种元素的个数（cntMap） 使用一个map&lt;int, vector&lt;int&gt;&gt;记录每种元素的位置（posMap） 使用一个priority_queue&lt;(cnt, lastPos, x)&gt;记录和寻找栈中出现次数最多的元素（heap） 对于push(x)操作，cntMap[x]++，并为x保存当前栈顶位置（不妨假定我们用一个数组来维护栈，且删除操作不回收空间），作为x的出现位置之一：posMap[x].push_back(curPos)。最后将元组(cnt, lastPos, x)存入heap中。（我知道C++现在还没有tuple，但是实际上就是这么个东西。）复杂度为O(log(N))（其中N表示总操作次数）。 对于pop()操作，从heap中取出堆顶元素，检查其内容是否合法（cnt == cntMap[x] &amp;&amp; lastPos == posMap[x].back()），直到找到一组合法的(cnt, lastPos, x)。然后删除x最靠近栈顶的出现位置，cntMap[x]--，posMap[x].pop_back()。复杂度还是O(log(N))。 C++中没有为priority_queue提供方便的删除函数，所以上述代码中每插入一个元素，都不计代价地向priority_queue中插入一个新的元组，而在pop()操作中需要检查元组的合法性。因为操作数量只有10000，所以这种操作在此题中还不会导致内存爆炸。 这种奇怪的操作手法是我从Dijstra最短路算法的C++ STL实现里学到的[1]。但是，如果真的会内存爆炸的话，考虑用便于删除的set代替priority_queue比较好[2]。 vector+stack+map 我觉得这是一种很非常有趣的做法。据说采用的是桶排序的思想。[3] 需要的数据结构包括： 一个vector&lt;stack&lt;int&gt;&gt;： vector是元素出现频率的“桶” stack&lt;int&gt;存储的是该频率下出现的所有元素，通过stack维护了元素之间的顺序性 一个map&lt;int, int&gt;：存储某一元素在栈中的当前频率 对于push(x)操作，首先在map中更新该元素的频率，然后在更新后的频率对应的桶中插入该元素，并且更新maxFreq。 对于pop()操作，从maxFreq对应的桶中弹出栈顶元素x，并在map中更新该元素的频率；如果该桶变空，则删除该桶，并更新maxFreq。 虽然我觉得这种算法是正确的，但我很难直观地想象这种方法为何正确。显然，所有桶中的元素加起来构成了这个栈中的所有元素，但它们到底是以何种形式分布在不同桶里的呢？大概是“插入该元素时该元素的出现频率”，或者说“第几个这种元素”。在需要删除时，删除的是最多的元素中最靠近栈顶的一个，或者说是其中最后一个插入的。 代码 map+heap 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class FreqStack &#123;private: struct Num &#123; int cnt; int lastTime; int number; friend bool operator &lt; (const Num&amp; a, const Num&amp; b) &#123; if (a.cnt != b.cnt) return a.cnt &lt; b.cnt; return a.lastTime &lt; b.lastTime; &#125; Num (const int&amp; c, const int&amp; l, const int&amp; n) &#123; cnt = c; lastTime = l; number = n; &#125; &#125;; map&lt;int, vector&lt;int&gt;&gt; posMap; map&lt;int, int&gt; cntMap; priority_queue&lt;Num&gt; heap; int pos;public: FreqStack() &#123; pos = 0; &#125; void push(int x) &#123; posMap[x].push_back(pos); cntMap[x]++; heap.push(Num(cntMap[x], pos, x)); pos++; &#125; int pop() &#123; while (!heap.empty()) &#123; Num num = heap.top(); heap.pop(); // cout &lt;&lt; heap.size() &lt;&lt; endl; // cout &lt;&lt; num.cnt &lt;&lt; ' ' &lt;&lt; num.lastTime &lt;&lt; ' ' &lt;&lt; num.number &lt;&lt; endl; if (num.cnt != cntMap[num.number] || num.lastTime != posMap[num.number].back()) continue; cntMap[num.number]--; posMap[num.number].pop_back(); if (cntMap[num.number] &gt; 0) &#123; num.lastTime = posMap[num.number].back(); num.cnt--; heap.push(num); &#125; return num.number; &#125; &#125;&#125;;/** * Your FreqStack object will be instantiated and called as such: * FreqStack obj = new FreqStack(); * obj.push(x); * int param_2 = obj.pop(); */// 用一个优先队列存储pair&lt;times, lastTime, number&gt;// 再用一个map存储每个number出现的位置，以及具体次数 vector+stack+map 123456789101112131415161718192021222324252627282930313233343536373839class FreqStack &#123;private: vector&lt;stack&lt;int&gt;&gt; bucket; unordered_map&lt;int, int&gt; freqMap; int maxFreq;public: FreqStack() &#123; maxFreq = 0; &#125; void push(int x) &#123; freqMap[x]++; int freq = freqMap[x]; if (freq &gt; maxFreq) &#123; maxFreq = freq; bucket.push_back(stack&lt;int&gt;()); &#125; bucket[freq-1].push(x); &#125; int pop() &#123; int x = bucket[maxFreq - 1].top(); bucket[maxFreq - 1].pop(); if (bucket[maxFreq - 1].empty()) &#123; maxFreq--; bucket.pop_back(); &#125; freqMap[x]--; return x; &#125;&#125;;/** * Your FreqStack object will be instantiated and called as such: * FreqStack obj = new FreqStack(); * obj.push(x); * int param_2 = obj.pop(); */ Dijkstra’s Shortest Path Algorithm using priority_queue of STL ↩︎ Dijkstra’s shortest path algorithm using set in STL ↩︎ JAVA O(1) solution easy understand using bucket sort ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 710. Random Pick with Blacklist（二分；STL）","slug":"2018-08-30-Leetcode-710-Random-Pick-with-Blacklist（二分；STL）","date":"2018-08-30T12:50:17.000Z","updated":"2018-08-30T13:48:17.000Z","comments":true,"path":"post/leetcode-710-random-pick-with-blacklist/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-710-random-pick-with-blacklist/","excerpt":"","text":"题目来源：https://leetcode.com/problems/random-pick-with-blacklist/description/ 标记难度：Hard 提交次数：3/6 代码效率： 二分：10.06% 重映射：45.67% 题意 给定区间[0, N)和一个该区间内的“黑名单”，要求以均匀的概率返回该区间内非黑名单的数字，且调用rand()的次数尽量少。 分析 二分 我感觉这是一道很妙的题。看到题之后，我的第一反应是：假定黑名单的长度为M，那么我们只需要随机[0, N - M)范围内的数字，然后把它们映射到[0, N)区间内就可以了。问题是怎么映射呢？ 于是我想出了这样一种做法：随机得到一个数字之后，计算黑名单中有多少个数小于等于这个数，然后把这个数量加到这个数上，返回结果。然后我就把代码交上去了，于是，很快我就发现这个做法错得有点离谱，因为它完全没有保证返回的数不在黑名单里。反例如N = 4, blacklist = [0, 1]，随机得到0时，上述做法会返回1。 于是我尝试从另一个角度来思考这个问题。我们显然可以显式地构建一个映射：顺序枚举[0, N - M)范围内的数，维护一个指针，指向下一个能够被映射的数，遇到黑名单中的数则跳过。这个做法是正确的，但考虑到1 &lt;= N &lt;= 1000000000的数据量，显然不可能把整个映射表都建立出来，然后去查表。 于是这个思路被否决了，我又回头去考虑怎么在线计算出准确的映射这个问题。我想了想：考虑“黑名单中有多少个数小于等于当前的数”这个思路其实是正确的，问题在于，被考虑的不应该是[0, N - M)中的数，而应该是[0, N)中的数。考察这个例子，N = 9, balcklist = [2, 3, 5]，令blacklist_before(i)表示黑名单中&lt;=i的数的个数： [0, N)中的数i blacklist_before(i) i - blacklist_before(i) 映射到[0, N - M)中 0 0 0 0 1 0 1 1 2 1 1 - 3 2 1 - 4 2 2 2 5 3 2 - 6 3 3 3 7 3 4 4 8 3 5 5 可以观察得到一些非常有趣的性质： i - blacklist_before(i)是非单调递增的，因为它代表的是[0, i]区间内不属于黑名单内的数的个数 当i - blacklist_before(i)没有递增时，表示i是一个黑名单内的数字 i在[0, N - M)区间中应该映射到的数与i - blacklist_before(i)两列很接近（从意义上来说也是） 所以可以从这个逆向映射的角度考虑，用二分的方法解决问题：假定在[0, N - M)中随机得到了y，我们需要找到满足x - blacklist_before(x) == y的x的lower_bound。然后就可以写了。 在讨论区里我看到了类似的做法，但是思考的角度不太一样。我们可以把从区间[0, N - M)中生成随机数r的情形这样分类：[1] r在[0, B[0])区间内，可以直接返回r r在[B[0], B[1] - 1)区间内，应返回r + 1 … r在[B[i]-i, B[i+1]-(i+1))区间内，应返回r + i + 1。注意到r + i + 1位于[B[i] + 1, B[i+1])区间内，因此这样做是安全的。 因此可以在B[i] - (i+1)数组中进行二分查找。 这种做法是在经过处理的blacklist数组上进行二分查找，而我是在[0, N)区间上直接查找，所以比我的做法更压缩一些。 HashMap重映射法 我之前考虑过建立整个映射表，但因为数据量而放弃了。然而，事实上，完全不需要把整个映射表都建立出来；或者不如说，完全不需要按顺序建立映射，只要保证所有数字都可以被随机取到即可。所以可以采取这样的一种做法：将黑名单中的元素分成两类，一类在[0, N - M)区间内，一类在[N - M, N)区间内。然后在[N - M, N)区间内为[0, N - M)区间内的黑名单元素顺序寻找映射（我看到了从前向后[2]和从后向前[3]两种方法，不过本质上是相同的），同时注意跳过那些同样在黑名单内的元素。 上述从后向前找映射的一个图示例子：N=10, blacklist=[3, 5, 8, 9]，将3和5映射为7和6。 代码 二分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123;private: int N; vector&lt;int&gt; blacklist; unordered_set&lt;int&gt; blackSet; random_device rd; mt19937 gen; uniform_int_distribution&lt;&gt; dist; int findMap(int y) &#123; int l = 0, r = N - 1; // need to find lower_bound // 二分真是一件Tricky的事情 while (l &lt; r) &#123; int mid = (l + r) / 2; int smaller = upper_bound(blacklist.begin(), blacklist.end(), mid) - blacklist.begin(); if (mid - smaller &lt; y) l = mid + 1; else r = mid; &#125; return l; &#125;public: Solution(int N, vector&lt;int&gt; blacklist): gen(rd()), dist(0, N - blacklist.size() - 1) &#123; this-&gt;N = N; this-&gt;blacklist = blacklist; sort(this-&gt;blacklist.begin(), this-&gt;blacklist.end()); for (int b: blacklist) blackSet.insert(b); &#125; int pick() &#123; int r = dist(gen); int m = findMap(r); // cout &lt;&lt; r &lt;&lt; ' ' &lt;&lt; m &lt;&lt; endl; // 事实证明，保证lower_bound之后，找到的数必然不是黑名单中的数 /* while (blackSet.find(m) != blackSet.end()) m++; */ return m; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(N, blacklist); * int param_1 = obj.pick(); */// 这个问题很有趣。// 既然从N个数的区间中屏蔽了B.length个点，那么就是从N - B.length的区间中随机选点// 然后换算一下。// 但是换算方法看起来是个很大的问题…… 重映射 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;private: int N; vector&lt;int&gt; blacklist; unordered_set&lt;int&gt; blackSet; unordered_map&lt;int, int&gt; blackMap; random_device rd; mt19937 gen; uniform_int_distribution&lt;&gt; dist;public: Solution(int N, vector&lt;int&gt; blacklist): gen(rd()), dist(0, N - blacklist.size() - 1) &#123; this-&gt;N = N; this-&gt;blacklist = blacklist; sort(this-&gt;blacklist.begin(), this-&gt;blacklist.end()); for (int b: blacklist) blackSet.insert(b); int M = blacklist.size(); int mapTo = N - M; for (int b: this-&gt;blacklist) &#123; if (b &gt;= N - M) break; while (blackSet.find(mapTo) != blackSet.end()) mapTo++; blackMap[b] = mapTo++; &#125; &#125; int pick() &#123; int r = dist(gen); if (blackSet.find(r) != blackSet.end()) return blackMap[r]; return r; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(N, blacklist); * int param_1 = obj.pick(); */ Simple Java solution with Binary Search ↩︎ Java O(B) constructor and O(1) pick, HashMap ↩︎ Java O(B) / O(1), HashMap ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search","slug":"alg-Binary-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search/"},{"name":"alg:Random","slug":"alg-Random","permalink":"https://zhanghuimeng.github.io/tags/alg-Random/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"}]},{"title":"CSP 201712 (2) 游戏（链表）","slug":"2018-08-29-CSP-201712-2-游戏（链表）","date":"2018-08-29T17:03:54.000Z","updated":"2018-08-29T17:08:54.000Z","comments":true,"path":"post/csp-201712-2/","link":"","permalink":"https://zhanghuimeng.github.io/post/csp-201712-2/","excerpt":"","text":"题意 试题编号：201712-2 试题名称：游戏 时间限制：1.0s 内存限制：256.0MB 问题描述 有n个小朋友围成一圈玩游戏，小朋友从1至n编号，2号小朋友坐在1号小朋友的顺时针方向，3号小朋友坐在2号小朋友的顺时针方向，……，1号小朋友坐在n号小朋友的顺时针方向。 游戏开始，从1号小朋友开始顺时针报数，接下来每个小朋友的报数是上一个小朋友报的数加1。若一个小朋友报的数为k的倍数或其末位数（即数的个位）为k，则该小朋友被淘汰出局，不再参加以后的报数。当游戏中只剩下一个小朋友时，该小朋友获胜。 例如，当n=5, k=2时： 1号小朋友报数1； 2号小朋友报数2淘汰； 3号小朋友报数3； 4号小朋友报数4淘汰； 5号小朋友报数5； 1号小朋友报数6淘汰； 3号小朋友报数7； 5号小朋友报数8淘汰； 3号小朋友获胜。 给定n和k，请问最后获胜的小朋友编号为多少？ 输入格式 输入一行，包括两个整数n和k，意义如题目所述。 输出格式 输出一行，包含一个整数，表示获胜的小朋友编号。 样例输入1 15 2 样例输出1 13 样例输入2 17 3 样例输出2 14 数据规模和约定 对于所有评测用例，1 ≤ n ≤ 1000，1 ≤ k ≤ 9。 分析 一个普通的链表绕圈和删除问题。 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;struct Node &#123; int num; Node* next; Node() &#123; num = 0; next = NULL; &#125; Node(int x) &#123; num = x; next = NULL; &#125;&#125;;int main() &#123; int n, k; cin &gt;&gt; n &gt;&gt; k; if (n == 1) &#123; cout &lt;&lt; 1 &lt;&lt; endl; return 0; &#125; Node* head = new Node(1); Node* p = head; for (int i = 2; i &lt;= n; i++) &#123; p-&gt;next = new Node(i); p = p-&gt;next; &#125; p-&gt;next = head; Node* last = p; p = head; int i = 1; while (p-&gt;next != p) &#123; if (i % k == 0 || i % 10 == k) &#123; p = p-&gt;next; delete last-&gt;next; last-&gt;next = p; &#125; else &#123; last = p; p = p-&gt;next; &#125; i++; &#125; cout &lt;&lt; p-&gt;num &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://zhanghuimeng.github.io/tags/CSP/"},{"name":"alg:Linked List","slug":"alg-Linked-List","permalink":"https://zhanghuimeng.github.io/tags/alg-Linked-List/"}]},{"title":"CSP 201712 (1) 最小差值（贪心）","slug":"2018-08-29-CSP-201712-1-最小差值（贪心）","date":"2018-08-29T16:29:54.000Z","updated":"2018-08-29T16:33:54.000Z","comments":true,"path":"post/csp-201712-1/","link":"","permalink":"https://zhanghuimeng.github.io/post/csp-201712-1/","excerpt":"","text":"题意 试题编号：201712-1 试题名称：最小差值 时间限制：1.0s 内存限制：256.0MB 问题描述 给定n个数，请找出其中相差（差的绝对值）最小的两个数，输出它们的差值的绝对值。 输入格式 输入第一行包含一个整数n。 第二行包含n个正整数，相邻整数之间使用一个空格分隔。 输出格式 输出一个整数，表示答案。 样例输入1 1251 5 4 8 20 样例输出1 11 样例说明1 相差最小的两个数是5和4，它们之间的差值是1。 样例输入2 1259 3 6 1 3 样例输出2 10 样例说明2 有两个相同的数3，它们之间的差值是0. 数据规模和约定 对于所有评测用例，2 ≤ n ≤ 1000，每个给定的整数都是不超过10000的正整数。 分析 和Leetcode 539基本是一样的。 代码 时间：15ms 空间：520.0KB 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;cstdlib&gt;using namespace std;int cmp(const void* x, const void* y) &#123; return *(int*)x - *(int*)y;&#125;int a[1005];int main() &#123; int n; cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) cin &gt;&gt; a[i]; qsort(a, n, sizeof(int), cmp); int ans = a[1] - a[0]; for (int i = 1; i &lt; n; i++) ans = min(ans, a[i] - a[i - 1]); cout &lt;&lt; ans &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://zhanghuimeng.github.io/tags/CSP/"}]},{"title":"CSP 201803 (2) 碰撞的小球（模拟）","slug":"2018-08-29-CSP-201803-2-碰撞的小球（模拟）","date":"2018-08-29T12:41:06.000Z","updated":"2018-08-29T15:06:00.000Z","comments":true,"path":"post/csp-201803-2/","link":"","permalink":"https://zhanghuimeng.github.io/post/csp-201803-2/","excerpt":"","text":"题意 试题编号：201803-2 试题名称：碰撞的小球 时间限制：1.0s 内存限制：256.0MB 问题描述 数轴上有一条长度为L（L为偶数)的线段，左端点在原点，右端点在坐标L处。有n个不计体积的小球在线段上，开始时所有的小球都处在偶数坐标上，速度方向向右，速度大小为1单位长度每秒。 当小球到达线段的端点（左端点或右端点）的时候，会立即向相反的方向移动，速度大小仍然为原来大小。 当两个小球撞到一起的时候，两个小球会分别向与自己原来移动的方向相反的方向，以原来的速度大小继续移动。 现在，告诉你线段的长度L，小球数量n，以及n个小球的初始位置，请你计算t秒之后，各个小球的位置。 提示 因为所有小球的初始位置都为偶数，而且线段的长度为偶数，可以证明，不会有三个小球同时相撞，小球到达线段端点以及小球之间的碰撞时刻均为整数。 同时也可以证明两个小球发生碰撞的位置一定是整数（但不一定是偶数）。 输入格式 输入的第一行包含三个整数n, L, t，用空格分隔，分别表示小球的个数、线段长度和你需要计算t秒之后小球的位置。 第二行包含n个整数a1, a2, …, an，用空格分隔，表示初始时刻n个小球的位置。 输出格式 输出一行包含n个整数，用空格分隔，第i个整数代表初始时刻位于ai的小球，在t秒之后的位置。 样例输入1 123 10 54 6 8 样例输出1 17 9 9 样例输入2 1210 22 3014 12 16 6 10 2 8 20 18 4 样例输出2 16 6 8 2 4 0 4 12 10 2 数据规模和约定 对于所有评测用例，1 ≤ n ≤ 100，1 ≤ t ≤ 100，2 ≤ L ≤ 1000，0 &lt; ai &lt; L。L为偶数。 保证所有小球的初始位置互不相同且均为偶数。 分析 这题看着很像紫书上的一道例题，同样可以用交换速度的思路去看，唯一的区别是小球会在线段端点处反射（好像？），但这并没有改变小球之间只是交换速度（或互相穿越），而相对顺序不变的事实。所以其实不需要模拟，直接按初始位置排序，然后计算出所有最终位置，再排序，然后根据初始顺序就可以知道每个小球的最终位置了。 事实上我又忘了怎么用两种排序方法调用std::sort了。事实上我觉得这种东西是不可能记住的，不如背诵一下qsort的用法。 参数： 数组起始位置 元素个数 元素size 比较函数，要求两个参数都是const void*类型，返回值为int 1234567891011121314151617181920// http://www.cplusplus.com/reference/cstdlib/qsort//* qsort example */#include &lt;stdio.h&gt; /* printf */#include &lt;stdlib.h&gt; /* qsort */int values[] = &#123; 40, 10, 100, 90, 20, 25 &#125;;int compare (const void * a, const void * b)&#123; return ( *(int*)a - *(int*)b );&#125;int main ()&#123; int n; qsort (values, 6, sizeof(int), compare); for (n=0; n&lt;6; n++) printf (\"%d \",values[n]); return 0;&#125; 代码 时间：15ms 空间：504.0KB 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;cstdlib&gt;using namespace std;struct Position &#123; int pos; int num;&#125;;int cmpPos(const void* x, const void* y) &#123; return ((Position*) x)-&gt;pos - ((Position*) y)-&gt;pos;&#125;int cmpNum(const void* x, const void* y) &#123; return ((Position*) x)-&gt;num - ((Position*) y)-&gt;num;&#125;Position initPos[105], laterPos[105];int main() &#123; int n, L, t; cin &gt;&gt; n &gt;&gt; L &gt;&gt; t; // 按顺序排序 for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; initPos[i].pos; initPos[i].num = i; &#125; qsort(initPos, n, sizeof(Position), cmpPos); // 计算之后的“模拟”位置 // 撞墙多次的情况显然循环了 t %= 2 * L; for (int i = 0; i &lt; n; i++) &#123; // 没撞到墙 if (initPos[i].pos + t &lt;= L) laterPos[i].pos = initPos[i].pos + t; // 撞墙一次 else if (L &lt; initPos[i].pos + t &amp;&amp; initPos[i].pos + t &lt;= 2 * L) laterPos[i].pos = L - (t - (L - initPos[i].pos)); // 撞墙两次 else laterPos[i].pos = t - (2 * L - initPos[i].pos); &#125; qsort(laterPos, n, sizeof(Position), cmpPos); for (int i = 0; i &lt; n; i++) laterPos[i].num = initPos[i].num; qsort(laterPos, n, sizeof(Position), cmpNum); cout &lt;&lt; laterPos[0].pos; for (int i = 1; i &lt; n; i++) cout &lt;&lt; ' ' &lt;&lt; laterPos[i].pos; cout &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://zhanghuimeng.github.io/tags/CSP/"}]},{"title":"CSP 201803 (1) 跳一跳（模拟）","slug":"2018-08-29-CSP-201803-1-跳一跳（模拟）","date":"2018-08-29T12:33:38.000Z","updated":"2018-08-29T12:36:00.000Z","comments":true,"path":"post/csp-201803-1/","link":"","permalink":"https://zhanghuimeng.github.io/post/csp-201803-1/","excerpt":"","text":"题意 试题编号：201803-1 试题名称：跳一跳 时间限制：1.0s 内存限制：256.0MB 问题描述 近来，跳一跳这款小游戏风靡全国，受到不少玩家的喜爱。 简化后的跳一跳规则如下：玩家每次从当前方块跳到下一个方块，如果没有跳到下一个方块上则游戏结束。 如果跳到了方块上，但没有跳到方块的中心则获得1分；跳到方块中心时，若上一次的得分为1分或这是本局游戏的第一次跳跃则此次得分为2分，否则此次得分比上一次得分多两分（即连续跳到方块中心时，总得分将+2，+4，+6，+8…）。 现在给出一个人跳一跳的全过程，请你求出他本局游戏的得分（按照题目描述的规则）。 输入格式 输入包含多个数字，用空格分隔，每个数字都是1，2，0之一，1表示此次跳跃跳到了方块上但是没有跳到中心，2表示此次跳跃跳到了方块上并且跳到了方块中心，0表示此次跳跃没有跳到方块上（此时游戏结束）。 输出格式 输出一个整数，为本局游戏的得分（在本题的规则下）。 样例输入 11 1 2 2 2 1 1 2 2 0 样例输出 122 数据规模和约定 对于所有评测用例，输入的数字不超过30个，保证0正好出现一次且为最后一个数字。 分析 一道模拟水题。直接模拟就行了。 代码 时间：15ms 空间：500.0KB 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;int main() &#123; int lastScore = 1; int sum = 0; int status; while (cin &gt;&gt; status) &#123; if (status == 0) break; else if (status == 1) &#123; lastScore = 1; sum++; &#125; else if (status == 2) &#123; if (lastScore == 1) &#123; lastScore = 2; sum += 2; &#125; else &#123; lastScore += 2; sum += lastScore; &#125; &#125; &#125; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://zhanghuimeng.github.io/tags/CSP/"}]},{"title":"Leetcode 720. Longest Word in Dictionary（枚举；Trie）","slug":"2018-08-27-Leetcode-720-Longest-Word-in-Dictionary（枚举；Trie）","date":"2018-08-27T19:22:43.000Z","updated":"2018-08-27T20:46:43.000Z","comments":true,"path":"post/leetcode-720-longest-word-in-dictionary/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-720-longest-word-in-dictionary/","excerpt":"","text":"题目来源：https://leetcode.com/problems/longest-word-in-dictionary/description/ 标记难度：Easy 提交次数：2/2 代码效率： 枚举：61.98% Trie：30.09% 题意 给定一系列字符串，找出满足这一条件的最长且字典序最小的字符串：这个字符串的所有前缀都包含在字符串集中。 分析 因为字符串数量只有1000，长度只有30，所以完全可以采用枚举的方法：先把所有字符串排序（这样可以保证每个字符串的前缀都排在它前面），按顺序把满足要求的字符串加入到一个set中；对于每个字符串，检查它的substr(1, length-1)子串是否包含在set中，如果是则满足要求。（所以里面也含有一些动态规划的思想）这一做法和题解中给出的做法相比有些差异，更类似于[1]，复杂度（假设在HashSet中插入和查询字符串的时间正比于字符串长度）大约是O(n∗log⁡(n)+∑wi)O(n * \\log{(n)} + \\sum w_i)O(n∗log(n)+∑wi​)。 如果数据量更大的话，更好的方法是使用Trie。把所有的字符串都插入到一棵Trie中，然后通过DFS或BFS找到最长的连续路径。这样复杂度只有O(∑wi)O(\\sum w_i)O(∑wi​)。 代码 枚举 12345678910111213141516171819202122232425class Solution &#123;public: string longestWord(vector&lt;string&gt;&amp; words) &#123; set&lt;string&gt; okToBuild; string longest; sort(words.begin(), words.end()); for (string word: words) &#123; if (word.length() == 1) &#123; okToBuild.insert(word); // 考虑到经过了排序，后一个判断条件其实是不必要的 if (word.length() &gt; longest.length() || (word.length() == longest.length() &amp;&amp; word &lt; longest)) longest = word; &#125; else &#123; if (okToBuild.find(word.substr(0, word.length() - 1)) != okToBuild.end()) &#123; okToBuild.insert(word); if (word.length() &gt; longest.length() || (word.length() == longest.length() &amp;&amp; word &lt; longest)) longest = word; &#125; &#125; &#125; return longest; &#125;&#125;; Trie 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123;private: struct TrieNode &#123; string str; TrieNode* next[26]; TrieNode() &#123; memset(next, 0, sizeof(next)); &#125; TrieNode(string s): str(s) &#123; memset(next, 0, sizeof(next)); &#125; &#125;; void insert(TrieNode* root, string str) &#123; TrieNode* cur = root; for (int i = 0; i &lt; str.length(); i++) &#123; char ch = str[i]; int index = ch - 'a'; if (cur-&gt;next[index] == NULL) &#123; cur-&gt;next[index] = new TrieNode(); &#125; cur = cur-&gt;next[index]; &#125; cur-&gt;str = str; &#125; string longest; void dfs(TrieNode* cur, int depth) &#123; if (cur == NULL) return; if (depth &gt; longest.length() &amp;&amp; cur-&gt;str.length() == depth) longest = cur-&gt;str; for (int i = 0; i &lt; 26; i++) if (cur-&gt;next[i] != NULL &amp;&amp; cur-&gt;next[i]-&gt;str.length() &gt; 0) dfs(cur-&gt;next[i], depth+1); &#125;public: string longestWord(vector&lt;string&gt;&amp; words) &#123; TrieNode* root = new TrieNode(); for (string word: words) insert(root, word); dfs(root, 0); return longest; &#125;&#125;; Java/C++ Clean Code ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Trie","slug":"alg-Trie","permalink":"https://zhanghuimeng.github.io/tags/alg-Trie/"}]},{"title":"Leetcode 893. Groups of Special-Equivalent Strings（map）","slug":"2018-08-26-Leetcode-893-Groups-of-Special-Equivalent-Strings（map）","date":"2018-08-26T23:24:39.000Z","updated":"2018-08-26T23:54:39.000Z","comments":true,"path":"post/leetcode-893-groups-of-special-equivalent-strings/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-893-groups-of-special-equivalent-strings/","excerpt":"","text":"题目来源：https://leetcode.com/problems/groups-of-special-equivalent-strings/description/ 标记难度：Easy 提交次数：2/3 代码效率： 排序：4ms 计数排序：36ms 题意 给定一系列字符串，对于每个字符串，可以随意交换模2同余的位置上的字符。如果经过交换后可以使得两个字符串相等，则称它们在同一组内。问这些字符串中共有几组。 分析 这是周赛（99）的第二题。这道题好像一共才做了5分钟，因为之前见过类似的题目了（Leetcode 49），做法也差不多。我感觉，最好写的方法（对于C++而言）就是分别取出奇数和偶数位置上的字符，分别排序，然后组合起来，作为键值进行统计。 考虑到效率和字符串本身的特点，仍然可以用计数排序的做法[1]，但这对于C++来说并不好写，因为没有像Java或Python那样方便的to_string类函数。 代码 排序 123456789101112131415161718192021class Solution &#123;public: int numSpecialEquivGroups(vector&lt;string&gt;&amp; A) &#123; // 把位置模2不同的两种串分开考虑 // 实际上，因为只需要统计group的数量，这里用set就足够了 map&lt;string, int&gt; groups; for (string str: A) &#123; string odd; string even; for (int i = 0; i &lt; str.length(); i++) if (i % 2 == 0) odd += str[i]; else even += str[i]; sort(odd.begin(), odd.end()); sort(even.begin(), even.end()); groups[odd + even]++; &#125; return groups.size(); &#125;&#125;; 计数排序 因为复杂的操作过程，常数太大，虽然复杂度减小了，速度反而慢了很多。 123456789101112131415161718192021222324252627class Solution &#123;private: string intToString(int x[], int len) &#123; string str; for (int i = 0; i &lt; len; i++) str += to_string(x[i]) + \",\"; return str; &#125;public: int numSpecialEquivGroups(vector&lt;string&gt;&amp; A) &#123; int hash[52]; set&lt;string&gt; groups; for (string str: A) &#123; memset(hash, 0, sizeof(hash)); for (int i = 0; i &lt; str.size(); i++) &#123; hash[str[i] - 'a' + (i % 2) * 26]++; // 中间wa了一次，因为把26写成2了，就这样居然还过了31个点 &#125; string h = intToString(hash, 52); if (groups.find(h) == groups.end()) groups.insert(h); &#125; return groups.size(); &#125;&#125;; Java Concise Set Solution ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 892. Surface Area of 3D Shapes（枚举），及周赛（99）总结","slug":"2018-08-26-Leetcode-892-Surface-Area-of-3D-Shapes（枚举），及周赛（99）总结","date":"2018-08-26T17:41:41.000Z","updated":"2018-08-26T19:19:00.000Z","comments":true,"path":"post/leetcode-892-surface-area-of-3d-shapes-and-weekly-contest-99/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-892-surface-area-of-3d-shapes-and-weekly-contest-99/","excerpt":"","text":"题目来源：https://leetcode.com/problems/surface-area-of-3d-shapes/description/ 标记难度：Easy 提交次数：2/2 代码效率： 按立方体枚举：8ms 按柱体枚举：4ms 题意 给定一个N*N的平面网格，以及每个网格上堆积了多少个立方体，求整体表面积。 分析 这是我参加的第三次周赛，排名稳步下降（683 / 3877），因为这次我只做出来两道题，然后就卡在第三道上了。事后发现，我的整个解法可能都是不可取的；以及我觉得第四题比第三题简单，比赛结束之后用STL随便拼了拼就做出来了，花了不到半个小时。 这也许说明不应该对着一道题死磕。不过我刷的题量确实还不够，连Medium刷得都不够。 这次比赛居然是两道Easy，一道Medium。 这道题的数据量只有N &lt;= 50，grid[i][j] &lt;= 50，所以很容易想到一种O(N^2 * max(grid[i][j]))的算法：枚举每个立方体，判断它的各面是否被周围的立方体遮住了，然后把没被遮住的部分加起来。题解的做法也是这样的；比赛的时候我就直接这么做了，花了大约8分钟。 事实上很容易想到一种优化方法。我们完全没有必要考虑每一个立方体有几个面被遮住了，只需要考虑对于每个柱子，有多少个面被遮住即可。[1] 代码 按立方体枚举 12345678910111213141516171819202122232425class Solution &#123;public: int surfaceArea(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int N = grid.size(); int sum = 0; // 遍历每一个方块 for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; N; j++) &#123; if (grid[i][j] &gt; 0) sum += 2; // 上下面 for (int k = 0; k &lt; grid[i][j]; k++) &#123; if (i == 0 || i &gt; 0 &amp;&amp; grid[i - 1][j] &lt;= k) sum++; if (i == N - 1 || i &lt; N - 1 &amp;&amp; grid[i + 1][j] &lt;= k) sum++; if (j == 0 || j &gt; 0 &amp;&amp; grid[i][j - 1] &lt;= k) sum++; if (j == N - 1 || j &lt; N - 1 &amp;&amp; grid[i][j + 1] &lt;= k) sum++; &#125; &#125; &#125; return sum; &#125;&#125;; 按柱体枚举 123456789101112131415161718192021222324252627class Solution &#123;public: int surfaceArea(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int sum = 0, N = grid.size(); for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; N; j++) &#123; if (grid[i][j] &gt; 0) sum += grid[i][j] * 4 + 2; /* // 这是一种更简洁的方法：每两个贴在一起的面只用考虑一次 // 只考虑每个柱子左边和上边消掉的面 // ref: https://leetcode.com/problems/surface-area-of-3d-shapes/discuss/163414/C++Java1-line-Python-Minus-Hidden-Area if (i &gt; 0) sum -= min(grid[i][j], grid[i-1][j]) * 2; if (j &gt; 0) sum -= min(grid[i][j], grid[i][j-1]) * 2; */ if (i &gt; 0) sum -= min(grid[i][j], grid[i-1][j]); if (i &lt; N - 1) sum -= min(grid[i][j], grid[i+1][j]); if (j &gt; 0) sum -= min(grid[i][j], grid[i][j-1]); if (j &lt; N - 1) sum -= min(grid[i][j], grid[i][j+1]); &#125; &#125; return sum; &#125;&#125;; Minus Hidden Area ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 401. Binary Watch（枚举）","slug":"2018-08-25-Leetcode-401-Binary-Watch（枚举）","date":"2018-08-25T09:05:03.000Z","updated":"2018-08-25T10:05:03.000Z","comments":true,"path":"post/leetcode-401-binary-watch/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-401-binary-watch/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-watch/description/ 标记难度：Easy 提交次数：1/1 代码效率：100% 题意 有一个二进制LED表，用6个LED灯（1, 2, 4, 8, 16, 32）表示分钟（0-59），4个LED灯（1, 2, 4, 8）表示小时（0-11）。给定共有多少个LED灯是亮的，求所有可能表示的时间。 分析 显然我们可以用搜索来解决这个问题：枚举小时表示中有多少个LED灯是亮的，然后找出所有可能的组合，最后拼在一起。3ms Java Solution Using Backtracking and Idea of &quot;Permutation and Combination&quot;使用的就是这一解法，非常直接。 但是由于时间表示本身的性质（就像在Leetcode 539中说的那样，一天其实只有24*60=1440分钟，24*600*60=86400秒），我们可以写出一种更简单的枚举方法：直接枚举每天的所有时间，然后计算该时间表示中1的数量是否符合要求就可以了。 于是我们又可以用__builtin_popcount了。除此之外，在Straight-forward 6-line c++ solution, no need to explain中，我看到了另一种计算方法： 1int num = bitset&lt;10&gt;(x).count(); 类模板bitset表示一个N位的固定大小序列。可以用标准逻辑运算符操作位集，并将它与字符串和整数相互转换。[1] 这也是个不错的方法（特别是记不住__builtin_popcount的全名的时候），不过我猜测效率会慢一些，毕竟是STL。 代码 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;string&gt; readBinaryWatch(int num) &#123; if (num &gt; 8) return &#123;&#125;; int hours[4] = &#123;1, 2, 4, 8&#125;; int minutes[6] = &#123;1, 2, 4, 8, 16, 32&#125;; vector&lt;string&gt; times; for (int hour = 0; hour &lt; 12; hour++) for (int minute = 0; minute &lt; 60; minute++) &#123; if (__builtin_popcount(hour) + __builtin_popcount(minute) == num) &#123; string time = to_string(hour) + \":\"; if (minute &lt; 10) time += \"0\"; time += to_string(minute); times.push_back(time); &#125; &#125; return times; &#125;&#125;; std::bitset ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"},{"name":"alg:Bit Manipulation","slug":"alg-Bit-Manipulation","permalink":"https://zhanghuimeng.github.io/tags/alg-Bit-Manipulation/"}]},{"title":"Leetcode 331. Verify Preorder Serialization of a Binary Tree（先序遍历）","slug":"2018-08-24-Leetcode-331-Verify-Preorder-Serialization-of-a-Binary-Tree（先序遍历）","date":"2018-08-24T15:30:05.000Z","updated":"2018-09-02T17:18:00.000Z","comments":true,"path":"post/leetcode-331-verify-preorder-serialization-of-a-binary-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-331-verify-preorder-serialization-of-a-binary-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/verify-preorder-serialization-of-a-binary-tree/description/ 标记难度：Medium 提交次数：3/5 代码效率： 冗长的做法：73.99% 考虑有向图的度：73.64% 递归删除子树：73.64% 题意 给定一个二叉树的先序遍历序列（但是其中列出了空结点），要求判断这个序列是否是合法的。 分析 我看到题目中说“不要把树重建出来”之后，随便脑补了一个算法：实际上是类似于重建的做法，用栈取代了递归建树的过程，没有明确记录每个结点的左孩子和右孩子都是什么，只记录了是否存在。中间WA了一次是因为系统要求把一个空结点也判定为合法的先序遍历序列。 做完之后我觉得这是一道非常有趣的题。我们都知道只用先序遍历是无法重建一棵树的，因为几乎完全无法确定树的形状；但把中间遍历过的空结点记录下来之后（这个说法不是很准确；我觉得准确的说法是，对于每个结点都无条件地访问它的左孩子和右孩子，如果访问到的结点为空，仍然按顺序记录到遍历序列中，但不会再去访问它的孩子，显然也没有），我们就可以把它重建出来了。我认为这些多出来的信息（空结点的位置）能够帮助我们确定树的形状，所以空结点实际上提供的信息量是很大的，这一点很有趣。 或者也可以采取另一种看法：在这里空结点就是叶结点，相当于在树上新加了一层叶子；我们仍然做的是一次普通的先序遍历，但是在其中标记了哪些是叶结点。依靠这些叶结点作为定位信息，我们可以把树重建出来。 2018.9.2 UPDATE：这不就是Leetcode输入数据里表示一棵树的方法…… 不过，如果把整棵树都真的重建出来，感觉像是过度利用已有的信息了，如果只需要验证这个序列的合法性，评论区给出了很多很妙的做法。 考虑有向图的度 7 lines Easy Java Solution中提供了一种非常有趣的做法：把二叉树看成一个有向图（当然，树本来就是有向图，但我平时很少这么看……），然后计算图中的总入度和总出度是否相等，且要求计算过程中总出度始终&gt;=总入度；如果满足要求，则原序列为合法的先序遍历序列。 计算总入度和总出度的方法是比较简单的： 根结点提供两个出度 每个除根结点以外的非空结点提供两个出度，一个入度 每个空结点提供一个入度 上述做法的必要性是显然的，对于一棵合法的树，它的总出度和总入度必然是相等的。至于充分性，我觉得可以考虑不合法的几种情况。一个先序遍历序列不合法，只可能是因为： 有的结点缺少左孩子或右孩子：出度+1 有的结点缺少父节点（除根结点外）：入度+1 但是，单纯这样考虑就会遇到问题：如果恰好有一个结点缺少一个孩子，另一个结点缺少一个父亲，那出度和入度就正好“中和”了。所以我们还需要“总出度始终&gt;=总入度”这个条件。我们在按顺序检查遍历序列的每个结点时，由先序遍历的性质，必然是先检查到父结点，再检查到子节点，所以每检查一个非根节点时，必须有足够的出度，才能保证它有父结点，否则树仍然是不合法的。 所以事实上这个条件可以缩得更紧：在处理完最后一个结点之前，要求总出度始终&gt;总入度。 The simplest python solution with explanation (no stack, no recursion)中的做法本质上是相同的，但作者解释得更好。 递归删除子树 Java intuitive 22ms solution with stack中提供了一种看起来很简单的方法： 遇到非空结点则入栈 遇到空结点时，检查栈顶是否为空结点 如果栈为空，返回错误 如果栈顶为非空结点，则将空结点入栈 如果栈顶为空结点，则将空结点弹出，并将栈顶（此时必为非空结点）也弹出，然后连续处理，直到栈顶不是空结点为止 验证最后栈中只剩一个空结点 这种方法本质上就是不断把子树替换成空结点。 我用一种比较笨的方法实现了替换，但实际上连续弹出结点的时候必然是先弹出一个空结点，再弹出一个非空结点，再弹出一个空结点……如此交替，且最后栈不能为空。 代码 冗长的做法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class Solution &#123;private: // https://stackoverflow.com/questions/236129/the-most-elegant-way-to-iterate-the-words-of-a-string std::vector&lt;std::string&gt; split(const std::string &amp;text, char sep) &#123; std::vector&lt;std::string&gt; tokens; std::size_t start = 0, end = 0; while ((end = text.find(sep, start)) != std::string::npos) &#123; tokens.push_back(text.substr(start, end - start)); start = end + 1; &#125; tokens.push_back(text.substr(start)); return tokens; &#125; struct Node &#123; bool left; bool right; Node() &#123; left = right = false; &#125; &#125;;public: bool isValidSerialization(string preorder) &#123; // 可以按照堆排序的思路，顺序计算每一个结点是否是valid的 // 不对，这个是前序遍历，不是层次遍历…… // 又遇到这个split的问题了== // 这是什么鬼特判 if (preorder == \"#\") return true; vector&lt;string&gt; tokens(split(preorder, ',')); stack&lt;Node&gt; tree; if (tokens.size() &lt; 1 || tokens[0] == \"#\") return false; tree.push(Node()); for (int i = 1; i &lt; tokens.size(); i++) &#123; if (tree.empty()) return false; if (tree.top().left &amp;&amp; tree.top().right) return false; if (!tree.top().left) tree.top().left = true; else tree.top().right = true; if (tokens[i] == \"#\") &#123; while (!tree.empty() &amp;&amp; tree.top().left &amp;&amp; tree.top().right) tree.pop(); &#125; else &#123; tree.push(Node()); &#125; &#125; if (!tree.empty()) return false; return true; &#125;&#125;; 考虑有向图的度 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;private: // https://stackoverflow.com/questions/236129/the-most-elegant-way-to-iterate-the-words-of-a-string std::vector&lt;std::string&gt; split(const std::string &amp;text, char sep) &#123; std::vector&lt;std::string&gt; tokens; std::size_t start = 0, end = 0; while ((end = text.find(sep, start)) != std::string::npos) &#123; tokens.push_back(text.substr(start, end - start)); start = end + 1; &#125; tokens.push_back(text.substr(start)); return tokens; &#125;public: bool isValidSerialization(string preorder) &#123; if (preorder == \"#\") return true; vector&lt;string&gt; tokens(split(preorder, ',')); int inDegree = 0, outDegree = 0; for (int i = 0; i &lt; tokens.size(); i++) &#123; if (i == 0) &#123; if (tokens[i] == \"#\") return false; outDegree += 2; &#125; else if (tokens[i] == \"#\") &#123; inDegree++; &#125; else &#123; inDegree++; outDegree += 2; &#125; if (outDegree &lt; inDegree || (outDegree == inDegree &amp;&amp; i != tokens.size() - 1)) return false; &#125; return outDegree == inDegree; &#125;&#125;; 递归删除子树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution &#123;private: // https://stackoverflow.com/questions/236129/the-most-elegant-way-to-iterate-the-words-of-a-string std::vector&lt;std::string&gt; split(const std::string &amp;text, char sep) &#123; std::vector&lt;std::string&gt; tokens; std::size_t start = 0, end = 0; while ((end = text.find(sep, start)) != std::string::npos) &#123; tokens.push_back(text.substr(start, end - start)); start = end + 1; &#125; tokens.push_back(text.substr(start)); return tokens; &#125;public: bool isValidSerialization(string preorder) &#123; vector&lt;string&gt; tokens(split(preorder, ',')); stack&lt;string&gt; tree; for (int i = 0; i &lt; tokens.size(); i++) &#123; string node = tokens[i]; if (i == 0) &#123; tree.push(node); continue; &#125; tree.push(node); while (tree.size() &gt;= 2) &#123; string n1 = tree.top(); tree.pop(); string n2 = tree.top(); tree.pop(); if (n1 == \"#\" &amp;&amp; n2 == \"#\") &#123; if (tree.empty()) return false; tree.pop(); tree.push(\"#\"); &#125; else &#123; tree.push(n2); tree.push(n1); break; &#125; &#125; &#125; return !tree.empty() &amp;&amp; tree.size() == 1 &amp;&amp; tree.top() == \"#\"; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"}]},{"title":"USACO 1.3.5: Dual Palindromes","slug":"2018-08-24-USACO-1-3-5-Dual-Palindromes","date":"2018-08-24T00:22:43.000Z","updated":"2018-08-24T00:29:43.000Z","comments":true,"path":"post/usaco-1-3-5-dual-palindromes/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-3-5-dual-palindromes/","excerpt":"","text":"题意 见洛谷 P1207。 分析 这道题和上一道用到的代码很像，所以复用了一些。以及，题解里有个很有趣的说法：因为双重回文数很稠密，所以我们可以用暴力算法寻找这些数。但是如何说明双重回文数很普遍呢？这听起来好像循环论证了。写个暴力代码，按最大数据规模跑一遍（对这道题是比较简单的）就知道暴力到底是否可行了。输入15 9999时，程序输出： 123456789101112131415102521030810658107941085810922109861125311314117571189811950122911235512419 说明暴力算法确实是可行的。 （虽然我选择暴力只是因为这个Section的主题是暴力搜索，连想都没想。） 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/*ID: zhanghu15TASK: dualpalLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;map&gt;#include &lt;algorithm&gt;using namespace std;string base10ToB(int B, int x) &#123; string baseB; if (x == 0) return \"0\"; while (x &gt; 0) &#123; baseB = (char)(x % B + '0') + baseB; x /= B; &#125; return baseB;&#125;bool checkIsPalindrome(string x) &#123; int n = x.length(); for (int i = 0; i + i &lt; n; i++) if (x[i] != x[n - i - 1]) return false; return true;&#125;int main() &#123; ofstream fout(\"dualpal.out\"); ifstream fin(\"dualpal.in\"); int N, S; fin &gt;&gt; N &gt;&gt; S; for (int i = S + 1; ; i++) &#123; int palNum = 0; for (int b = 2; b &lt;= 10; b++) &#123; if (checkIsPalindrome(base10ToB(b, i))) palNum++; if (palNum &gt;= 2) break; &#125; if (palNum &gt;= 2) &#123; fout &lt;&lt; i &lt;&lt; endl; if (--N == 0) break; &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.3.4: Palindromic Squares","slug":"2018-08-24-USACO-1-3-4-Palindromic-Squares","date":"2018-08-24T00:04:19.000Z","updated":"2018-08-24T00:10:19.000Z","comments":true,"path":"post/usaco-1-3-4-palindromic-squares/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-3-4-palindromic-squares/","excerpt":"","text":"题意 见洛谷 P1206。 分析 直接枚举就可以。进制转换不是很难，但是我遇到了一个小bug：在&lt;=4.8.0的MinGW中，stoi和to_string等几个函数是没法直接用的。[1]这个问题有解决方案，但是我懒得去修了，总之我发现可以直接把char赋给string。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/*ID: zhanghu15TASK: palsquareLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;map&gt;#include &lt;algorithm&gt;using namespace std;map&lt;int, string&gt; digitMap;void init() &#123; // 可以把char赋给string for (int i = 0; i &lt; 10; i++) digitMap[i] = char(i + '0'); // to_string does not work, a known issue for (int i = 10; i &lt;= 20; i++) digitMap[i] = (char) (i - 10 + 'A');&#125;string base10ToB(int B, int x) &#123; string baseB; if (x == 0) return \"0\"; while (x &gt; 0) &#123; baseB = digitMap[x % B] + baseB; x /= B; &#125; return baseB;&#125;bool checkIsPalindrome(string x) &#123; int n = x.length(); for (int i = 0; i + i &lt; n; i++) if (x[i] != x[n - i - 1]) return false; return true;&#125;int main() &#123; ofstream fout(\"palsquare.out\"); ifstream fin(\"palsquare.in\"); int B; fin &gt;&gt; B; init(); for (int i = 1; i &lt;= 300; i++) &#123; string square = base10ToB(B, i * i); if (checkIsPalindrome(square)) &#123; fout &lt;&lt; base10ToB(B, i) &lt;&lt; ' ' &lt;&lt; square &lt;&lt; endl; &#125; &#125; return 0;&#125; Bug 52015 - std::to_string does not work under MinGW ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.3.3: Name That Number","slug":"2018-08-22-USACO-1-3-3-Name-That-Number","date":"2018-08-22T23:35:24.000Z","updated":"2018-08-23T00:24:00.000Z","comments":true,"path":"post/usaco-1-3-3-name-that-number/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-3-3-name-that-number/","excerpt":"","text":"题意 见洛谷 P3864。 分析 简单的映射题。如果从编号出发计算所有可能的字母组合，然后再去字典里查找，那么复杂度会变得过高。题解中给出了一种利用二分查找进行优化的方法，但是不太好懂。显然把字典中的单词映射成号码，再根据号码去查找会简单（且好写）很多。 代码 我的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/*ID: zhanghu15TASK: namenumLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;map&gt;using namespace std;int main() &#123; ofstream fout(\"namenum.out\"); ifstream fin(\"namenum.in\"); ifstream fin2(\"dict.txt\"); map&lt;char, char&gt; numMap; numMap['A'] = numMap['B'] = numMap['C'] = '2'; numMap['D'] = numMap['E'] = numMap['F'] = '3'; numMap['G'] = numMap['H'] = numMap['I'] = '4'; numMap['J'] = numMap['K'] = numMap['L'] = '5'; numMap['M'] = numMap['N'] = numMap['O'] = '6'; numMap['P'] = numMap['R'] = numMap['S'] = '7'; numMap['T'] = numMap['U'] = numMap['V'] = '8'; numMap['W'] = numMap['X'] = numMap['Y'] = '9'; map&lt;string, vector&lt;string&gt;&gt; numToNameMap; // 似乎题目描述中没有明确说明，dict.txt中不会出现Q和Z？ // 经查，确实可能出现，所以要特判 string name, number; while (fin2 &gt;&gt; name) &#123; bool isOk = true; number.clear(); for (char ch: name) &#123; if (ch == 'Q' || ch == 'Z') &#123; isOk = false; break; &#125; number += numMap[ch]; &#125; if (isOk) numToNameMap[number].push_back(name); &#125; fin &gt;&gt; number; vector&lt;string&gt; validNames = numToNameMap[number]; if (validNames.size() == 0) fout &lt;&lt; \"NONE\" &lt;&lt; endl; else &#123; sort(validNames.begin(), validNames.end()); for (string validName: validNames) fout &lt;&lt; validName &lt;&lt; endl; &#125; return 0;&#125; 参考代码 Here is Argentina competitor’s Michel Mizrah’s solution using the first method with a binary search. While it is blazingly fast, it does have the disadvantage of some fairly tricky coding in the binary search routine. A single off-by-one error would doom a program in a contest. 具体见注释。事实上，我觉得这份代码体现的思想更类似于Trie，而不是二分——我真没看出来“二分”在哪。以及我似乎找到了这份代码中的一个bug。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;char num[12],sol[12];char dict[5000][13];int nsolutions = 0;int nwords;int maxlen;FILE *out;/*这个函数进行了一个枚举+二分的过程@charloc 下一个需要枚举的编号位置@low 当前二分下限@high 当前二分上限*/void calc (int charloc, int low, int high) &#123; // 枚举已经完成，判断当前二分区域中是否有符合要求的字符串 // 我觉得在此处其实不需要用strcmp，因为前面的字母必然是相等的 // 判断最后一个字母和长度相等即可 // 经过一些实验，这种做法居然不对！事实上我找到了这份代码中的一个bug。 // 在修复bug之后，这种做法就正确了。 if (charloc == maxlen) &#123; sol[charloc] = '\\0'; for (int x = low; x &lt; high; x++) &#123; // 修复bug后下列代码也是可行的： // if (strlen(dict[x]) == maxlen &amp;&amp; sol[charloc-1] == dict[x][charloc-1]) &#123; if (strcmp (sol, dict[x]) == 0) &#123; fprintf (out, \"%s\\n\", sol); nsolutions++; &#125; &#125; return; &#125; // 根据当前枚举编号的位置进行“二分” // 首先找到“字典中当前位置字符与枚举结果当前位置字符相等”的下限 // 然后遍历找到上限 // charloc == 0时，还没有开始对字符进行枚举，所以不需要进行这一步， // [low, high]的范围是整个字典 if (charloc &gt; 0) &#123; for (int j=low; j &lt;= high; j++)&#123; if (sol[charloc-1] == dict[j][charloc-1]) &#123; low=j; // 问题在于，这个while是有可能越界的。j有可能会超出high的范围 // 但原作者没有进行判断，导致[low, high)范围内的字符串并不一定满足要求 // 所以可能会溢出。 // 测试样例：26678268463 while (sol[charloc-1] == dict[j][charloc-1]) j++; high=j; break; &#125; if (j == high) return; &#125; &#125; if (low &gt; high) return; // 枚举下一个位置应有的字符 switch(num[charloc])&#123; case '2':sol[charloc] = 'A'; calc(charloc+1,low,high); sol[charloc] = 'B'; calc(charloc+1,low,high); sol[charloc] = 'C'; calc(charloc+1,low,high); break; case '3':sol[charloc] = 'D'; calc(charloc+1,low,high); sol[charloc] = 'E'; calc(charloc+1,low,high); sol[charloc] = 'F'; calc(charloc+1,low,high); break; case '4':sol[charloc] = 'G'; calc(charloc+1,low,high); sol[charloc] = 'H'; calc(charloc+1,low,high); sol[charloc] = 'I'; calc(charloc+1,low,high); break; case '5':sol[charloc] = 'J'; calc(charloc+1,low,high); sol[charloc] = 'K'; calc(charloc+1,low,high); sol[charloc] = 'L'; calc(charloc+1,low,high); break; case '6':sol[charloc] = 'M'; calc(charloc+1,low,high); sol[charloc] = 'N'; calc(charloc+1,low,high); sol[charloc] = 'O'; calc(charloc+1,low,high); break; case '7':sol[charloc] = 'P'; calc(charloc+1,low,high); sol[charloc] = 'R'; calc(charloc+1,low,high); sol[charloc] = 'S'; calc(charloc+1,low,high); break; case '8':sol[charloc] = 'T'; calc(charloc+1,low,high); sol[charloc] = 'U'; calc(charloc+1,low,high); sol[charloc] = 'V'; calc(charloc+1,low,high); break; case '9':sol[charloc] = 'W'; calc(charloc+1,low,high); sol[charloc] = 'X'; calc(charloc+1,low,high); sol[charloc] = 'Y'; calc(charloc+1,low,high); break; &#125;&#125;int main()&#123; FILE *in=fopen (\"namenum.in\", \"r\"); FILE *in2=fopen (\"dict.txt\", \"r\"); int j; out=fopen (\"namenum.out\",\"w\"); // 输入字典 for (nwords = 0; fscanf (in2, \"%s\", &amp;dict[nwords++]) != EOF; ) ; fscanf (in, \"%s\",&amp;num); maxlen = strlen(num); // 从初始位置开始枚举 calc (0, 0, nwords); if (nsolutions == 0) fprintf(out,\"NONE\\n\"); return 0;&#125;","categories":[],"tags":[{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.3.2: Transformations","slug":"2018-08-22-USACO-1-3-2-Transformations","date":"2018-08-22T18:39:37.000Z","updated":"2018-08-22T19:02:00.000Z","comments":true,"path":"post/usaco-1-3-2-transformations/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-3-2-transformations/","excerpt":"","text":"题意 见洛谷 P1205。 分析 矩阵旋转 模拟矩阵变换，包括反射和旋转。听起来像是计算机图形学基础……如果想不清楚坐标到底怎么变换，手动模拟一下就很显然了。当然，事实上这一点是可以进行严格的数学推导的[1]，但是里面用到了齐次坐标，我看不太懂。 另一个问题是，其实矩阵是可以做到原地旋转的，原理是每四个元素在旋转中组成一个圈，直接循环swap它们就可以了[2]。当然反射更可以做到原地。 运算符重载 这次标答的写法也用到了struct和运算符重载，这样写起来比较方便。不过我又一次（不知道第多少次了）忘掉了运算符重载的写法…… 这次重载了==和&gt;&gt;，其中&gt;&gt;需要重载为友元函数，且第一个参数是istream。参见[3]。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/*ID: zhanghu15TASK: transformLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;struct Board &#123; int n; bool tile[11][11]; bool original[11][11]; bool tmp[11][11]; Board(int n) &#123; this-&gt;n = n; &#125; friend istream &amp;operator &gt;&gt; (istream&amp; input, Board&amp; b) &#123; char ch; for (int i = 0; i &lt; b.n; i++) for (int j = 0; j &lt; b.n; j++) &#123; input &gt;&gt; ch; if (ch == '@') b.tile[i][j] = 1; else b.tile[i][j] = 0; &#125; memcpy(b.original, b.tile, sizeof(b.tile)); return input; &#125; bool operator == (Board&amp; b) &#123; if (n != b.n) return false; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; n; j++) if (tile[i][j] != b.tile[i][j]) return false; return true; &#125; void restore() &#123; memcpy(tile, original, sizeof(original)); &#125; void turnClockwise90() &#123; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; n; j++) tmp[j][n - i - 1] = tile[i][j]; memcpy(tile, tmp, sizeof(tmp)); &#125; void reflect() &#123; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; n; j++) tmp[i][n - j - 1] = tile[i][j]; memcpy(tile, tmp, sizeof(tmp)); &#125;&#125;;int N;int main() &#123; ofstream fout(\"transform.out\"); ifstream fin(\"transform.in\"); fin &gt;&gt; N; Board from(N), to(N); fin &gt;&gt; from &gt;&gt; to; // #1 from.turnClockwise90(); if (from == to) &#123; fout &lt;&lt; 1 &lt;&lt; endl; return 0; &#125; // #2 from.turnClockwise90(); if (from == to) &#123; fout &lt;&lt; 2 &lt;&lt; endl; return 0; &#125; // #3 from.turnClockwise90(); if (from == to) &#123; fout &lt;&lt; 3 &lt;&lt; endl; return 0; &#125; // #4 from.restore(); from.reflect(); if (from == to) &#123; fout &lt;&lt; 4 &lt;&lt; endl; return 0; &#125; // #5 for (int i = 0; i &lt; 3; i++) &#123; from.turnClockwise90(); if (from == to) &#123; fout &lt;&lt; 5 &lt;&lt; endl; return 0; &#125; &#125; from.restore(); if (from == to) &#123; fout &lt;&lt; 6 &lt;&lt; endl; return 0; &#125; fout &lt;&lt; 7 &lt;&lt; endl; return 0;&#125; How to rotate the positions of a matrix by 90 degrees ↩︎ Inplace rotate square matrix by 90 degrees | Set 1 ↩︎ C++ 二元运算符重载 ↩︎","categories":[],"tags":[{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 783 (530). Minimum Distance Between BST Nodes（二叉搜索树遍历）","slug":"2018-08-22-Leetcode-783-530-Minimum-Distance-Between-BST-Nodes（二叉搜索树遍历）","date":"2018-08-22T11:03:57.000Z","updated":"2018-08-22T11:21:00.000Z","comments":true,"path":"post/leetcode-783-530-minimum-distance-between-bst-nodes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-783-530-minimum-distance-between-bst-nodes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-distance-between-bst-nodes/description/ 标记难度：Easy 提交次数：1/1 代码效率：12.62% 题意 给定一个二叉搜索树，返回树中任意两个结点之间差的最小值。 分析 Leetcode有些题目，真是水得有点过头……这道题数据规模只有100，简直是直接枚举都能做了。当然正确的做法是中序遍历。我最开始还以为要像173题那样手写一个找后继的方法，结果发现根本不用，直接中序遍历然后记录上一个元素就行了。 甚至更水的是，这道题和530题基本一模一样（通过评论区的提示得知……），直接用同一份代码交上去就可以AC了，于是我收获了两个AC…… 不过，一个有趣的问题是，如果我们把530题的描述改一下，从“差的绝对值”改成“绝对值的差”会怎么样？这样改过之后，我觉得我们实际上获得了0-2棵子BST，以及一棵“反的”子BST（因为从负数取反了）。从树的角度来做处理其实不太好做，还不如干脆就把负数结点从树里全删掉，然后再把它们的绝对值加回去，最后再遍历。当然，更简单的做法是把树中的全部结点的绝对值都取出来，排序，然后直接做…… 代码 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: int last; int minDif; void traverse(TreeNode* cur) &#123; if (cur == NULL) return; traverse(cur-&gt;left); if (last != -1) minDif = min(minDif, cur-&gt;val - last); last = cur-&gt;val; traverse(cur-&gt;right); &#125;public: int minDiffInBST(TreeNode* root) &#123; last = -1; minDif = 1000000; traverse(root); return minDif; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"}]},{"title":"Leetcode 860. Lemonade Change（贪心）","slug":"2018-08-22-Leetcode-860-Lemonade-Change（贪心）","date":"2018-08-22T00:40:44.000Z","updated":"2018-08-22T09:25:00.000Z","comments":true,"path":"post/leetcode-860-lemonade-change/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-860-lemonade-change/","excerpt":"","text":"题目来源：https://leetcode.com/problems/lemonade-change/description/ 标记难度：Easy 提交次数：1/1 代码效率：15.43% 题意 你在卖一种5元的柠檬水，顾客会分别用5元、10元和20元的纸币购买，你在开始的时候没有零钱。给定顾客使用的纸币类型顺序，问你能否顺利完成找零过程。 分析 看起来是道水题，模拟就行，不过中间有一个选择的问题：当顾客使用20元纸币的时候，你应该找3张5元的纸币，还是找1张5元和1张10元呢？直觉告诉我们，应该尽量找1张5元和1张10元的，因为5元纸币的用途更广，而10元纸币除了在收到20元时找零，其他时候是花不出去的。 我在考虑如何形式化的证明这一问题。比如说，用stay-ahead方法。[1] 把原问题的目标扩大一下，优化目标变为“尽可能的服务最多的顾客”。记我们的算法给出的解（给每个顾客找零的纸币）为A=a1,a2,...,akA = \\\\{a_1, a_2, ..., a_k \\\\}A=a1​,a2​,...,ak​，最优解（之一）为O=o1,o2,...,omO = \\\\{ o_1, o_2, ..., o_m \\\\}O=o1​,o2​,...,om​。令f(i)f(i)f(i)表示按顺序服务完第iii个顾客后剩余的每种纸币的数量。由于我们的算法中会尽可能的节省5元纸币，所以对于任意iii，都满足fA5(i)≥fO5(i)f_{A5}(i) \\geq f_{O5}(i)fA5​(i)≥fO5​(i)，fA10(i)≤fO10(i)f_{A10}(i) \\leq f_{O10}(i)fA10​(i)≤fO10​(i)。因为总钱数不变，且只能用5元和10元纸币找零，所以这两种零钱的总数是一定的，5fA5(i)+10fA10(i)=5fO5(i)+10fO10(i)5f_{A5}(i) + 10f_{A10}(i) = 5f_{O5}(i) + 10f_{O10}(i)5fA5​(i)+10fA10​(i)=5fO5​(i)+10fO10​(i)。 下面证明AAA必然是一个最优算法。若AAA不是最优的，则必然k&lt;mk &lt; mk&lt;m，也就是AAA无法为第k+1k + 1k+1位顾客找零，但OOO可以。若第k+1k + 1k+1位顾客使用的是5元或10元纸币，由于fA5(k+1)≥fO5(k+1)f_{A5}(k + 1) \\geq f_{O5}(k + 1)fA5​(k+1)≥fO5​(k+1)，只要OOO满足要求，AAA必然满足要求，所以这显然是不可能的。若该顾客使用的是20元纸币，由于OOO可以为他找零，说明fO5(k+1)≥3f_{O5}(k + 1) \\geq 3fO5​(k+1)≥3，或fO5(k+1)≥1,fO10(k+1)≥1f_{O5}(k + 1) \\geq 1, f_{O10}(k + 1) \\geq 1fO5​(k+1)≥1,fO10​(k+1)≥1。如果fO5(k+1)≥3f_{O5}(k + 1) \\geq 3fO5​(k+1)≥3，和刚才的情况相同，AAA必然也满足要求。如果fO5(k+1)≥1,fO10(k+1)≥1f_{O5}(k + 1) \\geq 1, f_{O10}(k + 1) \\geq 1fO5​(k+1)≥1,fO10​(k+1)≥1，由于两种算法剩余的5元和10元纸币的总钱数必然相等，必有fA5(k+1)≥3f_{A5}(k + 1) \\geq 3fA5​(k+1)≥3或fA5(k+1)≥1,fA10(k+1)≥1f_{A5}(k + 1) \\geq 1, f_{A10}(k + 1) \\geq 1fA5​(k+1)≥1,fA10​(k+1)≥1，AAA仍然可以找零，推出矛盾。 综上，我们的算法可以给出最优解。 代码 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: bool lemonadeChange(vector&lt;int&gt;&amp; bills) &#123; // 收5元：没有问题 // 收10元：需要找一张5元 // 收20元：需要找3张5元，或1张5元+1张10元 // 所以从贪心的角度，我觉得对于收20元，优先找10元+5元是合理的 int fiveCnt = 0, tenCnt = 0, twentyCnt = 0; for (int bill: bills) &#123; if (bill == 5) fiveCnt++; else if (bill == 10) &#123; if (fiveCnt == 0) return false; fiveCnt--; tenCnt++; &#125; else if (bill == 20) &#123; if (tenCnt &gt; 0 &amp;&amp; fiveCnt &gt; 0) &#123; tenCnt--; fiveCnt--; twentyCnt++; &#125; else if (fiveCnt &gt;= 3) &#123; fiveCnt -= 3; twentyCnt++; &#125; else return false; &#125; &#125; return true; &#125;&#125;; Proof Techniques: Greedy Stay Ahead （另一种常见技巧是Greedy Exchange） ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"USACO 1.3.1: Milking Cows","slug":"2018-08-22-USACO-1-3-1-Milking-Cows","date":"2018-08-22T00:20:00.000Z","updated":"2018-08-22T00:28:00.000Z","comments":true,"path":"post/usaco-1-3-1-milking-cows/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-3-1-milking-cows/","excerpt":"","text":"题意 见洛谷 P1204。 分析 看到题目的第一反应是用线段树，但是既然前面的文章说的是搜索，而且数据范围只有[1, 1000000]，那是不是直接暴力就能过呢？想了想，N的范围是[1, 5000]，直接过还是有点悬的。 实际上，完全可以把所有区间排序，然后直接扫描，获得每个有农夫在挤奶的区间，以及每个空闲的区间，然后算出最大区间长度。另一种更好想的做法是，先把所有区间排序，然后把所有能合并的区间合并起来，最后再扫描。 我第一次提交的时候WA了，因为我不知怎的就看错题了，把求最大值看成了求和……不过本质上是一样的。 这无疑是一道很有趣的题。我直觉上会觉得，这种题目应该在离散化之后用线段树来解决；事实证明，离散化的思想就够了，线段树反而是杀鸡用牛刀（因为只需要整个区间上的两种统计量，而且都可以通过O(N)的代价计算出来，不需要区间查询或者区间归并什么的）。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*ID: zhanghu15TASK: milk2LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main() &#123; ofstream fout(\"milk2.out\"); ifstream fin(\"milk2.in\"); int N; int startTime, endTime; vector&lt;pair&lt;int, int&gt;&gt; times; fin &gt;&gt; N; for (int i = 0; i &lt; N; i++) &#123; fin &gt;&gt; startTime &gt;&gt; endTime; times.push_back(make_pair(startTime, endTime)); &#125; sort(times.begin(), times.end()); // 我傻了……不是要求和啊！是要求最大值啊！ int milkTimeStart = -1, milkTimeEnd = -1; int maxMilkTimeInterval = 0, maxIdleTimeInterval = 0; for (pair&lt;int, int&gt; time: times) &#123; startTime = time.first; endTime = time.second; if (milkTimeStart == -1) &#123; milkTimeStart = startTime; milkTimeEnd = endTime; &#125; else if (startTime &lt;= milkTimeEnd) &#123; // 连续挤奶 if (endTime &gt; milkTimeEnd) milkTimeEnd = endTime; &#125; else &#123; // 中间出现空闲 maxIdleTimeInterval = max(maxIdleTimeInterval, startTime - milkTimeEnd); maxMilkTimeInterval = max(maxMilkTimeInterval, milkTimeEnd - milkTimeStart); milkTimeStart = startTime; milkTimeEnd = endTime; &#125; &#125; maxMilkTimeInterval = max(maxMilkTimeInterval, milkTimeEnd - milkTimeStart); fout &lt;&lt; maxMilkTimeInterval &lt;&lt; ' ' &lt;&lt; maxIdleTimeInterval &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.2.4: Broken Necklace","slug":"2018-08-21-USACO-1-2-4-Broken-Necklace","date":"2018-08-21T23:06:53.000Z","updated":"2018-08-21T23:27:00.000Z","comments":true,"path":"post/usaco-1-2-4-broken-necklace/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-2-4-broken-necklace/","excerpt":"","text":"题意 见洛谷 P1203。 分析 因为数据量只有350，所以完全可以直接暴力：枚举每一个打破项链的位置，然后分别向左和向右模拟取同色珠子的过程，复杂度是O(N^2)。有一些可以简化模拟过程的小技巧： 把珠子的字符串复制两遍。好吧，这一点其实有一点tricky（所以我在代码里写的时候实际上复制了三份），但是我觉得复制两遍还是足够的。 不是枚举每一个打破的位置，而是模拟从当前位置开始，允许打破一次能得到的最大长度。本质上没有差异，但据说会更好写一些。 不判断枚举两侧时是否相互覆盖，因为一旦发生相互覆盖，说明必然可以数完全部珠子，只要把最终结果和N取最小值即可。 当然用动态规划的方法也是可以的，对于每个点，计算向左和向右分别最多能收集多少红色和蓝色的珠子，从左开始扫一遍，再从右开始扫一遍即可。 关于“复制两遍为何足够”的一些想法：通过这一遍的复制，环上所有可能的圈都展开成了2*N数组中的一个子线段，因此最优解之一必然会被上述模拟过程覆盖到。动态规划法也是这样。这件事看起来是显然的，但我写代码的时候显然并没有想清楚。 代码 模拟 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/*ID: zhanghu15TASK: beadsLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;cstring&gt;using namespace std;int main() &#123; ofstream fout(\"beads.out\"); ifstream fin(\"beads.in\"); int N; char tmp[355], beads[1200]; fin &gt;&gt; N; fin &gt;&gt; tmp; for (int i = 0; i &lt; N; i++) beads[i] = beads[i + N] = beads[i + 2 * N] = tmp[i]; int maxSum = -1; // 遍历每一个可以break的位置 for (int i = N; i &lt; 2 * N; i++) &#123; // break before i char color = 'w'; int sum = 0; for (int j = 0; j &lt; N; j++) &#123; if (beads[i + j] != 'w') &#123; if (color == 'w') color = beads[i + j]; else if (color != beads[i + j]) break; &#125; sum++; &#125; color = 'w'; for (int j = 1; j &lt;= N; j++) &#123; if (beads[i - j] != 'w') &#123; if (color == 'w') color = beads[i - j]; else if (color != beads[i - j]) break; &#125; sum++; &#125; if (sum &gt; N) sum = N; maxSum = max(maxSum, sum); &#125; fout &lt;&lt; maxSum &lt;&lt; endl; return 0;&#125; DP 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/*ID: zhanghu15TASK: beadsLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;cstring&gt;using namespace std;int main() &#123; ofstream fout(\"beads.out\"); ifstream fin(\"beads.in\"); int N; char tmp[355], beads[800]; // 开两倍其实就足够计算了 fin &gt;&gt; N; fin &gt;&gt; tmp; for (int i = 0; i &lt; N; i++) beads[i] = beads[i + N] = tmp[i]; // break before i // 注意语义！ int left_red[800], left_blue[800], right_red[800], right_blue[800]; left_red[0] = left_blue[0] = 0; for (int i = 1; i &lt; 2 * N; i++) &#123; if (beads[i - 1] == 'r') &#123; left_red[i] = left_red[i - 1] + 1; left_blue[i] = 0; &#125; else if (beads[i - 1] == 'b') &#123; left_red[i] = 0; left_blue[i] = left_blue[i - 1] + 1; &#125; else &#123; left_red[i] = left_red[i - 1] + 1; left_blue[i] = left_blue[i - 1] + 1; &#125; &#125; // 因为是break before i，所以可以从右端不存在处开始初始化 right_red[2 * N] = right_blue[2 * N] = 0; for (int i = 2 * N - 1; i &gt;= 0; i--) &#123; if (beads[i] == 'r') &#123; right_red[i] = right_red[i + 1] + 1; right_blue[i] = 0; &#125; else if (beads[i] == 'b') &#123; right_red[i] = 0; right_blue[i] = right_blue[i + 1] + 1; &#125; else &#123; right_red[i] = right_red[i + 1] + 1; right_blue[i] = right_blue[i + 1] + 1; &#125; &#125; // 不需要特判超过N的情况，因为超过N则必然可以达到N了 int maxSum = -1; for (int i = 0; i &lt; 2 * N; i++) maxSum = max(maxSum, max(left_red[i], left_blue[i]) + max(right_red[i], right_blue[i])); fout &lt;&lt; min(maxSum, N) &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.2.3: Friday the Thirteenth","slug":"2018-08-20-USACO-1-2-3-Friday-the-Thirteenth","date":"2018-08-20T02:11:22.000Z","updated":"2018-08-20T02:15:00.000Z","comments":true,"path":"post/usaco-1-2-3-friday-the-thirteenth/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-2-3-friday-the-thirteenth/","excerpt":"","text":"题意 见洛谷 P1202。 分析 比较简单的模拟题（或者说是暴力），但是思路有点绕。在做题的时候，我好好考虑了一下，这个月的13号和下个月的13号之间到底应该差多少天，结论是天数取决于这个月的天数，而和下个月的天数无关：因为我们可以把下个月的13天挪到这个月前面来，这样就凑齐了这个月的所有天数。这好像是一个很简单的结论，但是在日常生活中我从来没有仔细思考过这个问题，总有种“应该是个平均值吧”的错觉。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*ID: zhanghu15TASK: fridayLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;using namespace std;int daysInMonth[] = &#123;31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31&#125;;int thirteens[7];int main() &#123; ofstream fout(\"friday.out\"); ifstream fin(\"friday.in\"); int N; fin &gt;&gt; N; int dayOfWeek = 5; // 1900.1.13是周六 int year = 1900; for (int i = 0; i &lt; N; i++) &#123; for (int month = 0; month &lt; 12; month++) &#123; thirteens[dayOfWeek]++; dayOfWeek += daysInMonth[month]; if (month == 1 &amp;&amp; ((year % 4 == 0 &amp;&amp; year % 100 != 0) || year % 400 == 0)) dayOfWeek++; dayOfWeek %= 7; &#125; year++; &#125; // 输出顺序是周六，周日，周一，周二……有趣 // 好吧！USACO不接受行尾空格！ fout &lt;&lt; thirteens[5]; for (int i = 6; i &lt; 12; i++) fout &lt;&lt; ' ' &lt;&lt; thirteens[i % 7]; fout &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:Brute Force","slug":"alg-Brute-Force","permalink":"https://zhanghuimeng.github.io/tags/alg-Brute-Force/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 891. Sum of Subsequence Widths（子序列；ad hoc）","slug":"2018-08-19-Leetcode-891-Sum-of-Subsequence-Widths（子序列；ad-hoc）","date":"2018-08-19T17:55:20.000Z","updated":"2018-08-19T20:02:00.000Z","comments":true,"path":"post/leetcode-891-sum-of-subsequence-widths/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-891-sum-of-subsequence-widths/","excerpt":"","text":"题目来源：https://leetcode.com/problems/sum-of-subsequence-widths/description/ 标记难度：Hard 提交次数：1/1 代码效率：64ms 题意 给定数组A，考虑A的所有非空子序列。对于每个子序列，定义它的width为子序列中最大值-最小值。求A的所有非空子序列的width之和模1000000007。 分析 这是周赛的第4题。我比赛的时候花了40分钟也没想出来，但其实我感觉我已经接近正确答案了！我考虑了一会儿怎么用二分之类的方法之后，感觉针对width和序列本身去二分是不可取的，不如转而考虑每个元素会在多少个子序列里做最大值，在多少个子序列里做最小值。思路是正确的，但是我开始的时候看错题了，看成是subarray而非subsequence了……所以最后没做完…… 对于子序列而言，顺序不是很重要，所以首先可以把数组排序。[1]（这真是一个珍贵的直觉。）这之后，对于元素A[i]，有i个比它更小的元素，所以在2 ^ i个子序列中，它是最大的元素；有n - i - 1个比它更大的元素，所以在2 ^ (n - i - 1)个子序列中，它是最大的元素。所以，就A[i]而言，result += (2^i - 2^(n-i-1)) * A[i]。在实际求解过程中，为了避免重复求2的幂次，可以把上述代码按2的幂次进行拆分。[2] 之前我对重复元素的情况有些疑虑，但现在想来并不是必要的。在上述方法中，我们对每个子序列都恰好考虑了两遍：一遍是开头元素，一遍是结尾元素。即使子序列中存在重复的元素，也并不会影响其中的最大值和最小值的数值。 以及，因为A中数值的范围是确定的（[1, 20000]），我们可以采用计数排序的方法来对A进行排序。 代码 123456789101112131415161718192021222324252627282930313233class Solution &#123;private: void bucketSort(vector&lt;int&gt;&amp; A) &#123; int bucket[20005]; memset(bucket, 0, sizeof(bucket)); for (int x: A) bucket[x]++; int i = 0; for (int j = 1; j &lt;= 20000; j++) &#123; while (bucket[j] &gt; 0) &#123; A[i++] = j; bucket[j]--; &#125; &#125; &#125;public: int sumSubseqWidths(vector&lt;int&gt;&amp; A) &#123; bucketSort(A); int n = A.size(); int modulo = 1000000007; long long int pow[20005]; pow[0] = 1; for (int i = 1; i &lt;= n; i++) pow[i] = (pow[i - 1] &lt;&lt; 1) % modulo; long long int sum = 0; for (int i = 0; i &lt; n; i++) &#123; sum += ((pow[i] - pow[n-i-1] + modulo) % modulo) * A[i]; sum %= modulo; &#125; return sum; &#125;&#125;; Solution ↩︎ C++/Java/1-line Python Sort and One Pass ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 890. Find and Replace Pattern（map）","slug":"2018-08-19-Leetcode-890-Find-and-Replace-Pattern（map）","date":"2018-08-19T17:36:49.000Z","updated":"2018-08-19T17:45:00.000Z","comments":true,"path":"post/leetcode-890-find-and-replace-pattern/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-890-find-and-replace-pattern/","excerpt":"","text":"题目来源：https://leetcode.com/problems/find-and-replace-pattern/description/ 标记难度：Medium 提交次数：1/1 代码效率：4ms 题意 给定一系列word和一个pattern，判断对于每一个word，是否存在一种字母双射（实际上就是把字母映射到它的一个排列上），能把它映射为pattern。 分析 这是周赛的第三题，我在0:45时才提交，一共做了25分钟；但是回想起来，觉得这真是一道相当水的题，我怎么花了那么长时间的？ 具体做法没有任何难度，直接开一个map，比较word和pattern的每一个字母的同时记录映射，并判断映射有无矛盾。至于判断是否是双射，既可以再开一个map，也可以在map构造完成之后用set来判断value中有无重复的字母。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: vector&lt;string&gt; findAndReplacePattern(vector&lt;string&gt;&amp; words, string pattern) &#123; vector&lt;string&gt; permuteOk; for (string word: words) &#123; // try to map word to pattern map&lt;char, char&gt; patternMap; if (word.length() != pattern.length()) continue; bool isOk = true; for (int i = 0; i &lt; word.length(); i++) &#123; char source = word[i], target = pattern[i]; if (patternMap.count(source) &gt; 0) &#123; if (patternMap[source] != target) &#123; isOk = false; break; &#125; &#125; else patternMap[source] = target; &#125; if (!isOk) continue; set&lt;char&gt; inverseMap; for (auto const&amp; i: patternMap) if (inverseMap.count(i.second) &gt; 0) &#123; isOk = false; break; &#125; else inverseMap.insert(i.second); if (!isOk) continue; permuteOk.push_back(word); &#125; return permuteOk; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 888. Fair Candy Swap（数组），及周赛（98）总结","slug":"2018-08-19-Leetcode-888-Fair-Candy-Swap（数组），及周赛（98）总结","date":"2018-08-19T15:24:34.000Z","updated":"2018-08-19T16:28:34.000Z","comments":true,"path":"post/leetcode-888-fair-candy-swap-and-weekly-contest-98/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-888-fair-candy-swap-and-weekly-contest-98/","excerpt":"","text":"题目来源：https://leetcode.com/problems/fair-candy-swap/description/ 标记难度：Easy 提交次数：3/4 代码效率： 二分查找：76ms（暂缺数据） HashSet：136ms112ms 题意 给定两个数组，要求交换两个数，使得两个数组各自的总和相等。 分析 第二次参加比赛，名次比上回差了一些（362 / 3552），主要是因为第一题耗时太多了。也罢，我目前大概就是这个Leetcode周赛能稳定做出前三题的水平了，第四题基本做不出来。这对于一个参加过NOIP和省选的人来说的确是太菜了，但是不承认这一点并不能就让我变得更不菜。所以还是承认这个事实，然后尽量在此基础上有所进步比较好。 我在11:27时才提交成功第1题，之前还wa了一次。为什么会wa呢？看到这道题之后，我的第一想法是，很显然，我们可以直接计算出要交换的两个数的差值：delta = (Sb - Sa) / 2。然后我们要做的就是寻找具有这样差值的数对。于是我就“很自然地”把B数组排了个序，然后遍历A数组中的每一个数x，在B中用二分查找的方法寻找x + delta这个数是否存在。这种做法是正确的，复杂度是O((A.len + B.len) + A.len * log(B.len))（求和+遍历+二分查找）。我用std::lower_bound实现二分查找，但却忘了lower_bound的语义不是返回指向范围中首个等于value的迭代器，而是“返回指向范围[first, last)中首个不小于（即大于或等于）value的元素的迭代器，或若找不到这种元素则返回last”[1]。用人话说，就是我忘了检查lower_bound到底真的找到对应元素没有…… 修了bug之后就对了，但是实际上根本就不需要二分查找[2]。既然你要找的是一个固定的数，那么直接用HashSet不就好了？！复杂度降低到了O(A.len + B.len)。 所以说Leetcode数据还是弱，卡一下复杂度的话，n * log(n)的算法根本不应该过的。 在set中查找元素？ 但是为什么用了unordered_set之后，效率一下子低了那么多？经过查找资料，我认为是std::count和std::find的性能差距导致的问题。std::find只要找到元素就会返回；而std::count总是需要遍历所有元素，所以会比较慢[3]。把count换成find之后，快了大约20ms，验证了上述说法。 代码 二分查找 1234567891011121314151617181920212223242526class Solution &#123;public: vector&lt;int&gt; fairCandySwap(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B) &#123; // 那还是先sort一下，然后sum一下，找出A和B的差值 // 然后对A中的每一个数用这个差值二分查找 sort(A.begin(), A.end()); sort(B.begin(), B.end()); int sumA = 0, sumB = 0; for (int x: A) sumA += x; for (int x: B) sumB += x; int delta = sumB - sumA; delta &gt;&gt;= 1; for (int x: A) &#123; int toFind = x + delta; // cout &lt;&lt; x &lt;&lt; ' ' &lt;&lt; toFind &lt;&lt; endl; auto it = lower_bound(B.begin(), B.end(), toFind); if (it != B.end() &amp;&amp; *it == toFind) &#123; // 需要检查的 vector&lt;int&gt; ans = &#123;x, toFind&#125;; return ans; &#125; &#125; return &#123;&#125;; &#125;&#125;; HashSet 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; fairCandySwap(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B) &#123; int sumA = 0, sumB = 0; unordered_set&lt;int&gt; bset; for (int x: A) sumA += x; for (int x: B) &#123; sumB += x; bset.insert(x); &#125; int delta = (sumB - sumA) / 2; for (int x: A) &#123; if (bset.find(x + delta) != bset.end()) &#123; // bset.count(x + delta) &gt; 0 return &#123;x, x + delta&#125;; // 这么写居然是可以的 &#125; &#125; return &#123;&#125;; &#125;&#125;; std::lower_bound ↩︎ Solution ↩︎ Performance differences between std::count and std::find ↩︎","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 90. Subsets II（构造）","slug":"2018-08-19-Leetcode-90-Subsets-II（构造）","date":"2018-08-19T03:29:38.000Z","updated":"2018-08-19T04:22:38.000Z","comments":true,"path":"post/leetcode-90-subsets-ii/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-90-subsets-ii/","excerpt":"","text":"题目来源：https://leetcode.com/problems/subsets-ii/description/ 标记难度：Medium 提交次数：2/2 代码效率： 直接回溯：100.00% 迭代：23.82% 题意 找出一个数组中所有可能的子集。（可能有重复元素） 分析 这道题无论怎样都能搞出来，但是有一些做法比其他做法更加巧妙。我开始时的做法是这样的：先统计重复元素的个数，然后直接DFS。但事实上根本没有这样做的必要：把数组排序之后，重复元素会自动聚合在一起；由于所有的结果都是必须的，DFS也不一定必要。事实上我们可以迭代地构造这些子集：[a_1, a_m]的所有子集必然分为两种，一种是[a1, a_{m-1}]的所有子集，另一种是[a1, a_{m-1}]的所有子集中加上a_m。（C++ solution and explanation） 另一种思路甚至更加有趣。显然我们在这个问题中需要避免的是重复的子集；那么何时会出现重复的子集呢？在迭代式的构造方法中，当之前添加过的元素和当前元素相同时，就会出现重复。但我们可以直接在迭代过程中规避这个问题：当前元素和前一元素重复时，我们只对当前集合中添加了前一元素的一半继续进行复制和添加操作，不再重复对前一半进行相同的操作。（Simple iterative solution） 最后，如果数组为空，按照标准答案，我们应该返回一个空集。但实际上我认为应该返回一个含有空集的集合……所以我在题目中报了个错。 代码 直接回溯 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; ans; vector&lt;pair&lt;int, int&gt;&gt; diverseNum; void dfs(int i, vector&lt;int&gt;&amp; u) &#123; if (i &gt;= diverseNum.size()) &#123; ans.push_back(u); return; &#125; for (int j = 0; j &lt;= diverseNum[i].second; j++) &#123; for (int k = 1; k &lt;= j; k++) u.push_back(diverseNum[i].first); dfs(i + 1, u); for (int k = 1; k &lt;= j; k++) u.pop_back(); &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; // 这道题的复杂度可以说是比较高了 // 既然可能有duplicate，就先用map统计元素个数，然后枚举subset // 空集的子集？ if (nums.size() == 0) return ans; map&lt;int, int&gt; freq; for (int num: nums) freq[num]++; for (auto const&amp; i: freq) diverseNum.push_back(make_pair(i.first, i.second)); vector&lt;int&gt; u; dfs(0, u); return ans; &#125;&#125;; 迭代 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; subsets; if (nums.size() == 0) return subsets; subsets.push_back(vector&lt;int&gt;()); sort(nums.begin(), nums.end()); int lastIndex = 0; for (int i = 0; i &lt; nums.size(); i++) &#123; if (i == 0 || nums[i] != nums[i - 1]) lastIndex = 0; int size = subsets.size(); for (int j = lastIndex; j &lt; size; j++) &#123; subsets.push_back(subsets[j]); subsets.back().push_back(nums[i]); &#125; lastIndex = size; &#125; return subsets; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"}]},{"title":"USACO 1.2.2: Greedy Gift Givers","slug":"2018-08-19-USACO-1-2-2-Greedy-Gift-Givers","date":"2018-08-19T02:13:02.000Z","updated":"2018-08-19T02:16:00.000Z","comments":true,"path":"post/usaco-1-2-2-greedy-gift-givers/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-2-2-greedy-gift-givers/","excerpt":"","text":"题意 见洛谷 P1201。 分析 一道简单的模拟题，特别是使用STL之后，变得更加简单。可能需要稍微判断一下，需要分配礼物的人数为0的情况，不要出现除零错之类的。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*ID: zhanghu15TASK: gift1LANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;#include &lt;map&gt;using namespace std;int main() &#123; ofstream fout(\"gift1.out\"); ifstream fin(\"gift1.in\"); int NP; string nameInOrder[10]; map&lt;string, int&gt; bank; fin &gt;&gt; NP; for (int i = 0; i &lt; NP; i++) &#123; fin &gt;&gt; nameInOrder[i]; bank[nameInOrder[i]] = 0; &#125; for (int i = 0; i &lt; NP; i++) &#123; string giverName; fin &gt;&gt; giverName; int money, NG; fin &gt;&gt; money &gt;&gt; NG; if (NG &gt; 0) &#123; int moneyToGive = money / NG; int moneyLeft = money - NG * moneyToGive; bank[giverName] += moneyLeft - money; for (int j = 0; j &lt; NG; j++) &#123; string receiverName; fin &gt;&gt; receiverName; bank[receiverName] += moneyToGive; &#125; &#125; &#125; for (int i = 0; i &lt; NP; i++) fout &lt;&lt; nameInOrder[i] &lt;&lt; ' ' &lt;&lt; bank[nameInOrder[i]] &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"USACO 1.2.1: Your Ride Is Here","slug":"2018-08-19-USACO-1-2-1-Your-Ride-Is-Here","date":"2018-08-19T01:20:22.000Z","updated":"2018-08-19T01:27:22.000Z","comments":true,"path":"post/usaco-1-2-1-your-ride-is-here/","link":"","permalink":"https://zhanghuimeng.github.io/post/usaco-1-2-1-your-ride-is-here/","excerpt":"","text":"额，我竟然开始重刷USACO了……希望这次能刷完，不要像高中时那样半途而废吧。USACO的题目对现在的我说不上多有用，但这可能是种情结。 题意 见洛谷 P1200。（网上这道题的相关翻译到处都是，但我不知道现在NOCOW的镜像站还能活多久，所以还是看洛谷好了。） 分析 很水，直接乘了之后取模就可以了。考虑到26^5 = 11881376，甚至都不需要考虑乘法溢出的问题（虽然我还是做了）。 代码 123456789101112131415161718192021222324252627282930/*ID: zhanghu15TASK: rideLANG: C++14*/#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;using namespace std;int main() &#123; ofstream fout(\"ride.out\"); ifstream fin(\"ride.in\"); string comet, group; fin &gt;&gt; comet &gt;&gt; group; int cometProd = 1, groupProd = 1; for (char c: comet) cometProd = (cometProd * (c - 'A' + 1)) % 47; for (char c: group) groupProd = (groupProd * (c - 'A' + 1)) % 47; if (cometProd == groupProd) fout &lt;&lt; \"GO\" &lt;&lt; endl; else fout &lt;&lt; \"STAY\" &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"USACO","slug":"USACO","permalink":"https://zhanghuimeng.github.io/tags/USACO/"}]},{"title":"Leetcode 621. Task Scheduler（贪心）","slug":"2018-08-18-Leetcode-621-Task-Scheduler","date":"2018-08-18T20:45:05.000Z","updated":"2018-08-18T21:48:00.000Z","comments":true,"path":"post/leetcode-621-task-scheduler/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-621-task-scheduler/","excerpt":"","text":"题目来源：https://leetcode.com/problems/task-scheduler/description/ 标记难度：Medium 提交次数：2/5 代码效率： 排序+贪心：6.90% 直接贪心：98.84% 题意 有若干种任务，每种任务有若干个时间片，同一任务的两个时间片之间的间隔必须超过n。问执行完所有任务至少需要多少个时间片。 分析 很容易想到一种直接的贪心方法：每次选择已经到了冷却时间且剩余个数最多的任务来执行。 另一种思路则十分巧妙。事实上，上一种思路中我们浪费了过多的信息。从题意中可以看出，任务的名称和执行并没有明确的关系，因此不妨假设我们已经按任务所需时间片的数量从大到小排好序了，为A到Z。若n &gt;= 25，则任务的执行必然呈现出周期性，因为： 第1个时间片：因为之前没有执行过A，且A所需时间片最多，所以执行A 第2个时间片：A未到冷却时间；之前没有执行过B，且B在剩余任务中所需时间片最多，所以执行B 第3个时间片：A、B未到冷却时间；之前没有执行过C，且C在剩余任务中所需时间片最多，所以执行C …… 第26个时间片：只有Z未到冷却时间，执行Z 空闲…… 第n+2个时间片：由于A-Z已经各执行了一次，剩余时间片大小的顺序关系不变，因此仍然按上述顺序执行 …… 第？个时间片：此时只有时间片总量最大的A（也许还有B，等等）还没有执行完，执行完A后，我们就可以结束执行了。 此时用图来表现执行顺序，就会变成这样： 12345ABCD......ZXXXXABCD......ZXXXXABCD......ZXXXX......A 显然我们应该把n的界再缩小一些：假设实际任务的总数为m，则n &gt;= m - 1时，实际执行状况都是这样的。不妨设A的时间片个数为maxIntervals，时间片数量与A相等的任务个数为maxCount，则所需时间片总量为(maxIntervals - 1) * (n + 1) + maxCount。 当n &lt; m - 1时，我们只需先把前n + 1个任务安排好： 123456ABCDEABCDEABCDEABCDE...ABC 然后把剩余的任务按顺序插进去，有多少个就插多少个： 123456ABCDEFGHIABCDEFGHABCDEFGHABCDEFG...ABC 此时没有空闲时间片，所以需要的时间片总量为全部任务时间片的总量。 特别地，当n &lt; m - 1且maxCount &gt;= n - 1时，我们不需要按照n的循环来安排任务，直接按照m来循环即可： 12345ABCD......ZABCD......ZABCD......Z......AB 上述思路参考了concise Java Solution O(N) time O(26) space和Java O(n) time O(1) space 1 pass, no sorting solution with detailed explanation。 代码 排序+贪心 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: int leastInterval(vector&lt;char&gt;&amp; tasks, int n) &#123; int taskLeft[26]; memset(taskLeft, 0, sizeof(taskLeft)); int lastExecute[26]; memset(lastExecute, -1, sizeof(lastExecute)); for (char c: tasks) taskLeft[c - 'A']++; int now = 0; while (true) &#123; int task = -1, left = -1; bool found = false; for (int i = 0; i &lt; 26; i++) &#123; if (taskLeft[i] &gt; 0) &#123; found = true; if (lastExecute[i] == -1 || now - lastExecute[i] &gt; n) &#123; if (left == -1 || taskLeft[i] &gt; left) &#123; left = taskLeft[i]; task = i; &#125; &#125; &#125; &#125; if (!found) break; // cout &lt;&lt; now &lt;&lt; ' ' &lt;&lt; task &lt;&lt; endl; if (found &amp;&amp; task == -1) &#123; now++; continue; &#125; taskLeft[task]--; lastExecute[task] = now; now++; &#125; return now; &#125;&#125;; 直接贪心 1234567891011121314151617class Solution &#123;public: int leastInterval(vector&lt;char&gt;&amp; tasks, int n) &#123; int taskLeft[26]; memset(taskLeft, 0, sizeof(taskLeft)); for (char c: tasks) taskLeft[c - 'A']++; sort(taskLeft, taskLeft + 26); int maxes = 0; for (int i = 25; i &gt;= 0 &amp;&amp; taskLeft[i] == taskLeft[25]; i--) maxes++; return max((int) tasks.size(), (taskLeft[25] - 1) * (n + 1) + maxes); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Leetcode 202. Happy Number（数列）","slug":"2018-08-17-Leetcode-202-Happy-Number（数列）","date":"2018-08-17T20:34:31.000Z","updated":"2018-08-17T22:28:31.000Z","comments":true,"path":"post/leetcode-202-happy-number/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-202-happy-number/","excerpt":"","text":"题目来源：https://leetcode.com/problems/happy-number/description/ 标记难度：Easy 提交次数：3/3 代码效率： 普通方法：16.77% Floyd判圈算法：100.00% 42是万物的答案：16.77% 题意 判断一个正整数是否是快乐数。 分析 这道题本身倒是很简单：直接迭代对数位平方求和，直到找到循环或者得到1即可。但是快乐数还有很多非常有趣的性质。除此之外，我们还可以应用Floyd判圈算法来解决找循环的问题。（My solution in C( O(1) space and no magic math property involved )）这样会稍微牺牲一点计算的常数，但会大大减少Hash所需的存储空间。我记得上个学期《现代密码学》讲碰撞攻击的时候也用到了相似的思路。 快乐数的性质 有两篇题解都讲到了快乐数的性质（All you need to know about testing happy number!和Explanation of why those posted algorithms are mathematically valid），不过并不是很全面。这篇论文中讲到了更多的内容。 下面令f(n)f(n)f(n)表示对n进行数位平方和运算得到的结果。 性质1：集合H=1H = {1}H=1是一个不动点。 证明：显然，f(1)=12=1f(1) = 1^2 = 1f(1)=12=1。 性质2：集合S=4,16,37,58,89,145,42,20S = {4, 16, 37, 58, 89, 145, 42, 20}S=4,16,37,58,89,145,42,20表示了一个长度为8的循环。对于任意n∈Sn \\in Sn∈S，fm(n)∈Sf^m(n) \\in Sfm(n)∈S。 证明：f(4)=42=16f(4) = 4^2 = 16f(4)=42=16，f(16)=12+62=37f(16) = 1^2 + 6^2 = 37f(16)=12+62=37，f(37)=32+72=58f(37) = 3^2 + 7^2 = 58f(37)=32+72=58，f(58)=52+82=89f(58) = 5^2 + 8^2 = 89f(58)=52+82=89，f(89)=82+92=145f(89) = 8^2 + 9^2 = 145f(89)=82+92=145，f(145)=12+42+52=42f(145) = 1^2 + 4^2 + 5^2 = 42f(145)=12+42+52=42，f(42)=42+22=20f(42) = 4^2 + 2^2 = 20f(42)=42+22=20，f(20)=22+02=4f(20) = 2^2 + 0^2 = 4f(20)=22+02=4。 定理：对于任意自然数nnn，总存在自然数mmm，使得fm(n)∈Sf^m(n) \\in Sfm(n)∈S或fm(n)∈Hf^m(n) \\in Hfm(n)∈H。这意味着一个自然数或者是快乐数，或者在经过足够多次的fff运算后，总会落入SSS表示的循环中。 证明：对于任何自然数nnn，每一位数字的最大值都是9。当nnn为kkk位时，f(n)f(n)f(n)在nnn的每一位都为9时取到最大值92k9^2 k92k，因此f(n)&lt;81kf(n) &lt; 81kf(n)&lt;81k。由于kkk位数的第一位必然不是0，因此10k−1≤n&lt;10k10^{k-1} \\leq n &lt; 10^k10k−1≤n&lt;10k。显然，10k−110^{k-1}10k−1增长的速度比81k81k81k快得多，因此k≥4k \\geq 4k≥4时，81k≤10k−181k \\leq 10^{k-1}81k≤10k−1。由10k−1≤n10^{k-1} \\leq n10k−1≤n和f(n)≤81kf(n) \\leq 81kf(n)≤81k可知，f(n)≤81k≤10k−1≤nf(n) \\leq 81k \\leq 10^{k-1} \\leq nf(n)≤81k≤10k−1≤n，因此k≥4k \\geq 4k≥4时f(n)&lt;nf(n) &lt; nf(n)&lt;n，这意味着对于1000以上的数，它对应的计算结果必然比原来的数要小，函数是递减的。因此，只有k&lt;4k &lt; 4k&lt;4时，f(n)f(n)f(n)可能会大于等于nnn。这种情况下nnn最大可能值为999，此时f(n)=243f(n) = 243f(n)=243。 因此我们得到了999这个界：仅当n≤999n \\leq 999n≤999时，f(n)f(n)f(n)可能会大于等于nnn。但事实上我们可以把这个界缩得更小一些：显然，在[1,999][1, 999][1,999]的所有数中，f(999)f(999)f(999)是最大的，对于任意n∈[1,999]n \\in [1, 999]n∈[1,999]，有f(n)≤f(999)=243f(n) \\leq f(999) = 243f(n)≤f(999)=243。因此，当243&lt;n≤999243 &lt; n \\leq 999243&lt;n≤999时，f(n)≤243&lt;nf(n) \\leq 243 &lt; nf(n)≤243&lt;n。所以，仅当n≤243n \\leq 243n≤243时，f(n)f(n)f(n)可能会大于等于nnn。 当n&gt;243n &gt; 243n&gt;243时，函数是单调递减的，因此单由这样的nnn是不可能组成循环的；且必然存在自然数mmm，使得1≤f(m)(n)≤2431 \\leq f^{(m)}(n) \\leq 2431≤f(m)(n)≤243。下面，我们只需编程检查[1,243][1, 243][1,243]范围内的所有数。代码如下，运行之后检查结果，可以发现定理是正确的。 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;int calcHappy(int x) &#123; int sum = 0; while (x &gt; 0) &#123; sum += (x % 10) * (x % 10); x /= 10; &#125; return sum;&#125;int main() &#123; for (int i = 1; i &lt;= 243; i++) &#123; int x = i; cout &lt;&lt; i &lt;&lt; \", \"; while (x != 1) &#123; if (x == 4 || x == 16 || x == 37 || x == 58 || x == 89 || x == 145 || x == 42 || x == 20) &#123; break; &#125; x = calcHappy(x); &#125; cout &lt;&lt; x &lt;&lt; endl; &#125; return 0;&#125; 代码 普通方法 1234567891011121314151617181920212223242526272829class Solution &#123;private: int calcHappy(int x) &#123; int sum = 0; while (x &gt; 0) &#123; sum += (x % 10) * (x % 10); x /= 10; &#125; return sum; &#125;public: bool isHappy(int n) &#123; if (n == 1) return true; // 对于一个int，10 * 9^2 = 810，所以这样计算肯定不会爆栈的 bool visited[1000]; memset(visited, 0, sizeof(visited)); do &#123; // cout &lt;&lt; n &lt;&lt; endl; n = calcHappy(n); if (visited[n] == true) return false; visited[n] = true; &#125; while (n != 1); return true; &#125;&#125;; Floyd判圈算法 12345678910111213141516171819202122232425class Solution &#123;private: int calcHappy(int x) &#123; int sum = 0; while (x &gt; 0) &#123; sum += (x % 10) * (x % 10); x /= 10; &#125; return sum; &#125;public: bool isHappy(int n) &#123; if (n == 1) return true; int slow = n, fast = n; do &#123; slow = calcHappy(slow); fast = calcHappy(fast); fast = calcHappy(fast); &#125; while (slow != fast); return slow == 1; &#125;&#125;; 42是万物的答案 这一方法来自StephanPochmann，看上去非常有趣。由于10进制快乐数一共只有一个非平凡的循环：[4, 16, 37, 58, 89, 145, 42, 20]，而42恰好在这个集合中，所以我们可以利用42做一点事情——比如在代码中只写出一个数字，42。 我尝试在C++中复制这一做法，但彻底失败了。可能是因为我对lambda表达式不够熟悉吧…… 1234567891011121314151617181920212223class Solution &#123;private: int calcHappy(int x) &#123; string s = to_string(x); vector&lt;int&gt; squares; for (int i = 0; i &lt; s.length(); i++) squares.push_back(stoi(s.substr(i, 1)) * stoi(s.substr(i, 1))); return accumulate(squares.begin(), squares.end(), 0); &#125;public: bool isHappy(int n) &#123; int prev; while (n != 42) &#123; prev = n; n = calcHappy(n); if (prev == n) return true; &#125; return false; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"}]},{"title":"Leetcode 539. Minimum Time Difference（排序和取模）","slug":"2018-08-17-Leetcode-539-Minimum-Time-Difference（排序和取模）","date":"2018-08-17T10:38:34.000Z","updated":"2018-08-17T15:01:00.000Z","comments":true,"path":"post/leetcode-539-minimum-time-difference/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-539-minimum-time-difference/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-time-difference/description/ 标记难度：Medium 提交次数：1/1 代码效率： 普通排序：25.78% 优化和桶排序：89.80% 题意 给定若干个时间点（格式为HH:mm），求其中最小的时间间隔。 分析 总的来说是道非常水的题，直接把小时全都化成分钟，然后排序求间隔就可以了。唯一需要注意的是排序完之后开头和末尾的时间需要特殊处理。（就像12月和1月也是相连的那样。） 题解区里有很多很妙的想法。比如，有人声称，最多只有60*24个时间点，如果输入数据超过这一规模，则可以直接返回0，因为根据鸽巢原理，必然有重复的时间。因此，我们最多只需处理60*24规模的数据，所以这个算法是O(1)的！我觉得，这个算法由于格式限制，是无法scale的，所以说是O(1)倒也没有什么太大的问题，虽然这么说没什么意义。 因为数据规模的原因，显然可以用桶排序进行优化。 代码 普通排序 12345678910111213141516class Solution &#123;public: int findMinDifference(vector&lt;string&gt;&amp; timePoints) &#123; // 可以转换成int，然后计算模1440情况下的最小差值 vector&lt;int&gt; intTimes; for (string pnt: timePoints) &#123; int minutes = stoi(pnt.substr(0, 2)) * 60 + stoi(pnt.substr(3, 2)); intTimes.push_back(minutes); &#125; sort(intTimes.begin(), intTimes.end()); int minDif = (intTimes.front() - intTimes.back() + 1440) % 1440; for (int i = 1; i &lt; intTimes.size(); i++) minDif = min(minDif, intTimes[i] - intTimes[i - 1]); return minDif; &#125;&#125;; 优化和桶排序 快了大约8ms。 123456789101112131415161718192021222324252627class Solution &#123;public: int findMinDifference(vector&lt;string&gt;&amp; timePoints) &#123; if (timePoints.size() &gt; 1440) return 0; // 可以转换成int，然后计算模1440情况下的最小差值 int bucket[1440]; memset(bucket, 0, sizeof(bucket)); for (string pnt: timePoints) &#123; int minutes = stoi(pnt.substr(0, 2)) * 60 + stoi(pnt.substr(3, 2)); bucket[minutes]++; if (bucket[minutes] &gt; 1) return 0; &#125; int first = -1, last = -1, minDif = 1440; for (int i = 0; i &lt; 1440; i++) if (bucket[i] != 0) &#123; if (first == -1) first = i; if (last != -1) minDif = min(minDif, i - last); last = i; &#125; minDif = min(minDif, (first - last + 1440) % 1440); return minDif; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"}]},{"title":"Leetcode 881. Boats to Save People（贪心）","slug":"2018-08-17-Leetcode-881-Boats-to-Save-People（贪心）","date":"2018-08-17T09:55:41.000Z","updated":"2018-08-18T18:32:00.000Z","comments":true,"path":"post/leetcode-881-boats-to-save-people/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-881-boats-to-save-people/","excerpt":"","text":"题目来源：https://leetcode.com/problems/boats-to-save-people/description/ 标记难度：Medium 提交次数：1/1 代码效率：25.56% 题意 给定若干个人的重量，以及一条船的载重限制，一条船上最多载两个人，且总重量不能超过载重限制，问至少需要多少条船运载所有人。 分析 一种证明贪心算法正确的方法 一道非常简单（经典）的贪心问题，但我却被这样的一个问题困扰住了：对于当前重量最大的人，为何我们寻找的匹配是当前重量最小的人，而不是所有可能的匹配中重量最大的人？ 当然，寻找当前重量最小的匹配方法是正确的。6 lines Java O(nlogn) code, sorting + greedy, with greedy algorithm proof. 中提供了一份形式化的证明，翻译如下（作为贪心算法证明方法的参考）： 令S表示一种最优解（显然，由于优化目标只是船的数量，最优解可能不止有一种），O表示我们的算法输出的解。 贪心选择性质（greedy choice property）：选择只需依赖于当前情形，不需要依赖于未来的选择和子问题的其他解。 从最沉的人hi开始，有2种可能的情况： (a) 如果hi不能和其他任何人进入同一艘船，则在S和O中，hi都独自处于一艘船中。显然，在这种情况下，我们的这一选择是最优的，贪心选择性质维持不变。 (b) 如果hi可以和其他某一个人进入一艘船，则在O中，根据我们的算法，hi和最轻的人lo必然位于同一条船上。 在S中，如果他们也在同一条船上，则我们的这一步骤是最优的，贪心选择性质保持不变；如果他们不在同一条船上，则我们可以把hi和lo在船上的同伴m交换一下。显然，m &lt;= hi，因此交换是可以进行的。因为交换没有导致船变多，我们得到了一个新的最优解T，且在这种解中，hi和lo在同一条船上。这表明，我们的第一个步骤——把hi和lo放进同一条船中——是一个最优步骤，贪心选择性质也维持不变。 最优子结构性质（optimal substructure property）：对原问题的最优解必然包含对子问题的最优解 令P表示规模为n的原问题，其中n = people.length。从上述推导中，可以看出，在第一步之后，我们得到了一个子问题P'，规模为n'（如果hi独自占据一艘船，则n' = n - 1，否则n' = n - 2）。我们可以相似地对P'中的hi'和lo'进行和刚才一样的操作。 由于我们已经证明了，T也是一种最优解，且P'的解（不妨称之为O'）包含在T内，也是一种最优解，所以这一问题具有最优子结构性质。 综上，我们的算法符合贪心选择性质和最优子结构性质，证毕。 好吧，我之前并不知道贪心算法的这两种性质。按照算法导论上的说法，这两种性质实际上是用来分析问题的——只有证明问题具有这两种性质时，才能确定可以应用贪心算法。而在此处的证明里，作者把实际的解法也混在证明过程中了。而“证明问题符合贪心的两种性质”和“证明贪心算法的正确性”本质上是两个问题。事实上，此处作者的证明策略应该叫做“exchange arguments”。Proof methods and greedy algorithms这篇文章中包含了对两种策略的详细论述。 对于上述贪心算法的另一种理解 在开始查找这些资料之前，我尝试从直觉上去理解这种算法的重要性，并且确实找到了一种理解方法。 由于有一条船上最多坐两个人的限制，在这种算法下，实际上，我们是在为那些weight &gt; floor(limit/2)的人寻找配对的，能坐在同一条船里的人；结束寻找之后，那些weight &lt;= floor(limit/2)的人之间则可以随意组合。 把所有的人按重量排序，记mid = floor(limit/2)+1。 1| 0 | 1 | ... | mid-1 | mid | ... | n-1 | 显然，此时最重的人能够配对的人是最少的，次重的人能够配对的人可能会稍微多一些。记最重的人能够配对的人的位置区间为[0, r_1]，次重的人能够配对的人的位置区间为[0, r_2]……直到[0, r_mid]。显然，r_1 &lt;= r_2 &lt;= ... &lt;= r_mid。 现在我们实际上是在做这样一件事：从上述整数区间中选择一些点，使得它们具有这样的性质： 每个人只能在自己对应的区间中选点 点不能重复选择 我们的目的是最大化能选到点的人的数量。 此时，将最重的人与最轻的人匹配（假如他们能够匹配）的做法就很好理解了：我们实际上是为他选择了对应的线段中（还没被选择过的）最靠前的一个点。而“所有可能的匹配中重量最大的人”相当于是选择了线段上（还没被选择过的）最靠后的一个点。 对于这两种算法，不能找到匹配的情况都满足r_i &lt; i。所以这两种算法本质上是一样的。 我感觉我的证明能力不是很强。以后再遇到贪心问题的时候，我也会尝试去做一下问题的贪心性质和贪心算法的正确性这两种证明的。 在Leetcode上的英文回答 https://leetcode.com/problems/boats-to-save-people/discuss/156748/Python-short-2-pointer-solution-and-some-thoughts/166286 In short: I think both “smallest” and “possibly maximum” methods are correct, and they are in some way equivalent. Another person has provided a formal proof for the “smallest” selection method. (6 lines Java O(nlogn) code, sorting + greedy, with greedy algorithm proof. ) Of course, that method is correct, but this might not be immediately obvious. So I’d like to share my understanding of this problem with you. (So it’s not a formal proof.) Let mid = floor(limit/2), and divide those people into two groups: ‘heavy’ people, whose weight &gt; mid; and ‘light’ people, whose weight &lt;= mid. Minimizing the number of boats is equivalent to maximizing the number of boats with two people in them. It is obvious that, if a ‘heavy’ person wants to sit in a boat with another person, the other person must be a ‘light’ one; on the other hand, a ‘light’ person can certainly sit with another ‘light’ person, and maybe some of the ‘heavy’ people. Now, a solution is at hand: we first try to pair each ‘heavy’ person with a ‘light’ person, and put them in a boat; when a ‘heavy’ person can’t find a pair, we put him alone in a boat; finally, if there are any ‘light’ person left, we can arbitrarily pair them together. The biggest question is, how can we maximize these ‘heavy’-‘light’ pairs? Sort all the people in ascending order. Let n = people.length, and suppose there are altogether m heavy people, denoted by people[n-m], people[n-m+1], … people[n-1]. After sorting, the ‘light’ people that a ‘heavy’ person can pair with will form a interval. Denote these intervals by [0, r_{n-m}), [0, r_{n-m+1}), …, [0, r_{n-1}). (Intervals might be empty) Example: limit = 8, people = [2, 3, 3, 5, 6, 7] In this example, heavy = [5, 6, 7], light =[2, 3, 3]`. For 7, the interval is [0, 0) (no one can sit with 7); For 6, the interval is [0, 1) (2 can sit with 6); For 5, the interval is [0, 3) ([2, 3, 3] can all sit with 5). And it is obvious that r_{n-m} &gt;= r_{n-m+1} &gt;= ... &gt;= r_{n-1} &gt;= 0. So these intervals are all overlapping, and the left endpoints are all zero. Now we can analyze the difference between “smallest” and “possibly maximum” methods. When we choose the “smallest” person, we are choosing the leftmost point of the interval (which hasn’t be chosen yet); when we choose the “possibly maximum” person, we are choosing the rightmost point of the interval (which hasn’t be chosen yet). Because all intervals has 0 as the left endpoint, when we start from the heaviest person, only when r_k &lt; k (k is the number of ‘heavy’ people we have considered or is considering) can this ‘heavy’ person not find a ‘light’ person to pair. So, in these two methods, we find different ‘light’ people for the ‘heavy’ people to pair, but the set of ‘heavy’ people who cannot find a pair is the same. Example: limit = 8, people = [1, 2, 2, 2, 3, 4, 5, 6, 7, 7] people[i] k interval “smallest” pair “possibly maximum” pair people[9] = 7 1 [0, 1) 1 1 people[8] = 7 2 [0, 1) - - people[7] = 6 3 [0, 4) 2 2 people[6] = 5 4 [0, 5) 2 3 代码 12345678910111213141516171819class Solution &#123;public: int numRescueBoats(vector&lt;int&gt;&amp; people, int limit) &#123; sort(people.begin(), people.end()); int i = 0, j = people.size() - 1, sum = 0; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; people[i] + people[j] &gt; limit) &#123; j--; sum++; &#125; i++; j--; sum++; &#125; if (i == j) sum++; return sum; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"}]},{"title":"Leetcode 474. Ones and Zeroes（01背包）","slug":"2018-08-17-Leetcode-474-Ones-and-Zeroes（01背包）","date":"2018-08-17T04:50:09.000Z","updated":"2018-08-17T05:01:09.000Z","comments":true,"path":"post/leetcode-474-ones-and-zeroes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-474-ones-and-zeroes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/ones-and-zeroes/description/ 标记难度：Medium 提交次数：1/2 代码效率：25.73% 题意 有两种资源（0和1）的01背包。（倒是很符合“01”之义。） 分析 没什么好说的咯……因为是01背包，所以时间复杂度应该是无法优化的，为O(m * n * K)；但是空间复杂度可以通过滚动优化降低到O(m * n)。 我有时候很好奇，为什么动态规划的复杂度会这么高，无法进行更好的优化。我想，可能是因为我们要求的是最优解，所以必须遍历整个解空间，动态规划只是用一种聪明的方式进行了剪枝而已。 提交中Runtime Error了一次。经过试验，我发现，在Leetcode这里，在栈上定义526 * 100 * 100的int数组是会爆栈的，他们的栈空间到底是开了多大啊？我在网上查了一圈也没有查到。反正后来就换成滚动数组了。 代码 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int findMaxForm(vector&lt;string&gt;&amp; strs, int m, int n) &#123; // f[N][i][j]：在前N个字符串中，用i个0，j个1最多能组成多少个串 int N = strs.size(), digitCnt[N+1][2]; memset(digitCnt, 0, sizeof(digitCnt)); for (int i = 0; i &lt; N; i++) &#123; for (char c: strs[i]) &#123; if (c == '0') digitCnt[i+1][0]++; else digitCnt[i+1][1]++; &#125; &#125; // cout &lt;&lt; N &lt;&lt; ' ' &lt;&lt; m &lt;&lt; ' ' &lt;&lt; n &lt;&lt; endl; int f[2][m+1][n+1], ans = 0; // seems 526 100 100 is not ok memset(f, 0, sizeof(f)); // 对k进行滚动优化时，必须把k放在最外层循环 for (int k = 1; k &lt;= N; k++) &#123; for (int i = 0; i &lt;= m; i++) &#123; for (int j = 0; j &lt;= n; j++) &#123; if (i &lt; digitCnt[k][0] || j &lt; digitCnt[k][1]) f[k % 2][i][j] = f[(k-1) % 2][i][j]; else f[k % 2][i][j] = max(f[(k-1) % 2][i][j], f[(k-1) % 2][i-digitCnt[k][0]][j-digitCnt[k][1]] + 1); ans = max(ans, f[k % 2][i][j]); // cout &lt;&lt; i &lt;&lt; ' ' &lt;&lt; j &lt;&lt; ' ' &lt;&lt; k &lt;&lt; ' ' &lt;&lt; f[k % 2][i][j] &lt;&lt; endl; &#125; &#125; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"}]},{"title":"Wir Sind Helden歌词翻译（3）：Aurélie","slug":"2018-08-16-Wir-Sind-Helden歌词翻译（3）：Aurelie","date":"2018-08-16T19:35:31.000Z","updated":"2018-08-16T21:34:00.000Z","comments":true,"path":"post/wir-sind-helden-song-translation-3-aurelie/","link":"","permalink":"https://zhanghuimeng.github.io/post/wir-sind-helden-song-translation-3-aurelie/","excerpt":"","text":"歌词和翻译 歌词 翻译 Aurélies Akzent ist ohne Frage sehr charmant 奥瑞莉的口音无疑是非常迷人的 Auch wenn sie schweigt wird sie als wunderbar erkannt 即便她一动不动，她仍然看上去非常美丽 Sie braucht mit Reizen nicht zu geizen 她无需谨慎使用自己的吸引力 denn ihr Haar ist Meer und Weizen 因为她的秀发像是海浪和麦浪 Noch mit Glatze fräß ihr jeder aus der Hand 即使她变成光头，大家也都会爱她的 Doch Aurélie kapiert das nie 但奥瑞莉永远不明白 Jeden Abend fragt sie sich 每天晚上她都问自己 wann nur verliebt sich wer in mich 什么时候才会有人爱上我 Aurélie so klappt das nie 奥瑞莉，那样永远不会奏效的 Du erwartest viel zu viel 你期望得太多了 Die Deutschen flirten sehr subtil 德国人的调情是非常微妙的 Aurélie die Männer mögen dich hier sehr 奥瑞莉，这里的男人都非常喜欢你 Schau auf der Straße schaut dir jeder hinterher 你上街时，大家都在看你 Doch du merkst nichts weil sie nicht pfeifen 但因为他们不吹口哨，你什么都没注意到 und pfeifst du selbst die Flucht ergreifen 如果你开始吹口哨，他们就会逃跑 Du musst wissen hier ist weniger oft mehr 你必须知道，在这里，“少”才是“多” Ach Aurélie in Deutschland braucht die Liebe Zeit 哦，奥瑞莉，在德国，爱情需要时间 Hier ist man nach Tagen erst zum ersten Schritt bereit 过了这些天，你终于为第一步做好准备了 Die nächsten Wochen wird gesprochen 接下来的几周，你们将聊天 sich aufs Gründlichste berochen 你们极其仔细地打量对方 und erst dann trifft man sich irgendwo zu zweit 这之后你们才会在某处单独见面 Aurelie so klappt das nie… 奥瑞莉，那样永远不会奏效的…… Aurélie so einfach ist das eben nicht 奥瑞莉，事情远不是那么简单 Hier haben andre Worte ein ganz anderes Gewicht 这里不同词语的重要性有微妙的差别 All die Jungs zu deinen Füßen 所有的男孩都躺在你的脚下 wollen sie küssen auch die Süßen 想要亲吻像你这么可爱的人 aber du du merkst das nicht 但你完全没有注意到 wenn er dabei von Fußball spricht 因为他同时还在谈论足球 Ach Aurélie du sagst ich solle dir erklären 哦，奥瑞莉，你让我向你解释这一切 wie in aller Welt sich die Deutschen dann vermehren 德国人到底是怎样繁衍后代的 wenn die Blumen und die Bienen in Berlin nichts tun als grienen 柏林的鲜花和蜜蜂只会傻笑 und sich nen Teufel um Bestäubungsfragen scheren 从来不管传粉这类见鬼的问题 Aurélie so klappt das nie… 奥瑞莉，那样永远不会奏效的…… 一些想法 哈哈哈哈哈哈哈哈哈哈哈哈！ 这首歌的歌词非常俏皮，而且富有画面感。虽然只有叙事者一个人在说话，我却能通过Ta的话想象出奥瑞莉都说了些什么： “你说，什么时候才会有人爱上我啊？”——“你期望得太多了，德国人的调情是非常微妙的。” “真的吗？”——“这里的男人都非常喜欢你……在这里，‘少’才是‘多’。” “啊？德国男人为什么都这么胆小啊？”——“在德国，爱情需要时间……这之后你们才会在某处单独见面。” “这么闷骚的话到底怎样才有可能开始谈恋爱啊？？”——“事情远不是那么简单……因为他同时还在谈论足球” “算了，我放弃了。德国人到底是怎么从互相有好感进展到拉手拥抱接吻上床的？贵国是不是连小蜜蜂都不会传粉，只会对着鲜花傻笑的？” 我很喜欢最后一段的脑补。我不能直接看到奥瑞莉对叙事者抱怨德国人性格的具体内容，只能通过叙事者的转述想象，这使得歌词变得非常有趣。 Aurélie看起来像是一个法语名字。法国人大概是要浪漫直接得多吧……","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Wir Sind Helden","slug":"artist-Wir-Sind-Helden","permalink":"https://zhanghuimeng.github.io/tags/artist-Wir-Sind-Helden/"}]},{"title":"Leetcode 623. Add One Row to Tree（树）","slug":"2018-08-15-Leetcode-623-Add-One-Row-to-Tree（树）","date":"2018-08-15T00:57:05.000Z","updated":"2018-08-15T01:12:05.000Z","comments":true,"path":"post/leetcode-623-add-one-row-to-tree/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-623-add-one-row-to-tree/","excerpt":"","text":"题目来源：https://leetcode.com/problems/add-one-row-to-tree/description/ 标记难度：Medium 提交次数：1/1 代码效率： DFS：10.14% 栈：6.76% BFS：98.07% 题意 按照一定的规则，在一棵二叉树中增加一整层。 分析 总的来说是道水题，不过我开始做的时候并不能立刻反应出DFS、栈和BFS这三种经典思路。当然，这里面DFS是最好写的，且思路的本质是一样的。 以及我发现，如果现在输入数据是树，Leetcode的自定义输入数据框在聚焦的时候，上方会自动渲染出树的图形。Leetcode真是越来越强了…… 代码 这三份代码的内容真是差不多。但是队列实现的BFS明显比另外两种更快，不知道是什么缘故。 DFS 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;private: void findDepth(TreeNode* curNode, int curDep, const int&amp; targetDep, const int&amp; value) &#123; if (curNode == NULL) return; if (curDep &lt; targetDep) &#123; findDepth(curNode-&gt;left, curDep + 1, targetDep, value); findDepth(curNode-&gt;right, curDep + 1, targetDep, value); return; &#125; if (curDep == targetDep) &#123; TreeNode* newLeft = new TreeNode(value); newLeft-&gt;left = curNode-&gt;left; TreeNode* newRight = new TreeNode(value); newRight-&gt;right = curNode-&gt;right; curNode-&gt;left = newLeft; curNode-&gt;right = newRight; return; &#125; &#125;public: TreeNode* addOneRow(TreeNode* root, int v, int d) &#123; if (d == 1) &#123; TreeNode* newRoot = new TreeNode(v); newRoot-&gt;left = root; return newRoot; &#125; findDepth(root, 1, d - 1, v); return root; &#125;&#125;; 栈 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* addOneRow(TreeNode* root, int v, int d) &#123; if (d == 1) &#123; TreeNode* newRoot = new TreeNode(v); newRoot-&gt;left = root; return newRoot; &#125; stack&lt;pair&lt;TreeNode*, int&gt;&gt; s; d--; s.push(make_pair(root, 1)); while (!s.empty()) &#123; pair&lt;TreeNode*, int&gt; p = s.top(); s.pop(); TreeNode* cur = p.first; int depth = p.second; if (depth &gt; d) continue; if (depth &lt; d) &#123; if (cur-&gt;left != NULL) s.push(make_pair(cur-&gt;left, depth + 1)); if (cur-&gt;right != NULL) s.push(make_pair(cur-&gt;right, depth + 1)); continue; &#125; TreeNode* newLeft = new TreeNode(v); newLeft-&gt;left = cur-&gt;left; TreeNode* newRight = new TreeNode(v); newRight-&gt;right = cur-&gt;right; cur-&gt;left = newLeft; cur-&gt;right = newRight; &#125; return root; &#125;&#125;; BFS 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* addOneRow(TreeNode* root, int v, int d) &#123; if (d == 1) &#123; TreeNode* newRoot = new TreeNode(v); newRoot-&gt;left = root; return newRoot; &#125; queue&lt;pair&lt;TreeNode*, int&gt;&gt; q; d--; q.push(make_pair(root, 1)); while (!q.empty()) &#123; pair&lt;TreeNode*, int&gt; p = q.front(); q.pop(); TreeNode* cur = p.first; int depth = p.second; if (depth &gt; d) continue; if (depth &lt; d) &#123; if (cur-&gt;left != NULL) q.push(make_pair(cur-&gt;left, depth + 1)); if (cur-&gt;right != NULL) q.push(make_pair(cur-&gt;right, depth + 1)); continue; &#125; TreeNode* newLeft = new TreeNode(v); newLeft-&gt;left = cur-&gt;left; TreeNode* newRight = new TreeNode(v); newRight-&gt;right = cur-&gt;right; cur-&gt;left = newLeft; cur-&gt;right = newRight; &#125; return root; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"}]},{"title":"Leetcode 884. Uncommon Words from Two Sentences（字符串），及周赛（97）总结","slug":"2018-08-14-Leetcode-884-Uncommon-Words-from-Two-Sentences（字符串），及周赛（97）总结","date":"2018-08-14T22:31:52.000Z","updated":"2018-08-15T02:00:00.000Z","comments":true,"path":"post/leetcode-884-uncommon-words-from-two-sentences-and-weekly-contest-97/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-884-uncommon-words-from-two-sentences-and-weekly-contest-97/","excerpt":"","text":"题目来源：https://leetcode.com/problems/uncommon-words-from-two-sentences/description/ 标记难度：Easy 提交次数：1/1 代码效率：100.00% 题意 找出两个字符串中所有不重叠的词。不要求顺序。 分析 第一次参加Leetcode周赛，得到了233 / 3760的“好”成绩，这个数看起来简直特别吉利…… 此题完成于0:09:46，总的来说是一道超级水题，但我做的时候又遇到了那个经典的问题……嗯，没错，C++ std::string不提供split方法。于是我又一次紧张地去stackoverflow上查了一通。这之后我得出了一个这样的结论：分隔符为时的情况是平凡的，可以直接用std::stringstream的方法解决；至于其他情况，还是自己手动瞎搞吧。 知乎上有一些相关的讨论，但我还是对此很不满，每次有字符串处理需求的时候，就想丢下C++去用Python算了。 代码 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;private: vector&lt;string&gt; split(string str) &#123; // https://stackoverflow.com/questions/236129/the-most-elegant-way-to-iterate-the-words-of-a-string std::string buf; // Have a buffer string std::stringstream ss(str); // Insert the string into a stream std::vector&lt;std::string&gt; tokens; // Create vector to hold our words while (ss &gt;&gt; buf) tokens.push_back(buf); return tokens; &#125;public: vector&lt;string&gt; uncommonFromSentences(string A, string B) &#123; map&lt;string, int&gt; freq; vector&lt;string&gt; v1 = split(A); vector&lt;string&gt; v2 = split(B); for (string s: v1) freq[s]++; for (string s: v2) freq[s]++; vector&lt;string&gt; ans; for (string s: v1) if (freq[s] == 1) ans.push_back(s); for (string s: v2) if (freq[s] == 1) ans.push_back(s); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"Leetcode Contest","slug":"Leetcode-Contest","permalink":"https://zhanghuimeng.github.io/tags/Leetcode-Contest/"}]},{"title":"Leetcode 478. Generate Random Point in a Circle（随机）","slug":"2018-08-14-Leetcode-478-Generate-Random-Point-in-a-Circle（随机）","date":"2018-08-14T17:20:01.000Z","updated":"2018-08-14T22:17:01.000Z","comments":true,"path":"post/leetcode-478-generate-random-point-in-a-circle/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-478-generate-random-point-in-a-circle/","excerpt":"","text":"题目来源：https://leetcode.com/problems/generate-random-point-in-a-circle/description/ 标记难度：Medium 提交次数：1/1 代码效率： 极坐标法：64.06% 拒绝取样：97.20% 题意 给定平面上一个圆的圆心位置和半径，从圆中以均匀的概率随机选取点。 分析 拒绝取样 其实我的第一反应是用拒绝取样（Rejection Sampling）的思路来做：首先从这个圆的与坐标轴平行的外切正方形中均匀随机选取点，然后判断点是否位于圆中；如果不在，重新生成一个新的点，再次进行判断；否则直接返回。 直觉上来说，拒绝取样显然是正确的；不过我们可以用一种稍微更加形式化的方法来描述。（以下内容参考了拒绝采样（reject sampling）的简单认识，非常直观形象。） 下图是一个随机变量的密度函数曲线，试问如何获得这个随机变量的样本呢？ 如果你像我一样，已经把概率论与数理统计统统还给数学老师了，那么提示一下，概率密度函数（PDF）是累积分布函数（CDF）的导数，反映的是概率的“密集程度”。你可以设想一根极细的无穷长的金属杆，概率密度相当于杆上各点的质量密度。由于上述原因，概率密度函数曲线下的面积表示的就是取值概率。（参考了应该如何理解概率分布函数和概率密度函数？） 我们首先用一个矩形将这个密度曲线套起来，把密度曲线框在一个矩形里，如下图所示： 然后，向这个矩形里随机投点。随机投点意味着在矩形这块区域内，这些点是满足均匀分布的。投了大概10000个点，如下面这个样子： 显然，有的点落在了密度曲线下侧，有的点落在了密度曲线的上侧。上侧的点用绿色来表示，下侧的点用蓝色来表示，如下图： 只保留密度曲线下侧的点，即蓝色的点： 到这里，提一个问题：在密度曲线以下的这块区域里，这些点满足什么分布？均匀分布！这是拒绝采样最关键的部分，搞个矩形、向矩形里投点等等，所做的一切都是为了获得一个密度曲线所围成区域的均匀分布。只要能获得这样一个在密度曲线下满足均匀分布的样本，我们就可以获得与该密度曲线相匹配的随机变量的采样样本。方法是，只需把每个蓝点的横坐标提取出来，这些横坐标所构成的样本就是我们的目标样本。下图左侧，是按照以上方法获得的一个样本的直方图以及核密度估计，下图右侧，是开始的密度曲线。 Reject sampling solution中给出了一种简单明了的用拒绝采样实现此题的方法。 极坐标法 但是我觉得这个方法的逼格不够高。于是我心想，我们怎么表示一个圆内的点呢？那自然就是用极坐标法，半径+角度。那么我们随机一个半径，再随机一个角度，最后换算成直角坐标系里的坐标，不就可以了嘛！ ……只是听上去可以而已…… 交上去之后我发现，一共有8个测试样例，最后一个我总是过不去。我的随机性是不是真的写出了bug？我实在是想不出来错在哪里了，于是去看了看题解区——原来有这么多人和我有一样的困惑。是的，上述思路确实有问题。 当我写出上述代码的时候，我心里想的是：先用角度随机选择一条半径，然后在这条半径上随机选择一个点。但问题是我们不能把圆这样看成是很多半径的集合——或者说，这条半径上不同位置的点的密集程度是不一样的。显然距离圆心更远的一端被选择的概率应该更大。 直接对角度和半径都进行随机取样会产生这样的后果，靠近圆心的点被选择的概率偏大（Uniform random points in a circle using polar coordinates）： 我们重新考虑一下半径的问题。以半径rrr作为随机变量，则随机点落在rrr范围内的概率分布为 CDF(r)=r2R2\\text{CDF}(r) = \\frac{r^2}{R^2} CDF(r)=R2r2​ PDF(r)=ddrCDF(r)=2rR2\\text{PDF}(r) = \\frac{d}{dr} \\text{CDF}(r) = \\frac{2r}{R^2} PDF(r)=drd​CDF(r)=R22r​ 以[0, 1]均匀分布对CDF(r)\\text{CDF}(r)CDF(r)进行随机，则有r=Rrand()r = R \\sqrt{\\text{rand}()}r=Rrand()​。 C++中的数学运算 使用std::uniform_real_distribution生成随机实数比直接用rand()好得多，至少stackoverflow上是这么说的。具体使用方法如下： 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;iomanip&gt;#include &lt;string&gt;#include &lt;map&gt;#include &lt;random&gt;int main()&#123; std::random_device rd; // // Engines // std::mt19937 e2(rd()); //std::knuth_b e2(rd()); //std::default_random_engine e2(rd()) ; // // Distribtuions // std::uniform_real_distribution&lt;&gt; dist(0, 10); //std::normal_distribution&lt;&gt; dist(2, 2); //std::student_t_distribution&lt;&gt; dist(5); //std::poisson_distribution&lt;&gt; dist(2); //std::extreme_value_distribution&lt;&gt; dist(0,2); double rand = dist(e2)); return 0;&#125; 目前C++中并没有提供什么特别高级的获得PI值的方法，仍然是用C中提供的M_PI宏： 123#define _USE_MATH_DEFINES // 根据实际情况；参见https://stackoverflow.com/questions/1727881/how-to-use-the-pi-constant-in-c#include &lt;math.h&gt;M_PI std::cos和std::sin函数使用的是弧度。好久不写，都忘光了。 代码 拒绝取样 1234567891011121314151617181920212223242526class Solution &#123;private: double radius, x_center, y_center, x_leftdown, y_leftdown; std::random_device rd; std::mt19937 gen; std::uniform_real_distribution&lt;&gt; dis;public: Solution(double radius, double x_center, double y_center): gen(rd()), dis(0, 1) &#123; this-&gt;radius = radius; this-&gt;x_center = x_center; this-&gt;y_center = y_center; x_leftdown = x_center - radius; y_leftdown = y_center - radius; &#125; vector&lt;double&gt; randPoint() &#123; double x, y; do &#123; x = x_leftdown + 2 * radius * dis(gen); y = y_leftdown + 2 * radius * dis(gen); &#125; while ( (x - x_center) * (x - x_center) + (y - y_center) * (y - y_center) &gt; radius * radius); return &#123;x, y&#125;; &#125;&#125;; 极坐标 1234567891011121314151617181920212223class Solution &#123;private: double radius, x_center, y_center; std::random_device rd; std::mt19937 gen; std::uniform_real_distribution&lt;&gt; randDeg, randRadius;public: Solution(double radius, double x_center, double y_center): gen(rd()), randDeg(0, 2 * M_PI), randRadius(0, 1) &#123; this-&gt;radius = radius; this-&gt;x_center = x_center; this-&gt;y_center = y_center; &#125; vector&lt;double&gt; randPoint() &#123; double r = sqrt(randRadius(gen)) * radius; // ! double deg = randDeg(gen); double x = x_center + r * cos(deg); double y = y_center + r * sin(deg); return &#123;x, y&#125;; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Random","slug":"alg-Random","permalink":"https://zhanghuimeng.github.io/tags/alg-Random/"},{"name":"alg:Rejection Sampling","slug":"alg-Rejection-Sampling","permalink":"https://zhanghuimeng.github.io/tags/alg-Rejection-Sampling/"}]},{"title":"Leetcode 49. Group Anagrams（Hash）","slug":"2018-08-13-Leetcode-49-Group-Anagrams（Hash）","date":"2018-08-13T20:12:31.000Z","updated":"2018-08-13T20:31:00.000Z","comments":true,"path":"post/leetcode-49-group-anagrams/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-49-group-anagrams/","excerpt":"","text":"题目来源：https://leetcode.com/problems/group-anagrams/description/ 标记难度：Medium 提交次数：1/1 代码效率：24.16% 题意 将一个数组中的变位词（anagram）分别归类。 分析 总的来说是道水题，但是有许多种不同的实现方式。 HashMap+sort+容器 HashMap+sort 这种思路非常容易想到：把每个字符串排序之后，所有变位词的结果就相同了。我们可以把排序的结果作为map的键值。这种做法的时间复杂度是O(N * K * log(K))，其中K是字符串的最大长度。 值得注意的是，题目中的所有字符串都是小写字母，因此可以从排序和键值两方面进行优化。我们可以不用std::sort，而是用桶排序对字符串进行排序；我们甚至可以根本不排序，而是把每个字母出现的次数作为键值（这是题解中的第二种做法）。此时复杂度可以降低到O(N * K)。 容器 如何把若干个字符串存到map中的一个键值下？由于对顺序没有要求，事实上有很多容器可以选择，我看到了用multiset、vector、list的。 一些奇技淫巧 Java beat 100%!!! use prime number中介绍了这样的一种做法：用不同素数的幂作为hash值，即：Hash(str) = 2^count(a) * 3^count(b) * ... * 103^count(z)。这样我们就可以把HashMap中的hash步骤和字符串顺序统计的步骤巧妙地结合起来了，是一种非常高效的做法。 不过我仍然觉得这是一种奇技淫巧，因为：这种做法显然只适用于字符串长度比较短的情况，否则hash值估计要爆，效率也会降低，应当进行取模；但是进行取模之后，又要考虑hash冲突问题，这样就和一般的HashMap区别不是很大了。 map+容器 其实我之前完全没有想过，map的值可以是容器。事实上显然是可以的。以及，std::sort是可以给std::string排序的。（Sorting Characters Of A C++ String） 代码 1234567891011121314151617class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; map&lt;string, vector&lt;string&gt;&gt; anagrams; for (string str: strs) &#123; string sorted(str); sort(sorted.begin(), sorted.end()); anagrams[sorted].push_back(str); &#125; vector&lt;vector&lt;string&gt;&gt; ans; for (const auto&amp; i: anagrams) &#123; ans.push_back(i.second); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"}]},{"title":"为Hexo博客添加脚注插件","slug":"2018-08-12-为Hexo博客添加脚注插件","date":"2018-08-12T21:40:33.000Z","updated":"2018-08-12T23:32:00.000Z","comments":true,"path":"post/add-footnote-plugin-for-hexo-blog/","link":"","permalink":"https://zhanghuimeng.github.io/post/add-footnote-plugin-for-hexo-blog/","excerpt":"","text":"故事的开始 脚注和参考文献对于Hexo博客大概是一个过于“Heavy”的功能，但是我的确需要它。之前我一直采取自己手写html标签的方法来添加脚注和参考文献（方法好像来自stackoverflow）： 12&lt;a href=\"#bib1\" id=\"bib1ref\"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;&lt;a id=\"bib1\" href=\"#bib1ref\"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt; 得到的效果大概是这样的（链接点击后可以互相跳转）： 这是一句需要参考文献的话。[1] [1] 参考文献的具体内容。 这样写了五十几篇文章（之前英诗的脚注和参考文献都是这么解决的）之后，我终于厌倦满天飞的html标签和需要自己手动维护的编号了。 hexo-renderer-markdown-it插件 于是我找到了这个插件：hexo-renderer-markdown-it，其中包含了脚注功能。下面讲一下我的安装和配置过程吧。 Disclaimer：我只能保证以下内容在今天（2018.8.12）和当前插件的版本（3.4.1）是适用的。（虽然作者已经三年没有更新了，以至于有人fork了一个功能更强大的hexo-renderer-markdown-it-plus出来……虽然这个插件也有段时间没更新了） 首先卸载原来的markdown渲染插件（我这里原来是marked，这是Hexo提供的默认渲染插件），然后把hexo-renderer-markdown-it装上： 12npm un hexo-renderer-marked --savenpm i hexo-renderer-markdown-it --save 然后在根目录下的_config.yml中进行相应的配置。简单的配置方法只包括设置markdown格式，这里就不详述了。高级的配置方法中包含很多可选项： 12345678910111213141516171819202122232425262728293031# Markdown-it config## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wikimarkdown: # 渲染设置 render: # 置为true时，html内容保持不变；置为false时，html内容将被转义成普通字符串 html: true # 是否生成与XHTML完全兼容的标签（虽然我不懂是什么意思） xhtmlOut: false # 置为true时，每个换行符都被渲染成一个&lt;br&gt;（即Hexo的默认表现）；置为false时，只有空行才会被渲染为&lt;br&gt;（GFM的默认表现） breaks: true # 是否自动识别链接并把它渲染成链接 linkify: true # 是否自动识别印刷格式（意思是把(c)渲染为©这样的） typographer: true # 如果typographer被设置为true，则该选项用于设置将dumb quotes（\"\"）自动替换为smart quotes quotes: '“”‘’' # 设置所需插件 plugins: - markdown-it-abbr - markdown-it-footnote - markdown-it-ins - markdown-it-sub - markdown-it-sup # 锚点设置（因为我没有尝试相关内容，所以就不翻译相关说明了） anchors: level: 2 collisionSuffix: 'v' permalink: true permalinkClass: header-anchor permalinkSymbol: ¶ 插件的效果 这里的示例参考了markdown-it-footnote（也就是markdown-it自己用于实现脚注功能的插件）： 123456789101112Here is a footnote reference,[^1] and another.[^longnote][^1]: Here is the footnote.[^longnote]: Here's one with multiple blocks. Subsequent paragraphs are indented to show that they belong to the previous footnote.This paragraph won’t be part of the note, because it isn’t indented.Here is an inline note.^[Inlines notes are easier to write.Since you don't have to pick an identifier and move down to type the note.] Here is a footnote reference,[1] and another.[2] This paragraph won’t be part of the note, because it isn’t indented. Here is an inline note.[3] 这个插件似乎参考了Pandoc的规范： 脚注标识符中不能包含空格、tab或换行符，且标识符不会出现在最终的渲染结果中 每条脚注的前后都应该有空行 如果需要在脚注中分段，可以将后面的段缩进来表示它们属于同一段脚注 脚注不一定必须位于文档的最后部分，除了块元素内部，它们可以出现在其他任何位置（虽然在这个插件中并未实现） 行内脚注不能分段 （值得注意的是，[^1]:中的冒号是语法重要的一部分。） 在文章最下面应该能看到分割线和脚注的内容。说实话，我对这个插件的效果并不完全满意，因为我无法区分脚注和参考文献，也无法自定义脚注的显示位置。如果希望采用现有工具实现上述需求的话，可能改用个人维基效果会比较好，但那样又实在太“Heavy”了，我已经尝试过并放弃这种做法了。所以，如果以后有时间，我也尝试去开发一个markdown-it-footnote-plus一类的东西好了。 Here is the footnote. ↩︎ Here’s one with multiple blocks. Subsequent paragraphs are indented to show that they belong to the previous footnote. ↩︎ Inlines notes are easier to write. Since you don't have to pick an identifier and move down to type the note. ↩︎","categories":[],"tags":[{"name":"Blogging","slug":"Blogging","permalink":"https://zhanghuimeng.github.io/tags/Blogging/"}]},{"title":"《英诗金库》I-55：This life, which seems so fair, by W. Drummond","slug":"2018-08-12-《英诗金库》I-55：This-life-which-seems-so-fair-by-W-Drummond","date":"2018-08-12T21:21:28.000Z","updated":"2018-08-13T00:43:00.000Z","comments":true,"path":"post/this-life-which-seems-so-fair-by-w-drummond/","link":"","permalink":"https://zhanghuimeng.github.io/post/this-life-which-seems-so-fair-by-w-drummond/","excerpt":"","text":"作品基本信息 作品名称：This life, which seems so fair 作者：William Drummond（威廉·德拉蒙德） 出版年代：1616 编注：无 作品原文 This Life, which seems so fair, Is like a bubble blown up in the air By sporting children’s breath, Who chase it everywhere And strive who can most motion it bequeath: And though it sometime seem of its own might, Like to an eye of gold, to be fix’d there, And firm to hover in that empty height, That only is because it is so light. But in that pomp it doth not long appear; For, when 'tis most admired, in a thought[1], Because it erst[2] was nought, it turns to nought.[3] 译文 曹明伦 译 看起来这般炫丽的生命 倒象是肥皂泡漂浮在空中， 由嬉戏的孩子们把它吹胀， 把它追逐到整个世尘， 努力使它不停息地飘荡。 虽然它有时也显得庄重， 象纯粹的黄金，凝固不变， 稳稳地翱翔在茫茫太空， 可这正是因为它过分轻飘。 ——不能长久地保持它浮华的幻影； 因为哟，虽然它得到片刻的赞美， 可它本原就是虚无，定在虚无中消溶。 我的感想 这首诗是《Poems, The Second Part》中的Madrigal I[4]，显然是里面比较著名的一首诗。 我对这首诗第7-8行的理解和译文有些不同。我认为，这句话用一般的语序表达出来应该是这样的：“(This life seems) to be fixed there and firm to hover in that empty height, like to an eye of gold.”也就是说，就像对于“eye of gold”那样，生命看起来仿佛定住了，在虚空中稳定地漂浮。我觉得“eye of gold”可能是一个习语，但是没有查到相关的解释；我猜测这里是稳定不变的意思。 在这首诗中，生命被比喻为肥皂泡，虽然在短时间内看起来是绚丽的，但存在时间却非常短暂，可能瞬间就会破灭——这是诗中后两句所描述的；除此之外，作者还认为，生命来自于虚无，破灭之后，也会化为虚无。这比通常所说的“归于尘土”更空虚和悲观，却也更加轻盈，不留痕迹。 作者没有否认，至少生命看起来是绚丽的；但他实际上为我们描述了一种比单纯的“空虚”更悲观的生命观。“By sporting children’s breath… And strive who can most motion it bequeath”，我们的生命中发生的事情完全没有任何意义，而是随机发生的；或者说，也许生命有意义，但这种意义对于实际活着的我们完全无足轻重——嬉戏中的小孩也许会随便因为好玩而戳破一个肥皂泡，这可能就意味着某人的死亡。因而，生命除了“fair”之外的意义被完全消解了。 但甚至还有比生命更空虚的东西，那就是太空。在广阔而空虚的太空中，如此空幻的生命甚至也显得稳定不变了。但太空——或者说，虚无本身——是永恒的，而我们浮华的生命终究会在刹那间消溶在虚无中。 in a thought: ‘swift as a thought.’ or, as we should say, ‘in a flash.’（“像想法一样快”，或者说，“一刹那间”。） ↩︎ erst: ‘at first’: it is the superlative of ere=‘before.’（“erst”是“ere”的最高级，意为“最初”。） ↩︎ 最后两行在1616年的版本中作： For even when most admir’d, it in a thought, As swell’d from nothing, doth dissolve in nought. ↩︎ The poems of William Drummond of Hawthornden, Vol 1 by Drummond, William, 1585-1649; Ward, W. C. (William C.) ↩︎","categories":[],"tags":[{"name":"W.Drummond","slug":"W-Drummond","permalink":"https://zhanghuimeng.github.io/tags/W-Drummond/"},{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"曹明伦","slug":"曹明伦","permalink":"https://zhanghuimeng.github.io/tags/曹明伦/"}]},{"title":"Leetcode 887. Projection Area of 3D Shapes（简单立体几何）","slug":"2018-08-12-Leetcode-887-Projection-Area-of-3D-Shapes（简单立体几何）","date":"2018-08-12T01:37:41.000Z","updated":"2018-08-12T01:42:41.000Z","comments":true,"path":"post/leetcode-887-projection-area-of-3d-shapes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-887-projection-area-of-3d-shapes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/projection-area-of-3d-shapes/description/ 标记难度：Easy 提交次数：1/1 代码效率：99.84% 题意 计算一堆方块的三视图投影面积总和。 分析 大水题。 我的代码有点复杂了，考虑到题目说明了地板的大小是N * N，完全可以一遍统计出三视图的投影面积总和（因为此时前面和侧面是完全对称的）。（11 line 1 pass Java code and explanation of the problem, time O(N ^ 2) space O(1).） 代码 12345678910111213141516171819202122232425262728293031class Solution &#123;public: int projectionArea(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; // 顶面，直接统计有哪些方块不是0即可 int up = 0; for (int i = 0; i &lt; grid.size(); i++) for (int x: grid[i]) if (x != 0) up++; // 前面，统计每一列高度的最大值 int front = 0; vector&lt;int&gt; maxHeight(grid.size(), 0); for (int i = 0; i &lt; grid.size(); i++) &#123; for (int x: grid[i]) maxHeight[i] = max(maxHeight[i], x); front += maxHeight[i]; &#125; int left = 0; vector&lt;int&gt; maxHeight2(grid[0].size(), 0); for (int i = 0; i &lt; grid.size(); i++) &#123; for (int j = 0; j &lt; grid[i].size(); j++) maxHeight2[j] = max(maxHeight2[j], grid[i][j]); &#125; for (int h: maxHeight2) left += h; return up + front + left; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 347. Top K Frequent Elements（数量统计量）","slug":"2018-08-12-Leetcode-347-Top-K-Frequent-Elements（数量统计量）","date":"2018-08-12T01:02:31.000Z","updated":"2018-08-12T01:02:31.000Z","comments":true,"path":"post/leetcode-347-top-k-frequent-elements/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-347-top-k-frequent-elements/","excerpt":"","text":"题目来源：https://leetcode.com/problems/top-k-frequent-words/description/ 标记难度：Medium 提交次数：1/2 代码效率：98.50% 题意 从一个数组中选出出现次数前k多的元素。 分析 这道题和上一道Top K（Leetcode 692）基本是完全一样的——事实上，我是从那边的题解区过来的。区别可能是，这里完全没有对break tie的要求，所以我就直接用HashMap+桶排序做了（其他的做法参见3 ways to solve this problem），然后就过了。 中间错了一次是因为桶的数量开少了一个。 代码 12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; freq; for (int x: nums) freq[x]++; // 这道题的题干中没有提到break tie的问题啊…… // 如果按照没有tie的方法去做，那桶排序将变得非常简单 vector&lt;vector&lt;int&gt;&gt; bucket; for (int i = 0; i &lt;= nums.size(); i++) bucket.push_back(vector&lt;int&gt;()); for (auto const&amp; i: freq) bucket[i.second].push_back(i.first); vector&lt;int&gt; topk; while (topk.size() &lt; k) &#123; for (int j = bucket.size() - 1; j &gt;= 0; j--) &#123; for (int x: bucket[j]) if (topk.size() &lt; k) topk.push_back(x); else break; if (topk.size() &gt;= k) break; &#125; &#125; return topk; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Heap","slug":"alg-Heap","permalink":"https://zhanghuimeng.github.io/tags/alg-Heap/"}]},{"title":"Leetcode 692. Top K Frequent Words（数量统计量）","slug":"2018-08-11-Leetcode-692-Top-K-Frequent-Words（数量统计量）","date":"2018-08-11T23:10:23.000Z","updated":"2018-08-12T00:03:23.000Z","comments":true,"path":"post/leetcode-692-top-k-frequent-words/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-692-top-k-frequent-words/","excerpt":"","text":"题目来源：https://leetcode.com/problems/top-k-frequent-words/description/ 标记难度：Medium 提交次数：3/3 代码效率： O(n * log(n))：36.84% O(n * log(k))：36.84% 题意 从一个数组中选出出现次数前k多的元素。 分析 显然很容易想到这种解法：用map来统计每种元素出现的数量（O(n * log(n))），然后用priority_queue来选择出现次数前k多的元素（O(n * log(n))），整体时间复杂度为O(n * log(n))。我们可以迅速改进这种算法的时间复杂度（虽然实际运行时间并没有多大改进）：用unordered_map来统计每种元素出现的数量（O(n)），然后在保证priority_queue中的元素不超过k个的前提下选择出现次数前k多的元素（O(n * log(k))），这样时间复杂度可以降低到O(n * log(k))。 我们还可以进行进一步的优化。这篇题解指出，每种元素出现的数量的值最大为原数组的长度，因此我们并不需要动用优先队列来选择出现次数前k多的元素，用桶排序就可以了。为了保证先输出字典序小的元素，原作者在每个桶里搞了一棵Trie，因此这一处理过程的复杂度为O(n * ave_len)。 我想，用Trie处理字符串算是相当聪明的做法了——如果换成其他的有序数据结构或者排序算法，总归会有退化情况的。不过，如果字符串太长，处理时间仍然会变长。（不过我实在懒得去写了。） C++ STL代码技巧 通过阅读这份代码和查找资料，我感觉我又新学会了很多C++ STL的技巧。 map的一些特点 可以用std::map::count函数统计map中元素的个数。当然，map中的元素不可重复，因此这个函数的输出只可能为0或1。我把这个函数当做find的轻量版来用了…… 使用[]操作符访问map中的元素时，如果这个元素不存在，会自动插入该元素并将值置为空。所以代码中直接mmap[x]++是可行的。（What happens if I read a map’s value where the key does not exist?） 遍历map的几种方法 参考了C++ Loop through Map。 普通方法：迭代器 123456789map&lt;string, int&gt;::iterator it;for ( it = symbolTable.begin(); it != symbolTable.end(); it++ )&#123; std::cout &lt;&lt; it-&gt;first // string (key) &lt;&lt; ':' &lt;&lt; it-&gt;second // string's value &lt;&lt; std::endl ;&#125; C++ 11：auto和冒号（我感觉这种写法很像Java） 1234567for (auto const&amp; x : symbolTable)&#123; std::cout &lt;&lt; x.first // string (key) &lt;&lt; ':' &lt;&lt; x.second // string's value &lt;&lt; std::endl ;&#125; 注意上一种方法里ref的方式是-&gt;，这种方法里ref的方式是.。 C++ 17：这根本就是Python吧 1234567for( auto const&amp; [key, val] : symbolTable )&#123; std::cout &lt;&lt; key // string (key) &lt;&lt; ':' &lt;&lt; val // string's value &lt;&lt; std::endl ;&#125; 如何创建最小堆 我记得我之前曾经记录过，简单的创建一个最小堆的方法是： 1std::priority_queue&lt;int, std::vector&lt;int&gt;, std::greater&lt;int&gt; &gt; my_min_heap; 但是我没有考虑到如何为自建的类型创建比较方法。对于那些C算法库函数，写个返回bool的普通函数就行了，但对于C++ STL，显然没有这么简单——我果然还是不懂STL啊……简单来说，需要新建一个类，然后在里面重载()运算符，最后把这个类作为参数构造模板。下列代码来自How can I create Min stl priority_queue?： 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;struct compare&#123; bool operator()(const int&amp; l, const int&amp; r) &#123; return l &gt; r; &#125;&#125;; int main() &#123; priority_queue&lt;int,vector&lt;int&gt;, compare &gt; pq; pq.push(3); pq.push(5); pq.push(1); pq.push(8); while ( !pq.empty() ) &#123; cout &lt;&lt; pq.top() &lt;&lt; endl; pq.pop(); &#125; cin.get(); &#125; 代码 O(n * log(n)) 123456789101112131415161718192021222324252627282930313233class Solution &#123;private: struct compare &#123; bool operator()(const pair&lt;int, string&gt;&amp; p1, const pair&lt;int, string&gt;&amp; p2) &#123; if (p1.first != p2.first) return p1.first &lt; p2.first; return p1.second &gt; p2.second; &#125; &#125;;public: vector&lt;string&gt; topKFrequent(vector&lt;string&gt;&amp; words, int k) &#123; map&lt;string, int&gt; mmap; for (string w: words) &#123; if (mmap.count(w) == 1) mmap[w]++; else mmap[w] = 1; &#125; priority_queue&lt;pair&lt;int, string&gt;, std::vector&lt;pair&lt;int, string&gt;&gt;, compare&gt; pq; for (auto const&amp; x : mmap) &#123; pq.push(make_pair(x.second, x.first)); &#125; vector&lt;string&gt; ans; for (int i = 0; i &lt; k; i++) &#123; ans.push_back(pq.top().second); pq.pop(); &#125; return ans; &#125;&#125;; O(n * log(k)) 1234567891011121314151617181920212223242526272829303132class Solution &#123;private: struct compare &#123; // 改为构造最小堆 bool operator()(const pair&lt;int, string&gt;&amp; p1, const pair&lt;int, string&gt;&amp; p2) &#123; if (p1.first != p2.first) return p1.first &gt; p2.first; return p1.second &lt; p2.second; &#125; &#125;;public: vector&lt;string&gt; topKFrequent(vector&lt;string&gt;&amp; words, int k) &#123; unordered_map&lt;string, int&gt; mmap; // 即HashMap for (string w: words) &#123; mmap[w]++; // 直接+即可 &#125; priority_queue&lt;pair&lt;int, string&gt;, std::vector&lt;pair&lt;int, string&gt;&gt;, compare&gt; pq; for (auto const&amp; x : mmap) &#123; pq.push(make_pair(x.second, x.first)); if (pq.size() &gt; k) // 需要保持pq的size不超过k，否则就是O(n * log(n))了 pq.pop(); &#125; vector&lt;string&gt; ans; for (int i = 0; i &lt; k; i++) &#123; ans.insert(ans.begin(), pq.top().second); pq.pop(); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"},{"name":"alg:Heap","slug":"alg-Heap","permalink":"https://zhanghuimeng.github.io/tags/alg-Heap/"}]},{"title":"Leetcode 46. Permutations（全排列）","slug":"2018-08-11-Leetcode-46-Permutations（全排列）","date":"2018-08-11T17:32:30.000Z","updated":"2018-08-11T18:17:30.000Z","comments":true,"path":"post/leetcode-46-permutations/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-46-permutations/","excerpt":"","text":"题目来源：https://leetcode.com/problems/permutations/description/ 标记难度：Medium 提交次数：3/4 代码效率： next_permutation版本：99.91% 回溯法：99.92% Heap算法：99.92% Steinhaus–Johnson–Trotter算法：……懒得写了 题意 计算若干整数全排序，整数两两不同。 分析 STL版本 直接用STL中提供的next_permutation可能是最简单的一种方式了。但是，值得注意的是，在开始使用这个函数之前，需要把数组排序。 回溯法版本 用回溯法直接做也是一种思路，而且并不太难。 显然我基本已经把我的C忘光了（或者说我就没有好好学过STL和模板）。C vector的push_back函数使用的是相应的拷贝构造函数，所以不需要再单独复制一次vector。 Heap算法 可能是效率最高的排列算法之一。好吧，我一时搞不清楚这个算法了，但是按照维基百科的思路，应该很好写…… Steinhaus–Johnson–Trotter算法 之前读《组合数学》的时候曾经看到过这个算法，是一种很有趣的思路——虽然在开始做这道题之前，我已经把具体的算法给忘光了。……算了，现在懒得写了。 代码 STL版本 123456789101112class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; ans; sort(nums.begin(), nums.end()); // 如果使用next_permutation()，是需要排序的 do &#123; vector&lt;int&gt; x(nums); ans.push_back(x); &#125; while (next_permutation(nums.begin(), nums.end())); return ans; &#125;&#125;; 回溯法版本 1234567891011121314151617181920212223242526272829class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; ans; void dfs(vector&lt;int&gt;&amp; perm, vector&lt;int&gt;&amp; nums, vector&lt;bool&gt; used) &#123; if (perm.size() == nums.size()) &#123; vector&lt;int&gt; tmp(perm); // 事实上没有必要 ans.push_back(tmp); return; &#125; for (int i = 0; i &lt; nums.size(); i++) &#123; if (!used[i]) &#123; used[i] = true; perm.push_back(nums[i]); dfs(perm, nums, used); perm.pop_back(); used[i] = false; &#125; &#125; &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;bool&gt; used(nums.size(), false); vector&lt;int&gt; perm; dfs(perm, nums, used); return ans; &#125;&#125;; Heap算法 12345678910111213141516171819202122232425class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; ans; void generate(int n, vector&lt;int&gt;&amp; nums) &#123; if (n == 1) &#123; ans.push_back(nums); return; &#125; for (int i = 0; i &lt; n - 1; i++) &#123; generate(n-1, nums); if (n % 2 == 0) swap(nums[i], nums[n-1]); else swap(nums[0], nums[n-1]); &#125; generate(n - 1, nums); &#125;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; generate(nums.size(), nums); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"}]},{"title":"Leetcode 493. Reverse Pairs（数组子问题）","slug":"2018-08-11-Leetcode-493-Reverse-Pairs（数组子问题）","date":"2018-08-11T16:34:53.000Z","updated":"2018-08-11T17:21:00.000Z","comments":true,"path":"post/leetcode-493-reverse-pairs/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-493-reverse-pairs/","excerpt":"","text":"题目来源：https://leetcode.com/problems/reverse-pairs/description/ 标记难度：Hard 提交次数：1/4 代码效率：93.15% 题意 计算数组中重要逆序对的数量。称(i, j)为重要逆序对，当且仅当i &lt; j且nums[i] &gt; 2 * nums[j]。 分析 其实思路并不是很难。归并排序求逆序对的思路已经很平常了，这道题中直接把计数的条件改一改，只统计另一半数组中至少为当前的数的两倍的数的数量（而不是单纯“大于”）就可以了。 但是我提交了4次。第一次是数组边界写错了，后面几次都是被卡在这个*2上了——我还是第一次见到卡2 * (int) 2147483647这个位置的题，也可能是我孤陋寡闻吧。当然，我承认这么做有点道理，这和单纯比大小是不一样的。反正我最后手动在比较的时候把intcast成long long了。 一种合并的方法 我之前从来没有听说过inplace_merge这个函数。又一次在StephanPochmann的题解中看到了一些闻所未闻的东西之后，我去查了一下，发现：原来STL算法库里为我们提供了一个原址合并算法啊！ 12345678910template&lt;class Iter&gt;void merge_sort(Iter first, Iter last)&#123; if (last - first &gt; 1) &#123; Iter middle = first + (last - first) / 2; merge_sort(first, middle); merge_sort(middle, last); std::inplace_merge(first, middle, last); &#125;&#125; 利用这个算法来实现归并排序无疑是非常简单明了的。 另一个问题是，inplace_merge是如何实现的？我之前从未想过归并算法可以是原址的。事实是，确实可以。请参见Practical In-Place Merging这篇论文和相应的实现（InplaceMerge.hh）。不过这个算法的确有点复杂。 类似于逆序对的题目 讨论区里有一篇非常好的文章，对相似类型的题目进行了一个整体的讨论。简单来说，此类题目的共同点是：将数组分解，然后解决子问题。 通常我们有两种分解数组（子问题）的方法： 顺序分解：T(i, j) = T(i, j - 1) + C 二分分解：T(i, j) = T(i, m) + T(m + 1, j) + C，其中m = (i + j) / 2。 （是的，我之前没有想过，其实顺序分解也是可以做到O(n * log(n))的。） 顺序分解对于本题来说，也就意味着，顺序扫描数组，寻找以当前的数为逆序对的第二个元素的逆序对的数量。显然直接扫描是可以的，但是复杂度会上升到O(n^2)。为了提高搜索的效率，我们注意到，子数组内部的顺序不重要，因此我们可以把它转换成一棵二叉搜索树（或者任何类似的东西）。这样效率就可以提高到O(n * log(n))了。 二分分解就是我的做法：分别寻找元素都来自左半数组和右半数组的逆序对，然后寻找元素各自来自一侧的逆序对，最后加在一起。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution &#123;private: int* tmp; int split(int l, int r, vector&lt;int&gt;&amp; nums) &#123; if (l == r) return 0; int m = (l + r) &gt;&gt; 1; int sum = 0; sum += split(l, m, nums); sum += split(m+1, r, nums); // 统计important逆序对的数目 int i = l, j = m+1; while (i &lt;= m &amp;&amp; j &lt;= r) &#123; // 第一次遇到卡这里的题目…… while (i &lt;= m &amp;&amp; (long long)nums[i] &lt;= (long long)(nums[j]) * 2) i++; if (i &gt; m) break; sum += m - i + 1; j++; &#125; // 合并 i = l; j = m+1; int k = 0; while (i &lt;= m &amp;&amp; j &lt;= r) &#123; if (nums[i] &lt;= nums[j]) tmp[k++] = nums[i++]; else tmp[k++] = nums[j++]; &#125; while (i &lt;= m) tmp[k++] = nums[i++]; while (j &lt;= r) tmp[k++] = nums[j++]; for (i = l; i &lt;= r; i++) nums[i] = tmp[i - l]; return sum; &#125;public: int reversePairs(vector&lt;int&gt;&amp; nums) &#123; // 只是普通的求逆序对算法的一个变形 if (nums.size() == 0) return 0; tmp = new int[nums.size() + 1]; int sum = split(0, nums.size() - 1, nums); delete[] tmp; return sum; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Divide and Conquer","slug":"alg-Divide-and-Conquer","permalink":"https://zhanghuimeng.github.io/tags/alg-Divide-and-Conquer/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"},{"name":"alg:Binary Indexed Tree","slug":"alg-Binary-Indexed-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Indexed-Tree/"}]},{"title":"Wir Sind Helden歌词翻译（2）：23:55: Alles auf Anfang","slug":"2018-08-10-Wir-Sind-Helden歌词翻译（2）：23-55-Alles-auf-Anfang","date":"2018-08-10T22:18:55.000Z","updated":"2018-08-10T22:18:55.000Z","comments":true,"path":"post/wir-sind-helden-song-translation-2-23-55-alles-auf-anfang/","link":"","permalink":"https://zhanghuimeng.github.io/post/wir-sind-helden-song-translation-2-23-55-alles-auf-anfang/","excerpt":"","text":"https://music.163.com/#/song?id=19824349 歌词和翻译 歌词翻译参考了Wir sind Helden 23:55: Alles auf Anfang Songtext和Wir sind Helden - 23.55: Alles auf Anfang (English translation)。 歌词 翻译 Du wirst zahnlos geboren und ohne Zähne gewogen 你生下来时没有牙齿，因此是个温顺的人 Kriegst sie bis Mitte zwanzig schon wieder gezogen 难道到了二十多岁，你的牙又要叫人给拔掉吗？ Bist oh so verschüchtert, verzagt und vernagelt 天哪，你真是又胆小、又沮丧、又狭隘 Kein Licht dringt zu dir, so geplagt bist du, sternhageldicht 没有光明照耀着你，你深感苦恼，用毒品麻醉自己 Was dich runterzieht, sind deine schweren Arme 你沉重的双臂拖累着你 Wer schleicht, dem wird leicht kalt, darum schleichst du ins Warme 你爬起来感觉有点冷，所以你又爬回温暖中 Du nennst es Weltschmerz, ich nenn es Attitüde 你叫它悲观主义，我叫它人生态度 Es ist erst fünf vor zwölf und du bist schon so müde 才23:55，你就已经这么疲倦了 Ihr sagt: Kein Ende in Sicht (x2) 你说：看不到尽头啊 Wir sagen: Fünf vor zwölf, alles auf Anfang (x2) 我们说：23:55，一切才刚刚开始 Nimm deine Zähne, leg sie unter dein Kissen 拿起你的牙齿，把它们塞到枕头底下 Und sag der Fee, du möchtest folgendes wissen 告诉牙仙子，你想要知道这些问题的答案 Warum sinkt mir mein Herz in meine schweren Beine? 为什么我的心都沉到我僵硬的腿里了？ Ich kann kein Ende sehen von meiner langen Leine 我看不到这对我长久的束缚到底有没有尽头？ Das, was dich so beschwert, das sind die dicken Bären 把你压迫得如此痛苦的，是那些国际列强 Die sie dir aufbinden, du könntest dich beschweren 只要你抗议，他们也能解开这些束缚 Ob das von den Beinen haut, das wäre nur zu klären 无论这会不会让你的腿更强壮，一切都会更加清晰 Wenn die kleinlauten kleinen Leute im Kleinen deutlich lauter wären 胆怯弱小的人们在这样小的话题上声音会大得多 Ihr sagt: Kein Ende in Sicht (x4) 你说：看不到尽头啊 Wir sagen: Fünf vor zwölf, alles auf Anfang (x4) 我们说：23:55，一切才刚刚开始 Wer A sagt, muss auch B sagen 说了A的人，也必须说B Nach dem ganzen ABC fragen 你得问他要整张字母表 Wer Ach sagt, muss auch wehklagen 只说“哦”的人，现在必须悲叹 Wer Ja sagt, auch Ach nee sagen 说“是”的人，说“哦，不”吧 Fühlst du dich mutlos, fass endlich Mut, los 你觉得没有勇气吗？带上你的勇气，去吧 Fühlst du dich hilflos, geh raus und hilf, los 你感到无助吗？去帮助别人，去吧 Fühlst du dich machtlos, geh raus und mach, los 你感到无力吗？去运用你的力量，去吧 Fühlst du dich haltlos, such Halt und lass los 你缺乏安全感吗？去支持别人，去吧 Ihr sagt: Kein Ende in Sicht (x5) 你说：看不到尽头啊 Wir sagen: Fünf vor zwölf, alles auf Anfang (x5) 我们说：23:55，一切才刚刚开始 Ihr sagt: Kein Ende in Sicht 你说：看不到尽头啊 Wir sagen: Vier vor zwölf, alles auf Anfang 我们说：23:56，一切才刚刚开始 Ihr sagt: Kein Ende in Sicht 你说：看不到尽头啊 Wir sagen: Drei vor zwölf, alles auf Anfang 我们说：23:57，一切才刚刚开始 Ihr sagt: Kein Ende in Sicht 你说：看不到尽头啊 Wir sagen: 2, 1, auf die Zwölf 我们说：58，59，十二点了 一些说明： Weltschmerz是个有点老的概念了。这个词的字义是“对世界感到疲倦”（world weariness），实际上大概意思是，因为对邪恶和痛苦的极度敏感，对人生产生了一种疲倦悲伤的感觉。 中间一大段Los的文字游戏不由得让我想到了Rammstein的《Los》，基本是一样的意思。 这首歌在说什么？ 我本来是因为这首歌旋律活泼可爱才开始翻译的，结果翻译起来越来越不对。下面的内容摘自23:55 Alles auf Anfang (Attac Edition)，大概是说，这是一首鼓励德国现在对政治不那么感兴趣的年轻人走上街头，抗议全球化进程的歌。我的天哪…… 因为我德语也没有那么好，所以先不翻译了，谷歌可能比我做得都好。 Schon seit längerem unterstützen Wir sind Helden die globalisierungskritische Organisation Attac. Das Lied „23.55: Alles auf Anfang&quot; haben sie Attac zur freien Verwendung zur Verfügung gestellt. Das hier ist das Attac-Video zum Song. Judith Holofernes schreibt dazu: Als ich den Text für “23.55: Alles auf Anfang” geschrieben habe, dachte ich: den müsste man eigentlich an mal an Attac schicken! Völlig ohne Ziel, eigentlich nur als Liebesbeweis, quasi. Damals musste ich mich in jedem Interview mit der Frage nach der Politikverdrossenheit meiner sogenannten Generation herumschlagen, und ich dachte immer - guckt euch die Attacis an! Die Attaker? Attaqueure? Die sind doch alles andere als verdrossen, die sagen “Erst fünf vor zwölf?” und sind überhaupt nicht müde. Das war vor acht Jahren, der Song ist ewig bei uns im Orbit gekreist, weil wir nie glücklich waren mit der musikalischen Umsetzung. Als er dann zu dieser Platte endlich fertig und vorzeigbar war, haben wir ihn sofort an Attac geschickt - und uns natürlich wahnsinnig gefreut, als wir gehört haben, dass sie über unser “Geschenk” nicht nur entzückt waren, sondern tatsächlich ein eigenes Video dazu drehen wollten. Und jetzt, wo es fertig ist, freuen wir uns natürlich erst Recht. Da hat unser Lied ein Zuhause gefunden! Und wenn ich mich umgucke, wie absolut unverdrossen “meine” Generation heute auf die Straße geht, zusammen mit allen anderen, dann denke ich: vielleicht doch kein Zufall, dass die Musik sich so lange geziert hat. “Ob das vom Bein haut, das wäre nur zu klären, wenn die kleinlauten kleinen Leute im Kleinen deutlich lauter wären.”","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Wir Sind Helden","slug":"artist-Wir-Sind-Helden","permalink":"https://zhanghuimeng.github.io/tags/artist-Wir-Sind-Helden/"}]},{"title":"歌词翻译：Wisdom Pain, by Cruel Hand (Album: Prying Eyes)","slug":"2018-08-10-歌词翻译：Wisdom-Pain-by-Cruel-Hand-Album-Prying-Eyes","date":"2018-08-10T20:12:41.000Z","updated":"2018-08-10T20:58:00.000Z","comments":true,"path":"post/wisdom-pain-by-cruel-hand-album-prying-eyes-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/wisdom-pain-by-cruel-hand-album-prying-eyes-lyric-translation/","excerpt":"","text":"Anxiety inside of me, I’m starting to bust. Friends turn foe so easily, I need someone to fucking trust. Can’t you see I need room to breathe and space is a must? Everything I know to be crumbles to dust. I can’t stop this, it’s beyond me. I have tried, are you not listening? Reality and what’s “real to me” is what I cannot separate. Choosing one over the other is the reason why I’m fucking late. A window of opportunity smashed to bits and worthless to me. Constant inconsistency- my only consistency. So much wisdom in pain, so many lessons in hurt. You learn from a loss so I’ll take on your worst. Nothing can hit harder than my own regret so I live with what I’ve done and know that I can’t forget. 内心如此焦虑，我要开始破碎了。朋友们如此轻易地变成敌人，我需要我能他妈的信任的人。难道你看不出我需要地方透气，必须有一些空间吗？我所知道的一切都将碎成粉末。我无法阻止这些，这超出了我的能力。我已经努力过了，难道你没在听吗？我无法区分现实和“我眼中的现实”。我需要从中选择一种，因此我他妈的迟了。机遇之窗已被砸得粉碎，对我再无价值。我永远反复无常——这是我唯一始终不渝的地方。这么多来自痛苦的智慧，这么多来自伤害的教训。你从失败中吸取经验，所以我会承受最坏的情况。没有什么能比我自己的后悔更深地打击到我，所以我和我的过去生活在一起，我知道我无法忘记它们。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Cruel Hand","slug":"artist-Cruel-Hand","permalink":"https://zhanghuimeng.github.io/tags/artist-Cruel-Hand/"}]},{"title":"歌词翻译：Throwing Copper, by Touche Amore (Album: ...to the beat of a dead horse)","slug":"2018-08-09-歌词翻译：Throwing-Copper-by-Touche-Amore-Album-to-the-beat-of-a-dead-horse","date":"2018-08-09T22:34:56.000Z","updated":"2018-08-09T22:34:56.000Z","comments":true,"path":"post/throwing-copper-by-touche-amore-album-to-the-beat-of-a-dead-horse-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/throwing-copper-by-touche-amore-album-to-the-beat-of-a-dead-horse-lyric-translation/","excerpt":"","text":"Like staring at a flickering light: you don’t know when it’ll burn out, or how much time you have left to let it light up your life. Because when you’re at your darkest, it’s all you have to survive. Like throwing copper in a well: you’ll never know if wishes work only time can tell. But if superstitions can give someone faith, then I’m throwing my wallet and begging for change. 就像凝视着一丝颤动的光亮那样：你不知道它何时会熄灭，也不知道你还剩多少让它照亮你的生命的时间。因为在你最黑暗的时刻，你唯有依靠它生存下去。就像把铜币扔进井里那样：你永远都不会知道许愿到底有没有用，只有时间知道。但如果迷信可以给人带来信念，那我就把整个钱包都丢进去，乞求改变。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Touche Amore","slug":"artist-Touche-Amore","permalink":"https://zhanghuimeng.github.io/tags/artist-Touche-Amore/"}]},{"title":"Leetcode 88. Merge Sorted Array（归并）","slug":"2018-08-08-Leetcode-88-Merge-Sorted-Array（归并）","date":"2018-08-08T20:16:07.000Z","updated":"2018-08-08T20:24:00.000Z","comments":true,"path":"post/leetcode-88-merge-sorted-array/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-88-merge-sorted-array/","excerpt":"","text":"题目来源：https://leetcode.com/problems/merge-sorted-array/description/ 标记难度：Easy 提交次数：1/1 代码效率： 非原地版本：98.65% 原地版本：98.65% 题意 合并两个已排序的数组，把排序结果存放到第一个数组中（保证空间足够）。 分析 这是一道水题。不过其实需要一点点的思考。非原址的合并方法完全不需要思考。但是如果要求原址合并，那么从前向后合并会导致合并结果会覆盖第一个数组的数据。那么从后向前合并就可以了。被覆盖的数据必然是已经移动过的。这种操作数组的思路倒是有点类似于快排。 代码 非原地版本 123456789101112131415161718192021class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; // 不知道怎么进行原址merge，干脆新开一个vector // 从后向前应该可以保证不冲突？ vector&lt;int&gt; nums3; int i = 0, j = 0; while (i &lt; m &amp;&amp; j &lt; n) &#123; if (nums1[i] &lt; nums2[j]) nums3.push_back(nums1[i++]); else nums3.push_back(nums2[j++]); &#125; while (i &lt; m) nums3.push_back(nums1[i++]); while (j &lt; n) nums3.push_back(nums2[j++]); for (int k = 0; k &lt; nums3.size(); k++) nums1[k] = nums3[k]; &#125;&#125;; 原地版本 123456789101112131415class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; vector&lt;int&gt; nums3; int i = m - 1, j = n - 1, end = m + n - 1; while (i &gt;= 0 &amp;&amp; j &gt;= 0) &#123; if (nums1[i] &gt; nums2[j]) nums1[end--] = nums1[i--]; else nums1[end--] = nums2[j--]; &#125; while (j &gt;= 0) nums1[end--] = nums2[j--]; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"}]},{"title":"歌词翻译：Life in Shambles, by Cruel Hand (Album: Prying Eyes)","slug":"2018-08-07-歌词翻译：Life-in-Shambles-by-Cruel-Hand-Album-Prying-Eyes","date":"2018-08-07T16:13:21.000Z","updated":"2018-08-07T16:13:21.000Z","comments":true,"path":"post/life-in-shambles-by-cruel-hand-album-prying-eyes-lyric-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/life-in-shambles-by-cruel-hand-album-prying-eyes-lyric-translation/","excerpt":"","text":"Time flies by and you’re the only thing that stays on my mind. I can’t lie. Forget your face, every day I try. Life in shambles can we agree this is too much to handle? Life in shambles over fighting this losing battle. You can try to analyze… I won’t lie to myself, It’s been so long since I felt strong. Anger’s not strength, it’s a different defense, insanity is where I’m walking the fucking fence. You can try to magnify the broken pieces of my life… to come up short is no surprise. 时光飞逝，只有你一直留在我脑海里。我无法说谎。每天我都努力忘掉你的面容。生活一片狼藉——我们是不是都觉得这令人无法承受？生活一片狼藉——在这场失败的战斗中。你可以尝试去分析……我不愿自欺欺人，我好久没有感到过坚强了。愤怒不是力量，只是另一种保护方法，我正走在他妈的精神错乱的边缘上。你可以试着凑近来看看我破碎的人生……发现丢掉了很多东西也并不奇怪。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Cruel Hand","slug":"artist-Cruel-Hand","permalink":"https://zhanghuimeng.github.io/tags/artist-Cruel-Hand/"}]},{"title":"Leetcode 295. Find Median from Data Stream（堆）","slug":"2018-08-05-Leetcode-295-Find-Median-from-Data-Stream（堆）","date":"2018-08-05T19:20:47.000Z","updated":"2018-08-05T19:20:47.000Z","comments":true,"path":"post/leetcode-295-find-median-from-data-stream/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-295-find-median-from-data-stream/","excerpt":"","text":"题目来源：https://leetcode.com/problems/find-median-from-data-stream/description/ 标记难度：Hard 提交次数：2/2 代码效率： vector版本：17.75% 优先队列版本：17.75% 题意 写一个读入数据流并随时按要求输出中位数的工具类。 分析 我最开始的想法就是直接维护一个有序vector。这样做显然是可以的，但是每次插入的代价都是O(N)，看起来比较高。 交上去之后，我立刻想到了一种优化方法：维护一个二叉搜索树，这样插入和查询的代价就基本上都是O(log(N))了。不过我并没有写这个方法，因为我在题解里看到了一种很聪明的方法——维护两个堆。大根堆中存储较小的一半元素，小根堆中存储较大的一半元素，维护两个堆的大小大致相等，这样就可以直接通过这两个堆的堆顶计算中位数了。 代码 vector版本 123456789101112131415161718192021222324252627282930313233343536class MedianFinder &#123;private: vector&lt;int&gt; nums;public: /** initialize your data structure here. */ MedianFinder() &#123; // 最简单的方法就是直接把所有数缓存下来，排序，每次返回中间的值 // 但其实我感觉这样是不行的。 // 也许能用int做些文章？ // 或许应该保存一棵二叉搜索树，找median比较方便？ // 我感觉把所有数都存下来可能是必要的。 &#125; void addNum(int num) &#123; auto i = lower_bound(nums.begin(), nums.end(), num); nums.insert(i, num); /*for (int x: nums) cout &lt;&lt; x &lt;&lt; ' '; cout &lt;&lt; endl;*/ &#125; double findMedian() &#123; if (nums.size() % 2 != 0) return nums[nums.size() / 2]; return (nums[nums.size() / 2 - 1] + nums[nums.size() / 2]) / 2.0; &#125;&#125;;/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder obj = new MedianFinder(); * obj.addNum(num); * double param_2 = obj.findMedian(); */ 优先队列版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class MedianFinder &#123; // maxHeap: 较小的一半元素 // minHeap：较大的一半元素 priority_queue&lt;int&gt; maxHeap; priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minHeap;public: /** initialize your data structure here. */ MedianFinder() &#123; &#125; void addNum(int num) &#123; // cout &lt;&lt; num &lt;&lt; ' ' &lt;&lt; maxHeap.size() &lt;&lt; ' ' &lt;&lt; minHeap.size() &lt;&lt; endl; if (minHeap.size() == 0 || num &gt; minHeap.top()) minHeap.push(num); else maxHeap.push(num); // 维护maxHeap.size==minHeap.size || maxHeap.size==minHeap.size-1 while (maxHeap.size() &gt; minHeap.size()) &#123; minHeap.push(maxHeap.top()); maxHeap.pop(); &#125; while (minHeap.size() &gt; maxHeap.size() + 1) &#123; maxHeap.push(minHeap.top()); minHeap.pop(); &#125; &#125; double findMedian() &#123; double ans; if (minHeap.size() == 0) return 0; if (maxHeap.size() == minHeap.size()) ans = (maxHeap.top() + minHeap.top()) / 2.0; else ans = minHeap.top(); return ans; &#125;&#125;;/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder obj = new MedianFinder(); * obj.addNum(num); * double param_2 = obj.findMedian(); */","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Heap","slug":"alg-Heap","permalink":"https://zhanghuimeng.github.io/tags/alg-Heap/"}]},{"title":"Leetcode 829. Consecutive Numbers Sum（数列）","slug":"2018-08-05-Leetcode-829-Consecutive-Numbers-Sum","date":"2018-08-05T18:43:29.000Z","updated":"2018-08-05T18:43:29.000Z","comments":true,"path":"post/leetcode-829-consecutive-numbers-sum/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-829-consecutive-numbers-sum/","excerpt":"","text":"题目来源：https://leetcode.com/problems/consecutive-numbers-sum/description/ 标记难度：Medium 提交次数：1/2 代码效率：98.33% 题意 给定一个正整数N，问有多少种把N表示成若干个连续正整数之和的方法。 分析 我感觉这道题还挺好想的。既然要把N表示成一个等差数列（公差为1）的和，我们不妨设这个数列的首项是x，项数为m，则这个数列的和就是[x + (x + (m-1))]m / 2 = mx + m(m-1)/2 = N。接下来，一个很自然的想法就是，枚举m，通过上式判断对于相应的m是否存在合法的x。显然枚举的复杂度是O(sqrt(N))。 代码 错了一次是因为忘记把计数器初始化了。 1234567891011121314class Solution &#123;public: int consecutiveNumbersSum(int N) &#123; int ans = 0; for (int m = 1; ; m++) &#123; int mx = N - m * (m-1) / 2; if (mx &lt;= 0) break; if (mx % m == 0) ans++; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 14. Longest Common Prefix（最长公共前缀）","slug":"2018-08-05-Leetcode-14-Longest-Common-Prefix（最长公共前缀）","date":"2018-08-05T15:40:19.000Z","updated":"2018-08-05T15:40:19.000Z","comments":true,"path":"post/leetcode-14-longest-common-prefix/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-14-longest-common-prefix/","excerpt":"","text":"题目来源：https://leetcode.com/problems/longest-common-prefix/description/ 标记难度：Easy 提交次数：1/1 代码效率：97.59% 题意 找若干个字符串的最长公共前缀。 分析 直接找公共前缀就行。因为不是找公共子串，所以就变得特别水，而且很容易只能找到空串…… 这回真的是超级大水题了，都没有太大分析的意义。虽然也可以稍微想一下执行效率什么的吧，但我觉得本质实在差别不大。而且我觉得这道题质量不高。 代码 123456789101112131415161718192021class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; // 既然是最长公共前缀，那么应该要求是连续的吧…… if (strs.size() == 0) return \"\"; string prefix = strs[0]; for (int i = 1; i &lt; strs.size(); i++) &#123; if (prefix.length() == 0) return \"\"; int len = 0; while (len &lt; min(prefix.length(), strs[i].length())) &#123; if (prefix[len] != strs[i][len]) break; len++; &#125; prefix = prefix.substr(0, len); &#125; return prefix; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"}]},{"title":"Leetcode 283. Move Zeroes（数组指针）","slug":"2018-08-05-Leetcode-283-Move-Zeroes（数组指针）","date":"2018-08-05T11:19:59.000Z","updated":"2018-08-05T11:43:00.000Z","comments":true,"path":"post/leetcode-283-move-zeroes/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-283-move-zeroes/","excerpt":"","text":"题目来源：https://leetcode.com/problems/move-zeroes/description/ 标记难度：Easy 提交次数：1/1 代码效率：32.62% 题意 把数组中的0都移动到数组末尾，其他数的相对顺序保持不变。 分析 总的来说是道水题：需要移动的不是0，而是其他的数，把它们直接前移就行。这算是一种什么思路呢？巧妙地利用数组中的指针吗？也许这只是表象而已。Discuss里有人说这种思路类似于快速排序，怎么说呢，还真有点像，数组同样被划分成了几个区域，中间区域也是滚动向前的，只是这里被移动到后面的元素都是0。 代码 12345678910111213class Solution &#123;public: void moveZeroes(vector&lt;int&gt;&amp; nums) &#123; // 我感觉只要把所有的数都往前挪，最后在后面补0就可以了。 int validCnt = 0; for (int i = 0; i &lt; nums.size(); i++) &#123; if (nums[i] != 0) nums[validCnt++] = nums[i]; &#125; for (int i = validCnt; i &lt; nums.size(); i++) nums[i] = 0; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"}]},{"title":"Leetcode 338. Counting Bits（动态规划）","slug":"2018-08-05-Leetcode-338-Counting-Bits（动态规划）","date":"2018-08-05T10:50:53.000Z","updated":"2018-08-05T10:50:53.000Z","comments":true,"path":"post/leetcode-338-counting-bits/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-338-counting-bits/","excerpt":"","text":"题目来源：https://leetcode.com/problems/counting-bits/description/ 标记难度：Medium 提交次数：2/2 代码效率： naive算法：99.67% 动态规划：99.67% 题意 分别计算出[0, N]中每个数字的二进制表示中1的数量。（注意是分别计算，返回的结果是一个vector，而不是总和。） 进阶： 想出时间复杂度为O(N * sizeof(integer))的算法是很容易的。你能否尝试用O(N)的时间和空间复杂度解决这个问题？ 请不要使用类似于C++中的__builtin_popcount的函数。 分析 navie算法 好吧，其实我之前从未听说过__builtin_popcount这个函数，所以我立即去查了一下，并用到了我的naive版本的算法中。事实上，这是一个GCC编译器内置的函数（而不是属于C或C标准），利用特定CPU的指令（比如x86的LZCNT）完成计算二进制数中1的个数的操作。未来版本的C可能也会加入相应的支持。 所以这么做差不多可以达到时间复杂度为O(N)的要求。 动态规划 但是如果不用这种指令呢……？我开始时只能想到把一个32位数分成4或者8份然后分别去查表，但这样只是减少了一点常数，并不能摆脱sizeof(integer)的限制。于是我去看了题解—— 事实上，因为题目要求统计所有数的二进制表示中1的数量，这反而为我们提供了很大的便利。虽然统计一个数的代价很难降低，但显然，一个数的二进制表示和它之前的数是相关的：binary(x) = binary(floor(x/2)) || lastbit(x)。因此我们可以采用类似于动态规划的方法直接推导出当前的数的二进制表示中1的数量。 代码 naive算法 123456789101112class Solution &#123;public: vector&lt;int&gt; countBits(int num) &#123; // naive的算法想都不用想。但是不naive的…… // 我感觉二进制表示已经是很fundamental的了，不知道怎么优化比较好。 // 突然想到一个简单的方法：把每个32位数分成4或8份，然后直接查表。但是这并没有突破sizeof... vector&lt;int&gt; ans; for (int i = 0; i &lt;= num; i++) ans.push_back(__builtin_popcount(i)); return ans; &#125;&#125;; 动态规划法 12345678910class Solution &#123;public: vector&lt;int&gt; countBits(int num) &#123; vector&lt;int&gt; ans; ans.push_back(0); for (int i = 1; i &lt;= num; i++) ans.push_back(ans[i &gt;&gt; 1] + (i &amp; 1)); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Bit Manipulation","slug":"alg-Bit-Manipulation","permalink":"https://zhanghuimeng.github.io/tags/alg-Bit-Manipulation/"},{"name":"alg:Dynamic Programming","slug":"alg-Dynamic-Programming","permalink":"https://zhanghuimeng.github.io/tags/alg-Dynamic-Programming/"}]},{"title":"OSTEP第05章作业：Coding: Process APIs","slug":"2018-08-04-OSTEP第05章作业：Coding-Process-APIs","date":"2018-08-04T19:39:20.000Z","updated":"2018-08-04T19:39:20.000Z","comments":true,"path":"post/ostep-ch-05-homework-coding-process-apis/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-05-homework-coding-process-apis/","excerpt":"","text":"本章作业见http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf。 在本次作业中，你将熟悉刚讲到的进程管理API的用法。这可是很有趣的，代码写得越多越好。所以赶紧去写吧。 （以下代码运行结果来自Ubuntu 16.04） 1 写一个程序，调用fork()。在调用fork()之前，让主进程设置一个变量（如x）的值（如100）。子进程中这个变量的值是多少？当子进程和父进程都修改x的值时，会发生什么？ 程序代码见hw01.c。 程序输出如下： 1234567prompt&gt; ./hw01x = 100 (pid:2597)parent: x = 100 (pid:2597)parent: x = 101 (pid:2597)child: x = 100 (pid:2598)child: x = 99 (pid:2598)prompt&gt; 可以看出，子进程中x的值仍然为100，且父进程和子进程对x的修改是互相独立的。这是因为fork()系统调用把内存空间复制了一份（或者大概用了COW机制，不过这个暂时并不重要）。 2 写一个程序，通过open()系统调用打开一个文件，并调用fork()创建一个新的进程。子进程和父进程可以同时访问open()返回的文件描述符吗？如果它们同时写这个文件，会发生什么？ 程序代码见hw02.c。 程序输出如下： 12345prompt&gt; ./hw02prompt&gt; cat hw02.outputI am parentI am childprompt&gt; 可以发现，子进程和父进程可以同时访问这个文件，且输出结果基本是正常的。Linux实际上并不会保证并发的文件操作不出问题。不过，其实Linux的内部实现保证了read()和write()操作是串行执行的。详情可见How do filesystems handle concurrent read/write?。 3 再写一个调用fork()的程序。令子进程打印&quot;hello&quot;，父进程打印&quot;goodbye&quot;。你能否在父进程中不调用wait()的情况下保证子进程总是先打印？ 我感觉上一道题暗示我们，让子进程打印一点东西到文件中，然后在父进程中不断查看该文件中是否含有希望的信息。但我感觉这个做法可能不太可取。查了一些资料之后，我尝试让父进程用kill(2)检查子进程是否正在运行，但是我发现这也不可行，因为对僵尸进程进行这一检查也会返回0。事实上最科学的做法就是wait()系统调用了……所以我干脆用waitpid()好了。 程序代码见hw03.c。 程序输出如下： 1234prompt&gt; ./hw03Hello, I am childGoodbye, I am parentprompt&gt; 4 写一个程序，调用fork()，然后通过某种形式的exec()运行/bin/ls。你能否尝试使用exec()的所有变形，包括execl()、execle()、execlp()、execv()、execp()和execvpe()？这个调用为何有这么多种形式？ 程序代码见hw04.c。 程序输出如下： 1234567891011121314151617181920212223242526272829303132prompt&gt; ./hw04Parent: ready for execl(const char *path, const char *arg, ... /* (char *) NULL */)bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varParent: ready for execlp(const char *file, const char *arg, ... /* (char *) NULL */)bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varParent: ready for execle(const char *path, const char *arg, ... /*, (char *) NULL, char * const envp[] */)bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varParent: ready for execv(const char *path, char *const argv[])bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varParent: ready for execvp(const char *file, char *const argv[])bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varParent: ready for execvpe(const char *file, char *const argv[], char *const envp[])bin etc lib32 media root sys vmlinuzboot home lib64 mnt run tmpcdrom initrd.img libx32 opt sbin usrdev lib lost+found proc srv varprompt&gt; 我猜这些形式主要是为了满足用户不同的需求。实际上，exec后面的那些后缀的含义是这样的（参见了linux系统编程之进程（五）：exec系列函数（execl,execlp,execle,execv,execvp)使用）： l：参数以可变参数列表的形式给出，且以NULL结束（execl()，execle()，execlp()） 没有l：参数以char *arg[]形式给出，且arg最后一个元素必须为NULL（execv()，execp()，execvpe()） p：第一个参数不用输入完整路径，给出命令名即可，程序会在环境变量PATH当中查找命令（execlp()，execp()，execvpe()） 没有p：第一个参数需要输入完整路径（execl()，execle()，execv()） e：将环境变量传递给新进程（execle()，execvpe()） 没有e：不传递环境变量（execl()，execlp()，execv()，execp()） 5 写一个程序，让父进程调用wait()，等待子进程完成。wait()将返回什么？如果在子进程中调用wait()，会发生什么？ 程序代码见hw05.c。 程序输出如下： 123456prompt&gt; ./hw05I am parent (pid:4154)I am child (pid:4155)Child: wait() returns -1Parent: wait() returns 4155prompt&gt; 如果wait(2)找到了至少一个状态已经变化的子进程，则它会返回这个子进程的PID（因此此处父进程返回了子进程的PID，4155）；而子进程自己没有子进程，因此调用失败，返回-1。 6 稍微修改一下上一题中的程序，改为使用waitpid()，而不是wait()。waitpid()何时是有用的？ 程序代码见hw06.c。 程序输出如下： 123456prompt&gt; ./hw06I am parent (pid:4368)I am child (pid:4369)Child: waitpid(-1) returns -1Parent: waitpid(4369) returns 4369prompt&gt; 在需要等待某一个子进程执行完毕时，可以使用waitpid()。调用waitpid(-1)的效果与wait()基本是类似的。 7 写一个程序，创建一个子进程，并在子进程中关闭标准输出（STDOUT_FILENO）。在关闭该文件描述符之后，如果子进程调用printf()来打印输出，会发生什么？ 程序代码见hw07.c。 程序输出如下： 123prompt&gt; ./hw07I am parentprompt&gt; 结果，无论是关闭之前还是关闭之后的printf都没有在屏幕打印出结果。我并没有查到为什么…… 8 写一个程序，创建两个子进程，通过pipe()系统调用，把其中一个进程的标准输出连接到另一个的标准输入。 程序代码见hw08.c，参考了UNIX管道编程——使用pipe函数，dup函数，dup2函数。 程序输出如下： 12345prompt&gt; ./hw08Child 1 (pid=4727), writing to pipe.Child 2 (pid=4728), reading from pipe.Hello world , this is transported by pipe.prompt&gt;","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第04章作业：Simulation: process-run.py","slug":"2018-08-04-OSTEP第04章作业：Simulation-process-run-py","date":"2018-08-04T19:30:57.000Z","updated":"2018-08-04T19:30:57.000Z","comments":true,"path":"post/ostep-ch-04-homework-simulation-process-run-py/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-04-homework-simulation-process-run-py/","excerpt":"","text":"本章作业见http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-intro.pdf和http://pages.cs.wisc.edu/~remzi/OSTEP/Homework/HW-CPU-Intro.tgz。 作业说明和模拟器代码见https://github.com/zhanghuimeng/ostep-hw-translation/tree/master/ch04_Process-Intro。 这次作业没有明确地说明调度策略——这也是因为现在还没有介绍到调度策略这么复杂的东西。通过阅读代码，我发现选择下一个运行进程的策略是通过PID进行循环查找：从当前进程的PID开始，如果这个进程处于就绪态，则选择它；否则PID = (PID + 1) % 进程总数。这个策略不太实际（有点类似于FIFO，但是优先级依赖于PID），但显然对于手动模拟比较方便。 1 用以下参数运行程序：./process-run.py -l 5:100,5:100。CPU利用率（CPU处于使用状态的时间比例）是多少？为什么？用参数-c和-p验证你的回答的正确性。 我猜测Process0会先运行5个时间片；Process0运行完之后，Process1再运行5个时间片，也会结束。因为CPU运行完Process0就运行了Process1，中间没有空闲的时间，因此CPU利用率为100%。 运行结果如下（因为是win环境，所以用的是python）： 12345678910111213141516prompt&gt; python process-run.py -l 5:100,5:100 -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:cpu READY 1 3 RUN:cpu READY 1 4 RUN:cpu READY 1 5 RUN:cpu READY 1 6 DONE RUN:cpu 1 7 DONE RUN:cpu 1 8 DONE RUN:cpu 1 9 DONE RUN:cpu 1 10 DONE RUN:cpu 1Stats: Total Time 10Stats: CPU Busy 10 (100.00%)Stats: IO Busy 0 (0.00%) 可以看出这个推测是正确的。 2 用以下参数运行程序：./process-run.py -l 4:100,1:0。这些参数给定了两个进程，其中一个包含4条CPU指令，另一个只发出一个I/O请求并等待请求结束。两个进程都结束执行需要多长时间？用参数-c和-p验证你的回答的正确性。 Process0不发出I/O请求，因此它会一直执行到结束，共花费4个时间片。Process1发出一个I/O请求（1个时间片），I/O请求执行完毕需要5个时间片；因此，一共需要10个时间片结束执行。 运行结果如下（实际上刚才的结果参考了运行结果，因为我不知道所谓的“I/O请求花费5个时间片”算不算发出请求的指令的时间……当然从情理上和实验上来说都是不算的）： 12345678910111213141516prompt&gt; python process-run.py -l 4:100,1:0 -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:cpu READY 1 3 RUN:cpu READY 1 4 RUN:cpu READY 1 5 DONE RUN:io 1 6 DONE WAITING 1 7 DONE WAITING 1 8 DONE WAITING 1 9 DONE WAITING 1 10* DONE DONEStats: Total Time 10Stats: CPU Busy 5 (50.00%)Stats: IO Busy 4 (40.00%) 3 现在切换进程的顺序：./process-run.py -l 1:0,4:100。切换顺序对于结束执行的时间有影响吗？继续用参数-c和-p验证你的回答的正确性。 显然有影响，因为Process0发出一个I/O请求（花费1个时间片）后，就会切换到Process1开始执行（4个时间片）；与此同时，I/O请求需要5个时间片完成。因此执行时间减少到了6个时间片。这说明了进程切换的必要性，因为增加了并行性，可以增加各种设备的利用率。 运行结果如下： 123456789101112prompt&gt; python process-run.py -l 1:0,4:100 -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING RUN:cpu 1 1 3 WAITING RUN:cpu 1 1 4 WAITING RUN:cpu 1 1 5 WAITING RUN:cpu 1 1 6* DONE DONEStats: Total Time 6Stats: CPU Busy 5 (83.33%)Stats: IO Busy 4 (66.67%) 4 下面我们探索一下其他的参数。参数-S指定了进程发出I/O请求时系统的反应策略。当该参数的值为SWITCH_ON_END时，系统不会在当前进程发出I/O请求时切换到另一个进程，而是等待进程结束之后再切换。如果你用以下参数运行程序（-l 1:0,4:100 -c -S SWITCH_ON_END），会发生什么？ 这道题的进程配置和上一道题一样，但是如果在进程发出I/O请求时不切换，就相当于必须执行完当前进程才能切换到下一个，这样设备利用率显然会下降，而运行时间会增加。Process0执行完需要6个时间片，Process1需要4个时间片，因此总时间为10个时间片，与进程顺序颠倒时相同。 运行结果如下（好吧，这说明我的分析有一点问题，这似乎与结束的总时间如何计算有关）： 123456789101112131415prompt&gt; python process-run.py -l 1:0,4:100 -c -S SWITCH_ON_END -pTime PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING READY 1 3 WAITING READY 1 4 WAITING READY 1 5 WAITING READY 1 6* DONE RUN:cpu 1 7 DONE RUN:cpu 1 8 DONE RUN:cpu 1 9 DONE RUN:cpu 1Stats: Total Time 9Stats: CPU Busy 5 (55.56%)Stats: IO Busy 4 (44.44%) 5 现在把-S参数的值置为SWITCH_ON_IO，此时只要进程发出I/O请求，就会切换到别的进程。（参数为-l 1:0,4:100 -c -S SWITCH_ON_IO）。那么，会发生什么呢？用参数-c和-p验证你的回答的正确性。 把参数设置成这样似乎就是默认值。结论是和第4题的分析相同吧？ 运行结果如下（是的，的确如此）： 123456789101112prompt&gt; python process-run.py -l 1:0,4:100 -c -S SWITCH_ON_IO -pTime PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING RUN:cpu 1 1 3 WAITING RUN:cpu 1 1 4 WAITING RUN:cpu 1 1 5 WAITING RUN:cpu 1 1 6* DONE DONEStats: Total Time 6Stats: CPU Busy 5 (83.33%)Stats: IO Busy 4 (66.67%) 6 I/O请求结束时系统的执行策略也很重要。如果将参数-I的值置为IO_RUN_LATER，则I/O请求完成时，发出请求的进程不会立刻开始执行，当前运行中的进程会继续运行。如果使用以下参数组合，会发生什么？（./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER） IO_RUN_LATER似乎就是默认值。Process0首先发出一个I/O请求（1个时间片），之后Process1，Process2和Process3依次执行完毕（共15个时间片）；最后Process0再重新开始执行，花费10个时间片进行两个I/O请求。然后，似乎因为最后一条指令为I/O指令，所以需要多花一个时间片确认为DONE（这一点是根据运行结果凑出来的）。因此总时间为27个时间片。 这个调度方法比较愚蠢，如果把Process0的I/O请求分散开，可以提高CPU和I/O设备的利用率。这说明在设计调度策略的时候，我们应当考虑到I/O密集型进程和CPU密集型进程的不同特点。 运行结果如下： 123456789101112131415161718192021222324252627282930313233prompt&gt; python process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -pTime PID: 0 PID: 1 PID: 2 PID: 3 CPU IOs 1 RUN:io READY READY READY 1 2 WAITING RUN:cpu READY READY 1 1 3 WAITING RUN:cpu READY READY 1 1 4 WAITING RUN:cpu READY READY 1 1 5 WAITING RUN:cpu READY READY 1 1 6* READY RUN:cpu READY READY 1 7 READY DONE RUN:cpu READY 1 8 READY DONE RUN:cpu READY 1 9 READY DONE RUN:cpu READY 1 10 READY DONE RUN:cpu READY 1 11 READY DONE RUN:cpu READY 1 12 READY DONE DONE RUN:cpu 1 13 READY DONE DONE RUN:cpu 1 14 READY DONE DONE RUN:cpu 1 15 READY DONE DONE RUN:cpu 1 16 READY DONE DONE RUN:cpu 1 17 RUN:io DONE DONE DONE 1 18 WAITING DONE DONE DONE 1 19 WAITING DONE DONE DONE 1 20 WAITING DONE DONE DONE 1 21 WAITING DONE DONE DONE 1 22* RUN:io DONE DONE DONE 1 23 WAITING DONE DONE DONE 1 24 WAITING DONE DONE DONE 1 25 WAITING DONE DONE DONE 1 26 WAITING DONE DONE DONE 1 27* DONE DONE DONE DONEStats: Total Time 27Stats: CPU Busy 18 (66.67%)Stats: IO Busy 12 (44.44%) 7 将参数-I的值换成IO_RUN_IMMEDIATE，重新执行上述命令，此时，当I/O请求完成时，发出请求的进程会立刻抢占CPU。现在程序的运行结果有何不同？为什么让刚刚执行完I/O的进程立刻开始运行可能是个好主意？ 就像上一题所分析的那样，如果把I/O请求分散开来，则可以提高设备的利用率。在设计调度策略的时候应当考虑到进程的I/O密集程度，这个思路见于多级反馈队列调度算法中——如果进程用完了时间片则下移一个队列；否则，如果在时间片结束之前就发出了I/O请求，则保留在当前队列中。此时花费的总时间就是3条I/O指令加上15条CPU指令的时间。 运行结果如下： 123456789101112131415161718192021222324prompt&gt; python process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_IMMEDIATE -c -pTime PID: 0 PID: 1 PID: 2 PID: 3 CPU IOs 1 RUN:io READY READY READY 1 2 WAITING RUN:cpu READY READY 1 1 3 WAITING RUN:cpu READY READY 1 1 4 WAITING RUN:cpu READY READY 1 1 5 WAITING RUN:cpu READY READY 1 1 6* RUN:io READY READY READY 1 7 WAITING RUN:cpu READY READY 1 1 8 WAITING DONE RUN:cpu READY 1 1 9 WAITING DONE RUN:cpu READY 1 1 10 WAITING DONE RUN:cpu READY 1 1 11* RUN:io DONE READY READY 1 12 WAITING DONE RUN:cpu READY 1 1 13 WAITING DONE RUN:cpu READY 1 1 14 WAITING DONE DONE RUN:cpu 1 1 15 WAITING DONE DONE RUN:cpu 1 1 16* DONE DONE DONE RUN:cpu 1 17 DONE DONE DONE RUN:cpu 1 18 DONE DONE DONE RUN:cpu 1Stats: Total Time 18Stats: CPU Busy 18 (100.00%)Stats: IO Busy 12 (66.67%) 8 用下列随机生成的参数组合运行程序，比如-s 1 -l 3:50,3:50，-s 2 -l 3:50,3:50和-s 3 -l 3:50,3:50。你能否预测程序运行结果？将-I参数的值分别置为IO_RUN_IMMEDIATE和IO_RUN_LATER时，运行结果有何区别？将-S参数的值分别置为SWITCH_ON_IO和SWITCH_ON_END时，运行结果有何区别？ 8.1 使用参数-s 1 -l 3:50,3:50，输出如下： 123456789101112131415prompt&gt; python process-run.py -s 1 -l 3:50,3:50Produce a trace of what would happen when you run these processes:Process 0 cpu io ioProcess 1 cpu cpu cpuImportant behaviors: System will switch when the current process is FINISHED or ISSUES AN IO After IOs, the process issuing the IO will run LATER (when it is its turn) -I IO_RUN_LATER时： 123456789101112131415161718prompt&gt; python process-run.py -s 1 -l 3:50,3:50 -I IO_RUN_LATER -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:io READY 1 3 WAITING RUN:cpu 1 1 4 WAITING RUN:cpu 1 1 5 WAITING RUN:cpu 1 1 6 WAITING DONE 1 7* RUN:io DONE 1 8 WAITING DONE 1 9 WAITING DONE 1 10 WAITING DONE 1 11 WAITING DONE 1 12* DONE DONEStats: Total Time 12Stats: CPU Busy 6 (50.00%)Stats: IO Busy 8 (66.67%) -I IO_RUN_IMMEDIATE时结果相同，因为Process0发出的I/O请求在Process1完全执行结束之后才完成： -S SWITCH_ON_IO时结果也相同，因为这个是默认值。 -S SWITCH_ON_END时运行时间变长，如下： 1234567891011121314151617181920prompt&gt; python process-run.py -s 1 -l 3:50,3:50 -S SWITCH_ON_END -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:io READY 1 3 WAITING READY 1 4 WAITING READY 1 5 WAITING READY 1 6 WAITING READY 1 7* RUN:io READY 1 8 WAITING READY 1 9 WAITING READY 1 10 WAITING READY 1 11 WAITING READY 1 12* DONE RUN:cpu 1 13 DONE RUN:cpu 1 14 DONE RUN:cpu 1Stats: Total Time 14Stats: CPU Busy 6 (42.86%)Stats: IO Busy 8 (57.14%) 8.2 使用参数-s 2 -l 3:50,3:50，输出如下： 123456789101112131415prompt&gt; python process-run.py -s 2 -l 3:50,3:50Produce a trace of what would happen when you run these processes:Process 0 io io cpuProcess 1 cpu io ioImportant behaviors: System will switch when the current process is FINISHED or ISSUES AN IO After IOs, the process issuing the IO will run LATER (when it is its turn) -I IO_RUN_LATER时，输出如下，出现了两个进程同时I/O的情况（不过此时我们认为I/O是可以并行的，不存在等待I/O设备的问题）： 12345678910111213141516171819prompt&gt; python process-run.py -s 2 -l 3:50,3:50 -I IO_RUN_LATER -p -cTime PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING RUN:cpu 1 1 3 WAITING RUN:io 1 1 4 WAITING WAITING 2 5 WAITING WAITING 2 6* RUN:io WAITING 1 1 7 WAITING WAITING 2 8* WAITING RUN:io 1 1 9 WAITING WAITING 2 10 WAITING WAITING 2 11* RUN:cpu WAITING 1 1 12 DONE WAITING 1 13* DONE DONEStats: Total Time 13Stats: CPU Busy 6 (46.15%)Stats: IO Busy 11 (84.62%) -I IO_RUN_IMMEDIATE时，输出完全相同（因为I/O请求很多，所以当前I/O结束之后，CPU处于空闲状态，可以直接开始执行下一条指令）。 -S SWITCH_ON_IO时输出完全相同（因为这是默认值……）。 -S SWITCH_ON_END时运行时间大大增加了： 1234567891011121314151617181920212223242526272829prompt&gt; python process-run.py -s 2 -l 3:50,3:50 -S SWITCH_ON_END -p -cTime PID: 0 PID: 1 CPU IOs 1 RUN:io READY 1 2 WAITING READY 1 3 WAITING READY 1 4 WAITING READY 1 5 WAITING READY 1 6* RUN:io READY 1 7 WAITING READY 1 8 WAITING READY 1 9 WAITING READY 1 10 WAITING READY 1 11* RUN:cpu READY 1 12 DONE RUN:cpu 1 13 DONE RUN:io 1 14 DONE WAITING 1 15 DONE WAITING 1 16 DONE WAITING 1 17 DONE WAITING 1 18* DONE RUN:io 1 19 DONE WAITING 1 20 DONE WAITING 1 21 DONE WAITING 1 22 DONE WAITING 1 23* DONE DONEStats: Total Time 23Stats: CPU Busy 6 (26.09%)Stats: IO Busy 16 (69.57%) 8.3 使用参数-s 3 -l 3:50,3:50，输出如下： 123456789101112131415prompt&gt; python process-run.py -s 3 -l 3:50,3:50Produce a trace of what would happen when you run these processes:Process 0 cpu io cpuProcess 1 io io cpuImportant behaviors: System will switch when the current process is FINISHED or ISSUES AN IO After IOs, the process issuing the IO will run LATER (when it is its turn) -I IO_RUN_LATER时： 12345678910111213141516171819prompt&gt; python process-run.py -s 3 -l 3:50,3:50 -I IO_RUN_LATER -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:io READY 1 3 WAITING RUN:io 1 1 4 WAITING WAITING 2 5 WAITING WAITING 2 6 WAITING WAITING 2 7* RUN:cpu WAITING 1 1 8* DONE RUN:io 1 9 DONE WAITING 1 10 DONE WAITING 1 11 DONE WAITING 1 12 DONE WAITING 1 13* DONE RUN:cpu 1Stats: Total Time 13Stats: CPU Busy 6 (46.15%)Stats: IO Busy 9 (69.23%) -I IO_RUN_IMMEDIATE时输出不变，因为I/O请求结束的时间又一次恰好和CPU被占用的时间错开了。 -S SWITCH_ON_IO时输出不变（因为这仍然是默认值）。 -S SWITCH_ON_END时运行时间仍然会增加。 123456789101112131415161718192021222324python process-run.py -s 3 -l 3:50,3:50 -S SWITCH_ON_END -c -pTime PID: 0 PID: 1 CPU IOs 1 RUN:cpu READY 1 2 RUN:io READY 1 3 WAITING READY 1 4 WAITING READY 1 5 WAITING READY 1 6 WAITING READY 1 7* RUN:cpu READY 1 8 DONE RUN:io 1 9 DONE WAITING 1 10 DONE WAITING 1 11 DONE WAITING 1 12 DONE WAITING 1 13* DONE RUN:io 1 14 DONE WAITING 1 15 DONE WAITING 1 16 DONE WAITING 1 17 DONE WAITING 1 18* DONE RUN:cpu 1Stats: Total Time 18Stats: CPU Busy 6 (33.33%)Stats: IO Busy 12 (66.67%)","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"Leetcode 385. Mini Parser（字符串）","slug":"2018-08-04-Leetcode-385-Mini-Parser（字符串）","date":"2018-08-04T17:09:42.000Z","updated":"2018-08-04T17:47:00.000Z","comments":true,"path":"post/leetcode-385-mini-parser/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-385-mini-parser/","excerpt":"","text":"题目来源：https://leetcode.com/problems/mini-parser/description/ 标记难度：Medium 提交次数：1/1 代码效率：99.61% 题意 把一个整数嵌套列表的字符串解析成一个整数嵌套列表对象。 分析 这道题显然没什么算法难度，重点是写法，以及一些需要注意的细节。 要求是利用题目中给出的NestedInteger类型，而不是自己实现一个这种类型（我刚打开题目的时候被吓到了，以为要我自己用C++实现一个这种东西，那我肯定火速转Python啊。） 既然是多层嵌套列表，那么用递归逐层进行处理是很自然的想法。换成栈节省开销也不错。 如何在一层列表中判断每一项的界限？我最开始想直接用,作为分隔符split之，但很快发现这个想法大错特错，因为每一项自己内部也有嵌套的,。所以要加上判断[和]的个数的条件。 直接用stoi把string转成int，也不用自己考虑-的问题了，标准库真好用…… 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * // This is the interface that allows for creating nested lists. * // You should not implement it, or speculate about its implementation * class NestedInteger &#123; * public: * // Constructor initializes an empty nested list. * NestedInteger(); * * // Constructor initializes a single integer. * NestedInteger(int value); * * // Return true if this NestedInteger holds a single integer, rather than a nested list. * bool isInteger() const; * * // Return the single integer that this NestedInteger holds, if it holds a single integer * // The result is undefined if this NestedInteger holds a nested list * int getInteger() const; * * // Set this NestedInteger to hold a single integer. * void setInteger(int value); * * // Set this NestedInteger to hold a nested list and adds a nested integer to it. * void add(const NestedInteger &amp;ni); * * // Return the nested list that this NestedInteger holds, if it holds a nested list * // The result is undefined if this NestedInteger holds a single integer * const vector&lt;NestedInteger&gt; &amp;getList() const; * &#125;; */class Solution &#123;private: NestedInteger decomposeList(string s) &#123; // s是一个数字 // 好消息是，我感觉用了stoi之后，就不需要自己考虑-的问题了 if (s.length() &gt; 0 &amp;&amp; s[0] != &apos;[&apos;) return NestedInteger(stoi(s)); // s是一个列表 s = s.substr(1, s.length() - 2); NestedInteger nestedInteger; // 并不能简单地用,作为分隔，而是要找到一整个子列表 int start = 0, leftBrackets = 0; for (int i = 0; i &lt; s.length(); i++) &#123; if (s[i] == &apos;,&apos;) &#123; if (leftBrackets != 0) continue; nestedInteger.add(decomposeList(s.substr(start, i - start))); start = i + 1; &#125; if (s[i] == &apos;[&apos;) leftBrackets++; if (s[i] == &apos;]&apos;) leftBrackets--; &#125; if (start &lt; s.length()) nestedInteger.add(decomposeList(s.substr(start, s.length() - start))); return nestedInteger; &#125;public: NestedInteger deserialize(string s) &#123; // 刚看到这个的时候我很懵逼 // 原来是让我们利用这个interface来做题啊…… return decomposeList(s); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Recursion","slug":"alg-Recursion","permalink":"https://zhanghuimeng.github.io/tags/alg-Recursion/"}]},{"title":"Leetcode 771. Jewels and Stones（集合）","slug":"2018-08-04-Leetcode-771-Jewels-and-Stones（集合）","date":"2018-08-04T16:44:33.000Z","updated":"2018-08-04T16:54:00.000Z","comments":true,"path":"post/leetcode-771-jewels-and-stones/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-771-jewels-and-stones/","excerpt":"","text":"题目来源：https://leetcode.com/problems/jewels-and-stones/description/ 标记难度：Easy 提交次数：1/1 代码效率：98.31% 题意 统计一个字符串中属于某一特定集合的字符的数量。 分析 超级大水题，直接用STL集合就行。 借此机会复习了一下C++ set的用法： 定义：set&lt;int&gt; s; 查看大小： 集合是否为空：if (s.empty()) {} 集合中元素的数量：int size = s.size(); 插入：s.insert(val); 删除：s.erase(iterator); 查找： 计数：int cnt = s.count(val); 查找：auto iterator = s.find(val); （C++20里才会有contains函数可用，真是令人窒息……） 代码 12345678910111213class Solution &#123;public: int numJewelsInStones(string J, string S) &#123; set&lt;char&gt; jewels; for (char c: J) jewels.insert(c); int ans = 0; for (char c: S) if (jewels.count(c) &gt; 0) ans++; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Hash Table","slug":"alg-Hash-Table","permalink":"https://zhanghuimeng.github.io/tags/alg-Hash-Table/"}]},{"title":"Leetcode 477. Total Hamming Distance（统计量的转换）","slug":"2018-08-03-Leetcode-477-Total-Hamming-Distance（统计量的转换）","date":"2018-08-03T23:43:19.000Z","updated":"2018-08-03T23:52:00.000Z","comments":true,"path":"post/leetcode-477-total-hamming-distance/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-477-total-hamming-distance/","excerpt":"","text":"题目来源：https://leetcode.com/problems/total-hamming-distance/description/ 标记难度：Easy 提交次数：1/1 代码效率：39.56% 题意 给定若干个数，计算其中所有数对的海明（Hamming）距离之和。 分析 如果直接计算的话，O(N^2)的代价是不可忍受的。然后就很自然地想到，我们把这个问题横向转化一下：既然海明距离计算的只是每个对应二进制位的差异，那么，我们可以直接对所有数的这一位进行统计，得到0和1的个数，然后计算这一位对整体距离的贡献：count(0) * count(1)。 我感觉这种思路的转换方法很常见，但是我一时想不起来其他的例子了，大概最近刷题太少了吧。 代码 123456789101112131415161718class Solution &#123;public: int totalHammingDistance(vector&lt;int&gt;&amp; nums) &#123; int zeroBits[31]; memset(zeroBits, 0, sizeof(zeroBits)); for (int num: nums) &#123; for (int i = 0; i &lt; 31; i++) &#123; if ((num &amp; (1 &lt;&lt; i)) == 0) zeroBits[i]++; &#125; &#125; int ans = 0, n = nums.size(); for (int i = 0; i &lt; 31; i++) ans += zeroBits[i] * (n - zeroBits[i]); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Bit Manipulation","slug":"alg-Bit-Manipulation","permalink":"https://zhanghuimeng.github.io/tags/alg-Bit-Manipulation/"}]},{"title":"Leetcode 806. Number of Lines To Write String（模拟）","slug":"2018-08-03-Leetcode-806-Number-of-Lines-To-Write-String","date":"2018-08-03T23:07:12.000Z","updated":"2018-08-03T23:09:00.000Z","comments":true,"path":"post/leetcode-806-number-of-lines-to-write-string/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-806-number-of-lines-to-write-string/","excerpt":"","text":"题目来源：https://leetcode.com/problems/number-of-lines-to-write-string/description/ 标记难度：Easy 提交次数：1/1 代码效率：100.00% 题意 有一个数组的元素，每个元素有一个宽度，需要把它们按顺序分成若干行，每一行的宽度最大为100，问至少需要多少行，最后一行的实际宽度是多少。 分析 超级大水题，直接模拟就行。 代码 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; numberOfLines(vector&lt;int&gt;&amp; widths, string S) &#123; int lines = 1, width = 0; for (char s: S) &#123; if (width + widths[s - &apos;a&apos;] &lt;= 100) &#123; width += widths[s - &apos;a&apos;]; &#125; else &#123; lines++; width = widths[s - &apos;a&apos;]; &#125; &#125; vector&lt;int&gt; ans; ans.push_back(lines); ans.push_back(width); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"}]},{"title":"Leetcode 57. Insert Interval（区间合并）","slug":"2018-08-03-Leetcode-57-Insert-Interval（区间合并）","date":"2018-08-03T22:22:32.000Z","updated":"2018-08-03T22:54:00.000Z","comments":true,"path":"post/leetcode-57-insert-interval/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-57-insert-interval/","excerpt":"","text":"题目来源：https://leetcode.com/problems/insert-interval/description/ 标记难度：Hard 提交次数：1/2 代码效率：98.07% 题意 在一系列已经排好序的且不重叠的区间中插入一个新的区间，要求进行适当的合并，并且插入到正确的位置。 分析 我开始时的错误思路是这样的：遍历所有的旧interval，在能够进行合并时就把旧interval合并到新interval中，否则直接插入到新vector中；最后把更新过的interval插入到新vector中。这种做法显然有一个问题：如果新interval不需要和旧interval合并，那这种算法就找不到正确的插入位置了。我猜我的注意力被merge if necessary吸引住了，完全忘了有时候不需要合并这回事。 即使纠正了这个问题，我的代码也不是很优雅，最后我遍历了两次数组，在第二次遍历的时候硬是把新interval插进去了，使用的是insert： 12345auto it = vec.begin(); // 获得vector起始位置的迭代器// 第一个参数是插入位置（如果为vec.begin()+i，则事实上的效果是插入到第i个元素前面）// 第二个参数是插入的具体元素// std::vector::insert的重载甚多，感觉不能胜记……it = vec.insert(it, 200); 比较好的做法是这样的（灵感来自Short and straight-forward Java solution）：遍历所有旧interval，首先将所有严格位于新interval左侧的旧interval保存下来（当然，可能没有这样的interval）；然后将与新interval重叠的旧interval进行适当的合并，合并结束的时候，将新interval保存下来；最后将所有严格位于合并后的新interval右侧的旧interval保存下来（当然，也可能没有这样的interval）。 如果用Python而不是Java或C++，这个问题会稍微更好思考一点，毕竟Python的数组操作更加灵活……（参见7+ lines, 3 easy solutions中精妙的写法） P.S. 我最近找到了遍历C++ vector的更方便的写法（Iterate through a C++ Vector using a ‘for’ loop）： 1234vector&lt;int&gt; vi;...for(int i : vi) cout &lt;&lt; &quot;i = &quot; &lt;&lt; i &lt;&lt; endl; 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Definition for an interval. * struct Interval &#123; * int start; * int end; * Interval() : start(0), end(0) &#123;&#125; * Interval(int s, int e) : start(s), end(e) &#123;&#125; * &#125;; */class Solution &#123; bool isOverlap(Interval i1, Interval i2) &#123; return !(i1.end &lt; i2.start || i2.end &lt; i1.start); &#125; Interval merge(Interval i1, Interval i2) &#123; return Interval(min(i1.start, i2.start), max(i1.end, i2.end)); &#125;public: vector&lt;Interval&gt; insert(vector&lt;Interval&gt;&amp; intervals, Interval newInterval) &#123; // 现在的想法是，维护这个newInterval，然后遍历所有的旧interval，发现重叠时就更新newInterval，直到完全不重叠为止 // 需要证明的是，即使因为overlap更新了当前的interval，这并不会影响到之前的interval // 没有考虑到如何找到正确插入位置的问题。 vector&lt;Interval&gt; ans; int finished = -1; for (Interval interval: intervals) &#123; if (!isOverlap(interval, newInterval)) &#123; if (finished == 0) &#123; ans.push_back(newInterval); finished = 1; &#125; ans.push_back(interval); &#125; else &#123; if (finished == -1) finished = 0; newInterval = merge(newInterval, interval); &#125; &#125; // 找到正确的插入位置 if (finished != 1) &#123; for (int i = 0; i &lt; ans.size(); i++) &#123; if (ans[i].start &gt; newInterval.end) &#123; ans.insert(ans.begin() + i, newInterval); finished = 1; break; &#125; &#125; if (finished != 1) ans.push_back(newInterval); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"}]},{"title":"Leetcode 462. Minimum Moves to Equal Array Elements II（L1范数性质）","slug":"2018-08-03-Leetcode-462-Minimum-Moves-to-Equal-Array-Elements-II（L1范数性质）","date":"2018-08-03T21:16:11.000Z","updated":"2018-08-03T21:45:00.000Z","comments":true,"path":"post/leetcode-462-minimum-moves-to-equal-array-elements-2/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-462-minimum-moves-to-equal-array-elements-2/","excerpt":"","text":"题目来源：https://leetcode.com/problems/minimum-moves-to-equal-array-elements-ii/description/ 标记难度：Medium 提交次数：1/2 代码效率：79.95% 题意 min⁡∑i=1N∣si−x∣\\min \\sum_{i=1}^{N} |s_i - x|min∑i=1N​∣si​−x∣ 分析 我最开始做这道题的时候走了很多弯路，比如想用平均值和二分法。但实际上正确的解法是求中位数。详细解释可以看The Median Minimizes the Sum of Absolute Deviations (The L1 Norm)。 从直观上来说，可以想象xxx的值在数轴上移动，如果它左边有mmm个数，右边有nnn个数，此时如果xxx向左移动ϵ\\epsilonϵ（没有越过其他的数值），它到左边的数的总距离就会减少mϵm \\epsilonmϵ，到右边的数的总距离就会增加nϵn \\epsilonnϵ，对总和的贡献就是(n−m)ϵ(n-m) \\epsilon(n−m)ϵ。可以看出，在n&lt;mn &lt; mn&lt;m的情况下，我们总是应该向左移动。向右同理；总之大概可以推断出，x是中位数时这个结果是最小的。 另一种推导方法是直接取导数。 代码 12345678910111213141516171819class Solution &#123;private: int calcMoves(vector&lt;int&gt;&amp; nums, int x) &#123; int sum = 0; for (int num: nums) sum += abs(num - x); return sum; &#125;public: int minMoves2(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 0) return 0; sort(nums.begin(), nums.end()); return calcMoves(nums, nums[nums.size() / 2]); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 382. Linked List Random Node（水塘抽样）","slug":"2018-08-02-Leetcode-382-Linked-List-Random-Node（水塘抽样）","date":"2018-08-02T01:13:08.000Z","updated":"2018-08-03T21:14:00.000Z","comments":true,"path":"post/leetcode-382-linked-list-random-node/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-382-linked-list-random-node/","excerpt":"","text":"题目来源：https://leetcode.com/problems/linked-list-random-node/description/ 标记难度：Medium 提交次数：3/3 代码效率： 平凡的解法：71.27% 平凡但更好的写法：99.11% 水塘抽样法：70.97% 题意 从一个链表中随机取元素。 分析 平凡的思路 一种非常直接的想法是把链表当成数组，先遍历一遍链表，得到链表的总长度，然后每次按下标取随机数，在链表中顺序查找对应的数。此时预处理的时间复杂度为O(N)，每次获取随机数的平摊时间复杂度为O(N)。当然，如果直接新开一个O(N)的数组（vector），把链表缓存下来，然后直接按下标寻址，则每次获取随机数的时间复杂度会下降到O(1)。 虽然我们平时常用的生成随机数的搭配是srand(time(0))和rand()，但它们其实不是很符合伪随机数的要求，一部分原因是rand()生成的随机数的大小最大为RAND_MAX。（参见RAND_MAX）既然我们写的是C++，那么更标准的方法是采用std::uniform_int_distribution。使用方法如下： 1234567891011121314#include &lt;random&gt;#include &lt;iostream&gt;int main()&#123; std::random_device rd; // 将用于为随机数引擎获得种子 std::mt19937 gen(rd()); // 以播种标准 mersenne_twister_engine std::uniform_int_distribution&lt;&gt; dis(1, 6); for (int n=0; n&lt;10; ++n) // 用 dis 变换 gen 所生成的随机 unsigned int 到 [1, 6] 中的 int std::cout &lt;&lt; dis(gen) &lt;&lt; &apos; &apos;; std::cout &lt;&lt; &apos;\\n&apos;;&#125; 我写了相应的代码，但实在是太麻烦了，平时还是用rand()方便啊！ 水塘抽样法 至于水塘抽样法——它的优点是不需要提前扫描一遍以获得整个链表的大小，缺点是每次都需要遍历整个链表并取多次随机数来进行抽样，虽然时间复杂度仍然是O(N)，但隐含的常数变大了。我认为它适合的场景是一次取多个随机数，而不是这种情况。 我总是记不住水塘抽样法的原理，不如在这里把维基上的最简单的例子复述一遍：假定你想要从网易云音乐的全体曲库（显然原文不是网易云音乐，我就随便举个我熟悉例子）里随机取出10首乐曲，保存在“我喜欢的音乐”歌单中，但是你并不知道网易云音乐的曲库有多大。此时，你可以采用这种方法： 顺序浏览所有乐曲。 将前10首乐曲保存到歌单中。 浏览到第iii（i&gt;10i &gt; 10i&gt;10）首乐曲的时候，以10i\\frac{10}{i}i10​的概率保存这首新的乐曲（同时删除一首已保存的旧的曲子；其中每首旧乐曲被删除的概率都是110\\frac{1}{10}101​），也即以1−10i1 - \\frac{10}{i}1−i10​的概率删除这首乐曲。 不断重复上一过程，直到遍历完所有乐曲。 如果网易云音乐里一共只有10首乐曲，那么显然每首乐曲被保存下来的概率都是1。如果有11首乐曲，则在浏览到第11首乐曲的时候，我们保存这首乐曲的概率为1011\\frac{10}{11}1110​；对于之前的旧乐曲，其中某一首被保存下来的概率为 P(新乐曲没有被选择保存)+P(新乐曲被选择保存)⋅P(这一首没有被选择替换掉)=111+1011⋅910=1011P(\\text{新乐曲没有被选择保存}) + P(\\text{新乐曲被选择保存}) \\cdot P(\\text{这一首没有被选择替换掉}) \\\\\\\\ = \\frac{1}{11} + \\frac{10}{11} \\cdot \\frac{9}{10} = \\frac{10}{11}P(新乐曲没有被选择保存)+P(新乐曲被选择保存)⋅P(这一首没有被选择替换掉)=111​+1110​⋅109​=1110​ 也就是说，到目前为止，对于这11首乐曲，每一首仍然处于歌单中的概率都是1011\\frac{10}{11}1110​，这是符合我们的要求的。 在浏览到第12首乐曲的时候，我们保存这首乐曲的概率为1012\\frac{10}{12}1210​；而对于之前的那11首乐曲，它们仍然处于歌单中的概率为 P(在只看到过11首曲子的的时候，它们还在歌单里)⋅(P(第12首乐曲被直接丢弃了)+P(第12首乐曲被选择保留)⋅P(这一首没有被选择替换掉))=1011(212+1012⋅910)P(\\text{在只看到过11首曲子的的时候，它们还在歌单里}) \\cdot (P(\\text{第12首乐曲被直接丢弃了}) \\\\\\\\ + P(\\text{第12首乐曲被选择保留}) \\cdot P(\\text{这一首没有被选择替换掉})) \\\\\\\\ = \\frac{10}{11} (\\frac{2}{12} + \\frac{10}{12} \\cdot \\frac{9}{10})P(在只看到过11首曲子的的时候，它们还在歌单里)⋅(P(第12首乐曲被直接丢弃了)+P(第12首乐曲被选择保留)⋅P(这一首没有被选择替换掉))=1110​(122​+1210​⋅109​) 也就是说，现在每一首乐曲仍然处于歌单中的概率都是1012\\frac{10}{12}1210​，这是符合常理的。 严谨的证明需要用到数学归纳法，不过形式和上述思考过程非常类似，所以我就懒得再抄一遍了。 我觉得这是一种非常精妙的incremental的算法。 代码 平凡的解法 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123; int length; ListNode* head;public: /** @param head The linked list&apos;s head. Note that the head is guaranteed to be not null, so it contains at least one node. */ Solution(ListNode* head) &#123; length = 0; ListNode* p = head; this-&gt;head = head; while (p != NULL) &#123; length++; p = p-&gt;next; &#125; srand(time(0)); &#125; /** Returns a random node&apos;s value. */ int getRandom() &#123; int x = rand() % length; int i = 0; ListNode* p = head; while (i &lt; x) &#123; p = p-&gt;next; i++; &#125; return p-&gt;val; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(head); * int param_1 = obj.getRandom(); */ 平凡但更好的写法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123; int length; ListNode* head; random_device rd; // 将用于为随机数引擎获得种子 mt19937* gen; // 以播种标准 mersenne_twister_engine uniform_int_distribution&lt;&gt;* dis;public: /** @param head The linked list&apos;s head. Note that the head is guaranteed to be not null, so it contains at least one node. */ Solution(ListNode* head) &#123; length = 0; ListNode* p = head; this-&gt;head = head; while (p != NULL) &#123; length++; p = p-&gt;next; &#125; gen = new mt19937(rd()); dis = new uniform_int_distribution&lt;&gt;(0, length-1); &#125; /** Returns a random node&apos;s value. */ int getRandom() &#123; int x = (*dis)(*gen); int i = 0; ListNode* p = head; while (i &lt; x) &#123; p = p-&gt;next; i++; &#125; return p-&gt;val; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(head); * int param_1 = obj.getRandom(); */ 水塘抽样法 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123; ListNode* head;public: /** @param head The linked list&apos;s head. Note that the head is guaranteed to be not null, so it contains at least one node. */ Solution(ListNode* head) &#123; this-&gt;head = head; &#125; /** Returns a random node&apos;s value. */ int getRandom() &#123; // 进行水塘抽样 int ans = head-&gt;val; int i = 2; ListNode* p = head-&gt;next; while (p != NULL) &#123; int x = rand() % i; if (x == 0) ans = p-&gt;val; i++; p = p-&gt;next; &#125; return ans; &#125;&#125;;/** * Your Solution object will be instantiated and called as such: * Solution obj = new Solution(head); * int param_1 = obj.getRandom(); */","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"},{"name":"alg:Random","slug":"alg-Random","permalink":"https://zhanghuimeng.github.io/tags/alg-Random/"},{"name":"alg:Reservoir Sampling","slug":"alg-Reservoir-Sampling","permalink":"https://zhanghuimeng.github.io/tags/alg-Reservoir-Sampling/"}]},{"title":"Leetcode 844. Backspace String Compare（栈）","slug":"2018-08-02-Leetcode-844-Backspace-String-Compare（栈）","date":"2018-08-02T00:49:44.000Z","updated":"2018-08-02T01:01:00.000Z","comments":true,"path":"post/leetcode-844-backspace-string-compare/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-844-backspace-string-compare/","excerpt":"","text":"题目来源：https://leetcode.com/problems/backspace-string-compare/description/ 标记难度：Easy 提交次数：2/3 代码效率： 栈版本：12.03% 指针版本：100.00% 题意 给定两个由小写字母组成的字符串，其中包含一些向前删除字符（#）；问完成删除之后两个字符串是否相等。 进阶： 能否在O(N)时间复杂度和O(1)空间复杂度内解决？（虽然我觉得应该是“额外”空间，毕竟输入大小已经是O(N)了） 分析 不考虑空间的话，直接用两个栈模拟一下删除的过程。 考虑额外空间的话，直接把字符串自己当成栈，用两个指针分别指向栈顶就可以了。 代码 O(N)额外空间复杂度（栈） 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: bool backspaceCompare(string S, string T) &#123; stack&lt;char&gt; sstack, tstack; for (char c: S) &#123; if (c == &apos;#&apos;) &#123; if (!sstack.empty()) // 不小心把#也插入栈中了 sstack.pop(); &#125; else sstack.push(c); &#125; string ms; while (!sstack.empty()) &#123; ms = sstack.top() + ms; sstack.pop(); &#125; for (char c: T) &#123; if (c == &apos;#&apos;) &#123; if (!tstack.empty()) tstack.pop(); &#125; else tstack.push(c); &#125; string mt; while (!tstack.empty()) &#123; mt = tstack.top() + mt; tstack.pop(); &#125; cout &lt;&lt; ms &lt;&lt; &apos; &apos; &lt;&lt; mt &lt;&lt; endl; return ms == mt; &#125;&#125;; O(1)额外空间复杂度（指针） 12345678910111213141516171819202122232425262728class Solution &#123;public: bool backspaceCompare(string S, string T) &#123; int topS = 0, topT = 0; for (int i = 0; i &lt; S.length(); i++) &#123; char c = S[i]; if (c == &apos;#&apos;) &#123; if (topS &gt; 0) topS--; &#125; else S[topS++] = c; &#125; for (int i = 0; i &lt; T.length(); i++) &#123; char c = T[i]; if (c == &apos;#&apos;) &#123; if (topT &gt; 0) topT--; &#125; else T[topT++] = c; &#125; if (topS != topT) return false; return S.substr(0, topS) == T.substr(0, topT); &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Stack","slug":"alg-Stack","permalink":"https://zhanghuimeng.github.io/tags/alg-Stack/"},{"name":"alg:Two Pointers","slug":"alg-Two-Pointers","permalink":"https://zhanghuimeng.github.io/tags/alg-Two-Pointers/"}]},{"title":"Leetcode 475. Heaters（贪心）","slug":"2018-08-01-Leetcode-475-Heaters（贪心）","date":"2018-08-01T12:26:27.000Z","updated":"2018-08-01T18:43:00.000Z","comments":true,"path":"post/leetcode-475-heaters/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-475-heaters/","excerpt":"","text":"题目来源：https://leetcode.com/problems/heaters/description/ 标记难度：Easy 提交次数：1/1 代码效率：18.81% 题意 x轴上有若干个暖气和若干个房子，每个暖气能够覆盖到半径为x的圆内的房子，问至少取x为多少，才能覆盖所有房子。（所有暖气的半径是一样的） 分析 如果需要排序，则时间复杂度下限应该是O(nlog⁡n)O(n \\log{n})O(nlogn)。排序之后，很显然可以立刻利用二分查找（lower_bound或upper_bound）来寻找距离每所房子最近的暖气，并确定所需的最小半径。如果房子和暖气开始时都是排好序的，则很显然有O(n)O(n)O(n)的解法，因为此时随着房子坐标的递增，它在暖气中的lower_bound必然也是单调递增的，因此扫描一遍所有暖气就够了，具体解法可参见C++ O(N) speed O(1) space。 以及我每次都记不住upper_bound的用法。 调用方法：upper_bound(vector.begin(), vector.end(), val) 返回值：iterator（虽然这么说不算很准确） 返回值使用方法： *iterator：lower_bound的数值 iterator - vector.begin()：lower_bound对应的数在数组中的下标 iterator != vector.end()：是否找到了lower_bound 代码 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int findRadius(vector&lt;int&gt;&amp; houses, vector&lt;int&gt;&amp; heaters) &#123; // 既然标签是Easy，那我觉得大概是个贪心问题，至多是动态规划问题 // （当然这个思考方式是不好的） // 又看错题了，原来所有的暖气的半径要求是一样的。 // 我感觉有O(n)的解法，但是显然直接O(n * log(n))比较方便。 if (houses.size() &lt;= 0 || heaters.size() &lt;= 0) return 0; int n = houses.size(), m = heaters.size(); sort(houses.begin(), houses.end()); sort(heaters.begin(), heaters.end()); // 我决定为每一个房子找到离它最近的暖气。 int ans = 0; for (int i = 0; i &lt; n; i++) &#123; auto ub = upper_bound(heaters.begin(), heaters.end(), houses[i]); int dist; // 此house的坐标&gt;=所有heater的坐标 if (ub == heaters.end()) dist = houses[i] - heaters[m-1]; else &#123; int j = ub - heaters.begin(); dist = heaters[j] - houses[i]; if (j &gt; 0) dist = min(dist, houses[i] - heaters[j-1]); &#125; ans = max(ans, dist); &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Binary Search","slug":"alg-Binary-Search","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search/"},{"name":"alg:Greedy","slug":"alg-Greedy","permalink":"https://zhanghuimeng.github.io/tags/alg-Greedy/"}]},{"title":"Leetcode 357. Count Numbers with Unique Digits（组合数学）","slug":"2018-07-31-Leetcode-357-Count-Numbers-with-Unique-Digits（组合数学）","date":"2018-07-31T23:23:46.000Z","updated":"2018-07-31T23:28:00.000Z","comments":true,"path":"post/leetcode-357-count-numbers-with-unique-digits/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-357-count-numbers-with-unique-digits/","excerpt":"","text":"题目来源：https://leetcode.com/problems/count-numbers-with-unique-digits/description/ 标记难度：Easy 提交次数：2/5 代码效率：100.00% 题意 给定非负整数nnn，计算[0,10n][0, 10^n][0,10n]中没有重复数字的数的个数。 分析 这道题的数据量非常小（显然，n&gt;10时的个数与n=10时是相同的），因此，可以直接打表计算。 代码 结果错了好多次…… 两个边界情况： n=0时应该返回1 n&gt;10时应该返回8877691。虽然我开始时返回0也过了…… 123456789101112131415161718192021222324252627282930class Solution &#123;public: int countNumbersWithUniqueDigits(int n) &#123; // 显然，n&lt;=10 // 所以干脆直接打表算了。 // 下面的n指的是，这个数长度为n（因此0不能在第一位） // n = 1: 10 // n = 2: 9 * 9 = 81 // n = 3: 9 * 9 * 8 = 648 // n = 4: 9 * 9 * 8 * 7 = 4536 // n = 5: 9 * 9 * 8 * 7 * 6 = 27216 // n = 6: 9 * 9 * 8 * 7 * 6 * 5 = 136080 // n = 7: 9 * 9 * 8 * 7 * 6 * 5 * 4 = 544320 // n = 8: 9 * 9 * 8 * 7 * 6 * 5 * 4 * 3 = 1632960 // n = 9: 9 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 = 3265920 // n = 10: 9 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 * 1 = 3265920 if (n == 0) return 1; if (n == 1) return 10; if (n == 2) return 91; if (n == 3) return 739; if (n == 4) return 5275; if (n == 5) return 32491; if (n == 6) return 168571; if (n == 7) return 712891; if (n == 8) return 2345851; if (n == 9) return 3265920; if (n &gt;= 10) return 8877691; return 0; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Math","slug":"alg-Math","permalink":"https://zhanghuimeng.github.io/tags/alg-Math/"}]},{"title":"Leetcode 696. Count Binary Substrings（观察）","slug":"2018-07-31-Leetcode-696-Count-Binary-Substrings（观察）","date":"2018-07-31T22:08:02.000Z","updated":"2018-07-31T22:39:00.000Z","comments":true,"path":"post/leetcode-696-count-binary-substrings/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-696-count-binary-substrings/","excerpt":"","text":"题目来源：https://leetcode.com/problems/count-binary-substrings/description/ 标记难度：Easy 提交次数：1/1 代码效率：5.22% 题意 给定一个01串，问其中形如0011或1100（所有0连在一起，所有1也连在一起，数目相等）的子串共有多少个，不去重。 分析 这就是一个大水题，把所有连续的0或1子串的长度统计出来，就可以直接做了。 P.S. 我刚才本来想用正则表达式来表达0n1n0^n 1^n0n1n或1n0n1^n 0^n1n0n这个意思的，结果突然想起来，正则表达式的表示能力相当于有限状态自动机，而有限状态自动机表示不了0n1n0^n 1^n0n1n……（如果我没记错的话） 代码 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int countBinarySubstrings(string s) &#123; // 需要找出01数量相同，且所有0和所有1都连在一起（也就是形如0011或1100的串） // 只需把字符串分成连续的0或1，然后统计即可 // 这个写法效率低，但是很直观 vector&lt;int&gt; sub; char cur; int len = 0; for (int i = 0; i &lt; s.length(); i++) &#123; if (len == 0) &#123; cur = s[i]; len++; &#125; else if (cur == s[i]) len++; else &#123; sub.push_back(len); cur = s[i]; len = 1; &#125; &#125; if (len != 0) sub.push_back(len); if (sub.size() &lt; 1) return 0; int ans = 0; for (int i = 0; i &lt; sub.size() - 1; i++) ans += min(sub[i], sub[i+1]); return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"}]},{"title":"Leetcode 289. Game of Life（模拟）","slug":"2018-07-31-Leetcode-289-Game-of-Life","date":"2018-07-31T20:34:30.000Z","updated":"2018-07-31T21:52:00.000Z","comments":true,"path":"post/leetcode-289-game-of-life/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-289-game-of-life/","excerpt":"","text":"题目来源：https://leetcode.com/problems/game-of-life/description/ 标记难度：Medium 提交次数：1/1 代码效率：100% 题意 给定生命游戏（元胞自动机）的现有状态，根据规则计算下一个状态。 进阶： 能否就地解决这个问题？ 如果棋盘无穷大，如何解决该问题？ 分析 如果不要求就地解决，这就是一个模拟大水题。但是， What is in-place? 我本来以为就地解决会用到什么高级的思路，因此我没有想出来。结果别人给出的“就地解法”竟然只是把前后两个状态通过位运算的方法硬塞进一个int里而已……虽然我脑子在这种方面是不太灵光啦，但我认为这只是一种hack的方法，它利用的是编程语言的性质，而非真正的数学思路；从抽象的角度来说，每个格子只有位置信息和1 bit的状态信息，仅此而已。 但是我很快就不得不收回自己说的话。我刚才看了另一份题解，其实也可以从另一个角度来解释这种做法：其实我们在这个元胞自动机的每一个格子里又塞了一个有限状态自动机，像下图这样的。 我原来的想法可能有一定的道理，但显然是狭隘的。 数据的实际状况，以及状态压缩 读了Chapter 17 – The Game of Life和Chapter 18 – It’s a plain Wonderful Life之后，我意识到了一些甚至更有趣的事情。这本书中给出了对模拟生命游戏进行进一步的速度优化的两种主要思路（我决定不把对指针的巧妙操作列为主要思路之一）： 关注数据的实际状态。通过生命游戏的规则，我们很容易看出，活细胞的数量不会太多，而且细胞状态的变化并不频繁。因此，我们可以维护一张实际变化了的细胞位置的表，并在更新时主要处理这张表指向的细胞。 状态压缩。除了像上面说的那样，把当前和未来状态打包起来以外，我们还可以把相邻活细胞的数量也记为状态的一部分，甚至还可以把多个细胞的状态一起压缩。除了减少空间占用之外，查表的复杂度也减小了。 书中David Stafford的解法把这几种思路有机地结合在了一起，创造了一份非常精妙的代码，以至于我很难分别描述每种思路各自的好处。总之他的思路非常棒。 无穷多个细胞？ 即使细胞有无穷多个，活细胞的数目也应该是有限的，所以我们只需分别更新每个活细胞及其周围细胞的状态即可。参见Infinite board solution。 代码 这时候我的代码反而显得微不足道了呢…… 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; int n = board.size(); if (n &lt; 1) return; int m = board[0].size(); // 直接将原状态保存下来 vector&lt;vector&lt;int&gt;&gt; original; for (int i = 0; i &lt; n; i++) &#123; vector&lt;int&gt; tmp; for (int j = 0; j &lt; m; j++) tmp.push_back(board[i][j]); original.push_back(tmp); &#125; // 更新board for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; int cnt = 0; if (i &gt; 0) cnt += original[i-1][j]; if (i &lt; n-1) cnt += original[i+1][j]; if (j &gt; 0) cnt += original[i][j-1]; if (j &lt; m-1) cnt += original[i][j+1]; if (i &gt; 0 &amp;&amp; j &gt; 0) cnt += original[i-1][j-1]; if (i &gt; 0 &amp;&amp; j &lt; m-1) cnt += original[i-1][j+1]; if (i &lt; n-1 &amp;&amp; j &gt; 0) cnt += original[i+1][j-1]; if (i &lt; n-1 &amp;&amp; j &lt; m-1) cnt += original[i+1][j+1]; if (original[i][j] == 1) &#123; if (cnt &lt; 2 || cnt &gt; 3) board[i][j] = 0; else board[i][j] = 1; &#125; else if (cnt == 3) board[i][j] = 1; &#125; &#125; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Array","slug":"alg-Array","permalink":"https://zhanghuimeng.github.io/tags/alg-Array/"},{"name":"alg:Automata","slug":"alg-Automata","permalink":"https://zhanghuimeng.github.io/tags/alg-Automata/"}]},{"title":"Leetcode 93. Restore IP Address（搜索）","slug":"2018-07-31-Leetcode-93-Restore-IP-Address（搜索）","date":"2018-07-31T20:24:12.000Z","updated":"2018-07-31T20:30:00.000Z","comments":true,"path":"post/leetcode-93-restore-ip-address/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-93-restore-ip-address/","excerpt":"","text":"题目来源：https://leetcode.com/problems/restore-ip-addresses/description/ 标记难度：Medium 提交次数：1/3 代码效率：9.95% 题意 把一个数字串用小数点分隔成4段，问共能形成多少个合法的IP地址。 分析 这就是一个简单的搜索题，但是需要注意两个边界条件： 每一段的数字必须在0-255之间 数字不能有前导0 以及，做题过程中大概会用到两个函数： stoi：string转int substr(pos, len)：取string的子串，注意参数的含义 代码 我这个代码实在写得太繁琐了。与其用4层循环，还不如稍微简化一下…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;public: vector&lt;string&gt; restoreIpAddresses(string s) &#123; // 看起来像是简单的搜索问题。一个IP地址的一段只能是0-255，因此长度最多为3 // 中间可以进行剪枝 // 不知道有没有什么奇怪的边界情况 // 果然是有的，比如不应该有前导0 // 以及是否需要去重？ // 事实说明不需要。 vector&lt;string&gt; ans; int len[4], byte[4]; // 因为模板的原因，必须cast成int？ for (len[0] = 1; len[0] &lt;= min(3, (int) s.length()); len[0]++) &#123; byte[0] = stoi(s.substr(0, len[0])); if (byte[0] &gt; 255) continue; // 考虑前导0问题 if (len[0] &gt; 1 &amp;&amp; s[0] == &apos;0&apos;) continue; for (len[1] = 1; len[1] &lt;= min(3, (int) s.length() - len[0]); len[1]++) &#123; byte[1] = stoi(s.substr(len[0], len[1])); if (byte[1] &gt; 255) continue; if (len[1] &gt; 1 &amp;&amp; s[len[0]] == &apos;0&apos;) continue; for (len[2] = 1; len[2] &lt;= min(3, (int) s.length() - len[0] - len[1]); len[2]++) &#123; byte[2] = stoi(s.substr(len[0] + len[1], len[2])); if (byte[2] &gt; 255) continue; if (len[2] &gt; 1 &amp;&amp; s[len[0]+len[1]] == &apos;0&apos;) continue; len[3] = s.length() - len[0] - len[1] - len[2]; // 除了要考虑位数不够的情况，也要考虑位数太多的情况，这也是不合法的 if (len[3] &lt;= 0 || len[3] &gt; 3) continue; byte[3] = stoi(s.substr(len[0] + len[1] + len[2], len[3])); if (byte[3] &gt; 255) continue; if (len[3] &gt; 1 &amp;&amp; s[len[0]+len[1]+len[2]] == &apos;0&apos;) continue; string ip = s.substr(0, len[0]) + &quot;.&quot; + s.substr(len[0], len[1]) + &quot;.&quot; + s.substr(len[0] + len[1], len[2]) + &quot;.&quot; + s.substr(len[0] + len[1] + len[2], len[3]); ans.push_back(ip); // cout &lt;&lt; ip &lt;&lt; endl; &#125; &#125; &#125; return ans; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:String","slug":"alg-String","permalink":"https://zhanghuimeng.github.io/tags/alg-String/"},{"name":"alg:Backtracking","slug":"alg-Backtracking","permalink":"https://zhanghuimeng.github.io/tags/alg-Backtracking/"}]},{"title":"Leetcode 173. Binary Search Tree Iterator（中序遍历）","slug":"2018-07-30-Leetcode-173-Binary-Search-Tree-Iterator（中序遍历）","date":"2018-07-31T00:19:34.000Z","updated":"2018-07-31T00:53:00.000Z","comments":true,"path":"post/leetcode-173-binary-search-tree-iterator/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-173-binary-search-tree-iterator/","excerpt":"","text":"题目来源：https://leetcode.com/problems/binary-search-tree-iterator/description/ 标记难度：Medium 提交次数：1/1 代码效率：98.53% 题意 写一个二叉搜索树的迭代器，包括初始化、next()和hasNext()操作，要求平摊时间复杂度为O(1)，空间复杂度为O(h)。 分析 因为空间复杂度是O(h)，所以肯定不能把整个树直接存成一个数组然后直接查找，而是要利用树的性质。好吧，其实《数据结构》里在迭代版中序遍历中讲了这个东西。 与所有遍历一样，中序遍历的实质功能也可理解为，为所有节点赋予一个次序，从而将半线性的二叉树转化为线性结构。于是一旦指定了遍历策略，即可与向量和列表一样，在二叉树的节点之间定义前驱与后继关系。其中没有前驱（后继）的节点称作首（末）节点。 对于后面将要介绍的二叉搜索树，中序遍历的作用至关重要。相关算法必需的一项基本操作，就是定位任一节点在中序遍历序列中的直接后继。为此，可实现succ()接口如代码5.16所示。 123456789101112// 代码5.16 二叉树节点直接后继的定位template &lt;typename T&gt; BinNodePosi(T) BinNode&lt;T&gt;::succ() &#123; //定位节点v的直接后继 BinNodePosi(T) s = this; //记录后继的临时变量 if (rChild) &#123; //若有右孩子，则直接后继必在右子树中，具体地就是 s = rChild; //右子树中 while (HasLChild(*s)) s = s-&gt;lChild; //最靠左（最小）的节点 &#125; else &#123; //否则，直接后继应是“将当前节点包含于其左子树中的最低祖先”，具体地就是 while (IsRChild(*s)) s = s-&gt;parent; //逆向地沿右向分支，不断朝左上方移动 s = s-&gt;parent; //最后再朝右上方移动一步，即抵达直接后继（如果存在） &#125; return s;&#125; 这里，共分两大类情况。若当前节点有右孩子，则其直接后继必然存在，且属于其右子树。此时只需转入右子树，再沿该子树的最左侧通路朝左下方深入，直到抵达子树中最靠左（最小）的节点。 反之，若当前节点没有右子树，则若其直接后继存在， 必为该节点的某一祖先，且是将当前节点纳入其左子树的最低祖先。于是首先沿右侧通路朝左上方上升，当不能继续前进时，再朝右上方移动一步即可。 作为后一情况的特例，出口时s可能为NULL。这意味着此前沿着右侧通路向上的回溯，抵达了树根。也就是说，当前节点是全树右侧通路的终点——它也是中序遍历的终点，没有后继。 （摘自《数据结构(C++语言版)》（第三版），清华大学出版社，2013.9） 我的代码实现得不怎么漂亮，不过里面被注释掉的关键的一句代码path.push(_cur);变相实现了“右侧通路朝左上方上升，当不能继续前进时，再朝右上方移动一步”这个操作：栈中实际上存储的就是经过这个操作之后能够得到的结点，因此右转时的结点是不能入栈的。 代码 我的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class BSTIterator &#123;private: TreeNode* _root; TreeNode* _cur; stack&lt;TreeNode*&gt; path;public: BSTIterator(TreeNode *root) &#123; _root = root; _cur = root; // 找到树中最小的结点 while (_cur != NULL &amp;&amp; _cur-&gt;left != NULL) &#123; path.push(_cur); _cur = _cur-&gt;left; &#125; // cout &lt;&lt; _cur-&gt;val &lt;&lt; endl; &#125; /** @return whether we have a next smallest number */ bool hasNext() &#123; // 和next()的判断逻辑相同： // 当前结点有右子树，或者仍然有向上回溯的空间 return _cur != NULL; &#125; /** @return the next smallest number */ int next() &#123; int smallest = _cur-&gt;val; // cout &lt;&lt; smallest &lt;&lt; &apos; &apos; &lt;&lt; path.size() &lt;&lt; endl; // 寻找_cur的后继 // _cur的右子树不为空，此时后继必为_cur的右子树中最靠左的结点 if (_cur-&gt;right != NULL) &#123; // 必须注释掉这句话，因为path（这个名字起得不好）指的并不是从root到当前结点的路径上的所有结点 // 而是“右子树仍未被访问到的结点” // path.push(_cur); _cur = _cur-&gt;right; while (_cur-&gt;left != NULL) &#123; path.push(_cur); _cur = _cur-&gt;left; &#125; &#125; // _cur的右子树为空，此时需要向上回溯 // 因为TreeNode的定义中没有提供父结点指针，所以只好用栈来记录了 // 当然，按照邓公的意见，这样可以省空间，应该是最好的…… else &#123; if (path.size() &gt; 0) &#123; _cur = path.top(); path.pop(); &#125; else _cur = NULL; &#125; return smallest; &#125;&#125;;/** * Your BSTIterator will be called like this: * BSTIterator i = BSTIterator(root); * while (i.hasNext()) cout &lt;&lt; i.next(); */ Sample 20ms Submission 我刚发现在提交后的结果页面点时间会得到相应的标程，惊了，Leetcode真是越来越强了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class BSTIterator &#123;public: stack&lt;TreeNode *&gt; s; void addToStack(TreeNode * root)&#123; while(root)&#123; s.push(root); root=root-&gt;left; &#125; &#125; BSTIterator(TreeNode *root) &#123; addToStack(root); &#125; /** @return whether we have a next smallest number */ bool hasNext() &#123; return s.size()&gt;0; &#125; /** @return the next smallest number */ int next() &#123; int res = s.top()-&gt;val; TreeNode * top = s.top(); s.pop(); if(top-&gt; right)&#123; addToStack(top-&gt;right); &#125; return res; &#125;&#125;;/** * Your BSTIterator will be called like this: * BSTIterator i = BSTIterator(root); * while (i.hasNext()) cout &lt;&lt; i.next(); */","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Tree","slug":"alg-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Tree/"},{"name":"alg:In-Order Traversal","slug":"alg-In-Order-Traversal","permalink":"https://zhanghuimeng.github.io/tags/alg-In-Order-Traversal/"},{"name":"alg:Binary Search Tree","slug":"alg-Binary-Search-Tree","permalink":"https://zhanghuimeng.github.io/tags/alg-Binary-Search-Tree/"}]},{"title":"Leetcode 21. Merge Two Sorted Lists（链表操作）","slug":"2018-07-30-Leetcode-21-Merge-Two-Sorted-Lists（链表操作）","date":"2018-07-30T22:58:58.000Z","updated":"2018-07-30T22:58:58.000Z","comments":true,"path":"post/leetcode-21-merge-two-sorted-lists/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-21-merge-two-sorted-lists/","excerpt":"","text":"题目来源：https://leetcode.com/problems/merge-two-sorted-lists/description/ 标记难度：Easy 提交次数：1/1 代码效率：100.00% 题意 合并两个已排序的链表。 分析 注意边界情况。以及和链表搞来搞去实在并不能算是一件很有趣味的事情。 代码 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; ListNode* head = new ListNode(-1); // 新增的头结点，没有实际意义。当然也可以不加，写起来更麻烦一点。 ListNode* p = head; // 其实我刚才写了半天才发现自己理解错了。我以为要求是把两个list交替拼接起来。 // 但实际上是合并排序…… while (l1 != NULL &amp;&amp; l2 != NULL) &#123; if (l1-&gt;val &lt; l2-&gt;val) &#123; p-&gt;next = l1; l1 = l1-&gt;next; p = p-&gt;next; &#125; else &#123; p-&gt;next = l2; l2 = l2-&gt;next; p = p-&gt;next; &#125; &#125; if (l1 != NULL) p-&gt;next = l1; else if (l2 != NULL) p-&gt;next = l2; p = head-&gt;next; delete head; return p; &#125;&#125;;","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Linked List","slug":"alg-Linked-List","permalink":"https://zhanghuimeng.github.io/tags/alg-Linked-List/"}]},{"title":"Leetcode 207. Course Schedule（拓扑排序）","slug":"2018-07-30-Leetcode-207-Course-Schedule（拓扑排序）","date":"2018-07-30T22:31:58.000Z","updated":"2018-07-30T22:42:00.000Z","comments":true,"path":"post/leetcode-207-course-schedule/","link":"","permalink":"https://zhanghuimeng.github.io/post/leetcode-207-course-schedule/","excerpt":"","text":"题目来源：https://leetcode.com/problems/course-schedule/description/ 标记难度：Medium 提交次数：1/2 代码效率：99.48% 题意 给定一些课程和每门课对应的若干先修课程，要求必须修完对应先修课程才能修这门课，问是否存在一种修课顺序，能够修完所有的课。 分析 这本质上就是一个在有向图中寻找拓扑序的问题，直接套用模型就可以了。 P.S. 我们都知道拓扑排序一般的做法是记录每个结点的入度，然后在删除结点的同时更新其他点的入度。也就是说，我们用一个数字统计量来代替了集合，而这样做是十分合理的，因为在这一问题中，只有入度的累计才有意义，其具体内容没有意义。这很有趣。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123;public: // 我感觉这个只是问一个有向图里有没有圈。 // 所以感觉简单的拓扑排序就可以了。 bool canFinish(int numCourses, vector&lt;pair&lt;int, int&gt;&gt;&amp; prerequisites) &#123; if (numCourses &lt;= 1) return true; vector&lt;vector&lt;int&gt;&gt; graph; int in[numCourses]; // 入度 for (int i = 0; i &lt; numCourses; i++) &#123; in[i] = 0; vector&lt;int&gt; t; graph.push_back(t); &#125; // [0, 1]: 1 -&gt; 0 for (int i = 0; i &lt; prerequisites.size(); i++) &#123; int x = prerequisites[i].first; int y = prerequisites[i].second; in[x]++; graph[y].push_back(x); &#125; // 暂时不做堆优化，直接暴力 int finished = 0; while (finished &lt; numCourses) &#123; int found = -1; for (int i = 0; i &lt; numCourses; i++) if (in[i] == 0) &#123; found = i; break; &#125; if (found == -1) return false; // 上这门课 for (int j = 0; j &lt; graph[found].size(); j++) in[graph[found][j]]--; in[found] = -1; // 将这门课从已上列表里去掉……刚才忘了 finished++; &#125; return true; &#125;&#125;; 一些废话 因为要准备保研的机试，所以还是要刷题。但是我实在不知道该刷什么比较好。POJ上充满了经典题，CodeForces上每周都有比赛，UVa和《算法竞赛入门经典》是配套的。结果我最后还是来刷炙手可热的Leetcode了，因为最方便，可以勉强维持一点手感。我本来一直觉得用水题刷自己博客的屏很不合适，但是如果不这样，则实在没有办法逼自己继续做下去了。","categories":[],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://zhanghuimeng.github.io/tags/Leetcode/"},{"name":"alg:Graph","slug":"alg-Graph","permalink":"https://zhanghuimeng.github.io/tags/alg-Graph/"},{"name":"alg:Topological Sort","slug":"alg-Topological-Sort","permalink":"https://zhanghuimeng.github.io/tags/alg-Topological-Sort/"}]},{"title":"如何伸缩Spokes","slug":"2018-07-06-如何伸缩Spokes","date":"2018-07-08T03:40:34.000Z","updated":"2018-07-10T02:53:00.000Z","comments":true,"path":"post/stretching-spokes-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/stretching-spokes-translation/","excerpt":"","text":"这篇文章翻译自Stretching Spokes，我加入了一些自己的注解。 GitHub的Spokes系统存储了Git仓库的多个分布式副本。本文讨论了如何把把Spokes为仓库制作的副本分散到相互之间距离很远的的数据中心。 Spokes的背景 GitHub开发了一个名为Spokes的系统来存储我们用户的Git仓库的多个副本，并使副本保持同步。Spokes使用多种策略来确保在大多数情况下每个Git更新都能安全地复制到所有副本，并且在所有情况下至少能够复制到严格多数个副本。Spoke取代了在文件系统块级别进行复制的旧系统，改为在Git应用程序级别进行复制。 每个对Git仓库的push操作都会通过代理，这一代理会透明地将操作复制到多个文件服务器。早期版本的Spoke需要代理与所有副本之间都能够进行低延迟通信，以维持较高的更新速率。因此，副本之间的距离必须比较近。 但是，将仓库副本的位置分离的优点是众所周知的： 副本分散得越开，在影响一片较大地理区域的灾难中（例如飓风、地震和外星人入侵1），就越有可能有副本幸存。 如果多个区域中都有可用的副本，则可以将Git读取请求定向到距离最近的副本，从而减少传输时间。 本文首先解释了为什么延迟会带来问题，我们如何克服问题，使得Git数据能够分布式地存储在整片大陆上，以及这为我们的用户带来了哪些改进。、 副本之间相隔很远。那有什么好大惊小怪的呢？ 在开发Spokes之前，我们使用DRBD，对文件系统进行块级复制，以创建仓库副本。该系统对延迟非常敏感，因此我们不得不保证文件服务器副本相互靠近。这显然不够理想，解决这一问题就是最初推动Spokes发展的动力。 自从我们开始运行Spokes之后，我们就开始增加Spokes的仓库副本彼此之间的距离极限。副本之间相距越远，它们之间的延迟就越大。延迟大小限制了Spokes能够为每个仓库维持的Git引用更新（reference update）2的最大速率。 你可能会惊讶，我们居然需要担心这种问题。单个仓库的推送频率不会那么高吧？ 嗯，大多数 用户根本不会经常推送。但是如果你托管了近7000万个仓库，你总会发现某些项目使用了你从未预料到的工作流程。我们非常努力，才能保证Github能够为几乎所有的项目提供正常服务，但仍有一些极其荒谬的案例除外。 此外，为了进行内部记录，Github本身也产生了大量的引用更新。例如，每次用户推送一个pull request分支时，我们都必须记录push操作本身，可能需要将该分支同步到目标仓库，为该pull request计算测试merge和测试rebase3，这些操作都会产生引用。如果用户推送到项目的master分支，我们就需要为每一个目标是master的活跃pull request都计算一个测试merge和测试rebase。在某些仓库中，这可能会触发超过一百个引用的更新。 能够对具有高延迟的远程副本进行足够快的引用更新对于Spokes的可用性至关重要。具体来说，我们希望能够支持的每个仓库每秒的更新次数大于1。这意味着每次更新操作的预算只有使用几百毫秒。请记住，无论我们采用何种方法优化写操作，都不能因此减慢读操作的速度，因为读操作和写操作数量之比约为100:1。 减少往返次数 考虑到光速有限之类的烦心事，每次到副本的往返通信都需要时间。例如，横跨美国大陆的一次网络往返通信需要60-80毫秒。多往返几次就会耗尽我们的时间预算。 我们使用三阶段提交4来更新副本，同时将副本作为分布式锁，以确保更新数据库的顺序是正确的。总而言之，远程副本需要四次往返通信；这无疑是昂贵的，但还没有到无法接受的地步。（我们正在计划通过使用更先进的一致性算法来减少往返次数。） 我们尽可能地利用等待网络请求的时间来完成其他的工作。例如，当一个副本获取互斥锁时5，另一个副本可能正在计算校验和，而协调器（coordinator）6可能正在读数据库。 Git引用更新事务 三阶段提交是保持副本同步的关键。为了实现这一协议，我们需要每个副本能够回答“你能执行这些引用更新吗？”这一问题，然后根据协调器的指示提交或回滚事务。为了实现这一目标，我们在开源Git项目中实现了Git引用更新事务（可以通过类似于git update-ref --stdin的命令使用这一特性7&lt;/a）；为了保证事务的执行结果在副本间是确定的（deterministic），我们做了大量的工作。8首先，Git获取所有必要的本地引用的锁，然后验证旧值符合预期且新值是有意义的。如果一切正常，则提交这一试探性事务（tentative transaction）；否则，它将回滚一切更改。 加速Git引用更新 除了网络延迟之外，我们还必须考虑在单个副本上更新Git引用所需的时间。为此，我们还为与引用相关的操作实现了一些加速。这些变化也贡献回了开源Git项目。 使用校验和对副本进行比较 我们通过计算副本的所有引用及其值（和一些其他的东西）的校验和来概括副本的状态，称之为“Spokes校验和”。如果两个副本的Spokes校验和相同，则它们肯定拥有相同的逻辑内容。我们在每次更新后计算每个副本的Spokes校验和，作为验证它们保持同步的一项额外检查。 在具有大量引用的繁忙仓库中，从头开始计算Spokes校验和是比较昂贵的，并且会限制引用更新的最大速率。因此，我们会尽可能用逐步的方法来计算Spokes校验和。我们将该值定义为所有(refname, value)对的hash值的异或。因此，在更新引用时，我们可以通过下式来更新校验和的这一部分： 1new_checksum = old_checksum XOR hash(refname, oldvalue) XOR hash(refname, newvalue) 在我们知道旧Spokes校验和的情况下，计算新Spokes校验和的代价就很小了。 优先考虑用户发起的更新 即使进行了所有这些优化，一次参考更新仍然需要大约三分之一秒。这在大多数情况下都足够了。但是在我们之前提到的情况下，对master进行一次更新可能会导致上百次内部记录的引用更新（bookkeeping reference update），处理这些更新可能会使仓库在30秒内都处于忙状态。如果这些更新会在如此长的时间内阻止用户发起引用更新，则用户请求将被高度延迟，甚至会超时。 为了解决这一问题，我们将一些内部记录更新合并为几个事务，并且令用户发起的更新优先于内部记录更新（因为它们不需要立即被执行）。 GitHub.com和GitHub Enterprise的地理复制 Spokes为GitHub用户带来的最切实的好处是，可以通过地理位置较近的Spokes副本提供Git读取操作（fetch和clone）。由于Spokes可以快速找出哪些副本是最新的，它可以将读操作发送到距离最近的最新副本。Spokes已经在这方面加速了GitHub.com的许多用户的传输速度，而且，随着我们在更多地理区域增加副本，传输速度还会进一步提高。 GitHub Enterprise是GitHub的企业本地版，通过相同的底层Spokes技术，它现在也支持地理复制（Geo-replication）9了。甚至当用户远离中心GHE主机（main GHE host）10时，靠近这样的副本的用户也可以享受更快的Git传输速度。这些副本被配置为无投票权的（non-voting）11，因此，即使被地理复制的主机暂时无法访问，对中心GHE主机的Git推送也能继续进行。 结论 通过对Spokes的精心设计，以及对分布式引用更新的性能的仔细优化，Spokes现在能够在更长的距离范围内复制Git仓库了。这提高了GitHub.com和GitHub Enterprise的健壮性、速度和灵活性。 注释 1虽然我觉得，一旦外星人真的入侵，应该也没有时间考虑这个问题了。 2我不太明白“reference update”这一术语指代的是什么。Git文档似乎表明，这是用于保存commit对应的SHA-1值的文件： 我们可以借助类似于git log 1a410e这样的命令来浏览完整的提交历史，但为了能遍历那段历史从而找到所有相关对象，你仍须记住1a410e是最后一个提交。我们需要一个文件来保存SHA-1值，并给文件起一个简单的名字，然后用这个名字指针来替代原始的SHA-1值。 在 Git 里，这样的文件被称为“引用（references，或缩写为 refs）”；你可以在.git/refs目录下找到这类含有 SHA-1 值的文件。 3我感觉自己对merge和rebase的区别一无所知，也无从理解为什么要做这样的计算。大概是为了显示差异比较？（5.1 代码合并：Merge、Rebase 的选择） 4三阶段提交： 三阶段提交（英语：Three-phase commit），也叫三阶段提交协议（英语：Three-phase commit protocol），是在计算机网络及数据库的范畴下，使得一个分布式系统内的所有节点能够执行事务的提交的一种分布式算法。三阶段提交是为解决两阶段提交协议的缺点而设计的。 与两阶段提交不同的是，三阶段提交是“非阻塞”协议。三阶段提交在两阶段提交的第一阶段与第二阶段之间插入了一个准备阶段，使得原先在两阶段提交中，参与者在投票之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。 5并不理解具体是获取什么锁。 6我猜测这里的协调器指的应该是分布式事务处理协调器（distributed transaction coordinator），这种技术能够使得分布式计算的事务是可靠的。（参考了What is MSDTC and why do I need to care about it?，虽然不知道和数据库有什么关系。分布式系统真有趣！） 7我之前从未听说过update-ref这个命令。于是查阅手册，得知这是一个用于安全地更新引用中存储的对象名称的命令。 8为了说明他们确实做了很多工作，作者在这一句话里插入了9个链接，全是指向对应的commit和merge记录的。真是辛苦了…… 9简单来说，“地理复制”（Geo-replication）这个东西指的就是，通过多个活跃副本完成来自地理区域不同的数据中心的请求。不过好像还有一些其他的细节。 10“GHE”是“Github Enterprise”的缩写。 11“投票权”说的应该是在Spokes中实现弹性这篇文章中提到的实现持久性的方法：保证多数一致。在这里，我猜失去投票权的意思是，无论它的写入结果如何，都不参与投票（不需要获得对于它的独占锁定），如果发生不一致，再进行更新。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Github","slug":"Github","permalink":"https://zhanghuimeng.github.io/tags/Github/"},{"name":"Spokes","slug":"Spokes","permalink":"https://zhanghuimeng.github.io/tags/Spokes/"}]},{"title":"OSTEP第05章总结：Interlude: Process API","slug":"2018-07-07-OSTEP第05章总结：Interlude-Process-API","date":"2018-07-07T16:49:54.000Z","updated":"2018-08-04T19:37:00.000Z","comments":true,"path":"post/ostep-ch-05-summary-interlude-process-api/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-05-summary-interlude-process-api/","excerpt":"","text":"本章课本见http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf。 本章的内容是“幕间休息”（interlude）：这些章节讲的是OS中与具体API相关的内容，和原理关系不大，如果不想了解这些具体内容，可以跳过。（但是最好还是不跳过，因为实践出真知，对吧？）本章主要介绍了以下三个与进程创建相关的UNIX系统调用，以及它们的设计原理： fork() wait() exec() fork系统调用：通过复制来创建新进程 下面的例子说明了fork()系统调用的使用方法： 123456789101112131415161718192021// p1.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;intmain(int argc, char *argv[])&#123; printf(&quot;hello world (pid:%d)\\n&quot;, (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int) getpid()); &#125; else &#123; // parent goes down this path (main) printf(&quot;hello, I am parent of %d (pid:%d)\\n&quot;, rc, (int) getpid()); &#125; return 0;&#125; 上述程序的输出如下： 12345prompt&gt; ./p1hello world (pid:29146)hello, I am parent of 29147 (pid:29146)hello, I am child (pid:29147)prompt&gt; 可以看出，程序开始执行的时候打印了一条信息，其中包含了进程标识符（process identifier，PID）。该进程的PID是29146。在UNIX系统中，PID是进程的唯一标识。然后进程调用了fork()系统调用，通过拷贝当前进程创建了一个新进程。有趣的是，这两个进程几乎相同，都正准备从fork()系统调用返回。新进程（称为子进程；原来的进程称为父进程）不会从main()开始运行（因为hello world只被打印了一次），而是好像自己已经调用了fork()一样。这样设计的原因，将在后面进行解释。 子进程和父进程几乎相同（地址空间、寄存器、PC），只有一点区别：fork()调用的返回值不同。父进程的返回值是子进程的PID，而子进程的返回值是0。这一区别使得我们可以撰写代码分别处理这两种情况。 值得注意的另一点是，p1.c的输出是不确定的（nondeterminism）：当子进程创建的时候，系统中出现了两个活跃进程，而CPU调度器选择哪一个先开始运行是不确定的。因此，如果子进程被创建之后立刻开始运行，上述程序的输出就会变成这样： 12345prompt&gt; ./p1hello world (pid:29146)hello, I am child (pid:29147)hello, I am parent of 29147 (pid:29146)prompt&gt; wait系统调用：等待子进程退出 下面的例子说明了wait()系统调用的使用方法： 1234567891011121314151617181920212223// p2.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;intmain(int argc, char *argv[])&#123; printf(&quot;hello world (pid:%d)\\n&quot;, (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int) getpid()); &#125; else &#123; // parent goes down this path (main) int wc = wait(NULL); printf(&quot;hello, I am parent of %d (wc:%d) (pid:%d)\\n&quot;, rc, wc, (int) getpid()); &#125; return 0;&#125; 输出结果如下： 12345prompt&gt; ./p2hello world (pid:29266)hello, I am child (pid:29267)hello, I am parent of 29267 (wc:29267) (pid:29266)prompt&gt; 在这个例子中，父进程调用wait()，使得它在子进程结束执行之后才继续执行。当子进程结束之后，wait()调用才返回。此时，上述代码的输出显然是确定（deterministic）的了。如果父进程先运行，它会立刻调用wait()，等待子进程运行结束；因此子进程必然先运行。 exec系统调用：通过覆盖改变当前进程的内容 下面的例子说明了exec()系统调用的使用方法，它一般和fork()一起使用，用于创建新进程： 123456789101112131415161718192021222324252627282930// p3.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;sys/wait.h&gt;intmain(int argc, char *argv[])&#123; printf(&quot;hello world (pid:%d)\\n&quot;, (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int) getpid()); char *myargs[3]; myargs[0] = strdup(&quot;wc&quot;); // program: &quot;wc&quot; (word count) myargs[1] = strdup(&quot;p3.c&quot;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count printf(&quot;this shouldn’t print out&quot;); &#125; else &#123; // parent goes down this path (main) int wc = wait(NULL); printf(&quot;hello, I am parent of %d (wc:%d) (pid:%d)\\n&quot;, rc, wc, (int) getpid()); &#125; return 0;&#125; 输出结果如下： 123456prompt&gt; ./p3hello world (pid:29383)hello, I am child (pid:29384)29 107 1030 p3.chello, I am parent of 29384 (wc:29384) (pid:29383)prompt&gt; 事实上，在Linux中，exec()是一类系统调用的总称，一共有6个变种：execl()，execlp()，execle()，execv()，execvp()和execvpe()。详情见exec(3) 在这个例子中，在调用fork()创建子进程后，子进程调用了execvp()，用程序wc覆盖自己并开始执行该程序。wc是字数统计（word counting）程序，此处它被用来统计源文件p3.c中行、词和字节的数量。 fork()系统调用的设计固然很怪，它的“同伙”exec()也有够怪的。事实上，exec()所做的事情是这样的：给定一个可执行文件的名字（如wc）和一些参数（如p3.c），它会加载（load）这个可执行文件的代码（和静态数据），覆盖当前进程的代码段和静态数据，并且重新初始化进程的堆栈和其他内存空间。然后OS把参数作为新进程的argv数组，直接开始运行新程序。所以exec()调用并没有创建一个新进程；它只是把当前正在运行的进程（p3）换成了一个新的程序（wc）。在子进程执行exec()调用之后，p3.c就好像从未运行过一样了；对exec()的成功调用是不会返回的。 fork和exec的设计原因：方便shell和管道的实现 我们为什么要这样设计创建新进程的API呢？事实上，对于UNIX shell来说，在创建新进程的过程中把fork()和exec()分开是非常必要的，因为这样shell才能在调用fork()之后，调用exec()的过程之前运行一些代码来改变即将运行的程序的环境，这就使得我们可以创造很多有趣的特性。 shell是一个帮助你执行程序（命令）的用户程序。它显示一个命令提示符（prompt），然后等待你在里面打字。你在里面打一个命令（比如可执行程序的名字和参数）；然后，shell一般会找到这个可执行程序在文件系统中的位置，调用fork()创建一个新的子进程，然后（子进程）调用exec()的某个变种开始执行命令，最后（父进程）调用wait()等待命令执行结束。当子进程运行结束之后，shell（父进程）从wait()返回，再次打印出命令提示符，等待你的下一条指令。 把fork()和exec()分开使得shell能在其间够做很多有用的东西。比如，我们执行如下命令： 1prompt&gt; wc p3.c &gt; newfile.txt 在这个例子中，wc的输出被重定向（redirect）到输出文件newfile.txt中。shell完成这个任务的方法很简单：在创建子进程之后，调用exec()之前，shell关闭标准输出（standard output）并打开文件newfile.txt。这样，即将被执行的程序wc的任何输出都会被发送到这个文件而不是屏幕。 下面的代码实现了子进程输出的重定向。 123456789101112131415161718192021222324252627282930// p4.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/wait.h&gt;intmain(int argc, char *argv[])&#123; int rc = fork(); if (rc &lt; 0) &#123; // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); &#125; else if (rc == 0) &#123; // child: redirect standard output to a file close(STDOUT_FILENO); open(&quot;./p4.output&quot;, O_CREAT|O_WRONLY|O_TRUNC, S_IRWXU); // now exec &quot;wc&quot;... char *myargs[3]; myargs[0] = strdup(&quot;wc&quot;); // program: &quot;wc&quot; (word count) myargs[1] = strdup(&quot;p4.c&quot;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count &#125; else &#123; // parent goes down this path (main) int wc = wait(NULL); &#125; return 0;&#125; 该程序的输出如下： 1234prompt&gt; ./p4prompt&gt; cat p4.output32 109 846 p4.cprompt&gt; 这种方法的工作原理与OS管理文件描述符的方法相关。UNIX系统在分配文件描述符时，会从0开始寻找空闲的文件描述符。上一章中曾经讲过，对于一个进程，默认有三个文件描述符是开启的：标准输入（STDIN_FILENO=0）、标准输出（STDOUT_FILENO=1）和标准错误输出（STDERR_FILENO=2）。关闭标准输出之后，在调用open()分配新的文件描述符时，STDOUT_FILENO=1就成了第一个可用的文件描述符，于是它就指向了我们需要的输出文件./p4.output。于是，子进程之后对标准输出文件描述符的写操作会被透明地指向新打开的文件。（真是有趣的设计啊） UNIX管道（pipe）机制的实现方法类似。通过pipe()系统调用，一个进程的输出被连接到一个内核管道（pipe）中，另一个进程的输入也连接到这个相同的管道；这样，一个进程的输出就无缝连接到另一个进程的输入了。下面的例子通过管道命令实现了在文件中查找词并计算这个词出现次数的功能： 1grep -o foo file | wc -l 温馨提示 RTFM 我们刚才只是大概介绍了这些系统调用的基本原理，还有许多细节没有涉及到。为了了解这些细节，你应当去阅读手册。作为一个系统程序员，阅读手册（manual/man pages）是非常重要的，因为里面提供了很多细节，而且还可以帮助你减少烦你的同事的次数。如果你直接去问他们细节问题，他们可能会回答你：“RTFM。”（Read the fucking manual！） Get it right 兰普森（Butler W. Lampson）在他那篇广受好评的论文“Hints for Computer Systems Design”中这样说：“做正确的事。（Get it right.）抽象和简化都不能代替正确的做法。” 实际上，设计进程创建API有很多方法，但是UNIX的设计者选择了正确的那一种。（虽然我觉得本章中并没有充分论述它的正确性）","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"在Spokes中实现弹性（resilience）","slug":"2018-07-05-在Spokes中实现弹性（resilience）","date":"2018-07-05T23:31:15.000Z","updated":"2018-07-06T09:51:00.000Z","comments":true,"path":"post/building-resilience-in-spokes-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/building-resilience-in-spokes-translation/","excerpt":"","text":"这篇文章翻译自Building resilience in Spokes，我加入了一些自己的注解。 Spokes是我们的文件服务器的复制系统，我们在里面存储了超过3800万个Git仓库和超过3600万个gists。它至少存储了每个仓库和每个gist的三个副本，这样，即使服务器和网络出现故障，我们也可以提供持久且高可用的内容访问。Spokes使用Git和rsync1的组合来对存储库进行复制，修复和重新平衡。 Spokes是什么？ 在我们进入这一主题——如何实现弹性——之前，我们需要声明一个新的名字：DGit现在改名为Spokes了。 今年早些时候，我们宣布了我们的应用级Git复制系统，名为“DGit”（“Distributed Git”）。我们得到的反馈表明，“DGit”这个名字的区分度不高，可能会导致与Git项目本身混淆。所以我们决定重命名这个系统为Spokes。 “弹性”的定义 在任何系统或服务中，有两种衡量弹性的关键方法：可用性（availability）和持久性（durability）。系统的可用性指的是系统提供它应当提供的服务所需的运行时间。它可以提供内容吗？它能接受写操作吗？可用性可能是部分的，完整的或退化的：每个仓库都可用吗？是否有一些仓库——或者整个服务器——的访问很缓慢？ 系统的持久性指的是它对永久性数据丢失的抵抗能力。一旦系统接受了一个写操作——推送，合并，通过网站进行的编辑，创建新仓库等——它就应该永远不会破坏或回退该内容到之前的状态。这里的关键问题出现在系统接受写入时：需要存储多少副本，以及在哪里存储？显然，必须存储足够数量的副本，才能保证写操作不丢失的可能性足够高。 系统可以是持久但不可用的。例如，如果系统能够为当前写操作制造的副本数量不能超过最低要求，则系统可能会拒绝接受写操作。这样的系统对于写操作是暂时不可用的，不过它同时能够保证不会丢失数据。当然，系统也可以是不持久但可用的。例如，接收任何写入，无论它们是否可以安全地提交，。 读者可能会意识到这与CAP定理2有关。简而言之，系统最多可以满足以下三个特性中的两个： 一致性（consistency）：所有节点都读到相同的数据 可用性（availability）：系统可以满足读写请求 分区容错性（partition tolerance）：即使节点关闭或无法通信，系统也能正常工作 Spokes将一致性和分区容错性放在首位。在最坏的情况下，它将拒绝接受一些写入，对于这些写入，它不能同步提交至至少两个副本。 可用性 Spokes的可用性取决于底层服务器和网络的可用性，以及我们检测和绕过服务器和网络问题的能力。 单个服务器经常会变得不可用。自从今年春天开始试用Spokes以来，由于内核死锁和RAM芯片故障，我们的一些服务器崩溃了。有时，由于较轻的硬件故障或较高的系统负载，服务器能够提供的服务退化了。在所有这些情况下，Spokes都必须快速检测出问题并绕过它。每个存储库都复制在三台服务器上，因此即使一台服务器处于脱机状态，也基本总会有一个最新的可用副本可以访问。不过，Spokes可不只是它的每个单独的容错部分的总和。3 快速检测问题只是第一步。Spokes同时使用心跳服务（heartbeat）4和实际应用程序流量的组合来确定文件服务器何时停止工作。使用实际应用流量很关键，原因如下。首先，心跳服务的学习和反应速度很慢。我们的每个文件服务器每秒需要处理超过100个请求。如果心跳每秒发生一次，则只有在一百个请求都已经失败后才能发现故障。其次，心跳测试只能覆盖服务器功能的一个子集：例如，服务器是否可以接受TCP连接并响应无操作请求。但是如果失败的情形更微妙呢？如果Git二进制文件已损坏怎么办？如果磁盘访问停止了怎么办？如果所有经过身份验证的操作都失败怎么办？当真正的流量失败时，有时无操作服务仍然能够成功。 因此，Spokes会在处理实际应用程序流量时监视失败情况，如果有太多请求失败，它会将节点标记为脱机。当然，实际请求在正常情况下有时也会失败。例如，有人会尝试读取已经删除的分支，或尝试推送到他们无权访问的分支。因此，Spoke仅仅在三个请求连续失败时才将节点标记为脱机。这有时会导致完全健康的节点脱机——在正常情况下，三个请求也可能会连续失败——但这种情况很少发生，并且导致的代价并不大。 Spokes也使用心跳服务，但不是作为主要的故障检测机制。相反的是，心跳有两个目的：轮询系统负载，并在节点被标记为脱机后提供全清信号（all-clear signal）5。一旦心跳成功，该节点将再次标记为在线。如果在服务器出现问题的情况下心跳成功（检索系统负载几乎是无操作），则在三次失败的请求之后，节点将再次标记为脱机。 因此，Spokes在节点大约发生三次失败之后就会检测到故障。但是连续三次失败的操作仍然太多了！对于干净的故障——连接被拒绝或超时——所有操作都知道如何尝试下一个主机。请记住，Spokes对于每个仓库都维护了三个或更多的副本。对仓库的路由查询不只返回一个服务器，而是返回按优先顺序排序的三个（大约）最新副本的列表。如果对首选副本上的操作失败，则通常还有至少两个个副本可以尝试。 从一个服务器故障转移到另一个服务器的操作图（此处为远程过程调用（Remote Procedure Call，RPC）6）清楚地显示了服务器何时脱机。在下图中，有一个服务器在约1.5小时的时间内不可用；在此期间，数千个RPC操作被重定向到其他服务器。这样的图表是Spokes团队发现出错服务器的最佳检测方法。 Spokes的节点离线检测只是建议性的——这只是一种优化。连续三次失败的节点只会被移动到所有读操作的优先顺序列表的末尾，而不是直接从副本列表中移除。尝试一个可能离线的副本还是比根本不进行尝试要好的。 这个故障检测器对服务器故障很有效：当服务器过载或脱机时，对它的操作将失败。Spokes检测到这些故障，并暂时停止将流量定向到故障服务器，直到心跳成功为止。但是，网络和应用程序（Rails）服务器的故障更加混乱。给定的文件服务器可能只对应用程序服务器的一个子集处于脱机状态，而一个出错的应用程序服务器可能会看到每个文件服务器都处于脱机状态的假象。因此，Spokess的故障检测实际上是MxN7的：每个应用程序服务器都保留自己的脱机文件服务器列表。如果我们发现许多应用程序服务器都将某个文件服务器标记为脱机，那么它可能确实脱机了。而如果我们发现某一个应用程序服务器将许多文件服务器标记为脱机，则发现了一个应用程序服务器的错误。 下图说明了故障检测的MxN特性，并以红色显示，如果文件服务器dfs4处于脱机状态，哪些故障检测器会发现错误。8 在最近的一次事件中，开发环境中的一个前端应用程序服务器发生了无法解析文件服务器的DNS名称的错误。因为它无法到达文件服务器以向它们发送RPC操作或心跳，所以它得出结论，每个文件服务器都处于脱机状态。但是，只有那台应用程序服务器发生了这些错误；所有其他应用服务器都在正常工作。因此，这台坏掉的应用程序服务器在RPC故障转移图中变得非常明显，并没有没有生产流量因此受到影响。9 持久性 有时，服务器会失效。磁盘可能会失效；RAID控制器可能会失败；甚至整个服务器或整个机架上的全部机器都可能出现故障。即使面对这种逆境，Spokes也为仓库数据提供了持久性。 就像可用性那样，持久性的的实现基础是复制。Spokes至少保留了每个存储库，wiki和gist的三个副本，且这些副本位于不同的机架中。除非严格多数个副本可以应用更改并获得相同的结果，否则不接受对仓库的更新——推送，重命名，编辑维基等。 Spokes只需要一个额外的副本即可避免单节点故障。那么，为什么需要严格多数呢？存储库很可能在大致相同的时间被多次写入，这种情况是很常见的。这些写入可能会发生冲突：例如，一个用户可能会删除一个分支，而另一个用户将新的提交推送到同一个分支。冲突的写入必须被序列化——也就是说，必须在每个副本上以相同的顺序应用（或拒绝）这些写入，这样每个副本才能得到相同的结果。Spokes将写入序列化的方式是确保每次写入都获得对大多数副本的独占锁定。两个写入不可能同时获得多数锁定，因此Spokes通过完全消除并发写入来避免冲突。 如果一个仓库恰好有三个副本上，则在两个副本上的成功写入既保证了持久性，也保证了多数。如果仓库有四个或五个副本，则成功写入需要三个副本。 在很多其他的复制和共识协议（consensus protocols）中，写入到主副本的顺序是官方顺序，所有其他副本都必须按该顺序进行写入。主副本通常需要手动指定，或使用选举协议（election protocol）自动指定。Spokes简单地跳过这一步骤，并将每次写操作都视为一次选举——选择出胜出的顺序之后，可以直接得到写入结果，而不是得到一个能够指示写入顺序的获胜服务器。 无法在多数副本上以相同方式应用的任何写操作都会被Spokes从它被应用的副本上回退。实质上，每个写入操作都需要经过一个投票协议，投票失败方的任何副本都被标记为不健康——不可读取或写入——直到它们被修复。维修是自动和快速的。由于需要多数副本同意接受或回滚更新，在修复不健康的副本时，仍然至少有两个副本可以继续接受读取和写入。 需要明确的一点是，分歧和修复发生的概率是很小的。GitHub每天接受数百万次仓库写入操作。在典型的一天里，几十次写入才会导致一次非一致投票，通常是因为一个副本特别繁忙，到它的连接超时了，而其他副本在没有它的情况下投票成功，继续前进。落后的副本几乎总是在一两分钟内恢复，不会对仓库的可用性造成用户可见的影响。 整个磁盘和整个服务器的故障更罕见，但它们确实会发生。当我们必须移除整个服务器时，突然有数十万个仓库只剩下有两个副本了，而不是三个。这一状况也是可修复的。Spokes会定期检查每个仓库是否具有所需数量的副本；如果没有，则创建更多副本。可以在任何地方创建新副本，并且可以通过每个仓库剩余的两个副本中的任何一个进行复制。因此，服务器故障后的修复是N对N的。文件服务器的集群越大，从单节点故障中恢复的速度就越快。 正常关机 如上所述，Spokes可以快速透明地处理服务器脱机和永久失效。那么，我们可以将这一方法直接用于需要计划维护时对服务器的重启或移除吗？是，也不是。 我们的确可以通过sudo reboot重新启动服务器，也可以通过直接把服务器拔掉来移除它。但这样做有一些微妙的缺点，因此我们需要设计一种更谨慎的机制，重用一些用于应对崩溃和故障的相同逻辑。 简单地重新启动服务器不会影响未来的读写操作，这些操作将被透明地指向其他副本。它也不影响正在进行的写入操作，因为这些操作发生在所有副本上，而其他两个副本可以直接投票成功并继续写入，不需要我们正在重新启动的服务器上的副本。但重启确实会打断正在进行的读取操作。大多数读取操作——例如，获取README以显示在仓库的主页上——速度都很快，能够在服务器正常关闭之前完成。但有些读取，特别是大型仓库的克隆，取决于最终用户的网速，需要几分钟或几小时才能完成。直接打断这些操作是非常粗鲁的。可以在另一个副本上重新启动这些操作，但到目前为止的所有进度都将丢失。 因此，在Spokes中，为了主动重启一台服务器，我们需要先将它置于静默期（quiescing period）。当服务器处于静默状态时，它对于新的读取操作被标记为脱机，但允许现有的读取操作（包括克隆）完成。静默期可能会持续几秒到几个小时，具体取决于被重启的服务器上哪些读取操作处于活动状态。 可能会令人惊讶的是，写操作像往常一样被发送到服务器，即使它们静默也是如此。这是因为写操作需要在所有副本上运行，因此单个副本可以随时丢弃，不会发生用户可见的影响。此外，如果副本在静默时没有接收到任何写入操作，那么该副本将大大落后于其他副本，当它最终完全重新上线时，时会产生大量的追赶负载（catch-up load）。 我们不在Spokes文件服务器上执行“混乱猴子”（chaos monkey）测试10，原因与我们在重新启动它们之前要将它们置为静默状态的原因相同：避免中断需要长时间运行的读取操作。也就是说，我们不会仅仅为了确认突发的单节点故障仍然（在大多数情况下）是无害的而随机重启文件服务器。 虽然我们不执行“混乱猴子”测试，我们仍然会按需要对服务器轮流进行重启，这实现了大致相同的测试目标。当我们需要进行一些需要重启的更改时——比如更改内核或文件系统参数，或更改BIOS设置——我们会将这些服务器置于静默状态并重启它们。我们将机架作为可用性区域11，因此我们一次将整个机架置于静默状态。当给定机架中的服务器结束静默状态——即完成所有未完成的读取操作——我们分批重启这些服务器，每次最多五个。整个机架重启结束后，我们继续前进到下一个机架。 下图显示了在轮流重启期间失败的RPC操作。用不同的颜色标记每个服务器。值是堆叠的，因此在最高的峰值表示的时刻中，八个服务器在同时重启。浅红色块表示一台服务器未能正常重启，因此离线了大约两个小时。 用直接插拔的方法移除服务器的弊端与计划外重启的弊端类似。除了会中断任何正在进行的读取操作外，这种行为还会为在这台服务器上托管的所有仓库带来几个小时的额外风险。当一台服务器突然消失时，之前存储在里面的所有仓库现在都只剩下两个副本了。两个副本足够执行任何读取或写入操作，但两个副本无法承受额外的故障。换句话说，在没有警告的情况下就删除服务器，这样会增加在同一天晚些时候写入操作被拒绝的概率。我们的目标是将这种可能性保持在最低水平。 因此，在准备移除一台服务器之前，我们不再把它存储的仓库副本作为任何仓库的活跃副本。Spokes仍然可以使用该服务器进行读写操作。但当它询问是否所有仓库都有足够的副本时，其中一些仓库——有副本位于将被移除的服务器上的那些 ——将声称不够，然后创建更多的副本。修复这一问题的过程类似于服务器直接消失后的修复过程，不过，区别在于，现在服务器仍然可用，以防其他服务器出现故障。 结论 可用性是很重要的，而持久性甚至更为重要。可用性衡量的是服务响应请求的时间长度12。持久性衡量的是，服务能够可信地存储输入数据中的多少。 为了提供可用性和持久性，Spokes为每个仓库至少保留了三个副本。三个副本意味着，即使一个服务器失效，也不会对用户产生可见的影响。如果两个服务器都发生了故障，Spokes仍然可以为大部分仓库提供完全的访问权限，并为那些恰好有两个副本存储在这两个故障服务器上的存储库提供只读访问。 Spokes只在大多数副本——一般至少为两个——能够提交写入并得到相同的仓库状态时才接受对仓库的写入，这一要求通过确保所有副本上的写入顺序相同提供了一致性。通过在至少两个位置存储每个已提交的写入，它也可以在单个​​服务器发生故障时提供持久性。 Spokes的故障检测器通过监视实时应用程序流量，确定服务器何时脱机并绕过该问题。最后，Spokes具有自动修复功能，可在磁盘或服务器发生永久性故障时快速恢复。 注解 1关于rsync： rsync是Unix下的一款应用软件，它能同步更新两处计算机的文件与目录，并适当利用差分编码以减少数据传输量。rsync中的一项同类软件不常见的重要特性是每个目标的镜像只需发送一次。rsync可以拷贝／显示目录内容，以及拷贝文件，并可选压缩以及递归拷贝。 在常驻模式（daemon mode）下，rsync默认监听TCP端口873，以原生rsync传输协议或者通过远程shell如RSH或者SSH提供文件。SSH模式下，rsync客户端运行程序必须同时在本地和远程机器上安装。 rsync是以GNU通用公共许可证发行的自由软件。 2CAP定理： 在理论计算机科学中，CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点： 一致性（Consistence） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据） 分区容错性（P artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。） 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。 3不知道这个地方在说什么。是说Spokes能提供的功能远多于冗余性吗？ 4heartbeat的定义（http://blog.51cto.com/hoolee/1408615）： Heartbeat 项目是Linux-HA工程的一个组成部分，它实现了一个高可用集群系统。心跳服务和集群通信是高可用集群的两个关键组件，在 Heartbeat 项目里，由 heartbeat 模块实现了这两个功能。 heartbeat（Linux-HA）的工作原理：heartbeat最核心的包括两个部分，心跳监测部分和资源接管部分，心跳监测可以通过网络链路和串口进行，而且支持冗 余链路，它们之间相互发送报文来告诉对方自己当前的状态，如果在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运行在对方主机上的资源或者服务。 5所谓“All clear”是一种防空警报，它的含义是空袭已经结束，民众可以离开防空洞。 6远程过程调用： 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。 7我没有完全理解M*N是什么意思。不过我猜测，这指的是错误是可以双向检测的。 8这张图大概显示了3个fetch请求，一个远端git worker请求和一个web api请求。 9此处令人思考的是，这一故障检测是如何实现的。我们需要了解请求是否会失败，以及一些能够进行请求的非文件服务器记录下的请求失败情况。通过其他服务器的请求情况，实际上，我们可以确定这些服务器的实际运行状况。而RPC图大概是需要通过收集所有请求的实际状况来绘制的。绘制完成之后，Spokes系统可能会根据某种策略自动进行结点状况判断，也可以绘制成实时状态图，让人类判断里面发生错误的结点。 10Chaos monkey： Chaos Monkey是一种识别系统组并随机终止组中某个系统的服务。该服务在受控时间（不在周末和假日运行）和间隔（仅在工作时间运行）运行。在大多数情况下，我们将应用程序设计为在对等设备脱机时继续工作，但在这些特殊情况下，我们希望确保周围有人来解决和学习任何问题。考虑到这一点，Chaos Monkey只在工作时间运行，其目的是让工程师保持警觉并能够做出响应。 （其实就是在系统里自动造成随机失败，增加工程师的警觉性） 11（原注）将机架作为可用性区域处理意味着我们放置仓库副本的时候需要保证同一机架中不会存储同一存储库的两个副本。这样就可以保证，即使丢失了整个服务器机架，也不会影响托管在里面的任何仓库的可用性或持久性。我们选择机架作为可用性区域，是因为几种重要的故障模式（failure mode），特别是与电源和网络相关的故障模式，可能会同时影响整个服务器机架。 “可用性区域”（Availability Zone）由独立的数据中心构成，每个地区都是一个数据中心集群，这些数据中心之间距离足够近，这样可以保证数据库等应用的延迟足够低，但又足够远，这样可以防止出现意外时同时宕机，例如亚马逊在日本的数据中心就分布在不同的地震区。（香港：亚马逊云计算全球化布局下一站？） 12所以这个是单次请求所需的时间长度，和服务器自己的运行时间没有关系？那么，看来前面搞错了……","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Github","slug":"Github","permalink":"https://zhanghuimeng.github.io/tags/Github/"},{"name":"Spokes","slug":"Spokes","permalink":"https://zhanghuimeng.github.io/tags/Spokes/"}]},{"title":"DGit简介","slug":"2018-07-05-DGit介绍","date":"2018-07-05T21:46:43.000Z","updated":"2018-07-06T09:50:00.000Z","comments":true,"path":"post/introducing-dgit-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/introducing-dgit-translation/","excerpt":"","text":"这篇文章翻译自Introducing DGit，我加入了一些自己的注解。（大部分翻译来自谷歌翻译，水平比我更高，只有少数地方译错，我感觉翻译行业的前景很不乐观。） Edit：DGit现在改名叫Spokes了 GitHub在数百台服务器1上托管了超过3500万个存储库和超过3000万个Gists。在过去的一年中，我们构建了DGit，这是一种新的分布式存储系统，可显著提高对Git内容的提取和存储的可用性（availability），可靠性（reliability）和性能（performance）。 DGit是“Distributed Git”的缩写。正如许多读者已经知道的那样，Git本身是分布式的——Git存储库的任何副本都包含项目整个历史记录中的每个文件，分支和提交。DGit使用Git的这个属性在三个不同的服务器上保存每个存储库的三个副本。即使其中一个服务器出现故障，DGit的设计也能够使存储库的可用性不会发生中断。即使在极端情况下，存储库的两个副本同时不可用，存储库仍然可读（readable）；即，提取（fetch），克隆（clone）和大多数Web UI仍然能够继续工作。 DGit在应用程序层执行复制，而不是在磁盘层执行复制。不妨把这些副本看做是三个通过Git协议保持同步的松散耦合的Git仓库，而不是相同的充满了仓库的磁盘映像。此设计使我们能够以极大的灵活性确定仓库副本的存储位置以及用哪个副本进行读取操作。 如果需要使文件服务器脱机，则DGit会自动确定哪些仓库的副本少于三个，并在其他文件服务器上创建这些存储库的新副本。此“修复”过程将所有剩余的服务器用作源和目标。由于“修复”过程的吞吐量是N-N2，因此速度非常快。所有这一切都没有任何停机时间。 DGit只使用普通的Git 大多数最终用户将其Git仓库作为对象、包文件和引用存储在单个.git目录中。他们使用Git命令行客户端、GitHub Desktop等图形客户端或Visual Studio等IDE中内置的Git支持来访问仓库。可能会令人惊讶的是，GitHub的仓库存储层DGit是使用相同的技术构建的。为什么不使用SAN3，一个分布式文件系统？或者其他的能够将持久存储数据的问题抽象化的神奇的云技术？ 答案很简单：它速度快，而且很健壮。 Git对延迟非常敏感。一个简单的git log或者git blame命令可能需要顺序加载和遍历数千个Git对象。如果这些低级磁盘访问存在任何延迟，则性能会受到严重影响。因此，将仓库存储在分布式文件系统中是不可行的。Git是为访问高速磁盘而优化的，因此DGit文件服务器将仓库存储在本地高速SSD上。 在更高的层次上，Git还经过优化，可以在通过协议在Git仓库之间之间高效更新（例如，推送和提取）。因此，我们使用这些协议来保持DGit副本同步。 Git是一种成熟且经过良好测试的技术。为什么有一级方程式赛车可用时要重新发明轮子？ GitHub的理念始终是，通过尽可能接近用户使用Git的方式，在我们的服务器上使用Git4。DGit延续了这一传统。如果我们发现性能瓶颈或其他问题，我们有几个核心的Git和libgit2贡献者会解决这些问题，并将补丁提交到人人可用的开源项目。我们在Git方面的经验和专业知识使其成为用于DGit复制操作的的最优选择。 使用DGit前后的GitHub架构 之前，我们使用现有的磁盘层复制技术（即RAID和DRBD5）保存了仓库数据的副本。我们将文件服务器成对组织起来，每个活动文件服务器都有一个通过交叉电缆连接的专用在线备份服务器。每个磁盘有四个副本：主文件服务器上通过RAID保存两个副本，另外两个副本使用DRBD保存在该文件服务器的热备份上。如果文件服务器出现任何问题——例如，硬件故障，软件崩溃或过载情况——一名人类将确认故障并命令备用服务器接管。因此，冗余级别是良好的，但故障转移过程需要手动干预，并且不可避免地导致故障服务器上的仓库在一段时间内不可用。为了尽量减少此类事件，我们始终将仓库存储在专用且高度可靠的服务器上。 现在改为使用DGit，每个仓库都存储在三个服务器上，这三个服务器独立地分布在我们的大群文件服务器中。DGit自动选择托管每个仓库的服务器，使这些副本保持同步，并选择处理每个传入的读取请求最的佳服务器。写操作会同时被导入到三个副本中，仅仅当至少两个副本确认写入成功时才会提交。 现在GitHub把仓库存储在一个名为github-dfs的集群中——dfs是“DGit file server”的缩写。这些仓库存储在这些文件服务器上的本地磁盘中，并通过Git和libgit2进行服务。此集群的客户端包括Web前端和与用户的Git客户端通信的代理。 DGit的优势 DGit为GitHub用户和内部GitHub基础架构团队都提供了许多优势。它也是实现更多即将到来的创新的关键基础。 文件服务器不再必须作为成对的相同服务器部署，彼此靠近，并通过交叉电缆一对一连接。我们现在可以在任何空间配置中使用异构的文件服务器池。 在开始使用DGit之前，当整个服务器发生故障时，需要尽快将其替换，因为其备份服务器运行时没有备用服务器。两个服务器一起中断可能会使数十万个仓库无法访问。现在，当服务器出现故障时，DGit会快速制作其托管的仓库的新副本，并在整个集群中自动分发它们。 路由故障的破坏性大大减小了。我们不必重新启动并重新同步整个服务器，只需停止到服务器的路由流量，直到它恢复。现在可以安全地重启生产服务器，没有过渡期。由于服务器中断对DGit的破坏性较小，我们不再需要等待人类确认中断; 我们可以立即绕过它。 我们不再需要保留大多数时间都在闲置的热备用文件服务器。在DGit中，每个CPU和所有内存都可用于处理用户流量。虽然像push这样的写操作必须转到仓库的每个副本，但是任何副本都可以提供读操作。由于读操作的数量远远超过写操作，因此每个仓库现在可以处理的流量几乎是以前的三倍。下图显示了git处理在旧文件服务器（蓝色）和DGit服务器（绿色）上分别引起的CPU负载。蓝线标识活动服务器的平均值; 它们的热备件不包括在内。DGit服务器上的负载较低：峰值时大约低三倍，而低谷时大约低两倍。由于所有文件服务器都有无法在副本之间分配的后台维护任务，因此低谷性能的改进没有三倍那么多。 DGit可以自动平衡磁盘和CPU热点。添加服务器根本不需要计划：DGit只是随机地将现有仓库移动到新服务器，直到磁盘空间和CPU负载恢复平衡。随着现有仓库的扩展或缩小，DGit会移动它们以保持磁盘空间平衡。随着仓库受欢迎程度的增加或降低，DGit会转移负载以缓解CPU和内存热点。在下图中，一个DGit服务器集群（以红色显示）大部分已满，直到我们添加了一个新的服务器集群（以蓝色显示），其中包含更大的磁盘，以减轻磁盘空间压力。第三个集群（绿色）有两个服务器接收仓库，一个服务器放弃它们。继续移动存储库，直到所有服务器的磁盘空闲空间比例相近。 DGit减少了存储库之间的命运共享（fate sharing）6。在使用DGit之前，一组固定的仓库一起存储在单个服务器上和该服务器的备用服务器上。如果一个存储库太大，代价太昂贵或太受欢迎，那么该文件服务器上的其他仓库可能会变慢。在使用DGit之后，可以通过其他副本服务其他的仓库，这些副本不太可能与繁忙仓库的其他副本位于相同的服务器上。 副本的分离意味着我们可以将存储库的副本放在不同的可用区域中，甚至可以放在不同的数据中心中。可用性得到改善，我们（终于）可以通过在地理上靠近用户的服务器为用户提供内容。 DGit的试运行 DGit带来的变化是巨大的，所以我们一直在逐步推广它。DGit最复杂的特性是，复制不再是透明的：现在，每个存储库都显式存储在三台服务器上，而不是一台有自动同步热备份的服务器上。因此，DGit不能再依靠DRBD和RAID控制器来保持副本同步，必须实现自己的序列化处理（serializability）7，锁定（locking），故障检测（failure detection）和二次同步（resynchronization）8。我们将在以后的帖子中探讨这些内容丰富的主题。这些足以说明，在依赖DGit存储客户数据之前，我们需要彻底测试这些功能。我们的部署经过多个步骤： 我们首先移动了DGit开发人员的个人仓库。 我们移动了一些私人的，GitHub拥有的仓库，这些仓库不属于运行网站的一部分。我们首先在每个存储库中打开一个issue，请求我们的同事的允许。这既是一个礼貌的预先通知，也是一种开始向GitHub其余部分解释DGit的方法。 我们移动了GitHub的其余大部分私有仓库。 我们停止移动存仓库大约三个月，同时我们进行了大量测试，对DGit相关流程进行自动化，为DGit撰写了操作级别的文档，并且（咳咳）修复了偶尔发生的错误。 经过三个月的稳定运行后，我们移动了大多数GitHub拥有的公共存储库，以及外部用户拥有的那些存储库的fork。例如，Linguist的拥有者是GitHub，但其大约1,500个fork属于外部用户。托管公共仓库测试了DGit处理大型仓库的网络和更高流量负载的能力。 我们开始移动不属于GitHub的公共仓库。我们立即从GitHub的showcases和流行仓库中找出一些有很多分支的繁忙的仓库：包括Ruby、Rails、Bootstrap和D3等等，并且搬运了它们。我们的目标是在DGit中尽可能多地获取流量和不同的使用模式，同时仍然手工采集一小部分仓库的数据。 距离我们第一次移动自己的仓库六个月后，令人满意的是，DGit能够很好地托管网站，于是我们开始批量移动仓库。 在试运行阶段，我们不断尝试关闭服务器，有时会同时关闭几个服务器，此时它们正在提供实时生产流量。用户操作并没有受到影响。 在撰写本文时，58％的存储库和96％的Gists（占Git操作的67％）都迁移到了DGit中。我们正在尽快将剩余的文件服务器对转换为DGit服务器。 结论 GitHub始终致力于快速可靠地获取，推送和查看仓库。在未来几年内，我们将使用DGit作为我们的仓库存储层以实现这些目标，同时进行横向扩展并提高容错能力。 在接下来的一个月里，我们将发布更多对DGit背后的技术进行深入研究的帖子。 总结 我之前曾经在网上看到一篇相关的评论帖子，但是现在找不到了，我明天再找…… 注解 1这个服务器的数量比我想象的要少。（或者谷歌翻译错了，应该是成百上千台。） 2大概是因为源可以有多个，目标也可以有多个。不过这个吞吐量可能翻译错了，我也不懂“N-by-N”具体是什么意思。 3关于SAN（摘自维基百科）： 存储区域网络（英语：storage area network，缩写作 SAN）是一种连接外接存储设备和服务器的架构。人们采用包括光纤通道技术、磁盘阵列、磁带柜、光盘柜的各种技术进行实现。该架构的特点是，连接到服务器的存储设备，将被操作系统视为直接连接的存储设备。除针对大型企业的企业级存储方案外，随着在2000年后价格和复杂度的降低，越来越多的中小型企业也在逐步采用该项技术。 它访问的是磁盘设备，而不是文件。 4虽然我现在并不理解这个传统的存在意义和价值。 5DRBD=Distributed Replicated Block Device，一个基于软件在不同宿主之间创建块设备（硬盘、翻去、逻辑分区等）的镜像的存储复制服务。功能特性包括： 实时 透明 同步或异步 （https://docs.linbit.com/docs/users-guide-9.0/#p-intro） 6关于命运共享： 命运共享（Fate Sharing）建议将所有必要的状态放在通信端点，这些状态用于维护一个互动的通信关联（例如虚拟连接）。由于这个原因，导致通信失效的情况也会导致一个或更多端点失效，这样显然会导致整个通信的失败。命运共享是一种通过虚拟连接（例如，由TCP实现的连接）维持活动的设计理念，即便网络在一段时间内失效。命运共享也支持一种“带智能终端主机的哑网络”模型。 （端到端原则与命运共享原则；还是没太看懂） 7可串行化（Database Conflict Serializability [数据库冲突可串行化]）： 多个事务[Transaction]的并发执行是正确的，当且仅当其结果与按某一次串行地执行这些事务时的结果相同，称这种调度策略为可串行化的调度。–数据库系统概论第四版 8查了之后，发现一堆心脏病疗法，仍然无法很好地认识什么是resynchronization。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Github","slug":"Github","permalink":"https://zhanghuimeng.github.io/tags/Github/"},{"name":"Spokes","slug":"Spokes","permalink":"https://zhanghuimeng.github.io/tags/Spokes/"}]},{"title":"OSTEP第04章总结：The Abstraction: The Process","slug":"2018-07-04-OSTEP第04章总结：The-Abstraction-The-Process","date":"2018-07-04T01:30:08.000Z","updated":"2018-08-04T19:37:00.000Z","comments":true,"path":"post/ostep-ch-04-summary-the-abstraction-the-process/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-04-summary-the-abstraction-the-process/","excerpt":"","text":"本章课本见http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-intro.pdf。 这一章主要讲了OS的一种基本抽象模型：进程（Process）。 进程的定义 与进程相关的API 进程的创建过程和状态（生命周期） 进程的数据结构（进程控制块和进程状态队列） CPU的虚拟化 我们首先给出一个进程的非正式定义：进程是一个正在运行的程序。 我们通常希望同时运行多个（甚至成百上千个）程序。这样用起来很方便，但是我们遇到的挑战是：如何创造这样由很多个虚拟CPU的假象？ OS通过对CPU进行虚拟化创造这一假象。它不断地运行一个程序，暂停，然后再运行下一个。这被称作CPU的分时共享（time sharing），这种技术允许程序的并发，同时也会牺牲一定的性能，因为一个程序的运行时间肯定会慢得多。 我们可以把实现CPU的虚拟化的过程拆分成两个步骤： 机制（mechanism）：这是实现一种功能的底层方法或协议；如上下文切换（context switch），这是一种分时机制（time-sharing mechanism），用于帮助OS实现暂停一个程序后切换到下一个的功能 策略（policy）：这是利用底层机制，在OS内进行决策的算法；如调度（scheduling）算法会利用历史信息、程序信息和性能评价方式进行决策 这是一种模块化的程序设计思路。不过，本节中我们似乎既没有讲机制也没有讲策略，而是讲了一些抽象内容（进程）的基本概念。 进程的正式定义 上面给出的那个定义是正确的，然而并不全面。如何更具体地描述一个进程？一般来说，我们可以通过记录进程在运行过程中访问或影响的系统部分来描述一个进程。于是我们可以定义进程的机器状态（machine state）： 内存（地址空间）：包含指令和程序读写的数据 寄存器：通用寄存器和一些特殊寄存器，如PC（program counter）和栈指针、帧指针 I/O信息：进程开启的文件列表 与进程相关的API 既然进程是OS为我们提供的一种抽象，那么显然需要一些使用它的方法。因此下面介绍了一些与进程相关的API，一般来说，任何现代OS都提供了这些API： 创建（create）：创建新进程 销毁（destroy）：强制终止进程，对于失控的进程来说是很必要的 等待（wait）：等待其他进程结束运行 其他控制（miscellaneous control）：除了杀死或等待进程以外的控制方式，如将进程挂起后恢复运行的机制 状态（status）：通常会提供一些能够获得进程状态信息的接口，包括运行时间和状态 进程的生命周期 进程的创建过程 为了启动一个进程，OS需要做以下事情： 将程序的代码和静态数据（初始化了的变量）加载到进程地址空间中。通常程序以某种可执行文件格式存储在磁盘（或者SSD）中，所以OS需要从磁盘读取数据。 此时有一个加载策略的选择问题：积极加载（eager load）还是懒惰加载（lazy load） 积极加载：将所有代码和数据在运行之前就全部装入内存中，是早期和简单OS的做法 懒惰加载：用到对应的代码和数据时才加载，是现代OS的做法。 这个问题与分页（paging）和交换（swapping）有关，之后还会谈到。 为程序的运行栈分配内存；对栈进行初始化（比如把main函数的argc和argv放进去） 为程序的堆分配内存。堆用于在程序运行中动态分配内存，程序调用malloc()请求内存，调用free()释放内存。 对I/O进行初始化：对于类UNIX系统，每个进程默认有三个打开的文件描述符（file descriptor），用于标准输入、标准输出和标准错误输出，这使得进程能够从终端读入输入并打印到屏幕。我们将在本书的第三部分（持久化）中更多的谈到这个问题。 跳转到main()函数的起始点，将CPU的控制权交给新创建的进程。 进程的状态模型 创建了一个进程之后，它的状态（state）会不断变化。一个简化的进程三状态模型如下： 运行态（running）：进程正在处理器上运行，正在执行指令。 就绪态（ready）：进程已经准备好执行了，但由于某些原因，OS现在并没有运行它。 等待态（blocked）：进程执行了一些操作，使得它不能继续运行，直到发生某些其他事件为止。例如，进程启动对磁盘的I/O请求时，它就被阻塞了，此时其他的进程可以使用处理器。 上图说明了这个简化模型中进程如何在状态间迁移： OS可以通过调度使进程在运行态和就绪态之间转换 如果进程进入了等待态，则只有对应的事件发生时才会进入就绪态 下面举两个例子进行说明。在第一个例子中，两个进程只使用CPU而不进行I/O；调度策略是进程0执行完之后进程1才能开始执行。 在第二个例子中，进程会进行I/O操作。当进程0进行I/O之后，它进入阻塞状态。于是进程1开始运行。进程0的I/O完成之后，它进入就绪态，等待进程1执行结束之后继续执行。 事实上，在上述过程中，OS采用了以下两种策略： 在进程0进行I/O时切换到进程1：这个决策看起来是明智的，因为可以增加CPU使用率 在进程0的I/O操作结束之后，没有立即切换回切换0：这个策略的好坏很难说 （上述内容将出现在作业中） 进程的数据结构 上面的内容可以说是非常抽象了。所以下面会讲到，这些抽象的内容如何用OS中具体的数据结构来表示。 进程控制块 我们把进程信息对应的数据结构称为进程控制块（Process Control Block，PCB）。下面是xv6教学OS中一个实际的进程控制块的定义（也就是说，会涉及大量底层机制内容）： 1234567891011121314151617181920212223242526272829303132333435// the registers xv6 will save and restore// to stop and subsequently restart a processstruct context &#123; int eip; int esp; int ebx; int ecx; int edx; int esi; int edi; int ebp;&#125;;// the different states a process can be inenum proc_state &#123; UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE &#125;;// the information xv6 tracks about each process// including its register context and statestruct proc &#123; char *mem; // Start of process memory uint sz; // Size of process memory char *kstack; // Bottom of kernel stack // for this process enum proc_state state; // Process state int pid; // Process ID struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for the // current interrupt&#125;; 下面对其中一些比较重要的内容给出说明。首先可以看到，context中存储了通用寄存器的内容，用于上下文切换（保存一个暂停的进程的寄存器的值；在进程恢复运行时，这些值将被重新加载到寄存器中），这是之前讲到的。其次可以发现，这里定义了6种状态，和之前讲到的三状态模型不完全相符（这可能也体现了抽象策略和底层机制的区别）。除了运行态、就绪态和等待态以外，此处还定义了其他的状态，如初始（initial）态（进程刚被创建时的状态，对应的大概是上述代码中的EMBRYO态）和终止（final）态（进程已经退出，但尚未被完全清理，在类UNIX系统中，这一状态被称为僵尸（zombie）态）。进入终止态的进程允许其他进程（通常是创建这个进程的父进程）检查进程的返回值，查看它是否成功结束。父进程在自己结束之前会执行最后一个调用（wait()），等待子进程执行完成（进入终止态），此时OS可以清理子进程相关的数据结构。 （我不知道我有没有理解清楚关于僵尸态的内容） 进程状态队列 为了管理进程的状态，OS会维护一些进程状态队列，用来跟踪就绪进程、正在运行的进程和阻塞进程，并且在发生事件的时候唤醒正确的进程。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第03章总结：A Dialogue on Virtualization","slug":"2018-07-03-OSTEP第03章总结：A-Dialogue-on-Virtualization","date":"2018-07-03T01:46:29.000Z","updated":"2018-08-04T19:37:00.000Z","comments":true,"path":"post/ostep-ch-03-summary-a-dialogue-on-virtualization/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-03-summary-a-dialogue-on-virtualization/","excerpt":"","text":"本章课本见http://pages.cs.wisc.edu/~remzi/OSTEP/dialogue-virtualization.pdf。 这篇对话是本书第一部分——虚拟化（Virtualization）——的开头，简单叙述了一下虚拟化的概念。 Professor教授（我今后就这样叫他了，毕竟这位教授的名字就是“Professor”）举了一个这样的例子：假设我们有一个物理的桃子，有很多人都想吃桃子，但桃子只有一个，不能满足所有人的需求。于是我们通过某种神奇的技术，在物理桃子的基础上创造出许多虚拟桃子，仿佛每个人都拥有自己的桃子一般，但事实上只有一个桃子。 这时Student学生（同理）提了一个很好的问题：如果很多人同时共享一个桃子，他们应该会注意到这一点。Professor教授指出，这些人大部分时间都在干别的，所以把桃子直接拿走是完全可行的。 Student学生要求Professor教授举一个具体的例子——那就PCU吧。假定系统里有一个物理CPU，虚拟化技术使得系统里好像有很多虚拟CPU在同时运行。每个进程都认为它独占了一个虚拟CPU，而实际上只有一个物理CPU。OS的工作就是将实际的CPU进行虚拟化。 最后Professor教授表示，今后不会再有这么多桃子的例子，因为他自己也不是很喜欢吃桃子。（但是作者很喜欢吧？） 我很想探讨一下这个故事中的比喻到底指代的什么。桃子当然指的是被虚拟化后共享的资源——除了物理CPU之外，物理内存也被进程这样共享。不过桃子和CPU相比有一个小问题：桃子是会被吃完的，也就是说，这是一种不可再生资源，和CPU可以不断重复利用的性质不同。那我们就当这些食客只是在舔桃子好啦…… 所谓“很多人同时共享一个桃子会被注意到”也许只是Student学生随口一说的结果，但我觉得这一点说的更像是同步互斥问题。毕竟进程没有思想和感受，它们之间一般是相互隔离的，所谓“注意到”必然是进程通信或共享资源的结果，而这种时候是一定会出现同步互斥问题的。但是，如果这样认为，Professor教授给出的解决方案就有点儿怪了——这些人大部分时间都在干别的？我想这说的是CPU运行进程和设备I/O的并行化——I/O需要的时间很多，所以在需要进行I/O时，进程就主动放弃控制权，切换别的进程来继续占用CPU。这一点当然很好，不过好像并不能解决同步互斥问题。 不过这也并没有那么重要，希望Professor教授和Student在书里过得开心，吃点自己想吃的水果好啦。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第02章总结：Introduction to Operating Systems","slug":"2018-07-01-OSTEP第02章总结：Introduction-to-Operating-Systems","date":"2018-07-01T16:09:21.000Z","updated":"2018-08-04T19:37:00.000Z","comments":true,"path":"post/ostep-ch-02-summary-introduction-to-operating-systems/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-02-summary-introduction-to-operating-systems/","excerpt":"","text":"本章课本见http://pages.cs.wisc.edu/~remzi/OSTEP/intro.pdf。 这一章对全书内容做了一些简单的概括： 用三个程序概括了本书将讲到的三个基本概念（虚拟化、并发、持久化） 讲了一些OS的设计目标和OS的历史 基本概念概述 虚拟化 虚拟化是本书第一部分的主题。 CPU的虚拟化 1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;common.h&quot;int main(int argc, char *argv[]) &#123; if (argc != 2) &#123; fprintf(stderr, &quot;usage: cpu &lt;string&gt;\\n&quot;); exit(1); &#125; char *str = argv[1]; while (1) &#123; printf(&quot;%s\\n&quot;, str); Spin(1); &#125; return 0;&#125; 上述程序中调用的Spin()函数（具体程序见本章附带的代码）会在运行1秒后返回。这个程序会不断运行，每秒输出一个A，如下： 12345678prompt&gt; gcc -o cpu cpu.c -Wallprompt&gt; ./cpu &quot;A&quot;AAAAˆCprompt&gt; 如果同时运行不同的程序实例，CPU会不断在程序之间切换，使得每个程序都认为自己独占了CPU，这被称为CPU的虚拟化。 123456789101112131415161718prompt&gt; ./cpu A &amp; ; ./cpu B &amp; ; ./cpu C &amp; ; ./cpu D &amp;[1] 7353[2] 7354[3] 7355[4] 7356ABDCABDCACBD... 而OS选择什么程序来运行是一种策略，之后我们会学到相关内容（进程调度）。 内存的虚拟化 1234567891011121314151617181920212223242526272829#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;#include &quot;common.h&quot;intmain(int argc, char *argv[])&#123; if (argc != 2) &#123; fprintf(stderr, &quot;usage: mem &lt;value&gt;\\n&quot;); exit(1); &#125; int *p; // memory for pointer is on &quot;stack&quot; p = malloc(sizeof(int)); // malloc&apos;d memory is on &quot;heap&quot; assert(p != NULL); printf(&quot;(pid:%d) addr of p: %llx\\n&quot;, (int) getpid(), (unsigned long long) &amp;p); printf(&quot;(pid:%d) addr stored in p: %llx\\n&quot;, (int) getpid(), (unsigned long long) p); *p = atoi(argv[1]); // assign value to addr stored in p while (1) &#123; Spin(1); *p = *p + 1; printf(&quot;(pid:%d) value of p: %d\\n&quot;, getpid(), *p); &#125; return 0;&#125; 现代机器的内存模型就是一个数组，读写都需要给出地址。 上述程序所做的事很简单： 分配一些内存 打印内存的地址，以及程序的PID 将数0放入新分配的内存的第一个位置（4字节的int）中 循环，将p中存储的值+1 运行结果如下： 12345678prompt&gt; ./mem(2134) address pointed to by p: 0x200000(2134) p: 1(2134) p: 2(2134) p: 3(2134) p: 4(2134) p: 5ˆC 如果仍然同时运行几个程序的实例，则会发现，每个程序都在同一地址处分配内存，而且对这一内存处存储的值的更新是相互独立的。 1234567891011121314prompt&gt; ./mem &amp;; ./mem &amp;[1] 24113[2] 24114(24113) address pointed to by p: 0x200000(24114) address pointed to by p: 0x200000(24113) p: 1(24114) p: 1(24114) p: 2(24113) p: 2(24113) p: 3(24114) p: 3(24113) p: 4(24114) p: 4... 这说明OS对内存进行了虚拟化，每个进程访问的是自己的虚拟地址空间。 并发 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;common_threads.h&quot;volatile int counter = 0;int loops;void *worker(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; counter = counter + 1; &#125; pthread_exit(NULL);&#125;int main(int argc, char *argv[]) &#123; if (argc != 2) &#123; fprintf(stderr, &quot;usage: threads &lt;loops&gt;\\n&quot;); exit(1); &#125; loops = atoi(argv[1]); pthread_t p1, p2; printf(&quot;Initial value : %d\\n&quot;, counter); Pthread_create(&amp;p1, NULL, worker, NULL); Pthread_create(&amp;p2, NULL, worker, NULL); Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(&quot;Final value : %d\\n&quot;, counter); return 0;&#125; 这一程序通过调用Pthread_create创建了两个线程，分别将一个计数器自增N次，然后将计数器的结果输出。显然，正常情况下程序输出应该为2N。 1234prompt&gt; gcc -o thread thread.c -Wall -pthreadprompt&gt; ./thread 1000Initial value : 0inal value : 2000 但如果两个线程执行的次数N比较大，则程序的输出可能不再会为2N，而且会不太稳定。这是由于+1的操作不是原子的。 123456prompt&gt; ./thread 100000Initial value : 0Final value : 143012 // huh??prompt&gt; ./thread 100000Initial value : 0Final value : 137298 // what the?? 这体现了并发中可能出现的一些问题，我们将要在本书的第二部分讲到这些问题。 持久化 123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/types.h&gt;#include &lt;string.h&gt;void do_work() &#123; int fd = open(&quot;/tmp/file&quot;, O_WRONLY | O_CREAT | O_TRUNC, S_IRUSR | S_IWUSR); assert(fd &gt;= 0); char buffer[20]; sprintf(buffer, &quot;hello world\\n&quot;); int rc = write(fd, buffer, strlen(buffer)); assert(rc == strlen(buffer)); printf(&quot;wrote %d bytes\\n&quot;, rc); fsync(fd); close(fd);&#125;int main(int argc, char *argv[]) &#123; do_work(); return 0;&#125; 上述代码会创建文件/tmp/file，并在里面写入字符串hello world。 内存是一种易失性存储，所以需要能够持续性地存储程序的硬件和软件，也就是硬盘（SSD）和文件系统。 和虚拟化的内存地址空间相比，因为用户通常会使用文件来共享信息，所以OS并不会为每个应用进程创建虚拟化的磁盘。OS向硬盘写数据的过程是十分复杂的，但OS对此进行了抽象，可以通过系统调用来访问设备。因此OS可以被看成是一个标准库。 OS的设计目标 抽象：使系统更易用 高性能 保护：在应用程序之间，以及应用程序和系统之间提供保护和隔离 可靠性 节能、安全性、可移动性…… OS的历史 早期操作系统（大型机批处理系统）：基本只是标准库，需要操作员参与管理 中期操作系统：提供了文件系统和保护机制，系统调用和硬件特权级的概念出现了 多道程序系统：内存保护和并发的概念 现代操作系统：……","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第01章总结：A Dialogue on the Book","slug":"2018-07-01-OSTEP第01章总结：A-Dialogue-on-the-Book","date":"2018-07-01T16:03:36.000Z","updated":"2018-08-04T19:37:00.000Z","comments":true,"path":"post/ostep-ch-01-summary-a-dialogue-on-the-book/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-01-summary-a-dialogue-on-the-book/","excerpt":"","text":"本章课本见http://pages.cs.wisc.edu/~remzi/OSTEP/dialogue-virtualization.pdf。 这是全书开头的第一章，奠定了全书逗比的基调（雾）。这一章主要只是用来扯皮的，真正的介绍性内容在下一章。 本章讲述了一位叫“Professor”的教授和一位叫“Student”的学生的故事。 Professor指出，“Three Easy Pieces”这个题目是为了致敬费曼的“Six Easy Pieces”这本书。因为操作系统只有物理学的一半那么难，所以核心概念也只有物理学的一半那么多。（真的吗？） 我们将要讲授的3个核心概念是：虚拟化（virtualization），并发（concurrency）和持久化（persistence）。 我们将要学到OS如何工作，具体内容包括： OS如何决定下一个将在CPU上运行的是什么程序 如何在虚拟内存系统中处理内存过载 如何管理磁盘上的信息 如何建立一个可靠的分布式系统 等等 Professor对学习者的建议： 上课，听讲 每周结束时读这本书 考试之前再读一遍书（虽然可能我没有那么多的时间，我就没有） 做教授留的作业和项目 Professor：“不闻不若闻之，闻之不若见之，见之不若知之，知之不若行之；学至于行之而止矣。”（荀子《儒效篇》）","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"Miller-Rabin素性检测的原理与实现","slug":"2018-06-29-Miller-Rabin素性检测的原理与实现","date":"2018-06-29T18:34:39.000Z","updated":"2018-09-12T19:55:00.000Z","comments":true,"path":"post/the-principles-and-implementation-of-miller-rabin-primality-test/","link":"","permalink":"https://zhanghuimeng.github.io/post/the-principles-and-implementation-of-miller-rabin-primality-test/","excerpt":"","text":"Miller-Rabin素性检测的原理 按维基百科的说法，这个算法似乎本来是一个依赖于广义黎曼假设的确定性算法，后来经过改造，变成了一个依赖于二次剩余理论的非确定性算法。不过这个地方我也还没有完全搞懂，再说吧。 当然，即使不从历史角度出发，也是能比较清楚地搞懂这个算法的思路来源的。下面的介绍参考了相关的维基百科。[1] 首先介绍一个引理。12 mod p1^2 \\bmod p12modp和(−1)2 mod p(-1)^2 \\bmod p(−1)2modp总是得到1，我们称这两个数为1的“平凡平方根”。引理的内容是：当ppp为素数且p&gt;2p&gt;2p&gt;2时，不存在1 mod p1 \\bmod p1modp的“非平凡平方根”。为了证明该引理，我们假设xxx是1 mod p1 \\bmod p1modp的平方根，于是有 x2≡1( mod p)x^2 \\equiv 1 (\\bmod p) x2≡1(modp) (x+1)(x−1)≡0( mod p)(x + 1)(x - 1) \\equiv 0 (\\bmod p) (x+1)(x−1)≡0(modp) 也就是说，(x−1)(x+1)(x - 1)(x + 1)(x−1)(x+1)能够被素数ppp整除。根据欧几里得引理，必有ppp能够整除x−1x-1x−1或x+1x+1x+1，即x≡1( mod p)x \\equiv 1 (\\bmod p)x≡1(modp)或x≡−1( mod p)x \\equiv -1 (\\bmod p)x≡−1(modp)。因此，1 mod p1 \\bmod p1modp的平方根均为ppp的平凡平方根，引理得证。 下面我们进行一个信仰之跃，介绍Miller-Rabin算法的思路。假设nnn是一个奇素数，且n&gt;2n &gt; 2n&gt;2，此时n−1n - 1n−1必然为一个偶数，可以被表示为2s×d2^s \\times d2s×d的形式，其中sss和ddd均为正整数，且ddd是奇数。由费马小定理，对于一个素数nnn，有 an−1≡1( mod n)a^{n-1} \\equiv 1 (\\bmod n) an−1≡1(modn) 因此 a2sd≡1( mod n)a^{2^s d} \\equiv 1 (\\bmod n) a2sd≡1(modn) 由上述引理，我们可以对上式取平方根，得到的必然为平凡平方根1或-1。假如我们得到的平方根为1，则继续取平方根，如此循环，最后必然会得到下列两种情况之一： 得到某个0≤r≤s−10 \\leq r \\leq s -10≤r≤s−1，它满足a2rd≡−1( mod n)a^{2^r d} \\equiv -1 (\\bmod n)a2rd≡−1(modn) 发现对于任意0≤r≤s−10\\leq r \\leq s -10≤r≤s−1，都满足a2rd≡1( mod n)a^{2^r d} \\equiv 1 (\\bmod n)a2rd≡1(modn)，即ad≡1( mod n)a^d \\equiv 1 (\\bmod n)ad≡1(modn) Miller-Rabin素性检测就是上述原理的逆否：如果我们能找到这样一个aaa，使得对任意0≤r≤s−10 \\leq r \\leq s - 10≤r≤s−1，都满足以下两个式子： a2rd≡1( mod n)a^{2^r d} \\not\\equiv 1 (\\bmod n) a2rd​≡1(modn) ad≡1( mod n)a^d \\not\\equiv 1 (\\bmod n) ad​≡1(modn) 则nnn必然不是一个素数。我们用记号Wn(a)W_n(a)Wn​(a)表示aaa满足上述条件，称aaa是nnn为合数的一个凭证（witness to the compositeness of n）。 Miller-Rabin素性检测的算法伪代码 下面给出一种Miller-Rabin素性检测的算法伪代码。[2] 123456789101112Miller-Rabin(n) 把n-1写成n-1 = 2^k * m，其中m是一个奇数 选取随机整数a，使得1 &lt;= a &lt;= n-1 b = a^m (mod n) if b == 1 (mod n) return (&quot;n is prime&quot;) for i = 0 to k-1 if b == -1 (mod n) return (&quot;n is prime&quot;) else b = b^2 (mod n) return (&quot;n is composite&quot;) Miller-Rabin算法的正确性 上述证明虽然说明了Miller-Rabin算法能够在某些情况下证明nnn不是一个素数，但并没有证明这个算法对于素数不会做出错误判断，也没有说明这个算法能够给出正确判断的概率。事实上，上述算法是一个偏是的Monte-Carlo算法，且错误概率至多为14\\frac{1}{4}41​。 下面首先说明什么是“偏是的Monte-Carlo算法”（定义摘自[2]）。第一个问题是，何为判定问题和随机算法？ 一个判定问题（decision problem）是指只能回答“是（yes）”或者“否（no）”的问题。一个随机算法是指任一使用了随机数的算法（反过来，一个算法没有使用随机数，称为确定的算法）。 下面是对“判定问题的随机算法”的定义。 对于一个判定问题的一个偏是（yes-biased）Monte Carlo算法是具有下列性质的一个概率算法：一个“是”回答总是正确的，但一个“否”回答也许是不正确的。类似地，可定义一个偏否的（no-biased）Monte Carlo算法。我们说一个偏是Monte Carlo算法具有错误概率ϵ\\epsilonϵ，如果算法对任何回答应该为“是”的实例（instance）至多以ϵ\\epsilonϵ的概率给出一个不正确的回答“否”（这个概率是对于给定的输入，通过算法产生所有可能的随机选择进行计算而得出的）。 我们要回答的判定问题是这样的：给定一个正整数n≥2n \\geq 2n≥2，问nnn是一个合数吗？ 证明Miller-Rabin算法是一个偏是的Monte Carlo算法 使用反证法证明这一结论：假定上述算法对于某个素数nnn回答了“nnn为合数”，然后推出矛盾。由于算法回答“nnn为合数”，必有am≡1( mod n)a^m \\not\\equiv 1 (\\bmod n)am​≡1(modn)。现在考虑在算法中检测的bbb的序列。由于bbb在for循环的每一步中都做平方运算，因此我们测试的值序列为am,a2m,a2(k−1)ma^m, a^{2m}, a^{2^{(k-1)}m}am,a2m,a2(k−1)m。由于算法回答“nnn为合数”，可知对于0≤i≤k−10 \\leq i \\leq k-10≤i≤k−1，都满足： a2im≡−1( mod n)a^{2^i m} \\not\\equiv -1 (\\bmod n) a2im​≡−1(modn) 由于我们假设nnn为素数，由于n−1=2kmn - 1 = 2^k mn−1=2km，由费马小定理可知： a2km≡1( mod n)a^{2^k m} \\equiv 1 (\\bmod n) a2km≡1(modn) 因此a2k−1ma^{2^{k-1}m}a2k−1m是模nnn的1的平方根。由于nnn为素数，由引理可知，模nnn的1的平方根只有两个，即±1 mod n\\pm 1 \\bmod n±1modn。由算法执行过程，我们可以知道： a2k−1m≡−1( mod n)a^{2^{k-1} m} \\not\\equiv -1 (\\bmod n) a2k−1m​≡−1(modn) 由此可得 a2k−1m≡1( mod n)a^{2^{k-1} m} \\equiv 1 (\\bmod n) a2k−1m≡1(modn) 因此a2k−2ma^{2^{k-2}m}a2k−2m是模nnn的1的平方根。以此类推，重复上述过程，我们最后可以得到： am≡1( mod n)a^m \\equiv 1 (\\bmod n) am≡1(modn) 但在这种情况下，算法一开始就会回答“nnn为素数”，因此推出矛盾。 （好吧，其实我们并不是很需要这个证明，我只是把《密码学原理与实践》上的证明又抄了一遍而已……） 证明Miller-Rabin的错误概率不大于1/4 Rabin在1977年的论文[3]中证明了下列定理：若nnn为大约4的合数，则有 3(n−1)4≤c(b∣Wn(b))\\frac{3(n-1)}{4} \\leq c({b | W_n(b)}) 43(n−1)​≤c(b∣Wn​(b)) 其中Wn(b)W_n(b)Wn​(b)的意思上面已经讲过了，表示bbb是nnn为合数的一个凭证；c(S)c(S)c(S)表示集合SSS中元素的数目。上述定理表明，在[1,n−1][1, n-1][1,n−1]的整数中，最多只有14(n−1)\\frac{1}{4}(n-1)41​(n−1)个数不是nnn为合数的凭证。因此，在[1,n−1][1, n-1][1,n−1]中任选整数aaa进行测试，能够测试出nnn为合数的概率≤34\\leq \\frac{3}{4}≤43​，即Miller-Rabin算法的错误概率不大于14\\frac{1}{4}41​。（证明太长了，懒得看也懒得写了，总之论文里什么都有） 我们可能因此认为，连续对某个合数nnn进行NNN次测试，无法发现nnn为合数的概率小于(14)N(\\frac{1}{4})^N(41​)N。这个界当然是正确的，但它并不紧。事实上，有人[4]证明了更紧的界：如果我们不断随机选取kkk位（二进制位）的奇数，对这个数进行ttt次互相独立的随机Miller-Rabin检测，，输出第一个通过所有测试的数，令pk,tp_{k, t}pk,t​表示这个数是合数的概率，则pk,tp_{k, t}pk,t​比4−t4^{-t}4−t小得多。事实上，pk,tp_{k, t}pk,t​满足下列公式： k≥2k \\geq 2k≥2时，pk,t&lt;k242−kp_{k, t} &lt; k^2 4^{2 - \\sqrt{k}}pk,t​&lt;k242−k​ t=2,k≥88t = 2, k \\geq 88t=2,k≥88或3≤t≤k/9,k≥213 \\leq t \\leq k/9, k \\geq213≤t≤k/9,k≥21时，pk,t&lt;k3/22tt−1/242−tkp_{k, t} &lt; k^{3/2} 2^t t^{-1/2} 4^{2 -\\sqrt{tk}}pk,t​&lt;k3/22tt−1/242−tk​ t≥k/9,k≥21t \\geq k/9, k \\geq 21t≥k/9,k≥21时，pk,t&lt;720k2−5t+17k15/42−k/2−2t+12k2−k/4−3tp_{k, t} &lt; \\frac{7}{20} k 2^{-5t} + \\frac{1}{7} k^{15/4} 2^{-k/2 - 2t} + 12k 2^{-k/4 - 3t}pk,t​&lt;207​k2−5t+71​k15/42−k/2−2t+12k2−k/4−3t t≥k/4,k≥21t \\geq k/4, k \\geq 21t≥k/4,k≥21时，pk,t&lt;17k15/42−k/2−2tp_{k, t} &lt; \\frac{1}{7} k^{15/4} 2^{-k/2 -2t}pk,t​&lt;71​k15/42−k/2−2t Miller-Rabin算法的实现 实际上这是今年密码学的最后一个编程作业：要求生成若干个512bit的奇数并用Miller-Rabin算法验证它们是否为素数，可以用2000以下的素数进行试除。代码见https://gist.github.com/zhanghuimeng/e2305a5324c6705f4eba9d94f7308769。 选择python进行程序编写是因为python自带长整型功能，很方便。但是仍然有一些需要注意的地方，比如除法的精度[5]，我在这里debug了一段时间。如果需要验证自己生成的素数的正确性，可以参考这个网站[6]，可以检测很大（512bit是可以的，再大没试过）的数的素性。 如果我们把这个验证问题看做是“不断生成长度为512bit的奇数并进行验证，直到得到一个素数为止；之后重新进行这一实验”的过程，则可以应用论文[4]中给出的界： 3≤t≤k/9,k≥213 \\leq t \\leq k/9, k \\geq213≤t≤k/9,k≥21时，pk,t&lt;k3/22tt−1/242−tkp_{k, t} &lt; k^{3/2} 2^t t^{-1/2} 4^{2 -\\sqrt{tk}}pk,t​&lt;k3/22tt−1/242−tk​ 当k=512k = 512k=512时，对于几个比较小的ttt，可以计算出上述概率界： ttt pk,tp_{k, t}pk,t​ 3 2.1713×10−182.1713 \\times 10^{-18}2.1713×10−18 4 8.4138×10−228.4138 \\times 10^{-22}8.4138×10−22 5 9.1537×10−259.1537 \\times 10^{-25}9.1537×10−25 6 2.0681×10−272.0681 \\times 10^{-27}2.0681×10−27 7 8.1180×10−308.1180 \\times 10^{-30}8.1180×10−30 8 4.9304×10−324.9304 \\times 10^{-32}4.9304×10−32 9 4.2755×10−344.2755 \\times 10^{-34}4.2755×10−34 10 4.9937×10−364.9937 \\times 10^{-36}4.9937×10−36 11 7.5175×10−387.5175 \\times 10^{-38}7.5175×10−38 12 1.4097×10−391.4097 \\times 10^{-39}1.4097×10−39 13 3.2047×10−413.2047 \\times 10^{-41}3.2047×10−41 可以看出，取n=13n = 13n=13已经能够保证错误概率&lt;10−40&lt; 10^{-40}&lt;10−40了。事实上，计算机发生随机错误的概率大约是1.8×10−241.8 \\times 10^{-24}1.8×10−24，再增加迭代次数，将Miller-Rabin算法的准确度提得更高并无意义。[7] 参考文献 [1] 米勒-拉宾素性检验. https://zh.wikipedia.org/wiki/米勒-拉宾检验 [2] 《密码学原理与实践》第二版 P154 5.4 素性检测. [3] Probabilistic Algorithm for Testing Primality. https://ac.els-cdn.com/0022314X80900840/1-s2.0-0022314X80900840-main.pdf?_tid=a83dac24-31c7-42a4-bb29-f9ef85871027&amp;acdnat=1530269388_63d4d83bf5a9aebc8c2ddf333f080240 [4] Average case error estimates for the strong probable prime test. https://www.math.dartmouth.edu/~carlp/PDF/paper88.pdf [5] How to get the correct accuracy with big integer division in python. https://stackoverflow.com/questions/42709746/how-to-get-the-correct-accuracy-with-big-integer-division-in-python [6] Integer factorization calculator. https://alpertron.com.ar/ECM.HTM [7] RSA and prime-generator algorithms. https://stackoverflow.com/questions/4159333/rsa-and-prime-generator-algorithms/4160517#4160517","categories":[],"tags":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://zhanghuimeng.github.io/tags/Cryptography/"}]},{"title":"《英诗金库》I-54：Art thou poor, by T. Dekker","slug":"2018-06-26-《英诗金库》I-54：Art-thou-poor-by-Thomas-Dekker","date":"2018-06-26T17:01:34.000Z","updated":"2018-06-26T17:01:34.000Z","comments":true,"path":"post/art-thou-poor-by-t-dekker/","link":"","permalink":"https://zhanghuimeng.github.io/post/art-thou-poor-by-t-dekker/","excerpt":"","text":"作品基本信息 作品名称：The Happy Heart（称心满意） 作者：Thomas Dekker（托马斯·德克尔） 出版年代：1603 编注：德克尔（Thomas Dekker，1570?-1632），英国剧作家及散文家。这首诗选自他的喜剧《能忍受考验的格里丝尔》[1]。 作品原文 Art thou1 poor, yet hast thou golden slumbers? O sweet content! Art thou rich, yet is thy mind perplexed? O punishment! Dost thou laugh to see how fools are vexed To add to golden numbers2, golden numbers? O sweet content! O sweet, O sweet content! Work apace, apace, apace, apace; Honest labour bears a lovely face; Then hey nonny nonny, hey nonny nonny! Canst drink the waters of the crisped3 spring? O sweet content! Swimm’st thou in wealth, yet sink’st in thine own tears? O punishment! Then he that patiently want’s burden bears No burden bears, but is a king, a king! O sweet content! O sweet, O sweet content! Work apace, apace, apace, apace; Honest labour bears a lovely face; Then hey nonny nonny, hey nonny nonny! 译文 戴镏龄 译 你没有钱，却睡得甜丝丝？ 哦，知足常乐！ 你富裕，莫非却惶惑不安？ 哦，惩罚谴责！ 愚人为钱上堆钱而忧烦， 你看见是不是觉得这可笑？ 哦，知足常乐，知足常常乐！ 加快工作呀，加快，加快， 认真干活，就面容可爱； 啷哩，咳，啷哩，咳，啷哩啊啷哩！ 泉水涟漪，将它酌来品尝？ 哦，知足常乐！ 钱里翻滚，又泪水中浸泡？ 哦，惩罚谴责！ 贫穷的担子咬紧牙根挑， 这种人没负担，是南面王！ 哦，知足常乐，知足常常乐！ 加快工作呀，加快，加快， 认真干活，就面容可爱； 啷哩，咳，啷哩，咳，啷哩啊啷哩！ 我的感想 在Prothalamion那里卡了得有一个多月了，除了很忙之外，主要还是因为这首诗太长，读不完。所以先从下一首开始了。 有人（Amy Marcy Cheney Beach）曾经把这首歌改编成曲子。Youtube上有这首歌的演唱版本[2]，好像还不难听。不过更神奇的是，我发现这首歌曾经被Beatles（或者更准确的说是Paul McCartney）改编成一首叫&quot;Golden Slumbers / Carry That Weight / The End&quot;的歌，真是令人惊讶…… 好吧，其实看了这首诗，我心里还是挺不舒服的，不知道是当时的作者太不食人间烟火，还是现代社会已经彻底的变了。至少现在人们已经不喜欢“没有钱，却睡得好”这种说法了，没有钱，必定要天天焦虑，日日焦虑；而有了钱，心里就有了底气，可以每日睡得安稳了（虽然可能还是会焦虑自己的钱不如别人多）。（我不是说别人，我就是说“新世相”那个公众号） 所以Beatles改编的歌词还是很棒啊……至少感觉稍微更加温暖一些。 Once there was a way, To get back homeward. Once there was a way To get back home. Sleep, pretty darling, Dot not cry And I will sing a lullaby. Golden slumbers, Fill your eyes Smiles await you when you rise Sleep pretty darling Do not cry And I will sing a lullaby. Once there was a way To get back homeward Once there was a way To get back home Sleep, pretty darling Do not cry And I will sing a lullaby. Once, there was a way to get back homeward Once, there was a way to get back home Sleep, pretty darling, do not cry And I will sing a lullaby Boy, you’re going to carry that weight, Carry that weight a long time Boy, you’re going to carry that weight Carry that weight a long time I never give you my pillow I only send you my invitations And in the middle of the celebrations I break, I break, I break down Boy, you’re going to carry that weight Carry that weight a long time Boy, you’re going to carry that weight Carry that weight a long time Once, there was a way to get back homeward Once, there was a way to get back home Sleep, pretty darling, do not cry And I will sing a lullaby 参考文献 [1] Patient Grissel. https://en.wikipedia.org/wiki/Patient_Grissel [2] O Sweet Content. https://www.youtube.com/watch?v=nyu1nTkqxiE [3] Golden Slumbers / Carry That Weight / The End. https://www.youtube.com/watch?v=6qrDlRsARwk 脚注 1thou: i.e. the reader; the second and fourth lines are exclamations, not addresses.（“你”指的是读者；第二行和第四行是感叹，不是对读者说的话。） 2golden numbers: ‘large sums of gold.’（很多金钱。） 3crisped: lit. ‘curled,’ so ‘ruffled.’（卷曲而褶皱的。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"},{"name":"T.Dekker","slug":"T-Dekker","permalink":"https://zhanghuimeng.github.io/tags/T-Dekker/"}]},{"title":"《系统分析与控制》第一章习题","slug":"2018-06-22-《系统分析与控制》第一章习题","date":"2018-06-22T13:41:30.000Z","updated":"2018-06-22T13:41:30.000Z","comments":true,"path":"post/system-analysis-and-control-chapter-1-exercise/","link":"","permalink":"https://zhanghuimeng.github.io/post/system-analysis-and-control-chapter-1-exercise/","excerpt":"","text":"本章内容 这一章的内容可以说是比较简单的。习题已经概括了绝大多数的概念，因此不再赘述了。 习题 1 什么是开环控制、闭环控制和复合控制？它们各有什么优缺点？ 若控制器与控制对象之间只有正向作用而没有反向联系，这样的控制过程称为开环控制。开环控制的优点是结构简单、成本低廉、工作稳定；缺点是控制精度不高。 若控制器与控制对象之间既有正向作用又有反向联系，这样的控制过程称为闭环控制。控制对象对控制器的反向作用通常称为反馈，因此闭环控制也称反馈控制。闭环控制的优点是系统响应对外扰和系统参数变化不敏感；缺点是易引起过调，“振荡”和“发散”。 复合控制是将开环控制和闭环控制相结合的一种控制方式。它吸取了两者的长处，从而可达到较高的控制性能。 2 什么叫正反馈？什么叫负反馈？怎样判断反馈的极性？ 负反馈：在反馈控制中，误差的调节作用使得误差减小或消除。 正反馈：在反馈控制中，误差的调节作用使得误差进一步增加。 判断反馈极性的方法：在闭环系统的环路上任取一处a点断开，如下图所示。在断开处a加一小的扰动输入，然后检测或分析在断点的另一端a’所产生的输出信号，如果a’的信号与a点的信号极性相反，则说明原来的连接为负反馈，反之则为正反馈。 3 从功能分，闭环控制系统由哪些基本环节组成？它们各起什么作用？ 给定装置：用来产生参考输入 比较装置：将参考输入与反馈信号进行比较 校正装置：用来改善闭环系统的稳定性和其他性能 放大装置：信号放大及变换 执行装置：具体产生控制作用的装置 控制对象：实际被控过程 量测装置：量测输出量，产生所需要的反馈量 4 什么叫调节系统？什么叫跟踪系统？分别举例予以说明。 调节系统：参考输入为定值或很少变化，性能要求主要是抗干扰。例：温度控制系统，压力控制系统。 跟踪系统：参考输入随时间变化，要求输出量紧紧跟随输入量的变化而变化，同时也要求具有抗干扰性能；又称跟踪系统、随动系统或伺服系统。例：雷达天线跟踪目标的控制系统，弧焊机器人末端跟踪焊缝的控制系统。 5 什么叫有静差？什么叫无静差？分别举例予以说明。 无静差：系统进入稳态后，原理上输出量的稳态误差为零。 有静差：依靠反馈控制只能减小误差而不能完全消除误差。 6 下图为4个控制系统的原理图。 指出系统的控制对象、被控制量、给定量及主要的干扰。 画出系统的原理结构图，并指出各个组成元件的基本职能。 说明如何改变系统的给定量输入。 判断对于给定量输入及主要的干扰是否有静差。 7 下图是一个测量电阻值的平衡电桥，其中R1=R2R_1 = R_2R1​=R2​为已知标准电阻，RRR是可变电阻，RxR_xRx​是待测电阻。电桥的平衡条件是：R1:R2=R:RxR_1 : R_2 = R : R_xR1​:R2​=R:Rx​，这时A、B两点的电位差为0。当电桥不平衡时，检流计G的光点便不指零，这时需改变可调电阻R的滑臂的位置，当G重新指零时表示R=RxR = R_xR=Rx​，于是可以从标尺A上读出RxR_xRx​的电阻值。 现要求将该电桥设计成一个自动平衡电桥，它能根据RxR_xRx​的阻值自动地改变RRR的滑臂的位置，从而达到自动测量电阻的目的。画出它的简化原理图和原理结构图。","categories":[],"tags":[{"name":"SystemAnalysis&Control","slug":"SystemAnalysis-Control","permalink":"https://zhanghuimeng.github.io/tags/SystemAnalysis-Control/"}]},{"title":"《英诗金库》I-30：Like as the waves make towards the pebbled shore, by W. Shakespeare","slug":"2018-05-31-《英诗金库》I-30：Like-as-the-waves-make-towards-the-pebbled-shore-by-W-Shakespeare","date":"2018-05-31T00:00:00.000Z","updated":"2018-06-28T00:31:04.000Z","comments":true,"path":"post/like-as-the-waves-make-towards-the-pebbled-shore-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/like-as-the-waves-make-towards-the-pebbled-shore-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Revolutions（循环） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第六〇首。 作品原文 Like as the waves make towards the pebbled shore, So do our minutes hasten to their end; Each changing place with that which goes before, In sequent1 toil all forwars do contend. Nativity, once in the main of light, Crawls to maturity, wherewith being crown’d, Crooked eclipses 'gainst his glory fight, And Time that gave doth now his gift confound. Time doth transfix the flourish2 set on youth, And delves the parellels in beauty’s brow; Feeds on the rarities of nature’s truth, And nothing stands but for his scythe to mow: And yet, to times in hope3, my verse shall stand Praising thy worth, despite his cruel hand. 译文 梁宗岱 译 象波浪滔滔不息地滚向沙滩： 我们的光阴息息奔赴着终点； 后浪和前浪不断地循环替换， 前推后拥，一个个在奋勇争先。 生辰，一度涌现于光明的金海， 爬行到壮年，然后，既登上极顶， 凶冥的日蚀便遮没它的光彩， 时光又撕毁了它从前的赠品。 时光戳破了青春颊上的光艳， 在美的前额挖下深陷的战壕， 自然的至珍都被它肆意狂啖， 一切挺立的都难逃它的镰刀： 可是我的诗未来将屹立千古， 歌颂你的美德，不管它多残酷！ 我的感想 这又是莎士比亚的常见题材了。人生匆匆流逝，一切美好的事物都会被带走，所以不知道人生的意义在何处。但是歌颂美好事物的诗是永存的。这句话听起来很像陈词滥调，但我现在觉得莎士比亚可能真是这么想的了。 参考文献 脚注 1sequent: ‘following one another.’ （接连发生的。） 2transfix the flourish: ‘pierce through the gloss.’（戳穿了光彩。） 3times in hope: ‘ages yet to come.’（尚未来临的日子。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-31：Farewell! thou art too dear for my possessing, by W. Shakespeare","slug":"2018-05-31-《英诗金库》I-31：Farewell-thou-art-too-dear-for-my-possessing-by-W-Shakespeare","date":"2018-05-31T00:00:00.000Z","updated":"2018-06-28T21:40:42.000Z","comments":true,"path":"post/farewell-thou-art-too-dear-for-my-possessing-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/farewell-thou-art-too-dear-for-my-possessing-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Farewell! thou art too dear for my possessing 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第八七首。译者原有这样的译解：“诗人向爱友告别，并且撤销了他们以前因错误而订的盟约，但诗人似乎仍希望能从这种完全的解约而引起爱友的回心转意。” 作品原文 Farewell! thou art too dear for my possessing, And like enough thou know’st thy estimate: The charter1 of thy worth gives thee releasing; My bonds in thee are all determinate. For how do I hold thee but thy granting? And for that riches where is my deserving? The cause of this fair gift in me is wanting, And so my patent2 back again is swerving. Thyself thou gav’st, thy own worth then not knowing, Or me, to whom thou gav’st it, else mistaking; So thy great gift, upon misprision growing3, Comes home again, on better judgement making. Thus have I had thee as a dream doth flatter; In sleep, a king; but waking, no such matter. 译文 屠岸 译 再会！你太贵重了，我没法保有你， 你也多半明白你自己的价值： 你的才德给予你自由的权利； 我跟你订的盟约就到此为止。 你不答应，我怎能把你占有？ 对于这样的福气，我哪儿相配？ 我没有接受这美好礼物的理由， 给我的特许证因而就掉头而归。 你当时不知道自己的身价有多大， 或者是把我看错了，才给我深情； 所以，你这份厚礼，送错了人家， 终于回家了，算得是明智的决定。 我曾经有过你，象一场阿谀的迷梦， 我在那梦里称了王，醒来一场空。 我的感想 真的好惨。就现代的想法来看，那就是恋爱双方中一方前进得太快了，另一方跟不上；或者说，一方本来是年轻貌美，善解人意的，另一方配不上，却因为种种原因还是在一起了。不相配的人是不可能长久下去的。当然，这样也实在是太自卑了。 当然曾经也是很感动的。把这么优秀的自己送给了我，真是一份重礼啊。总之这首诗苦乐参半，其实也没有想象中那么惨。 最后两句写得很顺耳，节奏很棒。 刚才阅读了一些其他的解读。不过恕我直言，这里的爱人恐怕还是那位可爱的年轻男性。 TODO（我以前写的都是什么破烂解析？） 参考文献 脚注 1charter: properly a written grant of rights by the Sovereign; here his lady’s worth had given her such rights. （实际上是统治者对权利作出的书面保证；此处，这位夫人的价值给了她这样的权力。其实我也没看懂这个注解。） 2patent: a right similarly granted to the exclusive enjoyment of some privilege. 3upon misprision growing: ‘being based upon a misconception of your own value.’ The word is derived from the verb to misprize, and must not be confounded with the legal term misprision (akin to the French méprendre), meaning a wrongful act or omission.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"Wir Sind Helden歌词翻译（1）：Guten Tag & Die Konkurrenz","slug":"2018-05-26-Wir-Sind-Helden歌词翻译（1）：Guten-Tag-Die-Konkurrenz","date":"2018-05-26T01:14:40.000Z","updated":"2018-08-10T22:06:00.000Z","comments":true,"path":"post/wir-sind-helden-song-translation-1-guten-tag-die-konkurrenz/","link":"","permalink":"https://zhanghuimeng.github.io/post/wir-sind-helden-song-translation-1-guten-tag-die-konkurrenz/","excerpt":"","text":"好不容易熬过了操作系统期末考试（虽然考得真的很糟，因为忙于维护博客而忽略了一些重要的知识点，比如RAID之类的，不过毕竟这是自己选择的结果，也没有啥好说的），决定干点轻松愉快的事情——翻译德语歌词！ Wir Sind Helden是一支我相当喜欢的德国乐队。他们已经在2012年宣布无限期停止活动了，但是这并不影响我继续听他们的歌。他们的主唱声音很萌（特别像小姑娘，好萌……），歌曲风格轻快活泼，歌词内容经常令人莫名其妙，和曲风形成了鲜明的对比。 我的德语水平并不怎么样，所以这些歌词都是对着德语原文和英语翻译转译过来的。虽然我希望自己未来还能有时间好好学习德语，但我觉得制约我的翻译的瓶颈实际上是中文水平。 Die Konkurrenz 这首歌的歌词是2017年3月翻译的，稍微有点久远了。谷歌了一下，当时似乎参考了Wir Sind Helden:Die Konkurrenz/en Lyrics的歌词和翻译。 歌词 翻译 Du fährst dein Rad am Straßenrand 你在大马路上骑着自行车 begehrst nicht andrer Weib noch Land 你既不要别人的女人也不要土地 Begehren ist dir einerlei 欲望对你来说毫无意义 Du pfeifst und singst und fühlst dich frei 你吹着口哨唱着歌，感到无比自由 Du pfeifst und singst und fühlst dich frei 你吹着口哨唱着歌，感到无比自由 da zieht wer links an dir vorbei! 突然有人从左边超了你的车 Vorbeiziehen ist mir einerlei “我才不在乎是不是被人超车！” sagst du und wirst ganz blass dabei 你这样说的时候脸色却变白了 Die Konkurrenz schläft nicht (×4) 竞争永不息！(×4) Sag’s mir, Hippiekind! 告诉我，嬉皮小孩 Jetzt stehst du auf dem Dach der Welt 现在你正站在世界之巅 Die Welt hält still und dir gefällt sie 你喜欢这世界停滞不前 Du atmest tief und fühlst dich hier 你深吸一口气，感觉在此处 Du fühlst dich eins mit Welt und dir 你自己和世界合为一体 Du fühlst dich eins mit Welt und hier 你感到和此处的世界合为一体 Steht plötzlich einer neben dir! 突然有人站到了你旁边 Bist eins mit dir und mit der Welt 你本来认为你和世界合为一体 Bis einer sich für einser hält 直到有人硬塞到你们中间 Die Konkurrenz schläft nicht (×4) 竞争永不息！(×4) Sag’s mir, kleiner Punk! 告诉我，小朋克 Da zieht wer links an dir vorbei 有人从左边超了你的车 Sag, was macht das mit dir? （告诉我，你感觉怎么样？） Dem ist dein Pfeifen einerlei 没人真在乎你吹的口哨 Sag was macht das mit dir? （告诉我，你感觉怎么样？） Da steht ein andrer neben dir und fühlt sich eins 有人站到了你旁边，他感到和世界合为一体 Mit dem was deins war 可世界曾是我的 Nicht seins 不是他的 Sag, was macht die Konkurrenz? 告诉我，竞争都做了些什么 Du tust die Arbeit Hand in Hand 你们手拉手地干着活 Seit’ an Seite bestellst das Land 你们肩并肩地犁着地 Am Morgen geht’s einig und früh aus der Falle 你们早晨起床起得又快又早 Und ihr singt: Alle für einen! Einer für Alle 你们唱道：“人人为我，我为人人！” Ihr singt: Alle für einen! Einer für Alle 你们唱道：“人人为我，我为人人！” und dann kommt einer und macht alle Anderen alle 然后有人夺去所有收获，其他人空手而归 Am morgen geht’s eilig und früh aus der Falle 你早晨起床起得又快又早 Und du singst: jetzt bin ich der eine und ihr Anderen seid Alle 你唱道：“人人为的是我，我却不必为人人！” Die Konkurrenz, sie schläft nicht 竞争永不息！ Die Konkurrenz schläft nicht 竞争永不息！ Die Konkurrenz, sie schläft nicht 竞争它永不停息！ 说实话，我对这个翻译还挺满意的，唯一觉得自己傻的一点是，在网易云音乐里上传的版本里，把那些德语歌词中没有体现出来的语气词也给照样翻译出来了，这确实有点尴尬。 一年过去了，现在看到歌词里的“人人为我，我为人人！”，以及“从左边”超车，总觉得有点什么政治隐喻在里面。 Guten Tag 下面这个歌词只是预览版，还没有最后上传，还需要一些修改。 歌词 翻译 Meine Stimme gegen Dein Mobiltelefon 用我的声音换你们的移动电话 Meine Fäuste gegen Eure Nagelpflegelotion 用我的拳头换你们的美甲乳液 Meine Zähne gegen die von Doktor Best und seinem Sohn 用我的牙齿换贝斯特博士的牙齿护理产品 Meine Seele gegen Eure sanfte Epilation 用我的灵魂换你们的无痛脱毛药水 Es war im Ausverkauf im Angebot die Sonderaktion 当时所有的产品都在促销 Tausche blödes altes Leben gegen neue Version 我把愚蠢的旧生活升级成了新版本 Ich hatte es kaum zu Hause ausprobiert da wusste ich schon 结果在家试了几种东西之后我就发现 an dem Produkt ist was kaputt - das ist die Reklamation 你们的产品全都是坏的！我要投诉！ Ich will 我想 Ich tausch nicht mehr ich will mein Leben zurück (×3) 我不要再交换了！我要回到原来的生活！ Guten Tag, ich will mein Leben zurück 你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ Guten Tag ich gebe zu ich war am Anfang entzückt 你好，我承认我开始时被吸引了 aber euer Leben zwickt und drückt nur dann nicht wenn man sich bückt - 可这种扭曲的生活不断逼迫着我屈服于它！ Guten Tag 你好 Meine Stimme gegen die der ganzen Talkshownation 用我的声音换整个国家的脱口秀 Meine Fäuste für ein müdes Halleluja und Bohnen 用我的拳头换疲惫的哈利路亚与豆子 Meine Zähne gegen Eure zahme Revolution 用我的牙齿换你们的“驯服革命” Visionen gegen die totale Television 用我的眼睛换一台电视机 Es war im Ausverkauf im Angebot die Sonderaktion 当时所有的产品都在促销 Tausche blödes altes Leben gegen neue Version 我把愚蠢的旧生活升级成了新版本 Ich hatte es kaum zu Hause ausprobiert da wusste ich schon 结果在家试了几种东西之后我就发现 an dem Produkt ist was kaputt - das ist die Reklamation 你们的产品全都是坏的！我要投诉！ Ich will 我想 Ich tausch nicht mehr ich will mein Leben zurück (×3) 我不要再交换了！我要回到原来的生活！ Guten Tag, ich will mein Leben zurück 你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ Guten Tag ich gebe zu ich war am Anfang entzückt 你好，我承认我开始时被吸引了 aber euer Leben zwickt und drückt nur dann nicht wenn man sich bückt - 可这种扭曲的生活不断逼迫着我屈服于它！ Guten Tag 你好 Mobiltelefon 移动电话 Von Doktor Best und seinem Sohn 贝斯特博士的牙齿护理套装 Sonderaktion 促销 Das ist die Reklamation 这是投诉！ Der ganzen Talkshownation 充满脱口秀的国家 Revolution 革命 Visionen gegen die totale Television 用眼睛换一台电视机 Es war im Ausverkauf im Angebot die Sonderaktion 当时所有的产品都在促销 Tausche blödes altes Leben gegen neue Version 我把愚蠢的旧生活升级成了新版本 Ich hatte es kaum zu Hause ausprobiert da wusste ich schon 结果在家试了几种东西之后我就发现 an dem Produkt ist was kaputt - das ist die Reklamation 你们的产品全都是坏的！我要投诉！ Ich will 我想 Ich tausch nicht mehr ich will mein Leben zurück (×7) 我不要再交换了！我要回到原来的生活！ Guten Tag, ich will mein Leben zurück 你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ (Ich tausch nicht mehr)Guten Tag, guten Tag, ich will mein Leben zurück 你好，你好，我要回到原来的生活！ Guten Tag ich gebe zu ich war am Anfang entzückt 你好，我承认我开始时被吸引了 aber euer Leben zwickt und drückt nur dann nicht wenn man sich bückt - 可这种扭曲的生活不断逼迫着我屈服于它！ Guten Tag (×4) 你好 Guten 你 Tag 好 一些说明： Doktor Best und seinem Sohn似乎是德国一个有名的牙齿护理产品，现在下属于葛兰素史克。于是我翻译成“贝斯特博士”了。 我也不太清楚“Halleluja und Bohnen”到底应该是什么意思。可能和这部电影有关。 zahme Revolution是一本书，作者是Paulus Ebner，但我不太明白这本书说的是什么，以及在这里引用它的意义…… 总的来说，这首歌的语气好像一个人在给某家“公司”打电话投诉，声称现代消费主义带来的生活虽然开始时令人眼花缭乱，但实质上是令人痛苦而迷茫的，因此他要求退货，换回到原来的旧生活。想到这首歌是2003年发布的，不由得有种恍如隔世之感。 可是，还是回不去了啊。","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"},{"name":"Lyric","slug":"Lyric","permalink":"https://zhanghuimeng.github.io/tags/Lyric/"},{"name":"artist:Wir Sind Helden","slug":"artist-Wir-Sind-Helden","permalink":"https://zhanghuimeng.github.io/tags/artist-Wir-Sind-Helden/"}]},{"title":"《操作系统》第14讲：“实验5-用户线程管理”总结","slug":"2018-05-25-《操作系统》第14讲：“实验5-用户线程管理”总结","date":"2018-05-25T01:49:25.000Z","updated":"2018-05-25T01:49:25.000Z","comments":true,"path":"post/os-mooc-lecture-14-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-14-summary/","excerpt":"","text":"课程内容概述 TODO 练习 来自lab5 用户进程 在线练习和lab5 spoc 思考题。 选择填空题 下列叙述中正确的是() lab5建立了用户进程，且0~3GB都是用户可访问空间，用户进程可进行正常读写 lab5建立了用户进程，且3GB~4GB都是内核可访问空间，内核可进行正常读写 lab5中的第一个用户进程是内核创建的。 lab5中的用户进程可通过fork创建新的用户进程。 lab5中建立了用户进程这一点没啥问题。用户和内核可访问的空间这点有问题。简单来说，内核虚拟内存空间处于0xC00000000xF8000000位置（KERNBASEKERNTOP），用户进程可访问的虚拟内存空间位于0x0080000-0xB0000000位置（UTEXTUSERTOP）。 这样ucore把用户进程的虚拟地址空间分了两块，一块与内核线程一样，是所有用户进程都共享的内核虚拟地址空间，映射到同样的物理内存空间中，这样在物理内存中只需放置一份内核代码，使得用户进程从用户态进入核心态时，内核代码可以统一应对不同的内核程序；另外一块是用户虚拟地址空间，虽然虚拟地址范围一样，但映射到不同且没有交集的物理内存空间中。这样当ucore把用户进程的执行代码（ 即应用程序的执行代码） 和数据（ 即应用程序的全局变量等） 放到用户虚拟地址空间中时，确保了各个进程不会“非法”访问到其他进程的物理内存空间。 lab5通过do_execve函数执行新的程序，为此需要完成（） 更新用户进程的context 更新用户进程的代码内容 更新用户进程的数据内容 更新用户进程的页表基址 Lab5中的do_execve函数的主要功能就是，放弃当前程序的一切内存空间等资源，将新的程序填充到自己里面。所以显然上述内容都要更新。 123456789101112131415161718192021222324252627282930313233343536// do_execve - call exit_mmap(mm)&amp;put_pgdir(mm) to reclaim memory space of current process// - call load_icode to setup new memory space accroding binary prog.intdo_execve(const char *name, size_t len, unsigned char *binary, size_t size) &#123; struct mm_struct *mm = current-&gt;mm; if (!user_mem_check(mm, (uintptr_t)name, len, 0)) &#123; return -E_INVAL; &#125; if (len &gt; PROC_NAME_LEN) &#123; len = PROC_NAME_LEN; &#125; char local_name[PROC_NAME_LEN + 1]; memset(local_name, 0, sizeof(local_name)); memcpy(local_name, name, len); if (mm != NULL) &#123; lcr3(boot_cr3); if (mm_count_dec(mm) == 0) &#123; exit_mmap(mm); put_pgdir(mm); mm_destroy(mm); &#125; current-&gt;mm = NULL; &#125; int ret; if ((ret = load_icode(binary, size)) != 0) &#123; goto execve_exit; &#125; set_proc_name(current, local_name); return 0;execve_exit: do_exit(ret); panic(&quot;already exit: %e.\\n&quot;, ret);&#125; ucore docs中指出，此函数的主要工作流程如下： 首先为加载新的执行码做好用户态内存空间清空准备。如果mm不为NULL，则设置页表为内核空间页表，且进一步判断mm的引用计数减1后是否为0，如果为0，则表明没有进程再需要此进程所占用的内存空间，为此将根据mm中的记录，释放进程所占用户空间内存和进程页表本身所占空间。最后把当前进程的mm内存管理指针为空。由于此处的initproc是内核线程，所以mm为NULL，整个处理都不会做。 接下来的一步是加载应用程序执行码到当前进程的新创建的用户态虚拟空间中。这里涉及到读ELF格式的文件，申请内存空间，建立用户态虚存空间，加载应用程序执行码等。load_icode函数完成了整个复杂的工作。 lab5通过do_icode函数执行新的程序，为此需要完成（） 设置用户堆栈 修改页表 根据ELF执行文件的格式描述分配内存并填写内容 设置用户态的EFLAG寄存器不可屏蔽中断 ucore docs中给出的函数工作流程： 调用mm_create函数来申请进程的内存管理数据结构mm所需内存空间，并对mm进行初始化； 调用setup_pgdir来申请一个页目录表所需的一个页大小的内存空间，并把描述ucore内核虚空间映射的内核页表（ boot_pgdir所指） 的内容拷贝到此新目录表中，最后让mm-&gt;pgdir指向此页目录表，这就是进程新的页目录表了，且能够正确映射内核虚空间； 根据应用程序执行码的起始位置来解析此ELF格式的执行程序，并调用mm_map函数根据ELF格式的执行程序说明的各个段（代码段、数据段、BSS段等） 的起始位置和大小建立对应的vma结构，并把vma插入到mm结构中，从而表明了用户进程的合法用户态虚拟地址空间； 调用根据执行程序各个段的大小分配物理内存空间，并根据执行程序各个段的起始位置确定虚拟地址，并在页表中建立好物理地址和虚拟地址的映射关系，然后把执行程序各个段的内容拷贝到相应的内核虚拟地址中，至此应用程序执行码和数据已经根据编译时设定地址放置到虚拟内存中了； 需要给用户进程设置用户栈，为此调用mm_mmap函数建立用户栈的vma结构，明确用户栈的位置在用户虚空间的顶端，大小为256个页，即1MB，并分配一定数量的物理内存且建立好栈的虚地址&lt;–&gt;物理地址映射关系； 至此,进程内的内存管理vma和mm数据结构已经建立完成，于是把mm-&gt;pgdir赋值到cr3寄存器中，即更新了用户进程的虚拟内存空间，此时的initproc已经被hello的代码和数据覆盖，成为了第一个用户进程，但此时这个用户进程的执行现场还没建立好； 先清空进程的中断帧，再重新设置进程的中断帧，使得在执行中断返回指令“iret”后，能够让CPU转到用户态特权级，并回到用户态内存空间，使用用户态的代码段、数据段和堆栈，且能够跳转到用户进程的第一条指令执行，并确保在用户态能够响应中断； 其中设置中断帧这一步是Lab5的练习1。 关于进程管理的COW(Copy On Write)机制叙述正确的是（） 父进程创建子进程需要复制父进程的内存空间 父进程创建子进程需要给子进程分配内核堆栈 父进程创建子进程需要给子进程分配用户堆栈 父进程创建子进程需要创建子进程的页表,但不复制父进程内存空间 总之不需要复制也不需要分配，只是创建一个新的页表，然后和父进程页表指向相同位置。需要进行写时就新创建一页。 简答题 第一个用户进程创建有什么特殊的？ 用户态代码段的初始化 好吧，答案是这么说的，但是我并不认同……总之，本实验中第一个用户进程是由第二个内核线程initproc通过把hello应用程序执行 码覆盖到initproc的用户虚拟内存空间来创建的。具体的大概方法是调用kernel_execve()函数，触发SYS_exec系统中断，然后继续调用do_execve()和load_icode()函数完成这一过程。其他用户进程是用户进程通过SYS_fork系统调用创建的（大概）。 系统调用的参数传递过程？ 参见：用户态函数syscall()中的汇编代码。下面的代码摘自user/libs/syscall.c： 123456789101112131415161718192021222324static inline intsyscall(int num, ...) &#123; va_list ap; va_start(ap, num); uint32_t a[MAX_ARGS]; int i, ret; for (i = 0; i &lt; MAX_ARGS; i ++) &#123; a[i] = va_arg(ap, uint32_t); &#125; va_end(ap); asm volatile ( \"int %1;\" : \"=a\" (ret) : \"i\" (T_SYSCALL), \"a\" (num), \"d\" (a[0]), \"c\" (a[1]), \"b\" (a[2]), \"D\" (a[3]), \"S\" (a[4]) : \"cc\", \"memory\"); return ret;&#125; 很显然，参数是这样传递的： 触发INT 0x80中断（T_SYSCALL） eax中存放系统调用号 edx、ecx、ebx、edi、esi中按照顺序存放前五个参数 返回值存放在eax中 令人感到奇怪的是，这与Linux系统在x86架构下一般的习惯并不相符。（https://stackoverflow.com/questions/2535989/what-are-the-calling-conventions-for-unix-linux-system-calls-on-i386-and-x86-6，其中给出的顺序是ebx、ecx、edx、esi、edi）。不过这并不是很重要，总之这个顺序与kern/syscall/syscall.c中对应的代码是相符的： 1234567891011121314151617181920voidsyscall(void) &#123; struct trapframe *tf = current-&gt;tf; uint32_t arg[5]; int num = tf-&gt;tf_regs.reg_eax; if (num &gt;= 0 &amp;&amp; num &lt; NUM_SYSCALLS) &#123; if (syscalls[num] != NULL) &#123; arg[0] = tf-&gt;tf_regs.reg_edx; arg[1] = tf-&gt;tf_regs.reg_ecx; arg[2] = tf-&gt;tf_regs.reg_ebx; arg[3] = tf-&gt;tf_regs.reg_edi; arg[4] = tf-&gt;tf_regs.reg_esi; tf-&gt;tf_regs.reg_eax = syscalls[num](arg); return ; &#125; &#125; print_trapframe(tf); panic(&quot;undefined syscall %d, pid = %d, name = %s.\\n&quot;, num, current-&gt;pid, current-&gt;name);&#125; Ref: https://www.ibm.com/developerworks/library/l-ia/index.html getpid的返回值放在什么地方了？ 参见：用户态函数syscall()中的汇编代码 这个问题很平凡，只是放在eax里面了而已。（又不是fork……） ucore的内存布局中，页表、用户栈、内核栈在逻辑地址空间中的位置？ 参见kern/mm/memlayout.h： 12345678910111213#define VPT 0xFAC00000#define KSTACKPAGE 2 // # of pages in kernel stack#define KSTACKSIZE (KSTACKPAGE * PGSIZE) // sizeof kernel stack#define USERTOP 0xB0000000#define USTACKTOP USERTOP#define USTACKPAGE 256 // # of pages in user stack#define USTACKSIZE (USTACKPAGE * PGSIZE) // sizeof user stack 事实上，页表位于内核虚拟空间0xFAC000000xFB000000位置，用户栈位于用户虚拟空间?0xB0000000位置（因为栈是向下增长的），内核栈位于内核虚拟空间……诶怎么没说内核栈在什么位置？我猜是在~0xF8000000位置吧。 这个字符画的水平十分高超： 12345678910111213141516171819202122232425262728293031323334353637383940/* * * Virtual memory map: Permissions * kernel/user * * 4G ------------------&gt; +---------------------------------+ * | | * | Empty Memory (*) | * | | * +---------------------------------+ 0xFB000000 * | Cur. Page Table (Kern, RW) | RW/-- PTSIZE * VPT -----------------&gt; +---------------------------------+ 0xFAC00000 * | Invalid Memory (*) | --/-- * KERNTOP -------------&gt; +---------------------------------+ 0xF8000000 * | | * | Remapped Physical Memory | RW/-- KMEMSIZE * | | * KERNBASE ------------&gt; +---------------------------------+ 0xC0000000 * | Invalid Memory (*) | --/-- * USERTOP -------------&gt; +---------------------------------+ 0xB0000000 * | User stack | * +---------------------------------+ * | | * : : * | ~~~~~~~~~~~~~~~~ | * : : * | | * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * | User Program &amp; Heap | * UTEXT ---------------&gt; +---------------------------------+ 0x00800000 * | Invalid Memory (*) | --/-- * | - - - - - - - - - - - - - - - | * | User STAB Data (optional) | * USERBASE, USTAB------&gt; +---------------------------------+ 0x00200000 * | Invalid Memory (*) | --/-- * 0 -------------------&gt; +---------------------------------+ 0x00000000 * (*) Note: The kernel ensures that &quot;Invalid Memory&quot; is *never* mapped. * &quot;Empty Memory&quot; is normally unmapped, but user programs may map pages * there if desired. * * */ 在do_execve中的的当前进程如何清空地址空间内容的？在什么时候开始使用新加载进程的地址空间？ 清空进程地址空间是在initproc所在进程地址空间 CR3设置成新建好的页表地址后，开始使用新的地址空间 这个答案简直语无伦次……总之上面已经说过do_execve()函数的流程了。清空地址空间是通过释放mm_struct结构完成的（虽然initproc并不会这么做，因为它直接用的是内核的mm_struct）。至于页表，do_execve()在释放mm_struct之前会先换成内核自己的页表；load_icode()中，设置进程的新mm_struct时会加载新页表（第5步）。 新加载进程的第一级页表的建立代码在哪？ 在load_icode()的第2步中，调用了setup_pgdir(mm)。 do_execve在处理中是如何正确区分出用户进程和线程的？并为此采取了哪些不同的处理？ 我猜这道题说的是内核线程吧。 123456789if (mm != NULL) &#123; lcr3(boot_cr3); if (mm_count_dec(mm) == 0) &#123; exit_mmap(mm); put_pgdir(mm); mm_destroy(mm); &#125; current-&gt;mm = NULL;&#125; 内核线程的mm直接借用了内核自己的mm，所以这里处理了这一点。 第一个内核线程和第一个用户进程的创建有什么不同？ 相应线程的内核栈创建时，多了SS和ESP的设置； 用户进程需要创建用户地址空间，并把用户代码复制到用户地址空间； 设置ss和esp对应lab5的练习1：在用户进程的内核栈中存放的trapframe中填写对应的寄存器。其次就是要load_icode了，不能直接调用内核中的函数。而且不能和内核共用页表，要新建自己的页表。 尝试跟踪分析新创建的用户进程的开始执行过程？ ……反正我写的实验报告中是这么说的： load_icode函数成功结束运行后，系统中断返回到exit的第一行代码。exit本身的执行过程在此暂时忽略。 exit线程执行结束之后，系统切换到initproc线程，它进行检查并退出。 差不多吧。 为什么新进程的内核堆栈可以先于进程地址空间复制进行创建？ 内核栈在进程的内核地址空间，而各进程的内核地址空间是共享的。 进程复制的代码在哪？复制了哪些内容？ 以下代码来自lab5/kern/process/proc.c： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152intdo_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf) &#123; int ret = -E_NO_FREE_PROC; struct proc_struct *proc; if (nr_process &gt;= MAX_PROCESS) &#123; goto fork_out; &#125; ret = -E_NO_MEM; // 1. call alloc_proc to allocate a proc_struct proc = alloc_proc(); if (proc == NULL) &#123; // 参考答案添加了错误处理 goto fork_out; &#125; proc-&gt;parent = current; // 参考了答案 // 2. call setup_kstack to allocate a kernel stack for child process if (setup_kstack(proc) != 0) &#123; // 参考答案添加了错误处理 goto bad_fork_cleanup_proc; &#125; // 3. call copy_mm to dup OR share mm according clone_flag // CLONE_VM表示分享；实际上因为都在内核态所以什么都没做，只是assert NULL了 if (copy_mm(clone_flags, proc) != 0) &#123; // 参考答案添加了错误处理 goto bad_fork_cleanup_kstack; &#125; // 4. call copy_thread to setup tf &amp; context in proc_struct copy_thread(proc, stack, tf); // 5. insert proc_struct into hash_list &amp;&amp; proc_list // 参考了答案：关中断的原因是，进程号要求唯一性，此操作需要为原子操作，防止被打断而重复添加 // 所以参考答案是很有必要的。但是我认为在实验指导书中也应该说明一下。 bool intr_flag; local_intr_save(intr_flag); &#123; proc-&gt;pid = get_pid(); hash_proc(proc); // list_add_before(&amp;proc_list, &amp;proc-&gt;list_link); set_links(proc); &#125; local_intr_restore(intr_flag); // 6. call wakeup_proc to make the new child process RUNNABLE wakeup_proc(proc); // 7. set ret vaule using child proc&apos;s pid ret = proc-&gt;pid;fork_out: return ret;bad_fork_cleanup_kstack: put_kstack(proc);bad_fork_cleanup_proc: kfree(proc); goto fork_out;&#125; 可以看出，以上代码中复制的主要内容是mm_struct内存管理结构（相当于复制了一份虚拟内存及其中的内容）。 进程复制过程中有哪些修改？为什么要修改？ 参见上一题的代码，需要修改的内容包括： 为新进程分配一个新的进程控制块 分配一个新的内核栈 修改内核栈中存储的trapframe的内容 分配一个新的PID 分析第一个用户进程的创建流程，说明进程切换后执行的第一条是什么。 以下内容摘自ucore docs Lab5： 在确定了用户进程的执行代码和数据，以及用户进程的虚拟空间布局后，我们可以来创建用户进程了。在本实验中第一个用户进程是由第二个内核线程initproc通过把hello应用程序执行码覆盖到initproc的用户虚拟内存空间来创建的。 initproc的执行主体是init_main函数，这个函数在缺省情况下是执行宏KERNEL_EXECVE(hello)，而这个宏最终会调用kernel_execve函数来执行SYS_exec系统调用。 ucore收到此系统调用后，最终通过do_execve函数来完成用户进程的创建工作。此函数的主要工作流程如下： 首先为加载新的执行码做好用户态内存空间清空准备。如果mm不为NULL，则设置页表为内核空间页表，且进一步判断mm的引用计数减1后是否为0，如果为0，则表明没有进程再需要此进程所占用的内存空间，为此将根据mm中的记录，释放进程所占用户空间内存和进程页表本身所占空间。最后把当前进程的mm内存管理指针为空。由于此处的initproc是内核线程，所以mm为NULL，整个处理都不会做。 接下来的一步是加载应用程序执行码到当前进程的新创建的用户态虚拟空间中。这里涉及到读ELF格式的文件，申请内存空间，建立用户态虚存空间，加载应用程序执行码等。load_icode函数完成了整个复杂的工作。 load_icode函数的主要工作就是给用户进程建立一个能够让用户进程正常运行的用户环境。此函数有一百多行，完成了如下重要工作： 调用mm_create函数来申请进程的内存管理数据结构mm所需内存空间，并对mm进行初始化； 调用setup_pgdir来申请一个页目录表所需的一个页大小的内存空间，并把描述ucore内核虚空间映射的内核页表（boot_pgdir所指）的内容拷贝到此新目录表中，最后让mm-&gt;pgdir指向此页目录表，这就是进程新的页目录表了，且能够正确映射内核虚空间； 根据应用程序执行码的起始位置来解析此ELF格式的执行程序，并调用mm_map函数根据ELF格式的执行程序说明的各个段（代码段、数据段、BSS段等） 的起始位置和大小建立对应的vma结构，并把vma插入到mm结构中，从而表明了用户进程的合法用户态虚拟地址空间； 调用根据执行程序各个段的大小分配物理内存空间，并根据执行程序各个段的起始位置确定虚拟地址，并在页表中建立好物理地址和虚拟地址的映射关系，然后把执行程序各个段的内容拷贝到相应的内核虚拟地址中，至此应用程序执行码和数据已经根据编译时设定地址放置到虚拟内存中了； 需要给用户进程设置用户栈，为此调用mm_mmap函数建立用户栈的vma结构，明确用户栈的位置在用户虚空间的顶端，大小为256个页，即1MB，并分配一定数量的物理内存且建立好栈的虚地址&lt;–&gt;物理地址映射关系； 至此,进程内的内存管理vma和mm数据结构已经建立完成，于是把mm-&gt;pgdir赋值到cr3寄存器中，即更新了用户进程的虚拟内存空间，此时的initproc已经被hello的代码和数据覆盖，成为了第一个用户进程，但此时这个用户进程的执行现场还没建立好； 先清空进程的中断帧，再重新设置进程的中断帧，使得在执行中断返回指令“iret”后，能够让CPU转到用户态特权级，并回到用户态内存空间，使用用户态的代码段、数据段和堆栈，且能够跳转到用户进程的第一条指令执行，并确保在用户态能够响应中断； 至此，用户进程的用户环境已经搭建完毕。此时initproc将按产生系统调用的函数调用路径原路返回，执行中断返回指令“iret”（位于trapentry.S的最后一句）后，将切换到用户进程hello的第一条语句位置_start处（位于user/libs/initcode.S的第三句） 开始执行。 什么是写时复制？ 写时复制（Copy-on-Write，也缩写为COW），顾名思义，就是在写入时才真正复制一份内存进行修改。COW最早应用在*nix系统中对线程与内存使用的优化，后面广泛的被使用在各种编程语言中，如C++的STL等。在PHP内核中，COW也是主要的内存优化手段。在前面关于变量和内存的讨论中，引用计数对变量的销毁与回收中起着至关重要的标识作用。引用计数存在的意义，就是为了使得COW可以正常运作，从而实现对内存的优化使用。（50-写时复制COW机制） 写时复制的页表在什么时候进行复制？共享地址空间和写时复制有什么不同？ 在发生写操作时进行复制。共享地址空间并不在意是否发生写操作…… 存在有多个（n&gt;2）进程具有父子关系，且采用了COW机制的情况。这个情况与只有父子两个进程的情况相比，在设计COW时，需要注意的新问题是什么？有何解决方案？ 大概发生一次写操作可能有多个页表发生修改。 实践题 尝试在panic函数中获取并输出用户栈和内核栈的函数嵌套信息和函数调用参数信息，然后在你希望的地方人为触发panic函数，并输出上述信息。 没写。 尝试在panic函数中获取和输出页表有效逻辑地址空间范围和在内存中的逻辑地址空间范围，然后在你希望的地方人为触发panic函数，并输出上述信息。 没写。 尝试在进程运行过程中获取内核空间中各进程相同的页表项（代码段）和不同的页表项（内核堆栈）？ 没写。。。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第18讲：“信号量与管程”总结","slug":"2018-05-25-《操作系统》第18讲：“信号量与管程”总结","date":"2018-05-25T01:14:40.000Z","updated":"2018-05-25T01:14:40.000Z","comments":true,"path":"post/os-mooc-lecture-18-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-18-summary/","excerpt":"","text":"课程内容概述 信号量 信号量简介 信号量使用 互斥访问 条件同步 管程 条件变量 管程的语义 经典问题 生产者-消费者问题 信号量实现 管程实现 哲学家就餐问题 读者-写者问题 信号量（Semaphore） 信号量是操作系统提供的一种协调共享资源访问的方法。它和软件同步的区别是： 软件同步是平等线程间的一种同步协商机制 信号量是由操作系统进行管理的，它的地位高于进程（而非平等协商） 信号量由Dijkstra在20世纪60年代提出，目前仍然在OS中被使用。 信号量简介 信号是一种抽象数据类型： 由一个整型变量（sem）和两个原子操作组成 sem：要共享的资源的数目 P()操作（Prolaag，尝试减少，请求资源时进行） sem-1 若sem&lt;0，进入等待，否则继续运行 V()操作（Verhoog，增加，释放资源时进行） sem+1 若sem&lt;=0，则唤醒一个等待进程 信号量的一些特点： 信号量可以被认为是被保护的整数变量 初始化完成后，只能通过P()和V()操作修改 由操作系统保证，PV操作是原子操作 可以保证不受应用进程的干扰 P()操作可能阻塞，但V()操作不会阻塞 通常假定信号量是“公平的” 线程不会被无限期阻塞在P()操作（实际系统中有一个最长时限的参数，超时之后错误返回） 假定信号量等待按先进先出排队（但是在实际系统中公平有所偏差） 下面给出信号量在原理上的一个实现（之所以是原理上的实现，是因为实际实现时要考虑很多问题）： 1234567891011121314151617181920class Semaphore &#123; int sem; WaitQueue q;&#125;Semaphore::P() &#123; sem--; if (sem &lt; 0) &#123; Add this thread t to q; block(t); &#125;&#125;Semaphore::V() &#123; sem++; if (sem &gt;= 0) &#123; Remove a thread t from q; wakeup(t); &#125;&#125; 信号量使用 信号量一般可分为两类： 二进制信号量：资源数目为0或1 资源信号量：资源数目为任何非负值 下面讨论两个信号量的使用场景： 互斥访问：临界区的互斥访问控制 条件同步：线程间的事件等待 互斥访问 互斥访问的实现方法非常简单： 123456// 每类资源设置一个信号量，其初值为1mutex = new Semaphore(1);// 临界区的控制代码如下：mutex-&gt;P();Critical Section;mutex-&gt;V(); 在这种情况下，信号量的使用和锁相同。需要注意以下几点： 必须成对使用P()操作和V()操作 P()操作保证互斥访问临界资源 V()操作在使用后释放临界资源 PV操作不能次序颠倒、重复或遗漏 条件同步 举例：线程A执行完X模块之后，线程B才能执行Y模块。 12345678910111213141516// 设置一个初值为0的信号量condition = new Semaphore(0);// Thread AModule X &#123; ...&#125;condition.V();...// Thread B...condition.P();Module Y &#123; ...&#125; 管程（Monitor） 管程是一种用于多线程互斥访问共享资源的程序结构 采用面向对象方法，简化了线程间的同步控制 任一时刻最多只有一个线程执行管程代码 正在管程中的线程可临时放弃管程的互斥访问，等待事件出现时恢复（这是最大的特点） 管程的组成： 一个锁：控制管程代码的互斥访问 入口队列：每次只能有一个线程进入 0或多个条件变量：管理共享数据的并发访问 下面需要介绍一下条件变量了。 条件变量（Condition Variable） 条件变量是管程内的等待机制 进入管程的线程因资源被占用而进入等待状态 每个条件变量表示一种等待原因，对应一个等待队列 Wait()操作： 将自己阻塞在等待队列中 唤醒一个等待者或释放管程的互斥访问（即允许另外一个线程进入管程） Signal()操作： 将等待队列中的一个线程唤醒 如果等待队列为空，这就相当于是一个空操作 条件变量在原理上的实现和信号量有些类似： 1234567891011121314151617181920class Condition &#123; int numWaiting = 0; WaitQueue q;&#125;Condition::Wait(Lock lock) &#123; numWaiting++; Add this thread t to q; release(lock); schedule(); // need mutex acquire(lock);&#125;Condition::Signal() &#123; if (numWaiting &gt; 0) &#123; Remove a thread t from q; wakeup(t); // need mutex numWaiting--; &#125;&#125; 但是有很多不同的地方，如： 对管程的互斥锁的释放和获得 signal和P语义的不同：PV操作必须是成对的，但signal/wait操作完全不需要保证这一点 wait和V语义的不同：V操作后线程可能会继续执行，但wait操作后，线程必然进入等待队列并阻塞 执行signal/wait时，都默认已经获得了互斥锁 管程的语义 事实上管程一共有三种语义： Mesa语义 Hoare语义 Hansen语义 以下内容参考了Piazza上的讨论和CMU的课件。 考虑如下情况：线程A在条件变量的等待队列中等待资源，此时线程B在该资源（或者说该条件变量）上执行signal操作。 Mesa语义 线程B执行signal之后，不会立刻退出管程，而是执行到lock.release()之后才进入就绪态 线程A会被移动到入口等待队列中 在wait后被唤醒的进程不一定会被立刻调度，因此需要用while来检查条件 大部分实际实现的管程采用的是这一语义 Hoare语义 线程B执行signal之后，迅速唤醒等待中的线程A，自己进入signal队列中（这个队列是此语义特有的） 每次有线程退出时，先到signal队列中调度线程，如果signal队列空，才到入口等待队列调度线程 实际实现中一般不采用，因为需要多一个队列，代价增大了 Brinch Hanson语义 线程B退出的同时才执行signal操作 经典问题 生产者-消费者问题 有界缓冲区的生产者-消费者问题描述： 一个或多个生产者在生成数据后放在一个缓冲区里 单个消费者从缓冲区取出数据处理 任何时候只能有一个生产者或消费者可访问缓冲区 信号量实现 问题分析： 任何时刻只能有一个线程操作缓冲区，这是临界区（互斥访问） 缓冲区空时，消费者必须等待生产者（条件同步） 缓冲区满时，生产者必须等待消费者（条件同步） 用信号量描述每个约束： 二进制信号量mutex：互斥 资源信号量fullBuffers：缓冲区为满（信号量的值表示缓冲区中数据的个数） 资源信号量emptyBuffers：缓冲区为空（信号量的值表示缓冲区中空位的个数） 其中fullBuffers+emptyBuffers=缓冲区大小 （事实上，OSTEP中讨论了如果只使用一个资源信号量会导致死锁的问题，在此不再赘述了） 下面给出（原理上的）代码实现： 123456789101112131415161718192021class BoundedBuffer &#123; mutex = new Semaphore(1); fullBuffers = new Semaphore(0); emptyBuffers = new Semaphore(n);&#125;BoundedBuffer::Deposit(c) &#123; emptyBuffers-&gt;P(); mutex-&gt;P(); Add c to the buffer; mutex-&gt;V(); fullBuffers-&gt;V();&#125;BoundedBuffer::Remove(c) &#123; fullBuffers-&gt;P(); mutex-&gt;P(); Remove c from buffer; mutex-&gt;V(); emptyBuffers-&gt;V();&#125; 注意P操作之间不能颠倒顺序。V操作不会阻塞，就无所谓了。 管程实现 12345678910111213141516171819202122232425class BoundedBuffer &#123; Lock lock; int count = 0; Condition notFull, notEmpty;&#125;BoundedBuffer::Deposit(c) &#123; lock-&gt;Acquire(); while (count == n) notFull.Wait(&amp;lock); Add c to the buffer; count++; notEmpty.signal(); lock-&gt;Release();&#125;BoundedBuffer::Remove(c) &#123; lock-&gt;Acquire(); while (count == 0) notEmpty.Wait(&amp;lock); Remove c from buffer; count--; notFull.signal(); lock-&gt;Release();&#125; 信号量和管程实现的对比 （以下内容摘自Piazza，修正了一些typo） 如图，信号量中存有int变量sem以及WaitQueue变量q，根据信号量的实现代码（左下角ppt），我们可以得出sem和q的含义： q代表当前正在等待资源的线程组成的等待队列，若当前资源足够所有进程使用，q为空； sem代表【到目前为止，若所有请求该资源的线程都能够获取该资源，那么资源还剩下多少（这里我们假设资源个数可以为负）】； 对sem也可以有另一种理解：当sem非负时，sem代表剩余资源的个数；当sem为负数时，sem的绝对值代表等待队列q的长度。 而当我们使用条件变量解决有限资源问题时，我们通常会在条件变量之外，管程之中加入整型变量count（右上角ppt），来帮助条件变量记录当前剩余多少资源（非负）。查看条件变量的实现代码（右下角ppt），我们可以得出条件变量中整型变量numWaiting以及WaitQueue变量q的含义： q代表当前正在等待资源的线程组成的等待队列，若当前资源足够所有进程使用，q为空； numWaiting代表等待队列q的长度（非负）。 结合使用信号量以及条件变量解决有限资源问题的实例（左上及右上ppt），以及以上我们对信号量和条件变量的分析，我们可以得出以下结论： 在任一状态，信号量中的q和条件变量中的q完全相同； 当sem非负时，含义与管程中的count相同，此时numWaiting为0； 当sem为负数时，sem的绝对值等于numWaiting，此时count为0。 在生产者-消费者这个问题实例中： 信号量emptyBuffers与条件变量notFull是匹配的，满足上面3个条件，此时count在代码中以n - count的形式出现； 信号量fullBuffers与条件变量notEmpty是匹配的，满足上面3个条件，此时count在代码中以count的形式出现； 综上所述，两种解决方法是完全等价的，至于为什么用管程实现更加安全方便，个人认为老师在视频中并没有解释得很清楚，和老师讨论后得出结论如下： 用信号量的时候（左上角ppt），所有信号量都要自己维护，并配对好PV； 用管程的时候，我们可以理解为BoundedBuffer继承了一个管程类，因此操作系统会给BoundedBuffer中每一个方法自动加上锁（即右上角ppt中的lock-&gt;Acquire()和lock-&gt;Release()函数并不用自己写，是系统加上的），因此更加安全可控，容易查错。 但是个人认为使用条件变量也要根据条件配对好Wait和Signal函数，因此不比使用信号量更容易安全，这个问题见仁见智吧，但如果考试时候问到怎么回答大家懂的~ 更新：ucore lab7中实现信号量的sem值非负，这样看来ucore中信号量的sem值和条件变量中的count值应该是完全相等的。 哲学家就餐问题 问题描述： 5个哲学家围绕在一张圆桌周围 桌子上有5根筷子（或者说叉子……随便啦） 哲学家的动作包括思考和进餐 进餐时一个哲学家需要自己两边的两根筷子 如何保证哲学家们的动作有序进行，既不发生饥饿也不发生死锁？ 方案1： 每个筷子用一个信号量表示，sem=1 哲学家先拿第一根筷子，再拿第二根筷子，然后吃，最后放回两根筷子 多数情况下这一算法可行；但极端情况下会出现死锁，比如所有哲学家同时拿左边的筷子 方案2： 除了每根筷子的信号量之外，再加上一个互斥信号量，同时只能有一个哲学家就餐 能够保证顺序吃饭，但是浪费了资源和时间 方案3： 和方案1一样，使用5个信号量表示筷子 哲学家根据编号不同，拿取筷子的顺序不同 此时没有死锁，且允许两个人同时就餐 信号量实现 这一实现和ucore lab中给出的使用信号量的实现不太一样，而是参考了OSTEP中的做法（更准确地说是Dijkstra本人的做法）。 1234567891011121314151617181920212223242526272829// InitializationSemaphore forks[5];for (int i = 0; i &lt; 5; i++) forks[i] = new Semaphore(1);// Helper functionsint left(int p) &#123; return p; &#125;int right(int p) &#123; return (p + 1) % 5; &#125;// Thread xvoid Philosopher(int x) &#123; // Switch between thinking and eating while (true) &#123; think(); // get forks if (p == 4) &#123; // break dependency forks[right(x)].P(); forks[left(x)].P(); &#125; else &#123; forks[left(x)].P(); forks[right(x)].P(); &#125; eat(); // put forks forks[left(x)].V(); forks[right(x)].V(); &#125;&#125; 读者-写者问题 问题描述：对于一个共享数据，有两类使用者 读者：只读取数据，不修改（可以同时读） 写者：读取和修改数据（不可以同时写） 读写是互斥的 事实上，也需要考虑到，至少有两种可能的策略（而且还会有更多）： 读者优先策略： 只要有读者正在读状态，后来的读者就能直接进入 如果读者不断进入，则写者就处于饥饿 写者优先策略 只要有写者就绪，写者应尽快执行写操作（后来的读者需要阻塞） 如果写者持续不断就绪，则读者就处于饥饿 信号量实现 用信号量描述每个约束： 信号量WriteMutex 控制读写操作的互斥 初始化为1 读者计数Rcount 正在进行读操作的读者数目 初始化为0 信号量CountMutex 保护对读者计数的互斥修改 初始化为1 解决方案： 读者的互斥锁只针对于第一个读者，之后不再判断 因为Rcount也需要保护，所以外面也加上互斥锁 123456789101112131415161718192021void Writer() &#123; WriteMutex.P(); write; WriteMutex.V();&#125;void Reader() &#123; CountMutex.P(); if (Rcount == 0) WriteMutex.P(); Rcount++; CountMutex.V(); read; CountMutex.P(); Rcount--; if (Rcount == 0) WriteMutex.V(); CountMutex.V();&#125; 在这一实现中，只要有读者开始阅读，就必须等到全部读者都离开才能进行写操作。即使有写操作在等待，读者仍然先于写者，说明这是一种读者优先策略。 管程实现 管程中包括以下内容： 一个互斥锁 4个状态变量 2个条件变量：可读/可写 从判断条件可以看出，这一实现采用的是写者优先策略。不过其实我还没想明白能否把对AW和WW变量的修改移动到while循环外面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Database &#123; Lock lock; // 管程的互斥锁 int AR = 0; // Active Readers int AW = 0; // Active Writers int WR = 0; // Waiting Readers int WW = 0; // Waiting Writers Condition okToRead, okToWrite;&#125;// 两个基本操作Database::Read() &#123; StartRead(); // Wait until no writers read database; DoneRead(); // Exit &amp; wake up waiting writers&#125;Database::Write() &#123; StartWrite(); // Waite until no readers/writers; write database; DoneWrite(); // Exit &amp; wake up waiting readers/writers&#125;Private Database::StartRead() &#123; lock.Acquire(); while (AW + WW &gt; 0) &#123; WR++; okToRead.wait(&amp;lock); WR--; &#125; AR++; lock.Release();&#125;Private Database::DoneRead() &#123; lock.Acquire(); AR--; if (AR == 0 &amp;&amp; WW &gt; 0) okToWrite.signal(); lock.Release();&#125;Private Database::StartWrite() &#123; lock.Acquire(); while (AW + AR &gt; 0) &#123; WW++; okToWrite.wait(&amp;lock); WW--; &#125; AW++; lock.Release();&#125;Private Database::DoneWrite() &#123; lock.Acquire(); AW--; if (WW &gt; 0) okToWrite.signal(); else if (AW &gt; 0) okToRead.broadcast(); lock.Release();&#125; 练习 来自lec18 信号量与管程 在线练习和同步互斥(lec 18) spoc 思考题。 选择题 如果有5个进程共享同一程序段，每次允许3个进程进入该程序段，若用PV操作作为同步机制，则信号量S为-1时表示什么（） 有四个进程进入了该程序段 有一个进程在等待 有三个进程进入了程序段，有一个进程在等待 有一个进程进入了该程序段，其余四个进程在等待 一般来说，信号量实现中会满足，它的整数值如果为负数，则负数的绝对值表示等待中的线程数量。当然似乎也有些实现不是这么做的。 2元信号量可以初始化为（） 0或1 0或-1 只能为1 任意值 之所以可以初始化为0或1，是因为二元信号量至少有两种不同的使用场景： 资源数目为1，如只能互斥访问的代码关键区 代码条件等待，这种情况下有可能会先执行V操作，再执行P操作 多个进程对信号量S进行了6次P操作，2次V操作后，现在信号量的值是-3，与信号量S相关的处于阻塞状态的进程有几个（） 1个 2个 3个 4个 等待进程的数量就是信号量的值的负数。不过这样可以推导出，请求过信号量资源的进程为6个，得到资源的为2个，现在仍在等待的进程为3个，说明信号量的初值为6-2-3=1。 (2011年全国统考)有两个并发执行的进程P1和P2，共享初值为1的变量x。P1对x加1，P2对x减1。加1和减1操作的指令序列分别如下所示；两个操作完成后，x的值（）。 1234加一操作 减一操作Load R1,x load R2,xinc R1 dec R2store x,R1 store x,R2 可能为-1或3 只能为1 可能为0、1或2 可能为-1、0、1、1或2 分成以下几种情况讨论： P1和P2的执行完全错开（即加载了不同的x的值）：结果正确，x=1 P1和P2加载了相同的x的值：结果依赖于P1先写还是P2先写，如果P1先写则x=2，否则x=0 管程的主要特点有（） 局部数据变量只能被管程的过程访问 一个进程通过调用管程的一个过程进入管程 不会出现死锁 在任何时候，只能有一个进程在管程中执行 课上好像没有讲这么多管程的特点…… 关于管程的叙述正确的是（） 管程中的局部数据变量可以被外部直接访问 当一个进程在管程中执行时，调用管程的其他进程都不会被阻塞 在管程中的signal()与信号量中的signal()操作实现及意义完全相同 管程通过使用条件变量提供对同步的支持，这些条件变量包含在管程中，并且只有管程才能访问 管程中的局部变量只能通过管程的过程访问。一个进程在管程中执行时，调用管程的其他过程都会被阻塞。管程中的signal是通过条件变量实现的，而不是信号量，所以意义有微妙的不同。 简答题 什么是信号量？它与软件同步方法的区别在什么地方？ 信号量是由操作系统提供的一种协调共享资源访问的方法。信号量是一种抽象数据类，由一个被保护的整形变量（sem）和P()、V()两个原子操作组成，表示系统资源的数量。 区别： 软件同步是平等线程间的一种同步协商机制； 信号量是由地位高于进程的管理者OS协调的同步机制。 自旋锁为什么无法按先来先服务方式使用资源？ 原因：自旋锁是由TS指令实现的临界区申请操作，第一个检测到临界区空闲的申请者而不是第一个开始检测的申请者进入。也就是说，访问顺序是由硬件随机决定的。如果要实现FIFO方式，一般都需要一个队列。 下面是一种P操作的实现伪码。它能按FIFO顺序进行信号量申请吗？ 12345while (s.count == 0) &#123; //没有可用资源时，进入挂起状态； 调用进程进入等待队列s.queue; 阻塞调用进程;&#125;s.count--; //有可用资源，占用该资源； 参考回答： 它的问题是，不能按FIFO进行信号量申请。 它的一种出错的情况如下： 一个线程A调用P()原语时，由于线程B正在使用该信号量而进入阻塞状态；注意，这时value的值为0。 线程B放弃信号量的使用，线程A被唤醒而进入就绪状态，但没有立即进入运行状态；注意，这里value为1。 在线程A处于就绪状态时，处理机正在执行线程C的代码；线程C这时也正好调用P()原语访问同一个信号量，并得到使用权。注意，这时value又变回0。 线程A进入运行状态后，重新检查value的值，条件不成立，又一次进入阻塞状态。 至此，线程C比线程A后调用P原语，但线程C比线程A先得到信号量。 虽然参考答案是这么说的，但我觉得这有些牵强：事实上这种错误情况取决于V操作的语义。如果V操作能够保证使唤醒的进程立刻抢占处理机，就不会发生以上问题了。这就类似于管程的Hoare语义和Mesa语义的区别。 Piazza上有一个类似的讨论。事实上，在一般的Mesa语义下，使用if进行检查根本就是不正确的，需要用while。改用while之后，确实能保证正确性，但是FIFO无法保证了。 什么是条件同步？如何使用信号量来实现条件同步？ 条件同步是指线程间的事件等待。 条件同步的实现方法：定义初始值为0的信号量，事件触发进程使用V()操作表示事件出现，事件等待进程使用P()操作表示开始等待事件。 也就是说，此处P和V操作的顺序是颠倒的。 什么是生产者-消费者问题？ 生产者生成数据，并放入缓冲区 消费者从缓冲区取出数据，进行处理 任何时间只有一个进程访问缓冲区 为什么在生产者-消费者问题中先申请互斥信号量会导致死锁？ 如果先申请互斥信号量，后申请资源信号量，则在两种情况下可能会出现循环等待： 生产者获得互斥信号量后检查emptyBuffers资源信号量，发现缓冲区满了，于是进入睡眠状态；此时消费者无法获得互斥信号量，于是无法消耗缓冲区内的资源 消费者获得互斥信号量后检查fullBuffers资源信号量，发现缓冲区空了，于是进入睡眠状态；此时生产者无法获得互斥信号量，于是无法将资源放入缓冲区内 按答案中更抽象的说法就是这样： 缓冲区空时，生产者等待缓冲区的互斥访问，以便放入数据；消费者占有缓冲区访问权，等待生产者放入的数据 缓冲区满时，生产者占有缓冲区访问权，等待空的缓冲块；消费者等待缓冲区的互斥访问，以便取出数据 为什么互斥信号量的实现比资源信号量的实现要简单？请说明． 信号量中的整形变量的取值不同，互斥信号量的最大取值为1；而资源信号量的最大取值为资源总数。 事实上，互斥信号量和互斥锁是等价的。（如果不考虑sem值和等待进程数量关系的问题）。 管程的组成包括哪几部分？入口队列和条件变量等待队列的作用是什么？ 管程是一种并发程序的编程方法，由一个与入口队列对应的锁和若干个与共享数据访问的等待队列对应的条件变量组成，从而实现在任一时刻最多只有一个线程执行管程代码。 管程的组成部分： 一个锁：控制管程代码的互斥访问 入口队列：每次只能有一个线程进入 0或多个条件变量（及其对应的等待队列）：管理共享数据的并发访问 入口的等待队列和锁保证任一时刻最多只有一个线程执行管程代码；每个条件变量等待队列表示一种等待的资源。 管程与临界区有什么异同？ 相同点：在任一时刻最多只有一个线程执行管程代码或临界区代码 不同点：正在管程中的线程可临时放弃管程的互斥访问（进入条件变量的等待队列），等待事件出现时恢复；而临界区不支持临时退出 （所以其实在管程的概念里面我们已经不谈临界区了？） 为什么用管程实现的生产者-消费者问题中，可以在进入管程后才判断缓冲区的状态？ 因为管程允许临时放弃管程的互斥访问，而信号量并不支持临时放弃互斥访问权。在具体实现上，在管程内部的条件变量上进行等待时，会将管程的锁作为wait()操作的参数传递过去，此操作会同时放弃锁（返回时又会重新获得锁），因此不会导致死锁。 请描述管程条件变量的三种释放处理方式的区别是什么？条件判断中的while和if是如何影响释放处理中的顺序的？ Mesa管程：占用管程的当前进程可在任何时刻释放占用资源并唤醒相应的等待进程，当前进程继续执行，被唤醒进程放回入口等待队列队首等待当前进程释放管程访问权 Hoare管程：占用管程的当前进程可在任何时刻释放占用资源并唤醒相应的等待进程，当前进程进入唤醒队列等待，被唤醒进程继续执行直到释放管程访问权；管程空闲时，优先查看唤醒队列中的等待进程，唤醒队列中没有等待进程时再查看入口队列 Hansen管程：占用管程的当前进程只在退出管程时释放占用资源并唤醒相应的等待进程，被唤醒进程继续执行直到释放管程访问权 条件判断中while和if对释放处理中的执行顺序影响： 在Hansen和Mesa管程中，由于条件变量释放操作signal时并没有立即放弃管程访问权，资源的可用状态可能变化，需使用while()进行重新检查； 在Hoare管程中，由于条件变量释放操作signal同时表示立即放弃管程访问权，资源的可用状态保持不变，可使用if判断，不需要再次检查。 Ref: https://piazza.com/class/i5j09fnsl7k5x0?cid=894 Ref: https://www.andrew.cmu.edu/course/15-440-kesden/applications/ln/lecture6.html （不过在上述Piazza帖子中也有人提出了这样的问题：Hansen管程似乎是直接把访问权转移给了等待进程，这样还需要使用if来判断吗？） 哲学家就餐问题的方案2和方案3的性能有什么区别？ 方案2中，最多只有一个哲学家在吃饭 方案3中，最多可以有两个哲学家在同时吃饭 在读者-写者问题的读者优先和写者优先在行为上有什么不同？ 读者优先策略： 只要有读者正在读状态，后来的读者就能直接进入 如果读者不断进入，则写者就处于饥饿 写者优先策略 只要有写者就绪，写者应尽快执行写操作（后来的读者需要阻塞） 如果写者持续不断就绪，则读者就处于饥饿 在读者-写者问题的读者优先实现中优先于读者到达的写者在什么地方等待？ 互斥信号WriteMutex。因为这是控制读写互斥访问的锁。 实践题 请用管程with条件变量来实现信号量。 123456789101112131415161718192021222324class Semaphore &#123; Lock lock; // 管程的锁 int count; // 剩余可用资源个数 Condition isEmpty; // 表示是否有可用资源的事件的条件变量&#125;;Semaphore::Semaphore(int numRes) &#123; count = numRes;&#125;Semaphore::P() &#123; lock.acquire(); while (count == 0) isEmpty.wait(&amp;lock); count--; lock.release();&#125;Semaphore::V() &#123; lock.acquire(); count++; isEmpty.signal(); lock.release();&#125; 考虑到可能是Mesa语义的管程，因此进行了while检查。参考了这个Piazza帖子，我认为上述实现可以满足： 在任一状态，条件变量的等待队列与信号量的等待队列完全相同 当count != 0时，其含义与信号量中的sem相同，此时条件变量的numWaiting = 0 当count = 0时，条件变量的numWaiting等于信号量的sem的相反数（实现保证了count不会为负数） 请用信号量来实现管程with条件变量。 这个就有一定的难度了。当然，管程的核心是条件变量，其实实现条件变量就可以了。以下内容参考了Implementing Condition Variables with Semaphores这篇文章。 首先用信号量实现一个锁，这是非常容易的。 12345678class Lock &#123; Semaphore sm; public Lock() &#123; // constructor sm = new Semaphore(); sm.count =1; sm.limit = 1; &#125; public void Acquire() &#123; sm.P(); &#125; public void Release() &#123; sm.V(); &#125;&#125; 下面给出一种非常简单但是也非常错误的实现。该实现的显而易见的问题是，wait操作中对锁的释放和当前线程的睡眠不是原子的。然后好像会出现一个叫做“wake-up waiting race”的问题，不过此处好像并不会发生错误。以及，即使在没有线程正在等待时，signal操作也会使得信号量的值增加，这样，下一个等待进程就不会阻塞了，这是不正确的。 12345678910111213141516class CV &#123; Semaphore s; public CV() &#123; // Constructor s = new Semaphore(); s.count = 0; s.limit = 1; &#125; public void Wait(Lock m) &#123; // Pre-condition: this thread holds “m” m.Release(); s.P(); m.Acquire(); &#125; public void Signal() &#123; s.V(); &#125;&#125; 于是我们用信号量x作为互斥锁来保护wait操作，同时统计等待进程的个数。但这个实现也有两个问题： 由于s信号量的资源个数为1，因此最多只有一个调用wait的进程能够从s.P中返回，其余的都阻塞在s.P上；解决方法是把s的资源个数调到无限大 没有保证先进先出的语义 1234567891011121314151617181920212223242526272829303132class CV &#123; Semaphore s, x; int waiters = 0; public CV() &#123; // Constructor s = new Semaphore(); s.count = 0; s.limit = 1; x = new Semaphore(); x.count = 1; x.limit = 1; &#125; public void Wait(Lock m) &#123; // Pre-condition: this thread holds “m” x.P(); waiters++; x.V(); m.Release(); s.P(); m.Acquire(); &#125; public void Signal() &#123; x.P(); if (waiters &gt; 0) &#123; waiters--; s.V(); &#125; x.V(); &#125; public void Broadcast() &#123; x.P(); while (waiters &gt; 0) &#123; waiters--; s.V(); &#125; x.V(); &#125;&#125; 下一种实现中，加入了信号量h，它会使发出信号的线程在等待线程离开等待队列之前也阻塞。这个实现是正确的，但是似乎太麻烦了。论文最后表示，他们决定还是在OS中用硬件指令来实现条件变量。 123456789101112131415161718192021222324252627282930313233343536373839class CV &#123; Semaphore s, x; int waiters = 0; Semaphore h; public CV() &#123; // Constructor this.m = m; s = new Semaphore(); s.count = 0; s.limit = 999999; x = new Semaphore(); x.count = 1; x.limit = 1; h = new Semaphore(); h.count = 0; h.limit = 999999; &#125; public void Wait(Lock m) &#123; // Pre-condition: this thread holds “m” x.P(); waiters++; x.V(); m.Release(); s.P(); h.V(); m.Acquire(); &#125; public void Signal() &#123; x.P(); if (waiters &gt; 0) &#123; waiters--; s.V(); h.P(); &#125; x.V(); &#125; public void Broadcast() &#123; x.P(); for (int i = 0; i &lt; waiters; i++) s.V(); while (waiters &gt; 0) &#123; waiters--; h.P(); &#125; x.V(); &#125;&#125; 请评价如下的实现(用信号量来实现管程with条件变量)是否合理？简要说明理由。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Implementing a MonitorCONTROL VARIABLES: mutex: semaphore, initial value 1 (FREE) next: record, with 2 fields: next.sem: semaphore, initial value 0 next.count: counter, initial value 0 FOR EACH CONDITION x: x: record, with 2 fields: x.sem: semaphore, initial value 0 x.count: counter, initial value 0ENTRY PROTOCOL (at the beginning of each monitor function): /* wait for exclusive access to the monitor */ P(mutex);EXIT PROTOCOL (at the end of each monitor function): /* if there are processes in the &quot;next&quot; queue, release one */ if (next.count &gt; 0) V(next.sem); /* otherwise, release the monitor */ else V(mutex);WAIT ON CONDITION x (x.wait): /* first perform the exit protocol */ if (next.count &gt; 0) V(next.sem); else V(mutex); /* now wait on the condition queue */ x.count++; P(x.sem); x.count--;SIGNAL CONDITION x (x.signal): /* do nothing unless a process is waiting */ if (x.count &gt; 0) &#123; /* release the next waiting process */ V(x.sem); /* wait on the &quot;next&quot; queue */ next.count++; P(next.sem); next.count--; &#125; 每人使用C++或python语言用信号量和条件变量两种手段分别实现40个同步互斥问题中的一题。请先理解python threading 机制的介绍和实例 参考：2015年操作系统课的信号量问题回答 建议参考梁锡豪同学的输出信息显示方式，这种方式的可读性很好。 建议重视测试用例的设计，以检查自己的实现是否有错。 设计某个方法，能够动态检查出对于两个或多个进程的同步互斥问题执行中，没有互斥问题，能够同步等，以说明实现的正确性。 管程和信号量在解决同步互斥问题上是否等价？请证明/说明你的结论． Piazza上有两个非常优秀的讨论： https://piazza.com/class/i5j09fnsl7k5x0?cid=845：阐述了信号量和条件变量在具体实现和操作层面的异同 https://piazza.com/class/i5j09fnsl7k5x0?cid=839：对信号量和条件变量抽象的理解 简单来说，就是：信号量可以实现管程，管程可以实现信号量，所以在这个层面，二者等价。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第22讲：“实验8-文件系统”总结","slug":"2018-05-24-《操作系统》第22讲：“实验8-文件系统”总结","date":"2018-05-24T17:21:25.000Z","updated":"2018-05-24T17:21:25.000Z","comments":true,"path":"post/os-mooc-lecture-22-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-22-summary/","excerpt":"","text":"课程内容概述 本讲介绍了ucore中的文件系统。 TODO 练习 来自lec22 lab8 文件系统 在线练习和lab8 文件系统 (lec 22) spoc 思考题。 选择填空题 ucore实现的文件系统抽象包括（） 文件 目录项 索引节点 安装点 我猜这里主要说的是VFS文件系统中的内容。 struct file：应用程序能够看到的各种文件信息 struct inode：映射到特定文件系统的inode struct fs：保存了具体文件系统的结构、类型和信息 然后安装点是个啥我也不知道。 安装点是一个目录或文件，可在该处访问新文件系统、目录或文件。要安装文件系统或目录，安装点必须为一个目录；要安装文件，那么安装点必须为文件。（https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_72/com.ibm.aix.osdevice/mountpoint.htm） ucore实现的simple FS（简称SFS）采用的文件分配机制是（） 连续分配 链式分配 索引分配 位图分配 SFS使用的是一级索引。 索引分配的定义：为每个文件创建一个索引数据块，指向文件数据块的指针列表；文件头包含了索引数据块指针。 关于ucore实现的SFS阐述正确的是（） SFS的超级块保存在硬盘上，在加载simple FS时会读入内存中 SFS的free map结构保存在硬盘上，表示硬盘可用的数据块（扇区） SFS的root-dir inode结构保存在硬盘上，表示SFS的根目录的元数据信息 硬盘上的SFS ，除保存上述三种结构外，剩下的都用于保存文件的数据内容 除了前三种结构，剩下的用于保存文件的inode, dir/file的data。 关于ucore实现的Virtual FS（简称VFS）阐述正确的是() 已支持磁盘文件系统 已支持设备文件系统 已支持网络文件系统 已支持系统状态文件系统 后两种可实现，但现在还没实现 哈哈哈哈哈哈…… 关于ucore文件系统支持的I/O设备包括() 串口设备 并口设备 CGA设备 键盘设备 总之这些都支持。不过好像从Lab1就有了。 简答题 与文件系统相关的系统调用接口、虚拟文件系统VFS、简单文件系统SFS和设备I/O等四个部分各实现什么功能？ 系统调用接口：向应用进程提供文件访问的系统调用 虚拟文件系统VFS：屏蔽具体文件系统差异，对上提供一个统一的文件系统访问接口 简单文件系统SFS：解析和读写磁盘数据块中具体的SFS文件系统存储结构 设备I/O：完成实际磁盘设备上数据块的访问 文件系统中的文件、目录、索引节点(inode)和安装点(挂载点)这几种数据结构分别支持些什么操作？ 文件：open/close, read/write 目录：open/close, read 索引节点：lookup, read/write 挂载点：mount/unmount 请简要阐述ucore文件系统架构的四个组成部分。 系统调用接口：用户应用使用封装后的libc库函数，文件访问的libc库函数利用文件访问系统调用来实现 VFS：内核的系统调用（文件、目录接口）会转换成对VFS抽象的文件访问接口（索引节点、文件卷、设备等接口）的调用，VFS再把抽象的VFS接口转换成具体的文件系统SFS的访问接口 SFS：对具体文件系统存储结构进行解析，把SFS对接口（索引节点、文件卷、设备等接口）的访问请求转换成设备数据块的访问 I/O接口：不同具体设备上的数据块访问控制 请简要说明进程proc_struct、文件file、inode之间的关系。 进程控制块数据结构proc_struct中，struct files_struct *filesp指向进程的打开文件表 进程打开文件表中struct file *file指向系统打开文件中的相应文件状态数据 VFS中的系统打开文件表中struct inode *inode维护打开文件的状态信息，并最终对应到磁盘上的存储数据块 ucore中的进程打开文件表和系统打开文件表对应到具体的哪个数据结构上？ 进程打开文件表：proc_struct中的struct files_struct *filesp 系统打开文件表：不知道 SFS在硬盘上的四大部分主要是什么，有何作用？ superblock：数据块大小、文件卷名字等文件卷信息 root-dir inode：根目录的inode信息（存储位置等） freemap：数据块占用状态信息 data block：inode/文件数据/目录数据 硬盘上的SFS是如何加载到ucore中并初始化的？ ucore docs Lab8： 在sfs_fs.c文件中的sfs_do_mount函数中，完成了加载位于硬盘上的SFS文件系统的超级块superblock和freemap的工作。这样，在内存中就有了SFS文件系统的全局信息。 硬盘上的inode和内存中的inode的关系和区别是什么？ 内存中的inode数据结构sfs_inode中有一个字段sfs_disk_inode，它对应磁盘上的inode。 ucore docs Lab8： SFS中的磁盘索引节点代表了一个实际位于磁盘上的文件。 …… 可以看到SFS中的内存inode包含了SFS的硬盘inode信息，而且还增加了其他一些信息，这属于是便于进行是判断否改写、互斥操作、回收和快速地定位等作用。需要注意，一个内存inode是在打开一个文件后才创建的，如果关机则相关信息都会消失。而硬盘inode的内容是保存在硬盘中的，只是在进程需要时才被读入到内存中，用于访问文件或目录的具体内容数据 描述file, dir, inode在内存和磁盘上的格式和相关操作。 每一种类型的数据块都在SFS层中有对应的操作函数指针和数据结构定义。 事实上，file、dir和inode在内存和磁盘上都以inode形式存储： 内存：struct sfs_disk_inode 磁盘：inode 通过上表可以看出，如果inode表示的是文件，则成员变量direct[]直接指向了保存文件内容数据的数据块索引值。indirect间接指向了保存文件内容数据的数据块，indirect指向的是间接数据块（indirect block），此数据块实际存放的全部是数据块索引，这些数据块索引指向的数据块才被用来存放文件内容数据。 对于普通文件，索引值指向的block中保存的是文件中的数据。而对于目录，索引值指向的数据保存的是目录下所有的文件名以及对应的索引节点所在的索引块（磁盘块）所形成的数组。 file数据结构的主要内容是什么？与进程的关系是什么？ struct file数据结构定义在lab8/kern/fs/file.h中： 1234567891011struct file &#123; enum &#123; FD_NONE, FD_INIT, FD_OPENED, FD_CLOSED, &#125; status; bool readable; bool writable; int fd; off_t pos; struct inode *node; int open_count;&#125;; struct file数据结构的内容包括： status：文件状态 bool readable &amp; writable：文件操作类型 int fd：文件描述符 off_t pos：文件指针 struct inode *node：对应系统打开文件表项指针 int open_count：文件打开计数 struct file就是进程打开文件表对应的数据结构。 inode数据结构的主要内容是什么？与file的数据结构的关系是什么？ struct inode数据结构定义在lab8/kern/fs/vfs/inode.h中： 1234567891011121314struct inode &#123; union &#123; struct device __device_info; struct sfs_inode __sfs_inode_info; &#125; in_info; enum &#123; inode_type_device_info = 0x1234, inode_type_sfs_inode_info, &#125; in_type; int ref_count; int open_count; struct fs *in_fs; const struct inode_ops *in_ops;&#125;; struct inode数据结构的内容： in_info &amp; in_type：文件类型 ref_count &amp; open_count：引用计数 struct fs *in_fs：对下具体文件操作函数指针 const struct inode_ops *in_ops：对上inode操作函数指针 struct inode就是系统打开文件表对应的数据结构。 inode_ops包含哪些与文件相关的操作？ struct inode_ops数据结构定义在lab8/kern/fs/vfs/inode.h中，它是上层使用的inode操作函数： 123456789101112131415161718struct inode_ops &#123; unsigned long vop_magic; int (*vop_open)(struct inode *node, uint32_t open_flags); int (*vop_close)(struct inode *node); int (*vop_read)(struct inode *node, struct iobuf *iob); int (*vop_write)(struct inode *node, struct iobuf *iob); int (*vop_fstat)(struct inode *node, struct stat *stat); int (*vop_fsync)(struct inode *node); int (*vop_namefile)(struct inode *node, struct iobuf *iob); int (*vop_getdirentry)(struct inode *node, struct iobuf *iob); int (*vop_reclaim)(struct inode *node); int (*vop_gettype)(struct inode *node, uint32_t *type_store); int (*vop_tryseek)(struct inode *node, off_t pos); int (*vop_truncate)(struct inode *node, off_t len); int (*vop_create)(struct inode *node, const char *name, bool excl, struct inode **node_store); int (*vop_lookup)(struct inode *node, char *path, struct inode **node_store); int (*vop_ioctl)(struct inode *node, int op, void *data);&#125;; 文件中有每个操作的详细注释 open：打开文件 close：关闭文件 read：读文件 write：写文件 fstat：读文件信息 fsync：将脏缓存写回持久化存储介质 namefile：计算文件相对于文件系统根目录的路径 getdirentry：从目录中读一个文件名 reclaim：回收inode gettype：文件种类 tryseek：检查移动文件指针是否合法 truncate：重设文件大小，丢弃多余的数据 create：在目录中新建文件 lookup：在给定目录中按文件名查找文件 ioctl：管理I/O通道（？？） VFS是如何把键盘、显示输出和磁盘文件统一到一个系统调用访问框架下的？ VFS把键盘、显示和磁盘文件都视为文件，VFS对上提供的访问接口都是文件访问接口 VFS通过区别文件类型、文件操作类型、设备类型等来区别同类操作在不同设备的不同实现 device数据结构的主要内容是什么？与fs的关系是什么？与inode的关系是什么？ 这里的device指的应该是lab8/kern/fs/devs/dev.h中定义的struct device： 123456789101112/* * Filesystem-namespace-accessible device. * d_io is for both reads and writes; the iobuf will indicates the direction. */struct device &#123; size_t d_blocks; size_t d_blocksize; int (*d_open)(struct device *dev, uint32_t open_flags); int (*d_close)(struct device *dev); int (*d_io)(struct device *dev, struct iobuf *iob, bool write); int (*d_ioctl)(struct device *dev, int op, void *data);&#125;; struct device数据结构的内容： size_t d_blocks：数据块个数 size_t d_blocksize：数据块大小 设备操作函数指针（d_open, d_close, d_io, d_ioctl） fs和inode通过device数据结构中的设备操作函数指针实现对设备数据块的访问。 比较ucore中I/O接口、SFS文件系统接口和文件系统的系统调用接口的操作函数有什么异同？ 文件系统的系统调用接口（lab8/kern/syscall/syscall.c）：sys_open, sys_close, sys_read, sys_write, sys_seek, sys_fstat, sys_fsync, sys_chdir, sys_getcwd, sys_mkdir, sys_link, sys_rename, sys_unlink, sys_getdirentry, sys_dup, sys_pipe, sys_mkfifo, sys_mount, sys_umount, sys_ioctl VFS文件系统接口（lab8/kern/vfs/vfs.h）：vfs_open, vfs_close, vfs_link, vfs_symlink, vfs_readlink, vfs_mkdir, vfs_unlink, vfs_rename, vfs_chdir, vfs_getcwd SFS文件系统接口（lab8/kern/sfs/sfs.h）：sfs_rblock, sfs_wblock, sfs_rbuf, sfs_wbuf, sfs_sync_super, sfs_sync_freemap, sfs_clear_block, sfs_load_inode I/O接口（lab8/kern/devs/dev.h）：d_open, d_close, d_io, d_ioctl 实践题 理解文件访问的执行过程，即在ucore运行过程中通过cprintf函数来完整地展现出来读一个文件在ucore中的整个执行过程，(越全面细致越好) 完成代码填写，并形成spoc练习报告，需写练习报告和简单编码，完成后放到git server 对应的git repo中。 啊，这个完全没有时间去写了…… 在下面的实验代码的基础上，实现基于文件系统的pipe IPC机制。练习用的lab8 spoc exercise project source code 呃，这是lab8的附加题……","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第23讲：“I/O子系统”总结","slug":"2018-05-24-《操作系统》第23讲：“I-O子系统”总结","date":"2018-05-24T01:14:40.000Z","updated":"2018-05-24T01:14:40.000Z","comments":true,"path":"post/os-mooc-lecture-23-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-23-summary/","excerpt":"","text":"课程内容概述 常见设备I/O接口 进程的I/O方法 CPU与设备之间的I/O方法 连接方法 传输方法 通知方法 I/O请求生存周期 一类具体的I/O设备：磁盘 磁盘的工作机制和传输时间 磁盘调度算法 磁盘缓存 常见设备I/O接口 常见的接口分为三类。 设备接口类型 例子 访问特征 I/O命令 字符设备 键盘、鼠标、串口 以字节为单位顺序访问 文件访问接口 块设备 磁盘驱动器、磁带驱动器、光驱 均匀的数据块访问 文件系统接口、内存映射 网络设备 以太网、无线、蓝牙 格式化报文交换 网络报文、网络协议 进程的I/O方法 从进程的角度来看，I/O方法分为三种类型。 I/O类型 特点 读写方法 图示 阻塞I/O Wait 读写时，进程将进入等待状态，直到设备完成数据处理 非阻塞I/O Don’t Wait 读写时立即从read或write系统调用返回，返回值为成功传输字节数；可能不成功 异步I/O Tell Me Later 读写数据时，使用指针标记好用户缓冲区，立即返回；稍后内核将填充缓冲区/处理数据并通知用户 CPU与设备之间的I/O方法 内核通过I/O子系统控制各种硬件。 连接方法 一般来说，北桥芯片连接的是高速I/O设备，如内存和显卡；南桥芯片连接的是普通I/O设备，如磁盘和网络。 设备上的设备控制器是CPU和I/O设备间的接口，它向CPU提供特殊指令和寄存器，也就是CPU用来控制I/O设备的I/O地址，分为两种： I/O指令：通过I/O端口号访问设备寄存器 内存映射I/O：设备的寄存器/存储空间被映射到内存物理地址空间中，通过内存load/store指令完成I/O操作 传输方法 CPU与设备控制器之间的数据传输分为两种方式： 程序控制I/O（PIO，Programmed I/O） 通过CPU的in/out或者load/store传输所有数据（内存映射） 特点： 硬件简单，编程容易 消耗的CPU时间和数据量成正比 适用于简单的、小型的设备I/O 直接内存访问（DMA） 设备控制器可直接访问系统总线 控制器直接与内存互相传输数据 特点： 设备传输数据不影响CPU 需要CPU参与设置（这是必然的） 适用于高吞吐量I/O 通过DMA读取磁盘数据的例子 具体步骤如下： 设备驱动收到读取磁盘数据到内存地址X的请求 设备驱动控制磁盘控制器从磁盘读取数据 磁盘控制器初始化DMA传送 磁盘控制器传送数据到DMA控制器 DMA控制器传送C字节数据到内存地址X DMA控制器完成数据传送后，产生中断请求，通知CPU传送完成 通知方法 设备通知CPU（I/O操作完成时间、I/O操作是否发生错误、设备状态等）主要分为两种方式： CPU主动轮询 设备中断 轮询 处理流程： I/O设备在特定的状态寄存器中放置状态和错误信息 操作系统定期检测状态寄存器 特点： 简单 I/O操作频繁或不可预测时，开销大和延时长 设备中断 处理流程： CPU在I/O之前设置任务参数 CPU在发出I/O请求后，继续执行其他任务 I/O设备处理I/O请求 I/O设备处理完成时，触发CPU中断请求 CPU接收中断，分发到相应中断处理例程 特点： 处理不可预测事件效果好（CPU在每两条指令中间处理一次中断请求） 开销相对较高 I/O请求生存周期 显然，这是异步I/O请求。 一类具体的I/O设备：磁盘 磁盘的工作机制和传输时间 磁盘的主要组成部分包括： 磁盘轴 若干个盘片（围绕磁盘轴旋转） 磁道 扇区 磁头（上面有读写头） 在读取或写入时，磁头必须被定位在期望的磁道，并从所期望的柱面和扇区开始读写。在这一过程中，花时间最长的是磁头的移动。我们称寻道时间为定位到期望的磁道所花费的时间，旋转延迟为从0扇区开始处到达目的地花费的时间。一般来说，平均旋转延迟时间 是磁盘旋转一周时间的一半。 磁盘I/O传输一般分为以下5个步骤： 等待设备可用 等待通道（PIO或DMA通道）可用 寻道 旋转延迟 数据传输 后四个步骤被称为“设备忙”状态，所占用的时间一般认为是传输时间，公式为 Ta=Ts+12r+brNT_a = T_s+ \\frac{1}{2r} + \\frac{b}{rN} Ta​=Ts​+2r1​+rNb​ 公式各个部分的含义： TaT_aTa​：传输时间 TsT_sTs​：寻道时间（和磁头移动距离有关，花费的时间最多） 12r\\frac{1}{2r}2r1​：旋转延迟（1r\\frac{1}{r}r1​=旋转一周的时间） brN\\frac{b}{rN}rNb​：传输时间 bbb：传输的比特数 NNN：磁道上的比特数 rrr：磁盘转速 显然，最需要优化的是寻道时间。磁盘调度算法解决的就是这一问题。 磁盘调度算法 磁盘调度算法的目的：通过优化磁盘访问请求顺序来提高磁盘访问性能 进行磁盘调度的原因： 寻道时间是磁盘访问最耗时的部分 同时会有多个在同一磁盘上的I/O请求（所以可以调整顺序） 随机处理磁盘访问请求的性能表现很差 下列算法中使用的例子： 磁盘访问序列：98, 183, 37, 122, 14, 124, 65, 67 初始磁头位置：53 算法名称 做法 特征 例子 移动距离 先进先出（FIFO）算法 按顺序处理请求 能够保证公平；性能较差 53-&gt;98-&gt;183-&gt;37-&gt;122-&gt;14-&gt;124-&gt;65-&gt;67 640 最短服务时间优先（SSTF）算法 选择从磁臂当前位置需要移动最少的I/O请求 很不公平 53-&gt;65-&gt;67-&gt;14-&gt;98-&gt;122-&gt;124-&gt;183 236 扫描（SCAN）算法 磁臂在一个方向上移动，访问所有未完成的请求，直到磁臂到达该方向上最后的磁道；然后调换方向 判断简单；不公平，偏好中间位置磁道 53-&gt;37-&gt;14-&gt;0-&gt;65-&gt;67-&gt;98-&gt;122-&gt;124-&gt;183-&gt;199 236 循环扫描（C-SCAN）算法 对SCAN算法的改进：限制仅在一个方向上扫描；当最后一个磁道也被访问过了后，磁臂返回到磁盘的另外一端再次进行 比SCAN算法更公平 53-&gt;37-&gt;14-&gt;0-&gt;199-&gt;183-&gt;124-&gt;122-&gt;98-&gt;67-&gt;65 386 C-LOOK算法 对C-SCAN算法的改进：不走到磁盘的头，而是只走到最远的请求 同样能保证公平性 53-&gt;37-&gt;14-&gt;183-&gt;124-&gt;122-&gt;98-&gt;67-&gt;65 326 N步扫描（N-step-SCAN）算法 将磁盘请求队列分成长度为N的子队列，按FIFO算法依次处理所有子队列；再用扫描算法处理每个队列 防止磁头粘着现象 53-&gt;37-&gt;183-&gt;98-&gt;14-&gt;124-&gt;122-&gt;67-&gt;65 500 双队列扫描（FSCAN）算法 将磁盘请求队列分成两个子队列，交替使用扫描算法处理每一个队列；处理一个队列时，所有新生成的磁盘I/O请求都被放入另一队列中 比N步扫描更简单 53-&gt;37-&gt;183-&gt;122-&gt;98-&gt;67-&gt;65-&gt;14-&gt;124 441 一些细节： 认为SCAN、C-SCAN、C-LOOK和N步扫描算法都是先向低编号移动 N步扫描算法的N为3，使用的是C-LOOK扫描方法 FSCAN算法中假设后四个请求位于下一个队列，使用的也是C-LOOK扫描算法 课件上没有指出C-SCAN算法返回时到底是返回到另外一端还是“另外一端最靠边的请求”。鉴于有C-LOOK的改进，我就认为C-SCAN傻得直接走到另一端了。类似地，我也认为C-LOOK算法反转时只会走到另一端最远的请求，而不是另一端。 磁盘缓存 缓存是数据传输双方访问速度差异较大时，引入的速度匹配中间层。磁盘缓存 是磁盘扇区在内存中的缓冲区。磁盘缓存的调度算法很类似虚拟存储调度算法（不过倒了过来，虚拟存储是把内存缓存到磁盘，磁盘缓存是把磁盘缓存到内存==）。 单缓存与双缓存 根据缓冲区个数分类： 单缓存（Single Buffer Cache）：I/O设备写入时，CPU不能进行读操作（类似生产者-消费者问题） 双缓存（Double Buffer Cache）：有两个缓冲区，可以同时分别读写；结束之后可以交换 访问频率置换（Frequency-based Replacement）算法 问题：在一段密集磁盘访问后，LFU算法的引用计数变化无法反映当前的引用情况 算法思路： 考虑磁盘访问的密集特征，对密集引用不计数 在短周期中使用LRU算法，而在长周期中使用LFU算法 算法具体步骤： 把LRU算法中的特殊栈分成3部分，并为每个缓存块增加一个引用计数 新区域（New Section）：栈顶 中间区域（Middle Section） 旧区域（Old Section）：栈底 每次访问时： 栈中被访问的缓存块移到栈顶（这个是LRU的原始要求）；如果该块原来在新区域，引用计数不变（这个是符合LRU的）；否则引用计数+1 在新区域中引用计数不变的目的是避免密集访问对引用计数产生不利影响 在中间区域和旧区域中引用计数+1是为了使用LFU算法 未缓存数据块读入后放在栈顶，引用计数为1 在旧区域中引用计数最小的缓存块被置换（这是LFU的要求；但并不会在整个栈里找计数最小的） 中间区域的定义是为了避免新读入的缓存块在第一次离开新区域时马上被置换，有一个过渡期 例子：懒得想了，不写了 练习 来自lec23 IO设备 在线练习和IO设备(lec 23) spoc 思考题。 选择填空题 字符设备包括（） 键盘 鼠标 并口 串口 都是。因为它们的访问特征都是以字节为单位顺序访问。 块设备包括（） 硬盘 软盘 光盘 U盘 都是。因为它们的访问特征都是均匀的数据块访问。 网络设备包括（） 以太网卡 wifi网卡 蓝牙设备 网盘设备 网络设备的访问特征是格式化报文交换。而网盘在模拟实现上应该算块设备。 关于CPU与设备的通信方式包括（） 轮询 设备中断 DMA PIPE PIPE是用于进程间通信的。虽然DMA听起来是直接把数据写入到内存，不过还是需要CPU参与设置的。 关于IO数据传输的阐述正确的是（） 程序控制I/O(PIO, Programmed I/O)通过CPU的in/out或者load/store传输所有数据 DMA设备控制器可直接访问系统总线并直接与内存互相传输数据 DMA机制适合字符设备 PIO机制适合块设备 DMA机制适合块设备，PIO机制适合简单，低速的字符设备等。最后两个选项反了。 常用移臂调度算法包括（） 先来先服务（FIFO）算法 最短寻道时间优先（SSTF）算法 电梯调度（SCAN）算法 单向扫描（C-SCAN）算法 都对。除此之外还有CLOOK和N-step-SCAN算法。 在设备管理子系统中，引入缓冲区的目的主要有() 缓和CPU与I/O设备间速度不匹配的矛盾 减少对CPU的中断频率，放宽对CPU中断响应时间的限制 解决基本数据单元大小（即数据粒度）不匹配的问题 提高CPU和I/O设备之间的并行性 都对。 简答题 字符设备的特点是什么？ 以字节为单位顺序访问。 块设备的特点是什么？ 以均匀的数据块为单位随机访问。 网络设备的特点是什么？ 以格式化报文为单位的复杂交互访问。 阻塞I/O、非阻塞I/O和异步I/O这三种I/O方式有什么区别？ 阻塞I/O：数据读写操作后，进程将进入等待状态，直到完成操作时返回； 非阻塞I/O：数据读写操作后，进程将立即返回； 异步I/O：数据读写操作后，进程将立即返回；内核在完成操作时通知进程； 区别： 进程发出操作命令后，进程是否等待； 操作结果反馈方式 请描述I/O请求到完成的整个执行过程。 CPU通过总线与设备相连；CPU通过主动的I/O端口和映射内存读写操作与设备进行信息交互；设备通过中断请求来响应CPU的操作；在CPU的控制下，DMA可直接在设备接口与内存间的数据传输。 进程通过系统调用发送对设备的抽象操作命令 内核把抽象的设备操作命令转换成具体的设备I/O端口和映射内存读写序列，并在设备驱动中实施读写操作 当这个读写序列较长时，CPU会控制DMA进行内存与设备接口的直接数据传送 设备在收到控制序列后，执行操作动作，并在完成时向CPU发出中断请求 CPU通过中断服务例程响应设备的中断请求，并进行后续处理，直到系统调用返回，从而完成整个I/O操作过程。 IO数据传输有哪几种？ 程序控制I/O： CPU通过显式的IO指令，如x86的in, out等传输数据 memory读写方式，即把device的寄存器，内存等映射到物理内存中 直接内存访问（DMA）：在CPU的控制下，DMA控制器直接在内存与设备接口间传输数据 轮询方式的特点是什么？ 简单 I/O操作频繁或不可预测时，开销大和延时长 中断方式的特点是什么？ 处理不可预测事件效果好 开销相对较高 DMA方式的特点是什么？ 直接在内存与设备接口间进行数据传输 适合高速和简单的数据传输 CPU的开销小 请简要阐述磁盘的工作过程。 磁头移动到期望的磁道 盘片旋转定位到期望的柱面和扇区 开始读写 请描述磁盘I/O操作时间组成。 磁盘I/O操作一般分成五个步骤： 等待设备可用 等待通道（PIO或DMA通道）可用 寻道 旋转延迟 数据传输 其中后四个步骤被称为“设备忙”状态，一般认为是传输时间，公式为： Ta=Ts+12r+brNT_a = T_s+ \\frac{1}{2r} + \\frac{b}{rN} Ta​=Ts​+2r1​+rNb​ 请说明磁盘调度算法的评价指标。 总的I/O时间开销（显然） 公平性 平均等待时间（似乎这对磁盘调度不是很重要） 请描述FIFO、SSTF、SCAN、CSCAN、LOOK、C-LOOK、N-step-SCAN和FSCAN等磁盘调度算法的工作原理。 磁盘调度算法就是优化磁盘数据块的访问顺序。 先进先出（FIFO）算法：按请求顺序访问 最短寻道时间优先（SSTF）算法：从当前位置找当前最近的访问数据块位置 扫描（SCAN）算法：保持磁头移动方向到最远处，并顺序访问需要访问的数据块 循环扫描（C-SCAN）算法：只在一个方向上移动时访问数据的SCAN算法 LOOK算法：保持磁头移动方向到已有的最后一个请求，并顺序访问需要访问的数据块 C-LOOK算法：只在一个方向上移动时访问数据的LOOK算法； N步扫描（N-step-SCAN）算法： 将磁盘请求队列分成长度为N的子队列 按FIFO算法依次处理所有子队列 按扫描算法处理每个队列 双队列扫描（FSCAN）算法： 把磁盘I/O请求分成两个队列，交替使用扫描算法处理一个队列 新生成的磁盘I/O请求放入另一队列中 磁盘缓存的作用是什么？ 磁盘缓存是磁盘扇区在内存中的缓存区。作用是通过缓存访问，减少磁盘访问。 请描述单缓存(Single Buffer Cache)的工作原理。 只有一个缓存区，用户进程和I/O设备只能交替访问缓存区。 请描述双缓存(Double Buffer Cache)的工作原理。 设置两个缓存区，任何时刻用户进程和I/O设备可同时访问不同的缓存区。 请描述访问频率置换算法(Frequency-based Replacement)的基本原理。 思路： 考虑磁盘访问的密集特征，对密集引用不计数 短周期内采用LRU，长周期内采用LFU 做法： 把栈分成三个区域：新区域（栈顶）、中间区域、旧区域（栈底） 新区域中数据块的引用，不计数 中间区域和旧区域中数据块的引用，引用计数加 淘汰只在旧区域中找引用计数最小的数据块 实践题 请以键盘输入、到标准输出设备stdout的printf输出、串口输出、磁盘文件复制为例，描述ucore操作系统I/O从请求到完成的整个执行过程，并分析I/O过程的时间开销。 没做，现在还没做完lab8，感觉实在过于麻烦了。 完成磁盘访问与磁盘寻道算法的作业，然后实现CSCAN、LOOK、C-LOOK、FSCAN等磁盘调度算法中的一个。具体帮助和要求信息请看Chapter 37: Hard Disk Drives、disksim指导信息和disksim参考代码 看起来不难，但现在做起来意义不大，所以不做了。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》2014年期末考试分析","slug":"2018-05-23-《操作系统》2014年期末考试分析","date":"2018-05-23T16:46:19.000Z","updated":"2018-05-23T16:46:19.000Z","comments":true,"path":"post/os-mooc-2014-final-exam-analysis/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-2014-final-exam-analysis/","excerpt":"","text":"一 信号（12分） 在Linux/Unix中，一个用户从shell中执行了一个运行时间较长且不知何时能够结束的程序，Linux/UNIX可以让用户根据个人需求随时通过敲击Ctrl-C组合键来终止这个程序的执行。请回答如下问题。要求设计应该具有通用性，列出的设计实现不超过6点，每点不超过 4行。问题的执行流程描述不超过8行。 如果要在ucore中实现Linux/UNIX同样的功能，请问应该如何修改ucore来支持此功能？ uCore的shell也是一个程序，我们希望避免这个shell在执行中被用户敲入的Ctrl-C所终止，请问在保证1的要求前提下，如何修改ucore和shell来支持此功能？ 说明在你的设计下，shell和某一可被终止程序在执行过程中，用户敲击Ctrl-C后，uCore和shell的执行流程。 很显然，应该通过信号机制来实现相应的功能。我觉得可以修改编译器，使得编译时为每个程序自动加入信号处理例程，进程启动时将相应的信号处理函数注册到内核，发生SIGKILL（Ctrl+C组合）时将信号分发给进程，进程执行信号处理例程并退出。 shell可以在程序中屏蔽Ctrl+C信号 ucore和shell的执行流程： ucore接收到键盘中断 ucore识别出按下的键是Ctrl+C，发送信号 中断返回时检查到进程有未处理的信号，转入信号处理（这一步我们大概没有细讲……总之就是进入了正在执行的程序的信号处理例程） 信号处理例程使进程退出 shell继续wait 二 IPC机制 在具备了执行用户态进程的能力之后，uCore要为这些进程提供的一个重要服务，是用户进程之间的消息传递机制（Inter-Process Communication，简写为 IPC）。现在，我们要为uCore实现以下两个系统调用，以实现一种同步的IPC机制（暂不考虑超时等功能）： int sys_send_event(int pid, int event); 参数： pid - 该消息的目标进程的进程号； event – 消息内容，用一个整型表示。 返回值：消息成功发送时，返回0；否则，返回相应的错误代码。 int sys_recv_event(int *pid, int *event); 参数： pid - 函数返回时，*pid保存发出消息的进程的进程号，可以为NULL； event – 函数返回时，*event保存消息内容，可以为NULL。 返回值：消息成功接收时，返回 0；否则，返回相应的错误代码。 （1） 以下是一个基于上述IPC机制求质数的用户程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;ulib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;const int total = 1000;void primeproc(void)&#123; int index = 0, this, num, pid = 0;top: recv_event(NULL, &amp;this); cprintf(&quot;%d is a primer.\\n&quot;, this); while (recv_event(NULL, &amp;num) == 0) &#123; if ((num % this) == 0) &#123; continue; &#125; if (pid == 0) &#123; if (index + 1 == total) &#123; goto out; &#125; if ((pid = fork()) == 0) &#123; index++; goto top; &#125; if (pid &lt; 0) &#123; goto out; &#125; &#125; if (send_event(pid, num) != 0) &#123; goto out; &#125; &#125;out: cprintf(&quot;[%04d] %d quit.\\n&quot;, getpid(), index);&#125;int main(void)&#123; int i, pid; unsigned int time = gettime_msec(); if ((pid = fork()) == 0) &#123; primeproc(); exit(0); &#125; assert(pid &gt; 0); for (i = 2;; i++) &#123; if (send_event(pid, i) != 0) &#123; break; &#125; &#125; cprintf(&quot;use %d msecs.\\n&quot;, gettime_msec() - time); cprintf(&quot;primer3 pass.\\n&quot;); return 0;&#125; 简述这个程序是如何判断并输出前五个质数的。 主进程（称为P1）首先fork出一个子进程，子进程开始执行primeproc()函数（称为P2）。主进程从i = 2开始不断向P1发送内容为i的自然数，直到发送不成功为止。 P1进程不断循环： 接收P0发送的消息，将这个整数保存下来，作为质数this 不断接收P0发送的消息，保存为num；如果接收不成功，退出并打印信息 若num可以被this整除，显然num不是质数，跳出此次循环，继续等待消息 。。。不会了 学长答案说： 每个进程是一个输出一个素数，负责检验传进来的数是否整除这个素数，如果都过了在新建一个进程 我觉得从理论上来说确实是这样，但是不够详细。 （2） 给出一种基于等待队列的上述IPC机制的实现方案。 在我的妄想中这个是这样实现的： 建立两个等待队列：发送等待队列和接收等待队列 当进程发送消息时，检查目标进程是否在接收等待队列中，如果不在，则加入发送等待队列；如果在，则将目标进程取出，发送对应的消息 当进程接收消息时，检查发送等待队列中是否有进程发送的目标是它，如果有，则将该进程取出，接收对应的消息；否则加入接收等待队列 三 ucore中的信号量实现（10分） 在uCore中，信号量的定义如下 12345678910111213141516171819typedef struct &#123; int value; wait_queue_t wait_queue;&#125; semaphore_t;// __up 函数是信号量 V 操作的具体实现函数static __noinline void __up(semaphore_t *sem, uint32_t wait_state) &#123; bool intr_flag; local_intr_save(intr_flag); &#123; wait_t *wait; if ((wait=wait_queue_first(&amp;(sem-&gt;wait_queue)))==NULL) &#123; ________; &#125; else &#123; wakeup_wait(&amp;(sem-&gt;wait_queue), wait, wait_state, 1); &#125; &#125; local_intr_restore(intr_flag);&#125; （1） 补全程序中的空行________。 sem-&gt;value++; （2） 信号量的value值&gt;0时，表示________的数量；value值&lt;0时，表示________的数量。 剩余资源 等待队列中进程 （3） local_intr_save和local_intr_restore这两个函数的功能分别是什么？为什么要调用这两个函数？ 关中断和开中断；为了保证执行过程的原子性。 四 学生看MOOC同步问题（15分） 假设一个MOOC网站有1、2、3三种不同的课程视频可由学生选择学习，网站播放课程视频的规则为： 任一时刻最多只能播放一种课程视频，正在播放的课程视频是自动循环播放的，最后一个学生主动离开时结束当前课程视频的播放； 选择当前正在播放的课程视频的学生可立即进入播放页面，允许同时有多位选择同一种课程视频的学生观看，同时观看的学生数量不受限制； 等待观看其它课程视频的学生按到达顺序排队，当一种新的课程视频开始放映时，所有等待观看该课程视频的学生可依次序进入播放页面同时观看。 用一个进程代表一个学生，要求：用信号量的P、V操作实现上述规则，并给出信号量的 定义和初始值。 我认为这个问题有点像读者-写者问题。下面是我的实现方法（虽然我也觉得有一些问题）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#define COURSE 3semaphore mutex; // 保护互斥变量的锁semaphore wait[COURSE]; // 等待观看视频的学生队列int count[COURSE]; // 共享变量：等待/正在观看某视频的学生数量int cur; // 当前正在播放的视频/* INITIALIZATION */void initialize() &#123; mutex = new semaphore(1); cur = -1; for (int i = 0; i &lt; COURSE; i++) &#123; wait[i] = new semaphore(0); count[i] = 0; &#125;&#125;/* Student Thread */void Student(int choice) &#123; // 尝试开始观看 mutex.P(); count[choice]++; // 更新等待人数 if (cur != choice) &#123; if (cur &gt; 0) &#123; // 当前播放的视频不符合要求，在期望视频的等待队列上睡眠 mutex.V(); wait[choice].P(); &#125; else &#123; cur = choice; // 当前未播放视频，直接睡眠 mutex.V(); &#125; &#125; else &#123; mutex.V(); &#125; // Start to watch // End watching mutex.P(); count[choice]--; // 更新等待人数 if (count[choice] &gt; 0) &#123; for (int i = 0; i &lt; count[choice]; i++) // 唤醒所有准备观看此视频的学生 wait[choice].V(); &#125; else &#123; cur = -1; // 寻找下一个播放的视频 for (int i = 0; i &lt; COURSE; i++) &#123; if (count[i] &gt; 0) &#123; cur = i; for (int j = 0; j &lt; count[i]; j++) wait[i].V(); break; &#125; &#125; &#125; mutex.V();&#125; 学长的实现是这样的，说实话，我也不是很明白： 123456789101112131415161718192021222324252627avaid=1A=0,B=0,C=0waitA=waitB=waitC=0;观看:waitA+=1;P(avaid)if (countA+countB+countC==0) V(A);V(avaid)P(A);waitA-=1;P(avaid)countA+=1;V(avaid)V(A);看完:P(avaid)countA-=1;if (countA==0) &#123; V(avaid) P(A); if (waitB&gt;0) V(B); else if (waitC&gt;0) V(C);&#125; elseV(avaid) 五 Stride调度算法（12分） 在lab6中，我们实现了Stride Scheduling调度算法，并声称它对“进程的调度次数正比于其优先级”。对于优先级为2、3、5、7的4个进程，选取210为MAX_STRIDE，则： 简要描述Stride Scheduling调度算法。 四个进程的步长分别为：、、、。 假设四个进程的初始stride值均为0，证明：总有一个时刻，四个进程的stride值都是210，且此时四个进程被调度的次数正比于其优先级。 Stride调度算法： 每个进程有一个priority（优先级），pass和stride stride = BigStride / priority 每次调度时选择pass值最小的进程，更新该进程的pass：pass += stride 步长分别为105、70、42和30。 下列模拟过程假设在进程的pass值相等时，选择进程编号最小的执行。 此时，A被调度了2次，B被调度了3次，C被调度了5次，D被调度了7次，恰好与优先级成正比。之所以会这么规整，主要还是因为BigStride的值能够正好被各个优先级的值整除。 六 银行家算法（12分） 死锁是操作系统中资源共享时面临的一个难题。请回答下列与死锁相关的问题。 （1） 设系统中有下述解决死锁的方法： 银行家算法； 检测死锁，终止处于死锁状态的进程，释放该进程占有的资源； 资源预分配。 简述哪种办法允许最大的并发性，即哪种办法允许更多的进程无等待地向前推进？请按“并发性”从大到小对上述三种办法进行排序。 排序：2 &gt; 1 &gt; 3 原因： 银行家算法每满足一个资源请求时都会进行安全状态检查。因为安全状态中实际上包含了一部分不会发生死锁的状态，所以它会拒绝一些本来可以接受的请求，所以降低了一点并发性。 显然在这种做法下所有进程都可以无等待地推进，直到真的出现了死锁再进行处理。 直觉上来说，资源预分配的并发性比银行家算法更低，因为银行家算法至少保留了一些动态性能，而资源预分配完全牺牲了动态性。 （2） 假设一个使用银行家算法的系统，当前有5个进程P0, P1, P2, P3, P4，系统中有三类资源A、B、C，假设在某时刻有如下状态： Allocation矩阵： 进程 A B C P0 0 0 3 P1 1 0 0 P2 1 3 5 P3 0 0 2 P4 0 0 1 Max矩阵： 进程 A B C P0 0 0 4 P1 1 7 5 P2 2 3 5 P3 0 6 4 P4 0 6 5 Available向量：[1, 4, 0] 请问当前系统是否处于安全状态？如果系统中的可利用资源为（0, 6, 2），系统是否安全？如果系统处在安全状态，请给出安全序列；如果系统处在非安全状态，请简要说明原因。 首先计算Need矩阵：Need = Max - Allocation 进程 A B C P0 0 0 1 P1 0 7 5 P2 1 0 0 P3 0 6 2 P4 0 6 4 然后进行安全状态检测： Finish[P2] = false，Need[P2] &lt;= Available；于是释放P2资源，Available += [1, 3, 5] = [2, 7, 5]，Finish[P2] = true Finish[P0] = false，Need[P0] &lt;= Available；于是释放P0资源，Available += [0, 0, 3] = [2, 7, 8]，Finish[P0] = true Finish[P1] = false，Need[P1] &lt;= Available；于是释放P1资源，Available += [1, 0, 0] = [3, 7, 8]，Finish[P1] = true Finish[P3] = false，Need[P3] &lt;= Available；于是释放P3资源，Available += [0, 0, 2] = [3, 7, 10]，Finish[P3] = true Finish[P4] = false，Need[P4] &lt;= Available；于是释放P4资源，Available += [0, 0, 1] = [3, 7, 11]，Finish[P4] = true 发现系统处于安全状态。 如果将Available向量修改为[0, 6, 2]，重新进行安全状态检测： Finish[P0] = false，Need[P0] &lt;= Available；于是释放P0资源，Available += [0, 0, 3] = [0, 6, 5]，Finish[P0] = true Finish[P3] = false，Need[P3] &lt;= Available；于是释放P3资源，Available += [0, 0, 2] = [0, 6, 7]，Finish[P3] = true Finish[P4] = false，Need[P4] &lt;= Available；于是释放P4资源，Available += [0, 0, 1] = [0, 6, 5]，Finish[P4] = true 此时找不到满足条件的进程了，因此系统处于不安全状态。 七 SFS文件系统（12分） uCore实现了一个简单的文件系统Simple FS，假设该文件系统现已经装载到一个硬盘中（disk0），该硬盘的大小为20M，目前有三个文件A.txt，B.txt和C.txt存放在该硬盘中，三个文件的大小分别是48K，1M和4M。 （1） 简要描述SFS文件系统中文件数据的组织结构（即：SFS文件的数据的存放位置组织方式）。 以下答案来自os_course_exercise_library，总之这个仓库让我感觉十分惊诧。 一个superblock维护基本信息（1’）， 多个freemap（数量由分区大小确定，1’）， 一个根目录inode（1’）； 目录和文件均由一个inode和具体数据块组成，其中inode包含文件的基本属性、12个直接索引和一级/二级索引表的块地址（1’）， 目录的数据块中存放（文件名 、inode地址）的数组（1’）， 文件的数据块中存放文件的具体内容（1’）。 呃，有标答了哦。不过，要是我自己来回答，会这样说： ……然后就懒得说了，反正我还没做完Lab8，标答比我能总结出来的东西还是要强的。 （2） 请根据Simple FS的设计实现情况，画出该文件系统当前在disk0上的布局情况，需要给出相应结构的名称和起始块号。 答案来源同上。 （除了0、1、2以外，其它块地址均可变，言之有理即可） （2分） 0 superblock 1 根目录inode 2 freemap（640K，只需要1块） 3 根目录的数据块（包含A.txt、B.txt、C.txt的inode的地址） （1分） 4 A.txt的inode（包含12个直接索引块的地址） 5-16 A.txt的数据块 （2分） 17 B.txt的inode（包含12个直接索引块和1个一级间接索引） 18-29 B.txt的直接索引数据 30 B.txt的一级间接索引（包含244个数据块地址） 31-274 B.txt的一级间接索引块 （1分） 275 C.txt的inode（包含12个直接索引块和1个一级间接索引） 276-287 C.txt的一级间接索引块 288 C.txt的一级间接索引（包含1012个数据块地址） 289-1300 C.txt的一级间接索引块 这个硬盘的块大小是4KB（虽然不知道为什么），因此整个硬盘共有5120块，因此freemap的大小应该为5Kbit。第0块是superblock，第1块是根目录inode，第2块是freemap，用1块就够了。后面就开始链式存储具体的文件和目录内容。 3：根目录的数据块 4：A的inode。因为A的大小为48KB，因此12个直接索引块恰好能够装下，不需要一级索引。 5-16：A的数据块 17：B的inode。因为B的大小为1M，所以需要12个直接索引、1个一级索引块和244个间接索引。 18-29：B的直接索引数据块 30：B的一级索引块 31-274：B的间接索引数据块 275：C的inode。因为C的大小为4M，所以需要12个直接索引、1个一级索引块和1012个间接索引。 276-287：C的直接索引数据块 288：C的一级索引块 289-1300：C的间接索引数据块 八 VFS文件系统（12分） uCore的文件管理主要由以下四个部分组成：通用文件系统访问接口层，文件系统抽象层(VFS)，具体文件系统层以及外设接口层，其中VFS层的作用是用来管理不同的文件系统并向上提供一致的接口给内核其他部分访问。在ucore中我们已经实现了一个具体的文件系统：Simple FS，并将该文件系统装载到了disk0上，假设ucore又实现了一个文件系统FAT32，并将这个新的文件系统装载到了disk1上。 （1） 请简单描述一下如何修改VFS层的数据结构使其可以有效的管理上述已安装的具体文件系统。涉及VFS层的数据结构如下： 1234567891011struct file &#123; enum &#123; FD_NONE, FD_INIT, FD_OPENED, FD_CLOSED, &#125; status; bool readable; bool writable; int fd; off_t pos; struct inode *node; atomic_t open_count; &#125;; 1234567891011121314struct inode &#123; union &#123; struct device __device_info; struct sfs_inode __sfs_inode_info; &#125; in_info; /* info */ enum &#123; inode_type_device_info = 0x1234, inode_type_sfs_inode_info, &#125; in_type; /* info */ atomic_t ref_count; atomic_t open_count; struct fs *in_fs; const struct inode_ops *in_ops; &#125;; 1234567891011121314struct fs &#123; union &#123; struct sfs_fs __sfs_info; &#125; fs_info; /* info */ enum &#123; fs_type_sfs_info, &#125; fs_type; /* info */ int (*fs_sync)(struct fs *fs); struct inode *(*fs_get_root)(struct fs *fs); int (*fs_unmount)(struct fs *fs); void (*fs_cleanup)(struct fs *fs); &#125;; 12345678910111213struct inode_ops &#123; unsigned long vop_magic; int (*vop_open)(struct inode *node, uint32_t open_flags); int (*vop_close)(struct inode *node); int (*vop_read)(struct inode *node, struct iobuf *iob); int (*vop_write)(struct inode *node, struct iobuf *iob); int (*vop_getdirentry)(struct inode *node, struct iobuf *iob); int (*vop_create)(struct inode *node, const char *name, bool excl, struct inode **node_store); int (*vop_lookup)(struct inode *node, char *path, struct inode **node_store); ……&#125;; 对VFS必要的修改并不多，原因很简单：这是VFS。需要在以下位置添加必要信息： 在inode.in_info对应的匿名union中添加struct fat32_inode __fat32_inode_info; 在inode.in_type对应的匿名enum中添加inode_type_fat32_inode_info, 在fs.fs_info对应的匿名union中添加struct fat32_fs __fat32_info; 在fs.fs_type对应的匿名enum中添加fs_type_fat32_info, （3） 两个具体文件系统均已实现了对数据文件的4种基本操作。现在有某个用户态进程执行了一个copy(source_path, dest_path, ...)函数，该函数是把disk1根目录下的一个文件A.txt拷贝到了disk0的根目录下（不用考虑文件的大小），请结合ucore中对数据文件的操作流程描述一下这个函数的执行过程。 以下内容来自学长答案。 根据源文件目录调用vop_lookup查找文件的inode，这将调用FAT32的查找实现 根据目的文件路径调用vop_lookup查找文件的inode，这将调用SFS的查找实现 判断合法性 可能需要创建文件 open文件 建立buffer，对A调用vop_read，对B调用vop_write 关闭文件","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》ucore实验四“内核线程管理”报告","slug":"2018-05-23-《操作系统》ucore实验四“内核线程管理”报告","date":"2018-05-23T10:25:22.000Z","updated":"2018-05-23T10:25:22.000Z","comments":true,"path":"post/os-ucore-lab-4-report/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-ucore-lab-4-report/","excerpt":"","text":"实验目的 了解内核线程创建/执行的管理过程 了解内核线程的切换和基本调度过程 实验内容 实验2/3完成了物理和虚拟内存管理，这给创建内核线程（ 内核线程是一种特殊的进程） 打下了提供内存管理的基础。当一个程序加载到内存中运行时，首先通过ucore OS的内存管理子系统分配合适的空间，然后就需要考虑如何分时使用CPU来“并发”执行多个程序，让每个运行的程序（ 这里用线程或进程表示） “感到”它们各自拥有“自己”的CPU。 本次实验将首先接触的是内核线程的管理。内核线程是一种特殊的进程，内核线程与用户进程的区别有两个： 内核线程只运行在内核态 用户进程会在在用户态和内核态交替运行 所有内核线程共用ucore内核内存空间，不需为每个内核线程维护单独的内存空间 而用户进程需要维护各自的用户内存空间 相关原理介绍可看附录B：【原理】进程/线程的属性与特征解析。 练习0：填写已有实验 本实验依赖实验1/2/3。请把你做的实验1/2/3的代码填入本实验中代码中有“LAB1”,“LAB2”,“LAB3”的注释相应部分。 Lab1： kdebug.c:print_stackframe trap.c:idt_init trap.c:trap_dispatch Lab2： default_pmm.c:default_init default_pmm.c:default_init_memmap default_pmm.c:default_alloc_pages default_pmm.c:default_free_pages pmm.c:get_pte pmm.c:page_remove_pte Lab3： vmm.c:do_pgfault swap_fifo.c:__fifo_map_swappable swap_fifo.c:__fifo_swap_out_victim 练习1：分配并初始化一个进程控制块（需要编码） alloc_proc函数（位于kern/process/proc.c中）负责分配并返回一个新的struct proc_struct结构，用于存储新建立的内核线程的管理信息。ucore需要对这个结构进行最基本的初始化，你需要完成这个初始化过程。 【提示】在alloc_proc函数的实现中，需要初始化的proc_struct结构中的成员变量至少包括：state/pid/runs/kstack/need_resched/parent/mm/context/tf/cr3/flags/name。 请在实验报告中简要说明你的设计实现过程。请回答如下问题： 请说明proc_struct中struct context context和struct trapframe *tf成员变量含义和在本实验中的作用是啥？（提示通过看代码和编程调试可以判断出来） 1.1 具体实现 注释中给出了以下域的说明，其中有些是不需要在这个函数中进行分配的： enum proc_state state：表示进程状态，在此函数中应赋值为PROC_UNINIT，表示该进程的初始化尚未完成（对进程状态的修改在do_fork函数的最后，通过调用sched.c:wakeup_proc函数完成） int pid：初始赋值为-1，表示尚未分配（pid在do_fork函数中通过调用get_pid进行分配） int runs：已运行次数，此处赋值为0 uintptr_t kstack：内核堆栈起始地址，此时堆栈尚未分配，因此置为0；实际在do_fork函数中通过调用setup_kstack进行分配 volatile bool need_resched：当前进程是否需要调度；初始化为不需要（0） struct proc_struct *parent：当前进程的父进程，初始化为NULL；在do_fork中初始化为调用do_fork的当前进程 struct mm_struct *mm：内存管理，初始化为NULL；在do_fork中通过调用copy_mm进行初始化（虽然实际上直接使用了内核的mm，因为是内核线程） struct context context：在Lab5中发现context需要清零，但在此处似乎不初始化也能正常运行；在do_fork中通过调用copy_thread函数进行初始化 struct trapframe *tf：当前的中断帧，初始化为NULL；在do_fork中通过调用copy_thread函数进行初始化 uintptr_t cr3：当前进程的页表基地址；直接初始化为kernel的页表基地址boot_cr3 uint32_t flags：当前进程属性，因为是初始化，所以置为0了 char name[PROC_NAME_LEN + 1]：进程的名称，此处初始化似乎不是很重要，不过还是清零了 123456789101112131415161718192021// alloc_proc - alloc a proc_struct and init all fields of proc_structstatic struct proc_struct *alloc_proc(void) &#123; struct proc_struct *proc = kmalloc(sizeof(struct proc_struct)); if (proc != NULL) &#123; //LAB4:EXERCISE1 YOUR CODE proc-&gt;state = PROC_UNINIT; // 正在创建和初始化状态中 proc-&gt;pid = -1; // 参考了答案：未初始化的进程id为-1 proc-&gt;runs = 0; // 还没有运行过 proc-&gt;kstack = 0; // 参考了答案：初始化内核堆栈似乎是在do_fork()中进行的？ proc-&gt;need_resched = 0; // 初始化为不需要调度 proc-&gt;parent = NULL; proc-&gt;mm = NULL; // 之后也不会分配，因为都是内核态线程，所以直接使用内核的mm memset(&amp;(proc-&gt;context), 0, sizeof(struct context)); // 在LAB5中发现，忘了清零context了 // proc-&gt;tf = kmalloc(sizeof(struct trapframe)); // tf似乎不需要在此处设置 proc-&gt;cr3 = boot_cr3; // 参考了答案：内核态线程不需要分配新的页表地址；这对于正确执行是必需的 proc-&gt;flags = 0; // 参考了答案：标志位置为0 memset(proc-&gt;name, 0, PROC_NAME_LEN); // 参考了答案：将进程名清零，不过不是必需的 &#125; return proc;&#125; 1.2 context和trapframe的含义和用途 实验指导书中指出： context：进程的上下文，用于进程切换（参见switch.S）。在 uCore中，所有的进程在内核中也是相对独立的（例如独立的内核堆栈以及上下文等等）。使用context保存寄存器的目的就在于在内核态中能够进行上下文之间的切换。实际利用context进行上下文切换的函数是kern/process/switch.S:switch_to tf：中断帧的指针，总是指向内核栈的某个位置：当进程从用户空间跳到内核空间时，中断帧记录了进程在被中断前的状态。当内核需要跳回用户空间时，需要调整中断帧以恢复让进程继续执行的各寄存器值。除此之外，uCore内核允许嵌套中断。因此为了保证嵌套中断发生时tf总是能够指向当前的trapframe，uCore 在内核栈上维护了tf的链，可以参考trap.c::trap函数做进一步的了解。 经过阅读代码，我认为，switch_to的主要工作是把被切换的进程的各个通用寄存器（eip、esp、ebx、ecx、edx、esi、edi、ebp，但不包括段寄存器，因为kernel进程使用的段是相同的）保存到进程的context结构中，然后加载即将开始运行的进程的context结构中保存的通用寄存器。而trapframe就是我们在Lab1中已经了解的中断保存现场。对于内核线程，trapframe的意义似乎并不大，因为不需要进行用户空间到内核空间的切换。 今天我的某个叫wenj的同学指出了一个很有趣的问题，这使得我重新翻出了实验报告：context和trapframe中为何都存储了EIP？这两种结构的功能是否重复了？翻了翻实验指导书，发现其实这个问题已经有比较明确的解答了：trapframe一般来说是用户态切换到内核态用的，而context是内核态自己切换上下文用的（因为特权级不变，所以不需要存储页表基地址、段寄存器等内容）；不过用户态跳转到内核态的时候也需要保存context中的通用寄存器，因为trapframe不存通用寄存器。 以及，lab4中构建进程的过程是这样的： “硬”构造出第一个内核线程idleproc 调用do_fork函数，fork idleproc，生成initproc 事实上initproc返回时会假装自己是通过系统调用do_fork生成的，所以返回过程会比较复杂： uCore会执行进程切换，让initproc执行。在对initproc进行初始化时，设置了initproc-&gt;context.eip = (uintptr_t)forkret，这样，当执行switch_to函数并返回后，initproc将执行其实际上的执行入口地址forkret。而forkret会调用位于kern/trap/trapentry.S中的forkrets函数执行，具体代码如下： 123456789101112131415.globl __trapret__trapret:# restore registers from stackpopal# restore %ds and %espopl %espopl %ds# get rid of the trap number and error codeaddl $0x8, %espiret.globl forkretsforkrets:# set stack to this new process&apos;s trapframemovl 4(%esp), %esp //把esp指向当前进程的中断帧jmp __trapret 可以看出，forkrets函数首先把esp指向当前进程的中断帧，从_trapret开始执行到iret前，esp指向了current-&gt;tf.tf_eip，而如果此时执行的是initproc，则current-&gt;tf.tf_eip=kernel_thread_entry，initproc-&gt;tf.tf_cs = KERNEL_CS，所以当执行完iret后，就开始在内核中执行kernel_thread_entry函数了，而initproc-&gt;tf.tf_regs.reg_ebx = init_main，所以在kernl_thread_entry中执行“call %ebx”后，就开始执行initproc的主体了。Initprocde的主体函数很简单就是输出一段字符串，然后就返回到kernel_tread_entry函数，并进一步调用do_exit执行退出操作了。本来do_exit应该完成一些资源回收工作等，但这些不是实验四涉及的，而是由后续的实验来完成。至此，实验四中的主要工作描述完毕。 练习2：为新创建的内核线程分配资源（需要编码） 创建一个内核线程需要分配和设置好很多资源。kernel_thread函数通过调用do_fork函数完成具体内核线程的创建工作。do_kernel函数会调用alloc_proc函数来分配并初始化一个进程控制块，但alloc_proc只是找到了一小块内存用以记录进程的必要信息，并没有实际分配这些资源。ucore一般通过do_fork实际创建新的内核线程。do_fork的作用是，创建当前内核线程的一个副本，它们的执行上下文、代码、数据都一样，但是存储位置不同。在这个过程中，需要给新内核线程分配资源，并且复制原进程的状态。你需要完成在kern/process/proc.c中的do_fork函数中的处理过程。它的大致执行步骤包括： 调用alloc_proc，首先获得一块用户信息块。 为进程分配一个内核栈。 复制原进程的内存管理信息到新进程（但内核线程不必做此事） 复制原进程上下文到新进程 将新进程添加到进程列表 唤醒新进程 返回新进程号 请在实验报告中简要说明你的设计实现过程。请回答如下问题： 请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。 2.1 具体代码实现 函数的大致执行步骤与题目中列出的相同。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950intdo_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf) &#123; int ret = -E_NO_FREE_PROC; struct proc_struct *proc; if (nr_process &gt;= MAX_PROCESS) &#123; goto fork_out; &#125; ret = -E_NO_MEM; // 1. call alloc_proc to allocate a proc_struct proc = alloc_proc(); if (proc == NULL) &#123; // 参考答案添加了错误处理 goto fork_out; &#125; proc-&gt;parent = current; // 参考了答案 // 2. call setup_kstack to allocate a kernel stack for child process if (setup_kstack(proc) != 0) &#123; // 参考答案添加了错误处理 goto bad_fork_cleanup_proc; &#125; // 3. call copy_mm to dup OR share mm according clone_flag // CLONE_VM表示分享；实际上因为都在内核态所以什么都没做，只是assert NULL了 if (copy_mm(clone_flags, proc) != 0) &#123; // 参考答案添加了错误处理 goto bad_fork_cleanup_kstack; &#125; // 4. call copy_thread to setup tf &amp; context in proc_struct copy_thread(proc, stack, tf); // 5. insert proc_struct into hash_list &amp;&amp; proc_list // 参考了答案：关中断的原因是，进程号要求唯一性，此操作需要为原子操作，防止被打断而重复添加 // 所以参考答案是很有必要的。但是我认为在实验指导书中也应该说明一下。 bool intr_flag; local_intr_save(intr_flag); &#123; proc-&gt;pid = get_pid(); hash_proc(proc); nr_process++; // 参考答案添加在此处（我本来以为用了get_pid()就不需要这句了 list_add_before(&amp;proc_list, &amp;proc-&gt;list_link); &#125; local_intr_restore(intr_flag); // 6. call wakeup_proc to make the new child process RUNNABLE wakeup_proc(proc); // 7. set ret vaule using child proc&apos;s pid ret = proc-&gt;pid;fork_out: return ret;bad_fork_cleanup_kstack: put_kstack(proc);bad_fork_cleanup_proc: kfree(proc); goto fork_out;&#125; 2.2 能否为每个新线程赋值唯一ID 阅读代码可以得知，idleproc的PID是由proc_init函数设置的，但initproc的PID应该怎么设置呢？我的解决方法是把分配PID的过程移到do_fork函数中，这样至少能通过测试了。参考答案的做法也类似，不过在分配PID和将进程插入队列的过程中进行了关中断处理，保证原子操作。 PID的唯一性是通过关中断和get_pid函数保证的，该函数查看当前的全部进程，在不发生中断的情况下，可以保证新分配的PID与之前的PID是不冲突的。 12345678910111213141516171819202122232425262728293031323334// get_pid - alloc a unique pid for processstatic intget_pid(void) &#123; static_assert(MAX_PID &gt; MAX_PROCESS); struct proc_struct *proc; list_entry_t *list = &amp;proc_list, *le; static int next_safe = MAX_PID, last_pid = MAX_PID; if (++ last_pid &gt;= MAX_PID) &#123; last_pid = 1; goto inside; &#125; if (last_pid &gt;= next_safe) &#123; inside: next_safe = MAX_PID; repeat: le = list; while ((le = list_next(le)) != list) &#123; proc = le2proc(le, list_link); if (proc-&gt;pid == last_pid) &#123; if (++ last_pid &gt;= next_safe) &#123; if (last_pid &gt;= MAX_PID) &#123; last_pid = 1; &#125; next_safe = MAX_PID; goto repeat; &#125; &#125; else if (proc-&gt;pid &gt; last_pid &amp;&amp; next_safe &gt; proc-&gt;pid) &#123; next_safe = proc-&gt;pid; &#125; &#125; &#125; return last_pid;&#125; 练习3：阅读代码，理解 proc_run 函数和它调用的函数如何完成进程切换的。（无编码工作） 请在实验报告中简要说明你对proc_run函数的分析。并回答如下问题： 在本实验的执行过程中，创建且运行了几个内核线程？ 语句local_intr_save(intr_flag);....local_intr_restore(intr_flag);在这里有何作用？请说明理由。 完成代码编写后，编译并运行代码：make qemu 如果可以得到如附录A所示的显示内容（仅供参考，不是标准答案输出），则基本正确。 3.1 内核线程 分析一下proc_init函数的调用过程： 初始化proc_list和hash_list 调用alloc_proc函数分配idleproc所需的TCB块，检验是否分配成功 对idleproc进行基本设置（所以alloc_proc函数其实不需要干啥？）： PID=0 state=PROC_RUNNABLE kstack=bootstack need_resched=1 name=“idle” 将current变量置为idleproc 调用kernel_thread函数，用init_main函数创建一个内核线程 创建所需的trapframe 调用do_fork函数，创建新进程 调用alloc_proc，首先获得一块用户信息块。 为进程分配一个内核栈。 复制原进程的内存管理信息到新进程（但内核线程不必做此事） 复制原进程上下文到新进程 将新进程添加到进程列表 唤醒新进程 返回新进程号 验证创建initproc线程成功（PID不为0） proc_init函数是由kern_init函数调用的。在kern_init完成其余初始化之后，它调用cpu_idle函数，使得当前的idle_proc进程让出控制权，交给initproc线程，进行上下文的切换；执行完之后，回到kernel_thread_entry，退出。 由以上分析可知，在本实验的执行过程中，一共只创建了两个内核线程（idleproc和initproc）。 3.2 关中断的必要性 以下回答来自Piazza： 由于进程号要求唯一性，进程号分配时可能需要查看进程列表中全部进程以避免发生冲突。若进程号已分配而进程尚未添加进进程列表时被中断，则该进程号可能会被重复分配，故进程号分配与进程添加应为原子操作。因而在进行上述操作时需关闭中断。 3.3 proc_run函数如何完成进程切换 对进程切换的控制是通过sched.c:schedule函数完成的。一旦当前进程的need_resched变量被置为1，就调用schedule函数选择下一个要运行的进程，调用proc_run函数开始运行。 12345678910111213141516171819202122232425262728voidschedule(void) &#123; bool intr_flag; list_entry_t *le, *last; struct proc_struct *next = NULL; local_intr_save(intr_flag); &#123; current-&gt;need_resched = 0; last = (current == idleproc) ? &amp;proc_list : &amp;(current-&gt;list_link); le = last; do &#123; if ((le = list_next(le)) != &amp;proc_list) &#123; next = le2proc(le, list_link); if (next-&gt;state == PROC_RUNNABLE) &#123; break; &#125; &#125; &#125; while (le != last); if (next == NULL || next-&gt;state != PROC_RUNNABLE) &#123; next = idleproc; &#125; next-&gt;runs ++; if (next != current) &#123; proc_run(next); &#125; &#125; local_intr_restore(intr_flag);&#125; 然后就进入了proc_run函数。 123456789101112131415voidproc_run(struct proc_struct *proc) &#123; if (proc != current) &#123; bool intr_flag; struct proc_struct *prev = current, *next = proc; local_intr_save(intr_flag); &#123; current = proc; load_esp0(next-&gt;kstack + KSTACKSIZE); lcr3(next-&gt;cr3); switch_to(&amp;(prev-&gt;context), &amp;(next-&gt;context)); &#125; local_intr_restore(intr_flag); &#125;&#125; 代码的执行过程如下： 关闭中断，保证原子操作 调用load_esp0函数，设置任务状态段ts中特权态0下的栈顶指针esp0为要切换到的内核线程的内核栈的栈顶，即next-&gt;kstack + KSTACKSIZE（建立指针的目的是，进行特权态切换时能够正确定位处于特权态0时进程的内核栈的栈顶） 设置CR3寄存器的值为要切换到的内核线程的页目录表起始地址，这实际上是完成进程间的页表切换，不过在内核中的内存切换下其实用不到 由 switch_to函数完成具体的两个线程的执行现场切换，即切换各个寄存器，当switch_to函数执行完ret指令后，就切换到 initproc执行了 在切换现场时，倒数第二条汇编指令pushl 0(%eax)其实把context中保存的下一个进程要执行的指令地址context.eip放到了堆栈顶，这样接下来执行最后一条指令ret时，会把栈顶的内容赋值给EIP寄存器，这样就切换到下一个进程执行了。 事实上，在对initproc进行初始化时，设置了initproc-&gt;context.eip = (uintptr_t)forkret（见copy_thread函数），这样，当执行switch_to函数并返回后，将进入实际的执行入口地址forkret。而forkret会调用位于kern/trap/trapentry.S中的forkrets（参数是切换之后的进程的中断帧地址，该地址位于内核中线程对应的栈中，如果我没理解错的话）。 12345.globl forkretsforkrets: # set stack to this new process&apos;s trapframe movl 4(%esp), %esp jmp __trapret 可以看出，forkrets函数首先把esp指向当前进程的中断帧，然后跳转到__trapret，从中恢复中断帧的各个寄存器。这些寄存器是在kernel_thread函数中设置的，包括： tf.tf_cs = KERNEL_CS：和内核使用同一代码段（这是合理的，因为initproc对应的代码也是内核的一部分） tf.tf_ds = tf.tf_es = tf.tf_ss = KERNEL_DS：和内核使用同一数据（堆栈）段 tf.tf_regs.reg_ebx = (uint32_t)fn：寄存器中的ebx为函数起始地址 tf.tf_regs.reg_edx = (uint32_t)arg：寄存器中的edx指向函数参数地址 tf.tf_eip = (uint32_t)kernel_thread_entry：中断后的实际起始地址是kernel_thread_entry 1234567891011121314.globl __trapret__trapret: # restore registers from stack popal # restore %ds, %es, %fs and %gs popl %gs popl %fs popl %es popl %ds # get rid of the trap number and error code addl $0x8, %esp iret 对于initproc，current-&gt;tf.tf_eip=kernel_thread_entry，initproc-&gt;tf.tf_cs = KERNEL_CS，所以执行完iret后，就开始在内核中执行kernel_thread_entry函数了。 123456789.text.globl kernel_thread_entrykernel_thread_entry: # void kernel_thread(void) pushl %edx # push arg call *%ebx # call fn pushl %eax # save the return value of fn(arg) call do_exit # call do_exit to terminate current thread 首先把进程的参数入栈，然后调用起始地址（现在是实际的起始地址了，对于initproc，这个起始地址就是init_main函数的开头）。所以执行call %ebx后，就开始执行initproc的主体了。 执行结束后，返回到kernel_tread_entry函数，它会进一步调用proc.c:do_exit函数，执行退出操作。目前这个函数除了打印一点字符串没有做别的工作。 扩展练习Challenge：实现支持任意大小的内存分配算法 这不是本实验的内容，其实是上一次实验内存的扩展，但考虑到现在的slab算法比较复杂，有必要实现一个比较简单的任意大小内存分配算法。可参考本实验中的slab如何调用基于页的内存分配算法（注意，不是要你关注slab的具体实现）来实现first-fit/best-fit/worst-fit/buddy等支持任意大小的内存分配算法。 【注意】下面是相关的Linux实现文档，供参考 SLOB http://en.wikipedia.org/wiki/SLOB http://lwn.net/Articles/157944/ SLAB https://www.ibm.com/developerworks/cn/linux/l-linux-slab-allocator/ 没写。 分析参考答案 alloc_proc：和参考答案的实现类似，参考了答案中的一些我忘了写的部分，如初始化内核堆栈和将context清零 do_fork：参考了答案，添加了一些错误处理，以及分配pid时关中断 知识点 进程状态 进程控制块 内核栈和用户栈","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"ucore","slug":"ucore","permalink":"https://zhanghuimeng.github.io/tags/ucore/"}]},{"title":"《操作系统》2015年期末考试分析","slug":"2018-05-23-《操作系统》2015年期末考试分析","date":"2018-05-23T01:36:22.000Z","updated":"2018-05-23T01:36:22.000Z","comments":true,"path":"post/os-mooc-2015-final-exam-analysis/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-2015-final-exam-analysis/","excerpt":"","text":"试题来自。这个卷子实在过于长了，不仅莫名有一个完整的缓冲区问题的实现，还有一堆ucore代码需要阅读和填空。 一（10分） 在用do_execve启动一个用户态进程时，ucore需要完成很多准备工作，这些工作有的在内核态完成，有的在用户态完成。请判断下列事项是否是ucore在正常完成do_execve中所需要的，如果是，指出它完成于内核态还是用户态（通过修改trapframe，在iret时改变寄存器的过程被认为是在内核态完成）。 初始化进程所使用的栈 在栈上准备argc和argv的内容 将argc和argv作为用户main函数的参数放到栈上 设置EIP为用户main函数的地址 设置系统调用的返回值 需要；内核态 需要；内核态 需要；内核态不需要；用户态 需要；内核态不需要；用户态 不需要 这个题出的很没有意义啊，系统调用返回之后几乎就要立即跳转到用户进程指令的第一条了。 以下内容摘自ucore docs Lab5： 最终通过do_execve函数来完成用户进程的创建工作。此函数的主要工作流程如下： 首先为加载新的执行码做好用户态内存空间清空准备。如果mm不为NULL，则设置页表为内核空间页表，且进一步判断mm的引用计数减1后是否为0，如果为0，则表明没有进程再需要此进程所占用的内存空间，为此将根据mm中的记录，释放进程所占用户空间内存和进程页表本身所占空间。最后把当前进程的mm内存管理指针为空。由于此处的initproc是内核线程，所以mm为NULL，整个处理都不会做。 接下来的一步是加载应用程序执行码到当前进程的新创建的用户态虚拟空间中。这里涉及到读ELF格式的文件，申请内存空间，建立用户态虚存空间，加载应用程序执行码等。load_icode函数完成了整个复杂的工作。 …… load_icode函数的工作： 初始化mm 分配和设置页目录表 解析ELF文件，建立vma，初始化进程的用户态虚拟地址空间 分配物理内存空间，建立页表映射关系，拷贝程序内容 设置用户栈 将页目录表基地址加载到CR3寄存器中 重设进程中断帧，准备切换到用户态 至此，用户进程的用户环境已经搭建完毕。此时initproc将按产生系统调用的函数调用路径原路返回，执行中断返回指令“iret”（位于trapentry.S的最后一句） 后，将切换到用户进程hello的第一条语句位置_start处（位于user/libs/initcode.S的第三句） 开始执行。 2018.5.25 UPD： tsz同学指出，事实上这道题和第六大题的代码内容直接相关。从中可以看出，user/libs/initcode.S做的就是在用户态为main函数设置参数的工作。所以3和4的答案应该修改一下。事实证明，想当然是不好的。 二 VSFS（18分） 这道题和MOOC期末考试题中的第20题一模一样，所以略。 三 进程状态变化（16分） 在ucore中enum proc_state的定义包含以下四个值： PROC_UNINIT PROC_SLEEPING PROC_RUNNABLE PROC_ZOMBIE 请解释每一种状态的含义，以及各状态之间可能的迁移。 PROC_UNINIT：刚申请完进程控制块，进程还未被初始化 PROC_SLEEPING：进程处于等待状态 PROC_RUNNABLE：进程处于就绪或运行状态 PROC_ZOMBIE：僵尸状态，进程已经退出，等待父进程进一步回收资源 以下内容（进程的正常生命周期）摘自ucore docs Lab6： 进程的正常生命周期如下： 进程首先在cpu初始化或者sys_fork的时候被创建，当为该进程分配了一个进程控制块之后，该进程进入uninit态(在proc.c中alloc_proc)。 当进程完全完成初始化之后，该进程转为runnable态。 当到达调度点时，由调度器sched_class根据运行队列rq的内容来判断一个进程是否应该被运行，即把处于runnable态的进程转换成running状态，从而占用CPU执行。 running态的进程通过wait等系统调用被阻塞，进入sleeping态。 sleeping态的进程被wakeup变成runnable态的进程。 running态的进程主动exit变成zombie态，然后由其父进程完成对其资源的最后释放，子进程的进程控制块成为unused。 所有从runnable态变成其他状态的进程都要出运行队列，反之，被放入某个运行队列中。 以下内容摘自进程运行状态转变过程： 1234567891011process state changing: alloc_proc RUNNING + +--&lt;----&lt;--+ + + proc_run + V +--&gt;----&gt;--+PROC_UNINIT -- proc_init/wakeup_proc --&gt; PROC_RUNNABLE -- try_free_pages/do_wait/do_sleep --&gt; PROC_SLEEPING -- A + + | +--- do_exit --&gt; PROC_ZOMBIE + + + -----------------------wakeup_proc---------------------------------- 四 Stride调度算法（15分） 假设在lab6测试stride scheduling的过程中，采用如下默认配置：BigStride为0x7FFFFFFF，CPU时间片为50ms，测试过程包含五个进程，其初始stridepass均为1，优先级分别为1、2、3、4、5，测试时间为10s。下面给出了五种修改上述配置的方式，试讨论：对于每一种改动，测试结果相比改动之前是否会发生明显的变化？如果是，结果会变得更接近于理想情况，还是远离理想情况？ BigStride改为120 CPU时间片改为5ms 五个进程的初始pass改为100 五个进程的优先级设为2、4、6、8、10 测试时间延长到20s 在测试时间10s的情况下，时间片总个数为200。 如果将BigStride改为120，则stride最大为120，不会溢出，而且120能够整除1、2、3、4、5，更能够保证进程的pass按优先级推进，因此会更接近于理想情况 时间片总个数变成2000，因为进程stride有偏差，因此会远离理想情况 因为100这个值相比各个进程的stride太小了，所以应该不会有明显变化 不会有明显变化 同2，更远离理想情况 这个题目中不同学长的答案大相径庭，所以我选了一种我觉得合理的。事实上，Stride调度算法的论文中讨论了一下误差问题：在stride和优先级精确地成反比的情况下，各个线程之间按比例分配到的时间片数量的误差不超过1，也就是说，总误差是O(nc)（nc是线程数量）。所以大概stride计算不准确造成的影响是比较大的。 五 生产者-消费者问题（10分） 生产者-消费者问题是指，一组生产者进程和一组消费者进程共享一个初始为空、大小为3（不如说是BUFFER_SIZE）的缓冲区，只有缓冲区没满时，生产者才能把消息放入到缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或者一个生产者放入消息，或者一个消费者从中取出消息。 下面是生产者-消费者问题的一个实现和测试结果。请回答下面问题： 请用伪码给出信号量的PV操作实现。 这个实现正确吗？如果不正确，给出你的正确实现。 这两个测试用例能发现该实现中的可能错误吗？如果不能，请给出你的尽可能完整的测试用例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214==== producer-consumer.cpp ====#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;semaphore.h&gt;#include &lt;cstring&gt;#include &lt;unistd.h&gt;#include &lt;string&gt;#include &lt;cstdlib&gt;#include &lt;new&gt; // ::operator new[]using namespace std;#define BUFFER_SIZE 3#define SLEEP_SPAN 5#define WORK_SPAN 4#define PRODUCER 0#define CONSUMER 1int iflag = 0;int oflag = 0;sem_t empty, full, mutex;int empty_count, full_count;int data_num = 0;int num = 0;int buffer[BUFFER_SIZE] = &#123;&#125;;int p_task_done = -1;int c_task_done = -1;struct arg_struct &#123; arg_struct(int _id, int _start, int _work, string _indent): id(_id), start(_start), work(_work), indent(_indent) &#123;&#125; arg_struct(int _id): id(_id), start(0), work(0), indent(string(&quot;&quot;)) &#123;&#125; int id; int start; int work; string indent;&#125;;void* producer(void* argv)&#123; arg_struct arg = *(arg_struct*)argv; int id = arg.id; const char* indent = arg.indent.c_str(); sleep(arg.start); printf(&quot;%sSTART\\n&quot;, indent); sem_wait(&amp;mutex); /* 顺序错了 */ printf(&quot;%saMUTEX\\n&quot;, indent); sem_wait(&amp;empty); /* 顺序错了 */ printf(&quot;%saEMPTY\\n&quot;, indent); printf(&quot;%sENTER\\n&quot;, indent); int time = rand() % SLEEP_SPAN; sleep(arg.work); p_task_done++; printf(&quot;%sProd %d\\n&quot;, indent, p_task_done); buffer[iflag] = p_task_done; if (empty_count == 0) printf(&quot;Error: Produce while no empty\\n&quot;); iflag = (iflag + 1) % BUFFER_SIZE; empty_count--; full_count++; printf(&quot;%sEXIT\\n&quot;, indent); sem_post(&amp;mutex); printf(&quot;%srMUTEX\\n&quot;, indent); sem_post(&amp;full); printf(&quot;%srFULL\\n&quot;, indent); return NULL;&#125;void* consumer(void* argv)&#123; arg_struct arg = *(arg_struct*)argv; int id = arg.id; const char* indent = arg.indent.c_str(); sleep(arg.start); printf(&quot;%sSTART\\n&quot;, indent); sem_wait(&amp;full); printf(&quot;%saFULL\\n&quot;, indent); sem_wait(&amp;mutex); printf(&quot;%saMUTEX\\n&quot;, indent); printf(&quot;%sENTER\\n&quot;, indent); sleep(arg.work); ++c_task_done; if (full_count == 0) printf(&quot;Error: Consume while no full\\n&quot;); int tmp = buffer[oflag]; printf(&quot;%sCons %d\\n&quot;, indent, tmp); oflag = (oflag + 1) % BUFFER_SIZE; if (c_task_done != tmp) printf(&quot;Error: Consume data wrong\\n&quot;); if (c_task_done &gt; p_task_done) printf(&quot;Error: Over-consume!\\n&quot;); full_count--; empty_count++; printf(&quot;%sEXIT\\n&quot;, indent); sem_post(&amp;mutex); printf(&quot;%srMUTEX\\n&quot;, indent); sem_post(&amp;empty); printf(&quot;%srEMPTY\\n&quot;, indent); return NULL;&#125;#define N 3void testcase_producer_consumer(int ThreadNumber, int inst[2 * N][3]) &#123; pthread_t * p_consumer = new pthread_t[ThreadNumber]; pthread_t * p_producer = new pthread_t[ThreadNumber]; int c_count = 0, p_count = 0; printf(&quot;testcase_producer_consumer:\\n&quot;); /* For managed creation of &apos;ThreadNumber&apos; threads */ int st_time = 0; /* Print the first line */ int tmp_c = 0, tmp_p = 0; for (int i = 0; i &lt; ThreadNumber; i++) &#123; if (inst[i][0] == PRODUCER) &#123; printf(&quot;P%d\\t&quot;, tmp_p++); &#125; else if (inst[i][0] == CONSUMER) &#123; printf(&quot;C%d\\t&quot;, tmp_c++); &#125; &#125; printf(&quot;\\n&quot;); /* Create Producers and Consumers according to $inst*/ int rc; string indent(&quot;&quot;); for (int i = 0; i &lt; ThreadNumber; i++) &#123; if (inst[i][0] == PRODUCER) &#123; rc = pthread_create(p_producer + p_count, NULL, producer, new arg_struct(p_count, inst[i][1], inst[i][2], indent)); if (rc) printf(&quot;ERROR\\n&quot;); p_count++; &#125; else if (inst[i][0] == CONSUMER)&#123; rc = pthread_create(p_consumer + c_count, NULL, consumer, new arg_struct(c_count, inst[i][1], inst[i][2], indent)); if (rc) printf(&quot;ERROR\\n&quot;); c_count++; &#125; indent += &apos;\\t&apos;; &#125; /* wait until every thread finishes*/ for (int i = 0; i &lt; p_count; i++) &#123; pthread_join(p_producer[i], NULL); &#125; for (int i = 0; i &lt; c_count; i++) &#123; pthread_join(p_consumer[i], NULL); &#125; delete[] p_producer; delete[] p_consumer;&#125;int main(int argc, char** argv) &#123; srand((unsigned)time(NULL)); memset(buffer, 0, sizeof(int) * BUFFER_SIZE); sem_init(&amp;mutex, 0, 1); sem_init(&amp;empty, 0, BUFFER_SIZE); sem_init(&amp;full, 0, 0); empty_count = BUFFER_SIZE; full_count = 0; /* For managed creation of 2 * N threads */ int ThreadNumber = 2 * N ; int st_time = 0; int inst[2 * N][3] = &#123; /* &#123; Consumer or Producer to be create?, When does it start to work after being created?, st_stime += N means it starts N seconcds later than the previous P/C How long does it work after it enters critical zone? &#125; */ &#123;CONSUMER, st_time += 0, 2&#125;, &#123;CONSUMER, st_time += 1, 2&#125;, &#123;CONSUMER, st_time += 2, 2&#125;, &#123;PRODUCER, st_time += 3, 2&#125;, &#123;PRODUCER, st_time += 4, 2&#125;, &#123;PRODUCER, st_time += 5, 2&#125; &#125;; testcase_producer_consumer(ThreadNumber, inst); st_time = 0; int inst2[2 * N][3] = &#123; &#123;PRODUCER, st_time += 0, 2&#125;, &#123;PRODUCER, st_time += 1, 2&#125;, &#123;CONSUMER, st_time += 2, 2&#125;, &#123;CONSUMER, st_time += 3, 2&#125;, &#123;PRODUCER, st_time += 4, 2&#125;, &#123;CONSUMER, st_time += 5, 2&#125; &#125;; testcase_producer_consumer(ThreadNumber, inst2); return 0;&#125; 测试用例的执行输出结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104xyong@ubuntu-xyong:~/work$ gcc producer-consumer.cpp -lpthread -lstdc++xyong@ubuntu-xyong:~/work$ ./a.outtestcase_producer_consumer:C0 C1 C2 P0 P1 P2START START START START aMUTEX aEMPTY ENTER Prod 0 EXIT rMUTEX rFULLaFULLaMUTEXENTER STARTCons 0EXIT aMUTEX aEMPTY ENTERrMUTEXrEMPTY Prod 1 EXIT rMUTEX rFULL aFULL aMUTEX ENTER Cons 1 EXIT rMUTEX rEMPTY START aMUTEX aEMPTY ENTER Prod 2 EXIT rMUTEX rFULL aFULL aMUTEX ENTER Cons 2 EXIT rMUTEX rEMPTYtestcase_producer_consumer:P0 P1 C0 C1 P2 C2STARTaMUTEXaEMPTYENTER STARTProd 3EXITrMUTEXrFULL aMUTEX aEMPTY ENTER START aFULL Prod 4 EXIT rMUTEX rFULL aMUTEX ENTER START aFULL Cons 3 EXIT rMUTEX rEMPTY aMUTEX ENTER Cons 4 EXIT rMUTEX rEMPTY START aMUTEX aEMPTY ENTER Prod 5 EXIT rMUTEX rFULL START aFULL aMUTEX ENTER Cons 5 EXIT rMUTEX rEMPTYxyong@ubuntu-xyong:~/work$ 这道题真是又臭又长…… 信号量PV操作的伪代码：这个是十分简单了。 123456789101112131415P() &#123; sem--; if (sem &lt; 0) &#123; Add this thread t to q; block(p); &#125;&#125;V() &#123; sem++; if (sem &lt;= 0) &#123; Remove a thread t from q; wakeup(t); &#125;&#125; 这个实现是否正确？答案是不正确。producer线程的实现中获取mutex和empty信号量的顺序反了。总的来说，把这两个换一下就好了。 题目中给出的两个测试样例是这样的： 1234567891011121314151617181920int inst[2 * N][3] = &#123; /* &#123; Consumer or Producer to be create?, When does it start to work after being created?, st_stime += N means it starts N seconcds later than the previous P/C How long does it work after it enters critical zone? &#125; */ &#123;CONSUMER, st_time += 0, 2&#125;, &#123;CONSUMER, st_time += 1, 2&#125;, &#123;CONSUMER, st_time += 2, 2&#125;, &#123;PRODUCER, st_time += 3, 2&#125;, &#123;PRODUCER, st_time += 4, 2&#125;, &#123;PRODUCER, st_time += 5, 2&#125;&#125;;int inst2[2 * N][3] = &#123; &#123;PRODUCER, st_time += 0, 2&#125;, &#123;PRODUCER, st_time += 1, 2&#125;, &#123;CONSUMER, st_time += 2, 2&#125;, &#123;CONSUMER, st_time += 3, 2&#125;, &#123;PRODUCER, st_time += 4, 2&#125;, &#123;CONSUMER, st_time += 5, 2&#125;&#125;; 我给出的测试样例是这样的： 12345678int inst2[2 * N][3] = &#123; &#123;PRODUCER, st_time += 0, 2&#125;, &#123;PRODUCER, st_time += 1, 2&#125;, &#123;PRODUCER, st_time += 2, 2&#125;, &#123;PRODUCER, st_time += 3, 2&#125;, &#123;CONSUMER, st_time += 4, 2&#125;, &#123;CONSUMER, st_time += 5, 2&#125;&#125;; 题目中并没有要求Producer和Consumer的数量必须为3个。从理论上来说，只要Producer比Consumer大的个数在3个（也就是缓冲区的大小）以内，都能正常结束。但是在错误实现中会发生这样的问题：P1-P3生产完之后，P4获得mutex后开始在empty信号量上等待。但是，由于它占据了mutex，因此C1和C2无法进入临界区进行消费，于是也不会对empty信号量执行V操作，发生死锁。 六 ucore用户进程（16分） 下面是关于ucore中用户程序的生命历程的代码。请完成下面填空和代码补全。 （1） 在sh的命令行上输入args 1启动用户程序args，则sh会调用（1）创建新进程并调用（2）将args加载到该进程的地址空间中。（回答系统调用名称即可） SYS_fork SYS_exec 这一题使我觉得我应该复习一下ucore里的各种系统调用、实现方法及其作用。 （2） 将args从硬盘加载主要由load_icode完成，请补全以下代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187// load_icode - called by sys_exec--&gt;do_execvestatic intload_icode(int fd, int argc, char **kargv) &#123; /* LAB8:EXERCISE2 YOUR CODE HINT:how to load the file with handler fd in to process&apos;s memory? how to setup argc/argv? * MACROs or Functions: * mm_create - create a mm * setup_pgdir - setup pgdir in mm * load_icode_read - read raw data content of program file * mm_map - build new vma * pgdir_alloc_page - allocate new memory for TEXT/DATA/BSS/stack parts * lcr3 - update Page Directory Addr Register -- CR3 */ /* (1) create a new mm for current process * (2) create a new PDT, and mm-&gt;pgdir= kernel virtual addr of PDT * (3) copy TEXT/DATA/BSS parts in binary to memory space of process * (3.1) read raw data content in file and resolve elfhdr * (3.2) read raw data content in file and resolve proghdr based on info in elfhdr * (3.3) call mm_map to build vma related to TEXT/DATA * (3.4) callpgdir_alloc_page to allocate page for TEXT/DATA, read contents in file * and copy them into the new allocated pages * (3.5) callpgdir_alloc_page to allocate pages for BSS, memset zero in these pages * (4) call mm_map to setup user stack, and put parameters into user stack * (5) setup current process&apos;s mm, cr3, reset pgidr (using lcr3 MARCO) * (6) setup uargc and uargv in user stacks * (7) setup trapframe for user environment * (8) if up steps failed, you should cleanup the env. */ assert(argc &gt;= 0 &amp;&amp; argc &lt;= EXEC_MAX_ARG_NUM); if (current-&gt;mm != NULL) &#123; panic(&quot;load_icode: current-&gt;mm must be empty.\\n&quot;); &#125; int ret = -E_NO_MEM; struct mm_struct *mm; if ((mm = mm_create()) == NULL) &#123; goto bad_mm; &#125; if (setup_pgdir(mm) != 0) &#123; goto bad_pgdir_cleanup_mm; &#125; struct Page *page; struct elfhdr __elf, *elf = &amp;__elf; /* 2a */ if ((ret = load_icode_read(fd, elf, _(2a)_, 0)) != 0) &#123; goto bad_elf_cleanup_pgdir; &#125; if (elf-&gt;e_magic != ELF_MAGIC) &#123; ret = -E_INVAL_ELF; goto bad_elf_cleanup_pgdir; &#125; struct proghdr __ph, *ph = &amp;__ph; uint32_t vm_flags, perm, phnum; for (phnum = 0; phnum &lt; elf-&gt;e_phnum; phnum ++) &#123; off_t phoff = elf-&gt;e_phoff + sizeof(struct proghdr) * phnum; if ((ret = load_icode_read(fd, ph, sizeof(struct proghdr), phoff)) != 0) &#123; goto bad_cleanup_mmap; &#125; if (ph-&gt;p_type != ELF_PT_LOAD) &#123; /* 2b */ _(2b)_ &#125; if (ph-&gt;p_filesz &gt; ph-&gt;p_memsz) &#123; ret = -E_INVAL_ELF; goto bad_cleanup_mmap; &#125; if (ph-&gt;p_filesz == 0) &#123; continue ; &#125; vm_flags = 0, perm = PTE_U; if (ph-&gt;p_flags &amp; ELF_PF_X) vm_flags |= VM_EXEC; if (ph-&gt;p_flags &amp; ELF_PF_W) vm_flags |= VM_WRITE; if (ph-&gt;p_flags &amp; ELF_PF_R) vm_flags |= VM_READ; if (vm_flags &amp; VM_WRITE) perm |= PTE_W; if ((ret = mm_map(mm, ph-&gt;p_va, ph-&gt;p_memsz, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; &#125; off_t offset = ph-&gt;p_offset; size_t off, size; uintptr_t start = ph-&gt;p_va, end, la = ROUNDDOWN(start, PGSIZE); ret = -E_NO_MEM; end = ph-&gt;p_va + ph-&gt;p_filesz; while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; ret = -E_NO_MEM; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; if ((ret = load_icode_read(fd, page2kva(page) + off, size, offset)) != 0) &#123; goto bad_cleanup_mmap; &#125; start += size, offset += size; &#125; end = ph-&gt;p_va + ph-&gt;p_memsz; if (start &lt; la) &#123; /* ph-&gt;p_memsz == ph-&gt;p_filesz */ if (start == end) &#123; continue ; &#125; off = start + PGSIZE - la, size = PGSIZE - off; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page) + off, 0, size); start += size; assert((end &lt; la &amp;&amp; start == end) || (end &gt;= la &amp;&amp; start == la)); &#125; while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; ret = -E_NO_MEM; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page) + off, 0, size); start += size; &#125; &#125; sysfile_close(fd); vm_flags = VM_READ | VM_WRITE | VM_STACK; /* 2c */ if ((ret = mm_map(mm, _(2c)_, USTACKSIZE, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; &#125; assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-2*PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-3*PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-4*PGSIZE , PTE_USER) != NULL); mm_count_inc(mm); current-&gt;mm = mm; current-&gt;cr3 = PADDR(mm-&gt;pgdir); lcr3(PADDR(mm-&gt;pgdir)); //setup argc, argv uint32_t argv_size=0, i; for (i = 0; i &lt; argc; i ++) &#123; argv_size += strnlen(kargv[i],EXEC_MAX_ARG_LEN + 1)+1; &#125; uintptr_t stacktop = USTACKTOP - (argv_size/sizeof(long)+1)*sizeof(long); char** uargv=(char **)(stacktop - argc * sizeof(char *)); argv_size = 0; for (i = 0; i &lt; argc; i ++) &#123; uargv[i] = strcpy((char *)(stacktop + argv_size ), kargv[i]); /* 2d */ _(2d)_ &#125; stacktop = (uintptr_t)uargv - sizeof(int); /* 2e */ *(int *)stacktop = _(2e)_; struct trapframe *tf = current-&gt;tf; memset(tf, 0, sizeof(struct trapframe)); tf-&gt;tf_cs = USER_CS; tf-&gt;tf_ds = tf-&gt;tf_es = tf-&gt;tf_ss = USER_DS; tf-&gt;tf_esp = stacktop; tf-&gt;tf_eip = elf-&gt;e_entry; tf-&gt;tf_eflags = FL_IF; ret = 0;out: return ret;bad_cleanup_mmap: exit_mmap(mm);bad_elf_cleanup_pgdir: put_pgdir(mm);bad_pgdir_cleanup_mm: mm_destroy(mm);bad_mm: goto out;&#125; sizeof(struct elfhdr)（读一个elfhdr大小的文件数据） goto bad_cleanup_mmap;（这个很简单：已经设置了pgdir和mm了，因此如果失败需要清理；而且周围都是跳转到这里） USTACKTOP - USTACKSIZE（这段大概是映射用户栈空间，不过我并不是很明白） argv_size += strnlen(kargv[i], EXEC_MAX_ARG_LEN + 1) + 1;（得到当前的参数的长度） argc（把argc放到栈顶；之所以是栈顶，是因为gcc是从右向左压栈的） 这种默写代码的题目实在是无聊死了。 （3） 完成加载后会从内核态回到用户态，请补全此时的用户栈图示。（假定为写入部分全部初始化为0，注意使用小尾端） 地址 内容 0xb0000000 - 0xaffffffc 00 31 00 00 0xaffffff8 61 72 67 73 // ‘args’ 0xaffffff4 (3a) 0xaffffff0 (3b) 0xafffffec (3c) 0xafffffe8 (3d) 此时并不会直接进入main函数，而是执行以下代码，请简述其作用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//////// user/libs/initcode.S //////////.text.globl _start_start: movl $0x0, %ebp movl (%esp), %ebx lea 0x4(%esp), %ecx subl $0x20, %esp pushl %ecx pushl %ebx call umain1: jmp 1b////////// user/libs/umain.c ////////////#include &lt;ulib.h&gt;#include &lt;unistd.h&gt;#include &lt;file.h&gt;#include &lt;stat.h&gt;int main(int argc, char *argv[]);static intinitfd(int fd2, const char *path, uint32_t open_flags) &#123; int fd1, ret; if ((fd1 = open(path, open_flags)) &lt; 0) &#123; return fd1; &#125; if (fd1 != fd2) &#123; close(fd2); ret = dup2(fd1, fd2); close(fd1); &#125; return ret;&#125;voidumain(int argc, char *argv[]) &#123; int fd; if ((fd = initfd(0, &quot;stdin:&quot;, O_RDONLY)) &lt; 0) &#123; warn(&quot;open &lt;stdin&gt; failed: %e.\\n&quot;, fd); &#125; if ((fd = initfd(1, &quot;stdout:&quot;, O_WRONLY)) &lt; 0) &#123; warn(&quot;open &lt;stdout&gt; failed: %e.\\n&quot;, fd); &#125; int ret = main(argc, argv); exit(ret);&#125;","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》2017年期末考试分析","slug":"2018-05-22-《操作系统》2017年期末考试分析","date":"2018-05-22T11:21:25.000Z","updated":"2018-12-27T11:07:00.000Z","comments":true,"path":"post/os-mooc-2017-final-exam-analysis/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-2017-final-exam-analysis/","excerpt":"","text":"试题来自2017年春季学期操作系统课期末考试。 填空题（30分） 同学们认真完成了从lab0～lab8的所有实验，在实验实践过程中了解和学到了很多知识。下面是他们从最开始到近期的实验心得，请补充完整。 1 lab0: 小强发现完成实验需要在Linux下操作很多命令行工具，于是他认真学习了 lab0中的知识，了解到Linux中在命令行模式下可以通过执行命令(1.1)来显示当前目录的文件，如果编写的程序有语法错误，编译器(1.2)会报错，根据错误信息，可以修改程序，并可以通过硬件模拟器工具(1.3)来执行 ucore 操作系统。 ls gcc qemu 2 lab1: 小晔在bootloader的代码中添加了一条打印语句，但发现编译生成lab项目出错，原来在ucore中只要bootloader的执行代码段+数据段的长度超过了(2.1)字节，就无法形成合法有效的bootloader。开始写实验报告时，本来准备提交MS Word文档格式的实验报告，但仔细看过实验报告的提交要求，原来实验指导书中明确要求同学用(2.2)文档格式来提交实验报告，小晔之前没学过这个文档格式，不过上网一查，花很短时间就掌握了编写方法，迅速完成了lab1。 446510 Markdown 根据https://zh.wikipedia.org/wiki/%E4%B8%BB%E5%BC%95%E5%AF%BC%E8%AE%B0%E5%BD%95，主引导扇区中代码区的大小最多为446字节。 2018.5.24 UPD：经过tsz同学的提醒，我查证了一下lab1/tools/sign.c（用于生成磁盘主引导扇区的代码），发现里面是这么写的： 1234567891011char buf[512];memset(buf, 0, sizeof(buf));FILE *ifp = fopen(argv[1], \"rb\");int size = fread(buf, 1, st.st_size, ifp);if (size != st.st_size) &#123; fprintf(stderr, \"read '%s' error, size is %d.\\n\", argv[1], size); return -1;&#125;fclose(ifp);buf[510] = 0x55;buf[511] = 0xAA; 所以虽然维基说的没问题，但是ucore没有管什么“标准MBR分区表规划”，直接把0x55AA之外的510字节全用上了。 3 lab2: 小晖需要了解x86的内存大小与布局，页机制，页表结构等。硬件模拟器提供了 128MB的内存，并设定一个页目录项（PDE）占用(3.1)个Byte，一个页表项（PTE）占用(3.2)个 Byte。在lab2中可通过(3.3)和(3.4)两种方式获取系统内存大小，并且由于空闲的RAM空间不连续，所以bootloader简化处理，从物理内存地址(3.5)起始填充ucore os kernel的代码段和数据段。在ucore建立完页表并进入页模式后，ucore代码段的起始物理地址对应的虚拟地址为(3.6)。 4 4 BIOS中断调用 直接探测 0x00100000 0xC0100000 这块不愧是令人比较困惑。我可能需要复习一下ucore的内存映射方式了。 4 lab3: 小彤发现ucore在完成页机制建立后，内核某内存单元的虚拟地址va为 0xC2345678，且此时硬件模拟器模拟的的cr3寄存器的值为0x221000，则此va对应的页目录表的起始物理地址是(4.1)，此va对应的PDE的物理地址是(4.2)。如果一个页（4KB/页）被置换到了硬盘某8个连续扇区（0.5KB/扇区），该页对应的页表项（PTE）的最低位–present 位应该为(4.3) ，表示虚实地址映射关系不存在，而原来用来表示页帧号的高(4.4)位，恰好可以用来表示此页在硬盘上的起始扇区的位置（其从第几个扇区开始）。 0x00221000 0x00221C20 0 20 该va对应的页号和偏移量： 0xC2345678 = b11000010001101000101011001111000 页目录号 = b1100001000 = 0x308 页表号 = b1101000101 = 0x345 偏移量 = b011001111000 = 0x678 PDE地址 = CR3 + 4*页目录号 = 0x00221000 + 0xC20 = 0x00221C20 5 lab4: 小颖在理解进程管理中，仔细分析了ucore源码中的进程控制块数据结构(5.1)，且其中的关键域（也称field，字段）数据结构(5.2)用于保存被中断打断的运行现场，关键域数据结构(5.3)用于进行进程/线程上下文切换的保存与回复。 proc_struct trap_frame context 6 lab5: 小辰对用户进程的创建有了更深入的了解：用户进程在用户态下执行时，CS 段寄存器最低第两位的值为(6.1)。当ucore os kernel建立完毕第一个用户进程的执行环境后，通过执行x86机器指令(6.2)后，将从内核态切换到用户态，且将从用户进程的第一条指令处继续执行。当用户进程执行sys_exit系统调用后，ucore会回收当前进程所占的大部分资源，并把当前进程的状态设置为(6.3)。 3 IRET ZOMBIE 用户态下，CS段的RPL的值应该为3. 7 lab6: 小磊通过阅读代码，了解了ucore的调度框架和RR调度算法等，体会到调度本质上体现了对(7.1)资源的抢占，操作系统通过(7.2)来避免用户态进程长期运行，并获得控制权。 处理机执行能力（时间片？） 时钟中断 之所以1的回答是“处理机执行能力”，主要是因为第15讲里说，“处理机调度是管理处理机执行能力的资源”。我觉得答CPU之类的也可以。 8 lab7: 小航发现课本中阐述的同步互斥原理对实现细节简化了很多。在ucore中，通过利用x86机器指令(8.1)简洁地实现了入临界区代码，通过利用x86指令(8.2)简洁地实现了出临界区代码。通过分析ucore中管程的数据结构，可知道ucore中的管程机制是基于(8.3)机制和(8.4)机制来实现的。 CLI STI 信号量 等待队列 有时候分不清楚CLI和STI。事实上，CLI的意思是“Clean IF”，即将IF置零，屏蔽中断；STI的意思是“Set IF”，即将IF置1，不屏蔽中断。姑且这样记一下吧。 9 lab8: 小行了解到ucore中的文件系统架构包含四类主要的数据结构， (9.1)：它主要从文件系统的全局角度描述特定文件系统的全局信息。 (9.2)：它主要从文件系统中单个文件的角度描述了文件的各种属性和数据所在位置。 (9.3)：它主要从文件系统的文件路径的角度描述了文件路径中的特定目录。 (9.4)： 它主要从进程的角度描述了一个进程在访问文件时需要了解的文件标识，文件读写的位置，文件引用情况等信息。 超级块（SuperBlock） 索引节点（inode） 目录项（dentry） 文件（file） Lab8中的各种结构好多，完全不知道该回答什么啊。 2018.5.24 UPD：今天tsz同学提醒我，这个问题是实验指导书中的原话[1]： 从ucore操作系统不同的角度来看，ucore中的文件系统架构包含四类主要的数据结构，它们分别是： 超级块（SuperBlock）：它主要从文件系统的全局角度描述特定文件系统的全局信息。它的作用范围是整个OS空间。 索引节点（inode）：它主要从文件系统的单个文件的角度描述了文件的各种属性和数据所在位置。它的作用范围是整个OS空间。 目录项（dentry）：它主要从文件系统的文件路径的角度描述了文件路径中的特定目录。它的作用范围是整个OS空间。 文件（file）：它主要从进程的角度描述了一个进程在访问文件时需要了解的文件标识，文件读写的位置，文件引用情况等信息。它的作用范围是某一具体进程。 问答题（70分） 10. 同步互斥（10分） 下面列出的n个线程互斥机制的伪代码实现有误，请指出错误处，给出错误原因分析，描述错误会带来的后果（即给出反例：无法正确执行n线程有效互斥运行行为的执行序列）。最后请修正错误，使得伪代码正确。 12345678910111213141516171819INITIALIZATION: shared int num[n]; for (j=0; j &lt; n; j++) &#123; num[j] = j; &#125;-------------------------------ENTRY PROTOCOL (for Thread i): num[i] = MAX(num[0], ..., num[n-1]) + 1; for (j=0; j &lt; n; j++) &#123; if ((num[j] &gt; 0) &amp;&amp; ((num[j] &lt; num[i]) || (num[j] == num[i]) &amp;&amp; (j &lt; i))) &#123; while (num[j] &gt; 0) &#123;&#125; &#125; &#125;-----------------------------EXIT PROTOCOL (for Thread i): num[i] = 0;----------------------------- 这道题和2016年期末的26.2题几乎一模一样，唯一的区别是此处初始化时将num[j]初始化为j，而不是0。这一点显然违背了“空闲则入”的原则：假如线程n-1想要进入临界区，它必须等待编号比它小的线程全部进入过临界区，这可能会导致饥饿，所以还是应该初始化为0。因此，在线程i执行ENTRY PROTOCOL之前，num[i]必然为0。 在我的理解中，共享数组num[n]有两个含义： num[i] &gt; 0表示线程i正在等待或已经进入临界区；num[i] = 0表示线程i离开了临界区且并没有等待进入临界区 num[i] &gt; 0时，表示线程i等待的优先级，数字越大，优先级越低 基于以上的讨论，我认为，num数组中非0的值必须是互不相同的。从ENTRY PROTOCOL的实现可以看出，如果num[i] = MAX(num[0], ..., num[n-1]) + 1这一操作是原子的，则上述结论显然；如果这一操作不是原子的，则可能会出现两个线程i和j的优先级相同的情况。不妨设i&lt;j，且其他线程的num均为0。假如线程i在num[i]没有完成赋值之前被打断，切换到线程j，则j会发现其他线程的num均为0，于是进入临界区。之后切换回线程i，i检查时虽然发现num[i] == num[j]，但由于i &lt; j，于是也进入临界区，破坏了“忙则等待”要求。 假如能够保证num[i] = MAX(num[0], ..., num[n-1]) + 1这一操作是原子的，则上述实现是正确的，且可以删去(num[j] == num[i]) &amp;&amp; (j &lt; i)这一判断条件。在检查条件过程中被打断并不会影响算法的正确性，因为，即使已经被检查过的线程的优先级发生了变化，它也只可能变成0（它不再进入临界区，没有影响）或者优先级比当前线程变得更大（它退出临界区之后又想重新进入，需要取max），不需要重新进行等待。 但是现在的问题是怎么实现取max操作的原子性。如果直接加个互斥锁，不免太过智熄。（那我们还实现软件方法的N线程互斥干啥……）那就直接加个共享变量作为自旋锁好了，而且需要保证赋值过程是原子的。……虽然这样也完全没有意义，难道要直接改成Eisenberg &amp; McGuire算法么…… 123456789101112131415161718192021INITIALIZATION: shared int num[n]; shared bool choose[n]; for (j = 0; j &lt; n; j++) &#123; num[j] = 0; &#125; mutex = 0;-------------------------------ENTRY PROTOCOL (for Thread i): num[i] = MAX(num[0], ..., num[n-1]) + 1; // do this atomically for (j = 0; j &lt; n; j++) &#123; if ((num[j] &gt; 0) &amp;&amp; ((num[j] &lt; num[i]) || (num[j] == num[i]) &amp;&amp; (j &lt; i))) &#123; while (num[j] &gt; 0) &#123;&#125; &#125; &#125;-----------------------------EXIT PROTOCOL (for Thread i): num[i] = 0;----------------------------- 2018.5.24 UPD：tsz同学给出了一种想法，我还没有仔细思考过它的正确性： 12345678-------------------------------ENTRY PROTOCOL (for Thread i): num[i] = MAX(num[0], ..., num[n-1]) + 1; // do this atomically for (j = 0; j &lt; n; j++) &#123; if ((num[j] &gt; 0) &amp;&amp; ((num[j] &lt; num[i]) || (num[j] == num[i]) &amp;&amp; (j &lt; i)) || flag[j] &amp;&amp; (j &lt; i)) &#123; while (num[j] &gt; 0) &#123;&#125; &#125; &#125; 11. 管程（10分） 下面是一类管程机制的实现伪代码。 12345678910111213141516171819202122232425262728293031323334353637IMPLEMENTATION:monitor mt &#123; -----variable in monitor----------- semaphore mutex; semaphore next; int next_count; condvar &#123;int count, sempahore sem&#125; cv[N]; other shared variables in mt; ----condvar wait implementation---- cond_wait (cv) &#123; cv.count ++; if(mt.next_count&gt;0) V(mt.next); else V(mt.mutex); P(cv.sem); cv.count --; &#125; ----condvar signal implementation---- cond_signal(cv) &#123; if(cv.count&gt;0) &#123; mt.next_count ++; V(cv.sem); P(mt.next); mt.next_count--; &#125; &#125; ----routine examples in monitor---- Routines_in_mt () &#123; P(mt.mutex); real bodies of routines, may access shared variables, call cond_wait OR cond_signal if(next_count&gt;0) V(mt.next); else V(mt.mutex); &#125;&#125; 在上述伪码中，如果有3个线程a,b,c需要访问管程，并会使用管程中的2个条件变量 cv[0],cv[1]。请问cv[i]-&gt;count含义是什么？cv[i]-&gt;count是否可能&lt;0, 是否可能&gt;1？请说明原因，并给出相应的3个线程同步互斥执行实例和简要解释。请问 mt-&gt;next_count含义是什么？mt-&gt;next_count是否可能&lt;0, 是否可能&gt;1？请说明原因，并给出相应的3个线程同步互斥执行过程实例和简要解释。 这道题和2016年期末的27题一模一样，连笔误都一样，不解释了。 12. 理发师问题（20分） 理发店里有m位理发师、m把理发椅和n把供等候理发的顾客坐的椅子。理发师为一位顾客理完发后，查看是否有顾客等待，如有则唤醒一位为其理发；如果没有顾客，理发师便在理发椅上睡觉。一个新顾客到来时，首先查看理发师在干什么，如果理发师在理发椅上睡觉，他必须叫醒理发师，然后理发师理发，顾客被理发；如果理发师正在理发，则新顾客会在有空椅子可坐时坐下来等待，否则就会离开。请用信号量机制实现理发师问题的正确且高效的同步与互斥活动：请说明所定义的信号量的含义和初始值，描述需要进行互斥处理的各种行为，描述需要进行同步处理的各种行为；要求用类C语言的伪代码实现，并给出必要的简明代码注释。 感觉这个的初步实现到处都是，比如http://whatbeg.com/2017/03/06/semaphore.html#问题8：理发师问题。但是我现在都要困死了，实在思考不了这种高思维含量的东西。 2018.5.24 UPD：今天tsz同学给出了一种做法： 123456789101112131415161718192021222324// Customerint Customer() &#123; if (waitCnt &gt; n) return FAIL; waitLock.P(); waitCnt++; waitLock.V(); waitList.P(); // haircut waitLock.P(); waitCnt--; waitLock.V(); return SUCCEED;&#125;// Barbervoid Barber() &#123; while (true) &#123; while (waitCnt == 0); waitList.V(); &#125;&#125; 但我还没有仔细想过这个做法的正确性。 13. SPN算法（8分） 请给出平均周转时间的定义，请给出短进程优先算法的描述，请证明：短进程优先算法具有最小平均周转时间。 周转时间：进程从初始化到结束（包括等待）的总时间 平均周转时间：所有进程周转时间的平均数 短进程优先（SPN）算法：总是选择就绪队列中执行时间最短的进程占用CPU进入运行状态 证明： 假设就绪队列中共有N个进程，它们的执行时间分别为t1,t2,...,tNt_1, t_2, ..., t_Nt1​,t2​,...,tN​。不妨设t1≤t2≤...≤tNt_1 \\leq t_2 \\leq ... \\leq t_Nt1​≤t2​≤...≤tN​。则SPN算法的总周转时间为 T=t1+(t1+t2)+(t1+t2+t3)+...+(t1+t2+...+tN)=N∗t1+(N−1)∗t2+...+tN\\begin{aligned} T = t_1 + (t_1 + t_2) + (t_1 + t_2 + t_3) + ... + (t_1 + t_2 + ... + t_N) = N * t_1 + (N-1) * t_2 + ... + t_N \\end{aligned}​T=t​1​​+(t​1​​+t​2​​)+(t​1​​+t​2​​+t​3​​)+...+(t​1​​+t​2​​+...+t​N​​)=N∗t​1​​+(N−1)∗t​2​​+...+t​N​​​​ 假设我们交换了第i和j（i&lt;j）个进程的执行顺序，则此时，总周转时间会变为 T′=N∗t1+(N−1)∗t2+...+(N−i+1)∗tj+...+(N−j+1)∗ti+tN\\begin{aligned} T&#x27; = N * t_1 + (N-1) * t_2 + ... + (N-i+1) * t_j + ... + (N-j+1) * t_i + t_N \\end{aligned}​T​′​​=N∗t​1​​+(N−1)∗t​2​​+...+(N−i+1)∗t​j​​+...+(N−j+1)∗t​i​​+t​N​​​​ T′−T=(N−i+1)∗tj+(N−j+1)∗ti−(N−i+1)∗ti−(N−j+1)∗tj=(i−j)∗(ti−tj)&gt;=0\\begin{aligned} T&#x27; - T = (N-i+1) * t_j + (N-j+1) * t_i - (N-i+1) * t_i - (N-j+1) * t_j = (i-j) * (t_i - t_j) &gt;= 0 \\end{aligned}​T​′​​−T=(N−i+1)∗t​j​​+(N−j+1)∗t​i​​−(N−i+1)∗t​i​​−(N−j+1)∗t​j​​=(i−j)∗(t​i​​−t​j​​)&gt;=0​​ 由于任何进程执行顺序都可以通过对顺序排列的进程进行若干次交换而得到，上述证明表明，任何其他执行顺序得到的平均周转时间都不可能比SPN算法更优。因此，SPN算法具有最小平均周转时间。 14. LFU算法（14分） LFU是最近最不常用页面置换算法(Least Frequently Used)，小白听到两个LFU定义的说法，有些糊涂： 采用LFU算法的OS在碰到进程访问的物理内存不够时，换出进程执行期内被访问次数最少的内存页，当此页被换出后，其访问次数n会被记录下来，当此页被再次访问并被换入时，此页的访问次数为n+1。 采用LFU算法的OS在碰到进程访问的物理内存不够时，换出进程执行期内被访问次数最少的内存页，当此页被换出后，其访问次数清零，当此页被再次访问并被换入时，此页的访问次数为1。 请问你认为那种LFU的定义是正确的？请分别回答第一种/第二种LFU定义是否有Belady 异常现象。如没有，请给出证明，如有，请给出会引起Belady异常现象的的页数/页帧数设置以及访问序列。 呃，我不会啊……但我认为做法1显然不太可取。LFU算法比较严重的一个问题是计数器的劣化（这个名字是我随便起的）：之前被大量访问，但以后不再被使用的页不容易被换出。为了解决这个问题，计数器可以定期右移之类的。现在页计数器根本不会减小，怕不是要出事……不过被换出的页大概被访问次数是很少的，所以我也不知道1有什么用。 2大概有Belady现象。1不知道。看来需要仔细研究一下Piazza上给出的例子了。 2018.5.24 UPD： 今天zp同学提醒我，Piazza上有一个帖子讨论了这一内容。我们一般说的LFU的定义是第2种，而非第1种；该帖子指出，第1种定义下LFU不会出现Belady问题（虽然没有给出证明），而第2种定义下LFU会出现Belady问题，并举出了例子。 令访问序列为[0 0 1 1 1 2 2 0 0 2 2 3 1 3 1 3 1 3 1 3 1 3 1 … （之后无限循环3 1 3 1）]。在有2个物理页帧的情况下，访问过程是这样的（括号里是访问计数）： 访存 物理页a 物理页b 缺页 换出 0 0(1) - 0 - 0 0(2) - - - 1 0(2) 1(1) 1 - 1 0(2) 1(2) - - 1 0(2) 1(3) - - 2 2(1) 1(3) 2 0 2 2(2) 1(3) - - 0 0(1) 1(3) 0 2 0 0(2) 1(3) - - 2 2(1) 1(3) 2 0 2 2(2) 1(3) - - 3 3(1) 1(3) 3 2 1 3(1) 1(4) - - 3 3(2) 1(4) - - 1 3(2) 1(5) - - 3 3(3) 1(5) - - 1 3(3) 1(6) - - 可以看出，一共只会缺页6次，在之后的循环过程中不会缺页。 但是，如果物理页帧数量增加到3，访问过程会变成这样： 访存 物理页a 物理页b 物理页c 缺页 换出 0 0(1) - - 0 - 0 0(2) - - - - 1 0(2) 1(1) - 1 - 1 0(2) 1(2) - - - 1 0(2) 1(3) - - - 2 0(2) 1(3) 2(1) 2 - 2 0(2) 1(3) 2(2) - - 0 0(3) 1(3) 2(2) - - 0 0(4) 1(3) 2(2) - - 2 0(4) 1(3) 2(4) - - 2 0(4) 1(3) 2(4) - - 3 0(4) 3(1) 2(4) 3 1 1 0(4) 1(1) 2(4) 1 3 3 0(4) 3(1) 2(4) 3 1 1 0(4) 1(1) 2(4) 1 3 3 0(4) 3(1) 2(4) 3 1 1 0(4) 1(1) 2(4) 1 3 可以看出，现在已经缺页9次了，而且之后每访问一次都会发生缺页。 上述讨论可以说明一般的LFU算法有Belady问题。那么为什么修改过的（有记忆的）LFU算法可以没有Belady问题呢？stackoverflow上是这么说的： http://www.eecs.berkeley.edu/Pubs/TechRpts/1987/CSD-87-358.pdf section 1.3 defines the stack algorithm and finishes by working through an example of this for LFU. Basically you can maintain a stack as you follow through a trace of memory fetches such that the top i entries of the stack are the entries that will be held in memory if you have capacity for i entries in your memory. Since you can maintain such a stack a larger memory must always hold all of the entries kept in core for any smaller memory and so Belady’s anomaly is not possible. Of course this assumes an exact implementation of LFU with counters of infinite capacity. 上面的内容大概是说，修改过的LFU算法实际上相当于维护了一个很大的访问次数栈，栈中的页按访问次数排序，顶端的N个页驻留在内存中。因此，它本质上是一种栈算法，所以不存在Belady问题。具体证明我现在没时间去看了，欢迎大家自己去看论文。 15. 小明文件系统（8分） 小明为更好理解lab8，设计了一个简化文件系统Xiao Miang File System, 简称 xmfs。 xmfs的系统调用接口包括： mkdir() - 创建一个新目录 creat() - 创建一个空文件 open(), write(), close() - 打开文件，写文件，关闭文件 link() - 对文件创建一个硬链接（ hard link） unlink() - 对文件取消一个硬链接 (如果文件的链接数为0，则删除文件） 注意：通过 write()对文件写一个数据buffer时，常规文件的最大size是一个 data block，所以第二次写（写文件的语义是在上次写的位置后再写一个data block）会报错（文件大小满了）。如果data block 也满了，也会报错。 xmfs在硬盘上的总体组织结构如下： superblock：记录可用inode数量，可用data block数量 inode bitmap：已用/空闲inode的分配图（基于bitmap） inodes：inode的存储区域 data bitmap：data block的分配图（基于bitmap） data：data block的存储区域 xmfs的关键数据结构–inode数据结构如下： inode：包含3个fields（file type，data block addr of file content，reference count）,用list表示： file type: f -&gt; 常规文件： regular file, d -&gt; 目录文件： directory data block addr of file content: -1 -&gt; file is empty reference count: file/directory 的引用计数，注意directory的引用计数是指在此目录中的inode的个数 注意：比如，刚创建的一个空文件inode：[f a:-1 r:1]，一个有1个硬链接的文件inode：[f a:10 r:2] xmfs的关键数据结构–数据块（data block）结构如下： 一般文件的内容表示：只是包含单个字符的 list，即占一个 data block，比如[‘a’], [‘b’] … 目录的内容表示：多个两元组（name, inode_number）形成的list，比如，根目录 [(.,0) (…,0)]，或者包含了一个’f’文件的根目录[(.,0) (…,0) (f,1)]。 注意：一个目录的目录项的个数是有限的。block.maxUsed = 32 注意：data block 的个数是有限的,为fs.numData 注意：inode 的个数是有限的,为fs.numInodes 完整xmfs文件系统的参考实例： fs.ibitmap: inode bitmap 11110000 fs.inodes: [d a:0 r:5] [f a:1 r:1] [f a:-1 r:1] [d a:2 r:2] [] … fs.dbitmap: data bitmap 11100000 fs.data: [(.,0) (…,0) (y,1) (z,2) (x,3)] [u] [(.,3) (…,0)] [] … 对上述xmfs参考实例的解释：有8个inode空间,8个data blocks.其中，根目录包含5个目录项，“.”，“…”，“y”，“z”，“x”。而“y”是常规文件,并有文件内容，包含一个data block，文件内容为“u”。“z”是一个空的常规文件。“x”是一个目录文件，是空目录。 如果xmfs初始状态为： inode bitmap 10000000 inodes [d a:0 r:2] [] [] [] [] [] [] [] data bitmap 10000000 data [(.,0) (…,0)] [] [] [] [] [] [] [] 在执行了系统调用mkdir(&quot;/t&quot;)后，xmfs的当前状态为： inode bitmap 11000000 inodes [d a:0 r:3] [d a:1 r:2] [] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (t,1)] [(.,1) (…,0)] [] [] [] [] [] [] 请问接下来的4个状态变化所对应系统调用是什么？ 要求回答格式象上面“mkdir(&quot;/t&quot;)”一样。 （1） inode bitmap 11100000 inodes [d a:0 r:4] [d a:1 r:2] [f a:-1 r:1] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (t,1) (y,2)] [(.,1) (…,0)] [] [] [] [] [] [] （2） inode bitmap 11100000 inodes [d a:0 r:4] [d a:1 r:3] [f a:-1 r:2] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (t,1) (y,2)] [(.,1) (…,0) (c,2)] [] [] [] [] [] [] （3） inode bitmap 11100000 inodes [d a:0 r:4] [d a:1 r:3] [f a:2 r:2] [] [] [] [] [] data bitmap 11100000 data [(.,0) (…,0) (t,1) (y,2)] [(.,1) (…,0) (c,2)] [o] [] [] [] [] [] （4） inode bitmap 11110000 inodes [d a:0 r:5] [d a:1 r:3] [f a:2 r:2] [d a:3 r:2] [] [] [] [] data bitmap 11110000 data [(.,0) (…,0) (t,1) (y,2) (v,3)] [(.,1) (…,0) (c,2)] [o] [(.,3) (…,0)] [] [] [] [] create(&quot;/y&quot;) link(&quot;/y&quot;, “/t/c”) fd=open(&quot;/y&quot;), write(fd), close(fd) mkdir(&quot;/v&quot;) 这道题的形式非常类似于MOOC上的期末试题中的第20题。 uCore Lab Documents - ucore 文件系统总体介绍 - ucore文件系统总体结构 ↩︎","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》MOOC期末考试题分析","slug":"2018-05-20-《操作系统》MOOC期末考试题分析","date":"2018-05-20T12:00:04.000Z","updated":"2018-05-20T12:00:04.000Z","comments":true,"path":"post/os-mooc-final-exam-analysis/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-final-exam-analysis/","excerpt":"","text":"以下内容来自学堂在线《操作系统》在线课程的期末考试。因为只有单选题，所以没有什么难的。 某基于动态分区存储管理的计算机系统，其主存容量为55MB（初始为空），采用最佳适配（Best Fit）算法，分配和释放的顺序为：分配15MB，分配30MB，释放15MB，分配8MB，分配7MB，则此时主存中最大空闲分区的大小是（ ） 7MB 8MB 9MB 10MB 分配过程： 123456|----------------55MB--------------------||===15MB====|---------40MB---------------||===15MB====|======30MB======|---10MB----||---15MB----|======30MB======|---10MB----||---15MB----|======30MB======|=8MB=|-2MB-||=7MB=|-8MB-|======30MB======|=8MB=|-2MB-| EXPLANATION 下面是分配过程的表示。 0： 55 15： (15), 40 30： (15), (30), 10 ~15: 15, (30), 10 8: 15, (30), (8), 2 7: (7), 8, (30), (8), 2 在一个采用单地址方案（逻辑地址与物理地址是一一对应的）的分段存储系统中，内存地址长度为32位，其中段号占10位，则最大段长为（ ） 2^8字节 2^14字节 2^22字节 2^24字节 EXPLANATION 在段访问机制中，如果采用的是单地址方案，则段号的位数+段内偏移的位数=地址长度，所以段内偏移占了32 - 10 = 22 比特。 某计算机采用二级页表的分页存储管理方式，按字节编址，页大小为210字节，页表项大小为4字节，逻辑地址结构为“|一级页号|二级页号|页内偏移量|”，逻辑地址空间大小为216页，则表示整个逻辑地址空间的一级页表中包含表项的个数至少为（ ） 64 128 256 512 由于逻辑地址空间大小为216页，页大小为210字节，因此逻辑地址总长度为26，其中页内偏移量长度为10。我猜测一张页表最多占满一页，所以最多能够包含210/4=28=256个页表项。事实上，28*28恰好等于2^16（页），因此其实只有一种分配方法，就是一级页号长度=二级页号长度=8，每张页表都有256个页表项。 EXPLANATION 页大小为210B，页表项大小为4B，一页可以存放28个页表项，逻辑地址空间大小为216页，需要216个页表项，需要216/28 = 2^8 = 256个表项保存页表项。所以页目录表中包含的表项至少为256 在CPU中具有TLB和高速缓存(CACHE)的分页式存储管理系统中时，每次CPU取指令或取操作数，至少要访问（）次主存 0 1 2 3 一般取指令或取操作数需要经过以下过程： 查TLB TLB miss 从CR3寄存器中读出一级页表基地址，在一级页表中查出二级页表基地址 在二级页表中查出页帧物理地址 如果该页在内存中则直接查到 否则发生Page Fault，将对应页换入，重新执行上述过程 TLB hit 直接得到虚拟地址对应的物理地址 从物理地址中读数据 如果运气好的话，TLB hit，且对应的物理内存块缓存在cache中，则一次主存都不用访问。如果运气坏的话……我也想不起在ucore中最多会访问多少次主存了。 EXPLANATION 0次。因为CPU访问的页表项和要访问的内存单元可能会有缓存在TLB和cache中。 对于下列3种操作： （1）整数除以0； （2）cos数学函数调用； （3）read系统调用； 会导致用户进程从用户态切换到内核态的操作是 1、2 1、3 2、3 1、2、3 EXPLANATION 函数调用并不会切换到内核态，而除零操作引发中断，中断和系统调用都会切换到内核态进行相应处理 在缺页处理过程中，操作系统执行的操作可能是下列操作： （1）修改页表(page table) （2）磁盘I/O （3）分配页框（page frame） 中的（ ） 仅1、2 仅2、3 仅1、3 1、2、3 EXPLANATION 如果还有可分配给程序的内存，那么会分配新的页框，修改页表，从磁盘读取内容放入到分配的页框中。 一个虚拟存储器系统中，主存容量16MB，辅存容量2GB，地址寄存器位数32位。那么虚存最大容量为（ ） 2GB 16MB 2GB + 16MB 4GB 这是常见的障眼法了。群里有人曾经提问过，虚存4GB连主存+辅存都放不下，那怎么能说虚存最大为4GB呢？老师的回答是这样的：虚存大小不会受到硬盘的大小限制，因为这是虚存。因为是虚存，所以实际用到多少鬼知道。而且，甚至可以没有硬盘——比如无盘工作站、分布式系统、透明计算……虚存最后不一定需要对应到实际的物理存储的。所以虚存大小只和地址位数有关。（如果以上内容逻辑混乱，那是因为老师在微信里的回答比较零散。） EXPLANATION 虚拟存储器的最大容量跟虚拟地址空间有关，是2^32。 某进程的页面访问顺序为1、3、2、4、2、3、1、2，系统最多分配3个物理页面，那么采用LRU算法时，进程运行过程中会发生（ ）缺页 三次 四次 五次 六次 时间 访问页面 是否缺页 换出 栈顶（MRU） 栈底（LRU） 1 1 是 - 1 - - 2 3 是 - 3 1 - 3 2 是 - 2 3 1 4 4 是 1 4 2 3 5 2 否 - 2 4 3 6 3 否 - 3 2 4 7 1 是 4 1 3 2 8 2 否 - 2 1 3 EXPLANATION 解释：1（缺页） - 3（缺页） - 2（缺页） - 4（缺页，换出1） - 2 - 3 - 1（缺页，换出4） - 2 设两个进程共用一个临界区资源对应的互斥信号量mutex。当一个进程进入了临界区，另一个进程等待时，mutex应该等于多少（） -1 0 1 2 在一般的实现下，如果信号量的值为负数，则它的相反数=等待进程个数。 EXPLANATION 两个进程共用一个临界区的互斥信号量mutex，那么mutex的取值范围应该是1到-1，1表示没有进程进入临界区并且也没有进程等待，0表示有一个进程进入临界区，-1表示有一个进程进入临界区并且另一个进程等待。 (1)多个进程对信号量S进行了6次P操作，2次V操作后，现在信号量的值是-3，与信号量S相关的处于阻塞状态的进程有几个（ ） 1 2 3 4 (2)如10.(1)所描述的情况,信号量S的初值是（） 1 2 3 4 等待进程数量为3。初值-6+2=-3，因此初值=1。 EXPLANATION -3+6-2=1 用于互斥的二值信号量可以初始化为（） 0或1 0或-1 只能为1 任意值 事实上，用于互斥作用的信号量初值应该置1，用于条件等待作用的信号量初值应该置0。 EXPLANATION 通常操作系统区分计数信号量与二值信号量，二进制信号量的值只能为0或1 设与某资源关联的信号量Sem初值为4，当前值为2。若M表示该资源的可用个数，N表示等待该资源的进程数，则M、N分别是（） 0、1 1、0 1、2 2、0 显然可用个数为2，没有进程在等待。 EXPLANATION 信号量表示当前可用的相关资源数。当信号量Sem&gt;0时，表示还有Sem个相关资源可用；而当信号量Sem&lt;=0时，表示有|Sem|个进程在等待该资源。所以该资源可用数是2，等待该资源的进程数是0。 有两个并发执行的进程P1和P2，共享初值为1的变量x。加1和减1操作的指令序列分别如下所示。 P1：对x执行加一操作 123load R1,xinc R1store R1,x P2：对x执行减一操作 123load R2,xdec R2store R2,x 两个操作完成后，x的值（ ） 可能为-1或3 只能为1 可能为0、1或2 可能为-1、0、1、1或2 EXPLANATION 依次执行P1-1，P1-2，P1-3，P2-1，P2-2，P2-3，得到的结果是1；依次执行P1-1，P1-2，P2-1，P2-2，P2-3，P1-3，得到的结果是2；依次执行P2-1，P2-2，P1-1，P1-2，P1-3，P2-3得到的结果是0 资源的有序分配策略可以破坏死锁的（）条件 互斥 请求和保持 不剥夺 循环等待 EXPLANATION 资源的有序分配策略属于死锁预防的一种，死锁预防是通过破坏4个必要条件中的1个或者多个以确保系统不会发生死锁。采用资源有序分配法是破坏了“环路”条件，即破坏了循环等待。 若一个用户进程通过read系统调用读取一个磁盘文件中的数据，则下列关于此进程的叙述中，正确的是（） I. 若文件的数据不在内存中，则该进程进入睡眠等待状态 II. 请求read系统调用会导致CPU从用户态切到核心态 III. read系统调用的参数应包含文件的名称 仅I、II 仅I、III 仅II、III I、II和III 中间做错了，不是D。问题就在于，这个是read调用，不是open调用。 EXPLANATION 对于I，当所读文件的数据不在内存时，产生I/O请求，原进程进入阻塞状态，知道所需数据从外存调入内存后，才将该进程唤醒。对于II，read系统调用通过陷入将CPU从用户态进入核心态，从而获取操作系统提供的服务。对于III，读一个文件首先要用open系统调用打开该文件。open参数包含文件的路径名与文件名，read只需要open返回的文件描述符，不用文件名作为参数。read要求三个输入参数：1文件描述符fd；2buf缓冲区首地址；3传送的字节数n。read的功能试图从fd所指示的文件中读入n个字节的数据，并将它们送到buf所指示的缓冲区中。 用户删除某文件的过程中，操作系统不可能执行的操作是（） 删除文件所在的目录 删除与此文件关联的目录项 删除与此文件对应的文件控制块 释放与此文件关联的内存缓冲区 这个好像是常识。 EXPLANATION 删除文件不能删除文件所在的目录，而与此文件关联的目录项和文件控制块需要随着文件一同删除，同时释放文件关联的内存缓冲区。 设文件A的当前引用计数值为1，先建立文件A的符号链接（软链接）文件B，再建立文件A的硬链接C，然后删除文件A。此时，文件B和文件C的引用计数分别是（） 0,1 1,1 1,2 2,1 B是我随便选的，实际上我并不会算引用计数。 EXPLANATION 建立符号链接时，引用计数为1；建立硬链接时，引用计数加1。删除文件时，删除操作对于符号链接是不可见的，这并不影响符号链接文件；当以后通过符号链接访问文件时，发现文件不存在；但对于硬链接删除操作，引用计数值减1，若值大于0，则不会真正删除文件数据，因为还有其他的硬链接或文件索引指向此文件。当建立B时，A和B的引用计数值都为1.当建立C时，A和B的引用计数值分别为2和1。删除A时，C的引用计数值为2-1=1，B的引用计数值不变。 在多用户操作系统中，某文件占用10个磁盘块，现在要把该文件磁盘块逐个读入主缓冲区，并送用户区进行分析。假设一个缓冲区与一个磁盘块大小相同，把一个磁盘块读入缓冲区的时间为100μs，将缓冲区的数据传送到用户区的时间是50μs，CPU对一块数据进行分析的时间为50μs。在单缓冲区和双缓冲区结构下，读入并分析完该文件的时间分别是（ ） 1500μs，1000μs 1550μs，1100μs 1550μs，1550μs 2000μs，2000μs 单缓冲区：(100+50) * 10 + 50 = 1550μs 双缓冲区：100 + 100*9 + 50 + 50 = 1100μs EXPLANATION 单缓冲区下，当上一个磁盘块从缓冲区读入用户区完成时下一磁盘块才能开始读入，所以当最后一块磁盘块读入用户区完毕时，所用时间为150×10＝1500，加上处理最后一个磁盘块的cpu处理时间50，最后结果为1550。 双缓冲区下，读入第一个缓冲区之后可以立刻开始读入第二个缓冲区，读完第二个缓冲区之后，第一个缓冲区的数据已经传送到用户区，因此不存在等待磁盘块从缓冲区读入用户区的问题，也就是100×10＝1000，再加上最后一个缓冲区的数据传输到用户区并有CPU处理的时间50+50=100，总的时间是1000+100=1100。 假设磁头当前位于第105道，正在向磁道序号增加的方向移动。现有一个磁道访问请求序列为35，45，12，68，110，180，170，195。采用SCAN调度（电梯调度）算法得到的磁道访问序列是() 110，170，180，195，68，45，35，12 110，68，45，35，12，170，180，195 110，170，180，195，12，35，45，68 12，35，45，68，110，170，180，195 A对应的是SCAN算法（磁臂在一个方向上移动，访问所有未完成的请求，直到磁臂到达该方向上最后的磁道；然后调换方向） 我猜测B对应的是SSTF算法（选择从磁臂当前位置需要移动最少的I/O请求）；C对应的是CLOOK算法（限制仅在一个方向上扫描；当最后一个请求也被访问过了后，磁臂返回到磁盘的另外一端再次进行扫描）；D不知道是啥。 EXPLANATION SCAN调度算法就是电梯调度算法，顾名思义就是如果开始时磁头往外就一直要到最外面，然后再返回向里（磁头编号一般是最外面为0号往里增加），就像电梯若往下则一直要下到最底层才会再上升一样。 某操作系统中建立了一个基于索引节点(index node)结构的文件系统very simple file system, 简称vsfs。 vsfs的用户操作包括(以函数形式表示): mkdir(“str”) - 创建一个新目录,目录名称为”str” creat(“str”) - 创建一个空文件,空文件名称为“str” fd=open(“str”), write(fd), close(fd) – 打开文件”str”,会返回一个整型数fd, 然后对文件写一个buffer,注意常规文件的最大size是一个data block,所以第二次写(写文件的语义是在上次写的位置后再写一个data block)会报错(文件大小满了)。或者如果data block也满了,也会报错。 link(“a1”,”b1”) - 对文件”a1”创建一个硬链接(hard link)文件”b1” unlink(“b1”) - 对文件“b1”取消一个硬链接,如果文件的链接数为0,则删除此文件 vsfs在硬盘上的布局: superblock : 可用inode数量,可用data block数量 inode bitmap : inode的分配图(基于bitmap) inodes : inode的存储区域 data bitmap : data block的分配图(基于bitmap) data : data block的存储区域 vsfs的关键数据结构: inode数据结构: inode : 包含3个fields, 用 list 表示 file type: f -&gt; 常规文件:regular file, d -&gt; 目录文件:directory data block addr of file content: -1 -&gt; file is empty reference count: file/directory的引用计数,注意directory的引用计数是指在此目录中的inode的个数 注意:比如,刚创建的一个空文件inode: [f a:-1 r:1], 一个有1个硬链接的文件inode: [f a:10 r:2] 数据块内容结构: 一般文件的内容的表示:只是包含单个字符的list,即占一个data block,比如[‘a’], [‘b’] … 目录内容的表示: 多个两元组(name, inode_number)形成的list,比如, 根目录[(.,0) (…,0)], 或者包含了一个’f’文件的根目录[(.,0) (…,0) (f,1)] 。 注意: 一个目录的目录项的个数是有限的。 block.maxUsed = 32 data block的个数是有限的,为 fs.numData inode的个数是有限的,为 fs.numInodes 完整文件系统的例子: fs.ibitmap: inode bitmap 11110000 fs.inodes: [d a:0 r:5] [f a:1 r:1] [f a:-1 r:1] [d a:2 r:2] [] … fs.dbitmap: data bitmap 11100000 fs.data: [(.,0) (…,0) (y,1) (z,2) (x,3)] [u] [(.,3) (…,0)] [] … 表明: 此文件系统有8个inode空间, 8个data blocks. 其中,根目录包含5个目录项，“.”,“…”,“y”,“z”,“x”。 而“y”是常规文件,并有文件内容,包含一个data block,文件内容为“u”。“z”是一个空的常规文件。“x”是一个目录文件，是空目录。 如果vsfs初始状态为: inode bitmap 10000000 inodes [d a:0 r:2] [] [] [] [] [] [] [] data bitmap 10000000 data [(.,0) (…,0)] [] [] [] [] [] [] [] 请问接下来的连续6个状态变化的对应用户操作是什么?据此回答以下6个问题 (1) inode bitmap 11000000 inodes [d a:0 r:3] [d a:1 r:2] [] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c&quot;); unlink(&quot;/c&quot;); creat(&quot;/c&quot;); fd=open(“/c”), write(fd), close(fd) 显然多了一个目录。 EXPLANATION mkdir(&quot;/c&quot;); (2) inode bitmap 11100000 inodes [d a:0 r:3] [d a:1 r:3] [f a:-1 r:1] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0) (h,2)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c/h&quot;); unlink(&quot;/c/h&quot;); creat(&quot;/c/h&quot;); fd=open(“/c/h”), write(fd), close(fd) 在c目录下多了一个空文件h。 EXPLANATION creat(&quot;/c/h&quot;); (3) inode bitmap 11100000 inodes [d a:0 r:3] [d a:1 r:4] [f a:-1 r:2] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0) (h,2) (p,2)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c/p&quot;); creat(&quot;/c/p&quot;); link(&quot;/c/h&quot;, “/c/p”); unlink(&quot;/c/h&quot;); 文件/c/h和目录/c的引用记录增加了，/c目录下多了一个p文件。 EXPLANATION link(&quot;/c/h&quot;, “/c/p”); (4) inode bitmap 11100000 inodes [d a:0 r:3] [d a:1 r:3] [f a:-1 r:1] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0) (p,2)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c/h&quot;); unlink(&quot;/c/p&quot;); link(&quot;/c/h&quot;, “/c/p”); unlink(&quot;/c/h&quot;); 文件/c/h和目录/c的引用记录减少了，文件/c/h被删除了。 EXPLANATION unlink(&quot;/c/h&quot;); (5) inode bitmap 11000000 inodes [d a:0 r:3] [d a:1 r:2] [] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c&quot;); unlink(&quot;/c&quot;); creat(&quot;/c/p&quot;); unlink(&quot;/c/p&quot;); 文件/c/p也被删除了。 EXPLANATION unlink(&quot;/c/p&quot;); (6) inode bitmap 11100000 inodes [d a:0 r:3] [d a:1 r:3] [f a:-1 r:1] [] [] [] [] [] data bitmap 11000000 data [(.,0) (…,0) (c,1)] [(.,1) (…,0) (f,2)] [] [] [] [] [] [] 对应用户操作是（ ） mkdir(&quot;/c/f&quot;); creat(&quot;/c/f&quot;); link(&quot;/c&quot;,&quot;/c/f“); fd=open(“/c/f”), write(fd), close(fd) 新建了一个文件f。 EXPLANATION creat(&quot;/c/f&quot;);","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》2016年期末考试分析","slug":"2018-05-19-《操作系统》2016年期末考试分析","date":"2018-05-19T14:13:49.000Z","updated":"2018-12-19T00:23:00.000Z","comments":true,"path":"post/os-mooc-2016-final-exam-analysis/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-2016-final-exam-analysis/","excerpt":"","text":"试题来自20160524-期末考试题目-v1a.pdf。 判断题（20分） 在进程控制块数据结构中，必须为进程建立内核栈结构，确保进程可以得到操作系统的可靠服务和管理等支持。（√） 以下解释摘自ucore docs Lab4： 每个线程都有一个内核栈，并且位于内核地址空间的不同位置。对于内核线程，该栈就是运行时的程序使用的栈；而对于普通进程，该栈是发生特权级改变的时候使保存被打断的硬件信息用的栈。uCore在创建进程时分配了2个连续的物理页（参见memlayout.h中KSTACKSIZE的定义） 作为内核栈的空间。这个栈很小，所以内核中的代码应该尽可能的紧凑，并且避免在栈上分配大的数据结构，以免栈溢出，导致系统崩溃。kstack记录了分配给该进程/线程的内核栈的位置。主要作用有以下几点。首先，当内核准备从一个进程切换到另一个的时候，需要根据kstack 的值正确的设置好tss（可以回顾一下在实验一中讲述的 tss在中断处理过程中的作用），以便在进程切换以后再发生中断时能够使用正确的栈。其次，内核 栈位于内核地址空间，并且是不共享的（ 每个线程都拥有自己的内核栈） ，因此不受到mm的管理，当进程退出的时候，内核能够根据kstack的值快速定位栈的位置并进行回收。 在进程切换过程中，进程上下文信息的保存与恢复过程必须在内核态完成。（√） 以下内容摘自ucore docs Lab4： context：进程的上下文，用于进程切换（参见switch.S）。在uCore中，所有的进程在内核中也是相对独立的（例如独立的内核堆栈以及上下文等等） 。使用context保存寄存器的目的就在于在内核态中能够进行上下文之间的切换。实际利用context进行上下文切换的函数是在kern/process/switch.S中定义的switch_to。 进程的上下文信息除了context以外，还包括页表信息（CR3寄存器），访问和修改这些内容需要特权指令，因此必须在内核态完成。 对于父进程而言，fork()的返回值只能是子进程的pid号。（×） 如果fork()不成功，则会返回-1。 对于分属不同进程的线程A和线程B之间进行切换，必须要切换页表。（√） 同一进程的不同线程共享同一页表，但不同进程对应的页表一般是不同的。 在用户空间中实现的线程模型可以有效的避开操作系统调度带来的时间开销。（?） 我猜这是第11讲“进程和线程”中的内容。用户线程的优点是同一进程内的用户线程切换快，但是内核并不了解用户线程，因此只能按进程分配CPU时间；而内核线程的创建、终止和切换的代价相对较大（因为需要在内核态实现），但可以以线程为单位进行CPU时间分配。总的来说，避免操作系统的调度是不太可能的，所以我认为此题的描述是错误的。 2018.5.25 UPD：tsz同学认为此题题意不清。我同意这一观点。用户态实现的线程切换的时候的确可以不通过OS的进程调度，但是当然，完全避开OS的调度是不太可能的。 2018.12.19 UPD：评论区酒和弦的回复提醒了我，“避开操作系统调度带来的时间开销”的意思不一定是真的要避开操作系统的调度，而是用用户线程调度替代OS线程调度。这的确可以节省时间开销。[1]不过我仍然认为这道题的含义不明确，所以现在我把答案改成了？ 对于应用程序而言，编译器生成的程序地址是虚拟地址，由操作系统建立段/页表完成虚实地址转换。（√） 好像确实是这么回事。 对于采用段页式的x86而言，CPU访问一个虚拟地址时，如TLB访问缺失，则需先通过页表，再通过段表才能找到对应的物理地址。（×） 反了，是先通过段表，再通过页表。 通过动态链接库和操作系统的页表设置，可以让多个不同的应用程序运行时共用一个库函数（如printf等）的代码实现。（√） 反正就是可以通过页表设置映射到同一块物理内存。OS本身的代码也是这么操作的。 当设置好GDT（全局描述符表）的内容：然后CPU执行lgdt指令加载GDT；接着立刻执行incl 0x80指令时，CPU将查找GDT并完成虚拟地址0x80到线性地址的转换。（×） 这道题的表述比较模糊不清。不过据说这个描述是错误的，因为里面没有提到对GDT项指向的段寄存器的更新。 在32位计算机系统中，由于4GB内存普遍存在，导致虚拟内存管理已经不再有存在的必要。（×） 这种说法显然有很多问题，比如： 4GB仍然很不够用 虚拟内存管理的功能不止有增加“虚拟”内存，还有细粒度的对内存访问权限和内存共享的管理 对于实时系统中的优先级反转（反置）问题，可通过优先级继承算法或优先级天花板算法来解决。（√） 这是第15讲“处理机调度”中的内容。优先级继承算法的思路是，占有资源的低优先级进程继承申请资源的高优先级进程的优先级；而优先级天花板算法的思路是，占有资源进程的优先级和所有可能申请该资源的进程的最高优先级相同。 信号量机制可实现基于条件变量的管程机制，反之亦然。（√） 信号量和条件变量是等价的（也就是它们可以互相实现）。 在多CPU系统中，仅通过CPU中断使能和屏蔽指令，就可实现对临界区代码的互斥保护。（×） 因为有多个CPU，因此使能单个CPU的中断完全不能保证互斥保护。 在银行家算法中，不安全状态不一定会造成死锁。（√） 操作系统中的虚拟文件系统屏蔽了底层具体文件系统的差异性，给上层应用提供了统一的访问接口。（√） 这是很原理性的话了。显然是对的。 在Linux中，存在不需要把数据保存到磁盘上的文件系统，比如/proc文件系统，其作用是给应用程序提供一种内核信息的访问通道。（√） 是的。以下内容摘自深入理解linux系统下proc文件系统内容： Linux系统上的/proc目录是一种文件系统，即proc文件系统。与其它常见的文件系统不同的是，/proc是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，用户可以通过这些文件查看有关系统硬件及当前正在运行进程的信息，甚至可以通过更改其中某些文件来改变内核的运行状态。 基于/proc文件系统如上所述的特殊性，其内的文件也常被称作虚拟文件，并具有一些独特的特点。例如，其中有些文件虽然使用查看命令查看时会返回大量信息，但文件本身的大小却会显示为0字节。此外，这些特殊文件中大多数文件的时间及日期属性通常为当前系统时间和日期，这跟它们随时会被刷新（存储于RAM中）有关。 为了查看及使用上的方便，这些文件通常会按照相关性进行分类存储于不同的目录甚至子目录中，如/proc/scsi目录中存储的就是当前系统上所有SCSI设备的相关信息，/proc/N中存储的则是系统当前正在运行的进程的相关信息，其中N为正在运行的进程（可以想象得到，在某进程结束后其相关目录则会消失）。 大多数虚拟文件可以使用文件查看命令如cat、more或者less进行查看，有些文件信息表述的内容可以一目了然，但也有文件的信息却不怎么具有可读性。不过，这些可读性较差的文件在使用一些命令如apm、free、lspci或top查看时却可以有着不错的表现。 在当前的计算机系统中，存在计算能力比CPU还快的外设。（√） 我也不知道到底是什么外设……不过我大胆猜测这里指的是GPU。不过，即使是CPU和GPU的比较，这个说法仍然不见得是很严谨的。 造成GPU和CPU根本差别的原因在于不同的目标需求：GPU假设运行其上的工作都是高度可并行的，而CPU需要同时很好的支持并行和顺序操作。于是，CPU需要大的片上缓存和复杂的控制逻辑，GPU则利用多线程并行运行节省了片上的大缓存，同时针对一簇线程执行同一套控制逻辑。因此，在高度并行化且数据规模巨大的应用下，GPU可以获得很高的浮点运算性能，然而如果问题无法良好映射到某个合适的并行模型或当数据规模较小时，SIMT就无法发挥并行的优势，CPU与GPU之间的数据交换也会大大降低运算效率。不过，后一个问题在刚刚发布的CUDA4.0中已经通过GPUDirect2.0得到了改进)。 作者：王洋子豪 链接：https://www.zhihu.com/question/19584781/answer/12292363 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 DMA机制允许外设不经过CPU进行数据传输。（√） 以下内容摘自直接内存访问： 直接内存访问（Direct Memory Access，DMA）是计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统（电脑外设），可以独立地直接读写系统内存，而不需中央处理器（CPU）介入处理 。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。 循环扫描算法（C-SCAN）对硬盘访问带来的好处在U盘上不存在。（√） 循环扫描算法是对扫描算法的改进。如果对磁道的访问请求是均匀分布的，当磁头到达磁盘的一端，并反向运动时落在磁头之后的访问请求相对较少。这是由于这些磁道刚被处理，而磁盘另一端的请求密度相当高，且这些访问请求等待的时间较长，为了解决这种情况，循环扫描算法规定磁头单向移动。例如，只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。（磁盘调度算法） 对于U盘和SSD等随机访问的Flash半导体存储器，采用FCFS（先来先服务）调度策略更高效。 因为Flash的半导体存储器的物理结构不需要考虑寻道时间和旋转延迟，可直接按I/O请求的先后顺序服务。（https://www.nowcoder.com/questionTerminal/64fe6441b3fe47708803354979645a36） 访问频率置换算法（Frequency-based Replacement）的基本思路是，在短周期中使用LFU算法，而在长周期中使用LRU算法。（×） 其实我现在还没有学到这里，但似乎这个描述反了，应该是短周期使用LRU，长周期使用LFU。 填空题（20分） 21 在基于x86-32的ucore操作系统中，一般函数调用的参数通过（1.1）传递，系统调用的参数通过（1.2）传递，将系统调用号存放在（1.3），通过（1.4）指令进入内核态。此时还应该保存执行现场，需要在trapframe里保存（1.5）、（1.6）、（1.7）等信息（填三项即可）。 栈 寄存器和栈 eax寄存器 int 0x80 通用寄存器 EFLAGS寄存器 EIP 以下内容摘自系统调用和函数参数传递： 系统调用参数传递： x86_32 通过中断（int 0x80）来实现 寄存器 eax 中存放系统调用号，同时系统调用返回值也存放在 eax 中 当系统调用参数小于等于6个时，参数则必须按顺序放到寄存器 ebx，ecx，edx，esi，edi ，ebp中 当系统调用参数大于6个时，全部参数应该依次放在一块连续的内存区域里，同时在寄存器 ebx 中保存指向该内存区域的指针 x86_64 通过中断（syscall）指令来实现 寄存器 eax 中存放系统调用号，同时系统调用返回值也存放在 eax 中 当系统调用参数小于等于6个时，参数则必须按顺序放到寄存器 rdi，rsi，rdx，r10，r8，r9中 当系统调用参数大于6个时，全部参数应该依次放在一块连续的内存区域里，同时在寄存器 ebx 中保存指向该内存区域的指针 函数参数传递： x86_32 C调用约定（即用__cdecl关键字说明）按从右至左的顺序压参数入栈，由调用者把参数弹出栈。 x86_64 当参数少于7个时， 参数从左到右放入寄存器: rdi, rsi, rdx, rcx, r8, r9。当参数为7个以上时， 前6个与前面一样， 但后面的依次从&quot;右向左&quot;放入栈中。 struct trapframe的定义如下（摘自kern/trap/trap.h）： 12345678910111213141516171819202122struct trapframe &#123; struct pushregs tf_regs; uint16_t tf_gs; uint16_t tf_padding0; uint16_t tf_fs; uint16_t tf_padding1; uint16_t tf_es; uint16_t tf_padding2; uint16_t tf_ds; uint16_t tf_padding3; uint32_t tf_trapno; /* below here defined by x86 hardware */ uint32_t tf_err; uintptr_t tf_eip; uint16_t tf_cs; uint16_t tf_padding4; uint32_t tf_eflags; /* below here only when crossing rings, such as from user to kernel */ uintptr_t tf_esp; uint16_t tf_ss; uint16_t tf_padding5;&#125; __attribute__((packed)); 可以看出，trapframe中保存的信息包括： 通用寄存器（tf_regs，其中保存了edi、esi、ebp、ebx、edx、ecx和eax） 中断错误码（err） eip（指令指针） cs（代码段寄存器） EFLAGS寄存器 esp（栈寄存器，可选） ss（堆栈段寄存器，可选） 22 （2.1）是一种将不同文件名链接至同一个文件的机制，它可以使同一文件具有多个不同的名字，而文件系统只存在一个文件内容的副本。（2.2）和原文件共享一个相同的inode号（文件在文件系统上的唯一标识）。若原文件删除了，则（2.3）不能访问它指向的原文件，而（2.4）则是可以的。（2.5）可以跨越磁盘分区，但（2.6）不具备这个特性。 链接 软链接硬链接 软链接 硬链接 软链接 硬链接 以下内容摘自Linux软连接和硬链接： Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 【硬连接】 硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 【软连接】 另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。 更详细的解释可以参见关于硬链接和软连接（符号链接）的区别。 2018.5.25 UPD：经过wj同学的提示，我发现不知为何2抽风写错了。共享inode号的应该是硬链接。 23 RAID是一种机制，即把多块独立的硬盘按某种方式组合，形成硬盘阵列，从而提供比单块硬盘更快的访问性能或更可靠的数据存储能力。组成磁盘阵列的不同方式称为RAID级别，其中，（3.1）级别没有数据冗余存储功能，而（3.2）的数据可靠性在所有的RAID级别中是最高的。RAID 5是一种存储性能、数据安全和存储成本兼顾的磁盘阵列组成方式。它至少需要（3.3）块硬盘。当RAID5的一个磁盘数据发生损坏后，可利用剩下的数据和相应的（3.4）信息去恢复被损坏的数据。 RAID 0 RAID 6 3 校验 RAID-0：磁盘条带化 把数据块分成多个子块，存储在独立的磁盘中 通过独立磁盘上并行数据块访问来提供更大的磁盘带宽 RAID-1：磁盘镜像 向两个磁盘写入相同的数据，从任何一个磁盘读取 RAID-4：带校验的磁盘条带化 数据块级的磁盘条带化+专用奇偶校验磁盘 RAID-5：带分布式校验的磁盘条带化 分摊校验磁盘的带宽限制 把校验和分布在各个磁盘上 RAID-6：每组条带块有两个冗余块，允许两个磁盘错误 24 信号提供了异步处理事件的一种方式。例如，用户在终端按下“Ctrl-C”键，会产生可使当前进程终止的SIGINT信号。每一个信号对应一个（4.1）数，定义在头文件&lt;signal.h&gt;中。信号处理行为可由三种方式可供选择：（4.2）、（4.3）、（4.4）。 整 捕获 忽略 屏蔽 这部分是第20讲“死锁和进程通信”里的，但是我几乎都忘掉了……总之，信号和“信号号”的对应关系很类似于中断和中断号的关系，但是并没有一个明确的名称，所以我觉得回答“整数”是可以的。（参考https://blog.csdn.net/jnu_simba/article/details/11746217） 问答题（60分） 25. 银行家算法（10分） 下面是采用银行家算法的操作系统在某一时刻的资源分配状态。 Allocation矩阵： A B C D P0 0 0 1 2 P1 1 0 0 0 P2 1 3 5 4 P3 0 6 3 2 P4 0 0 1 4 Max矩阵： A B C D P0 0 0 1 2 P1 1 7 5 0 P2 2 3 5 6 P3 0 6 5 2 P4 0 6 5 6 Available矩阵： A B C D 1 5 2 0 请回答下列问题： 请写出当前时刻的Need矩阵的内容是什么？ 当前时刻，系统是否处于安全状态？ 接下来，如果进程P1发出一个请求(0, 4, 2, 0)。这个请求能否立刻被满足？ 要获得Need矩阵，只需将Allocation矩阵从Max矩阵中减去。于是得到： Need矩阵： A B C D P0 0 0 0 0 P1 0 7 5 0 P2 1 0 0 2 P3 0 0 2 0 P4 0 6 4 2 下面判断系统是否处于安全状态： Finish[P0] = false，Need[P0] &lt;= Available；于是释放P0资源，Available += [0, 0, 1, 2] = [1, 5, 3, 2]，Finish[P0] = true Finish[P2] = false，Need[P2] &lt;= Available；于是释放P2资源，Available += [1, 3, 5, 4] = [2, 8, 8, 6]，Finish[P2] = true Finish[P1] = false，Need[P1] &lt;= Available；于是释放P1资源，Available += [1, 0, 0, 0] = [3, 8, 8, 6]，Finish[P1] = true Finish[P3] = false，Need[P3] &lt;= Available；于是释放P3资源，Available += [0, 6, 3, 2] = [3, 14, 11, 8]，Finish[P3] = true Finish[P4] = false，Need[P4] &lt;= Available；于是释放P4资源，Available += [0, 0, 1, 4] = [3, 14, 12, 12]，Finish[P4] = true 算法结束，系统处于安全状态 如果P1发出请求为Request = [0, 4, 2, 0]： Request &lt;= Need[P1]，资源申请未超过限度 Request &lt;= Available，不需等待 假设资源已分配，更新各矩阵内容： Allocation矩阵： A B C D P0 0 0 1 2 P1 1 4 2 0 P2 1 3 5 4 P3 0 6 3 2 P4 0 0 1 4 Available矩阵： A B C D 1 1 0 0 Need矩阵： A B C D P0 0 0 0 0 P1 0 3 3 0 P2 1 0 0 2 P3 0 0 2 0 P4 0 6 4 2 然后判断当前状态是否为安全状态： Finish[P0] = false，Need[P0] &lt;= Available；于是释放P0资源，Available += [0, 0, 1, 2] = [1, 1, 1, 2]，Finish[P0] = true Finish[P2] = false，Need[P2] &lt;= Available；于是释放P2资源，Available += [1, 3, 5, 4] = [2, 4, 6, 6]，Finish[P2] = true Finish[P1] = false，Need[P1] &lt;= Available；于是释放P1资源，Available += [1, 4, 2, 0] = [3, 8, 8, 6]，Finish[P1] = true Finish[P3] = false，Need[P3] &lt;= Available；于是释放P3资源，Available += [0, 6, 3, 2] = [3, 14, 11, 8]，Finish[P3] = true Finish[P4] = false，Need[P4] &lt;= Available；于是释放P4资源，Available += [0, 0, 1, 4] = [3, 14, 12, 12]，Finish[P4] = true 算法结束，系统处于安全状态 由于分配后系统仍然处于安全状态，这个请求可以立刻被满足。 26. 同步互斥（10分） 通过软件机制可正确实现互斥机制。 （1） 下列二线程互斥机制的伪码实现是否有错？请给出原因分析，如果有错请给出反例。 12345678910111213INITIALIZATION: shared int turn; ... turn = i ;ENTRY PROTOCOL (for Thread i ): /* wait until it&apos;s our turn */ while (turn != i ) &#123; &#125;EXIT PROTOCOL (for Thread i ): /* pass the turn on */ turn = j ; 事实上这就是第17讲“同步互斥”中“基于软件的同步方法”中介绍的第一种错误做法。这种做法满足“忙则等待”，但不满足“空闲则入”。线程i和j必须轮流访问临界区；如果i始终不进入临界区，则j无法进入，会发生饥饿。 我有时会忽略“空闲则入”这条规则，事实上这也是临界区实现中非常重要的一条规则。 （2） 下列N线程互斥机制的伪码实现是否有误？请给出原因分析，如果有错请给出反例。 123456789101112131415161718192021222324252627INITIALIZATION: typedef char boolean; ... shared int num[n]; ... for (j=0; j &lt; n; j++) &#123; num[j] = 0; &#125; ...ENTRY PROTOCOL (for Thread i): /* choose a number */ num[i] = max(num[0], ..., num[n-1]) + 1; /* for all other Threads */ for (j=0; j &lt; n; j++) &#123; /* wait if the Thread has a number and comes ahead of us */ if ((num[j] &gt; 0) &amp;&amp; ((num[j] &lt; num[i]) || (num[j] == num[i]) &amp;&amp; (j &lt; i))) &#123; while (num[j] &gt; 0) &#123;&#125; &#125; &#125;EXIT PROTOCOL (for Thread i): /* clear our number */ num[i] = 0; 这种做法是错误的。假设有两个进程，i&lt;j，Ti正在执行num[i] = max(num[0], ..., num[n-1]) + 1;时，已计算得max(num[0], ..., num[n-1])==0；此时切换到Tj，也计算得max(num[0], ..., num[n-1])==0，随后num[j]=1，Tj先进入临界区。随后切换到Ti，计算得到num[i]=1，检查后Ti也进入临界区，违反互斥。 据说修改num[i]前后应用bool变量choose[i]保护起来，在后面枚举其他进程时先要等待choose[i]完成。这样就可以解决问题了。 （上述解释来自学长答案；这种做法和Eisenberg &amp; Mcquire还是挺不像的） 27. 信号量与管程（15分） 123456789101112131415161718192021222324252627282930313233343536373839404142IMPLEMENTATION:monitor mt &#123; -----variable in monitor----------- semaphore mutex; // the mutex lock for going into the routines in monitor, should be initialized to 1 semaphore next; // the next is used to down the signaling proc, some proc should wake up the sleeped cv.signaling proc. should be initialized to 0 int next_count; // the number of of sleeped signaling proc, should be initialized to 0 condvar &#123;int count, sempahore sem&#125; cv[N]; // the condvars in monitor, count initial value 0, sem initial value 0 other shared variables in mt; // shared variables should protected by mutex lock --------condvar wait--------------- cond_wait (cv) &#123; cv.count ++; if(mt.next_count&gt;0) V(mt.next); // first perform the EXIT PROTOCOL else V(mt.mutex); P(cv.sem); // now wait on the condition waiting queue (cv.sem) cv.count --; &#125; --------condvar signal-------------- cond_signal(cv) &#123; if(cv.count&gt;0) &#123; // do nothing unless a process is waiting on condition waiting queue (cv.sem) mt.next_count ++; V(cv.sem); // release the waiting process which on condition waiting queue (cv.sem) P(mt.next); // wait on the &quot;next&quot; waiting queue for cv.signaling proc mt.next_count--; &#125; &#125; --------routines in monitor------------- routineA_in_mt () &#123; P(mt.mutex); // ENTRY PROTOCOL (at the beginning of each monitor routines), wait for exclusive access to the monitor ... real body of routineA // in here, may access shared variables, call cond_wait OR cond_signal ... if(next_count&gt;0) // EXIT PROTOCOL (at the end of each monitor function) V(mt.next); // if there are processes(sleeped cv.signaling proc) in the &quot;next&quot; queue, release one else V(mt.mutex); // otherwise, release the monitor &#125;&#125; （1） 请说明管程的特征。上述管程实现是哪种类型的管程？ 管程的特征： 管程是一种用于多线程互斥访问共享资源的程序结构 采用面向对象方法，简化了线程间的同步控制 任一时刻最多只有一个线程执行管程代码 正在管程中的线程可临时放弃管程的互斥访问，等待事件出现时恢复 很显然，这就是ucore Lab7中实现的管程，属于Hoare语义。在这种语义下，如果条件变量上有进程正在等待，发出signal的进程会立刻进入等待状态，将控制权交给被唤醒的进程。 （2） 在上述伪码中，如果有3个线程a，b，c需要访问管程，并会使用管程中的2个条件变量cv[0]，cv[1]。 请问cv[i]-&gt;count的含义是什么？cv[i]-&gt;count是否可能&lt;0，是否可能&gt;1？请举例或说明原因。 请问mt-&gt;next_count的含义是什么？mt-&gt;next_count是否可能&lt;0，是否可能&gt;1？请举例或说明原因。 cv[i]-&gt;count的含义是在该条件变量上等待的线程数。显然这个数不可能&lt;0。如果有多于1个线程执行了cond_wait(cv[i])操作且还未被唤醒，这个数是可能&gt;1的。 mt-&gt;next_count的含义是发出signal后暂时进入等待状态的线程的个数。显然，这个数不可能&lt;0。假设b执行cond_wait(cv[0])开始等待，c也执行cond_wait(cv[0])开始等待。a进入管程，执行cond_signal(cv[0])，唤醒b，a进入signal队列；b被唤醒后，立即执行cond_signal(cv[0])，唤醒c，b也进入signal队列。此时mt-&gt;next_count=2。 28. stride调度算法（10分） 请描述stride调度算法的思路？stride算法的特征是什么？stride调度算法是如何避免stride溢出问题的？ 思路： 每个进程有两个属性： pass：当前位置 stride：一次要前进的步数 stride ∝ 1 / priority 选择进程的方法： 执行当前pass最小的进程 该进程的pass += stride 重复该过程 特征： stride越小（优先级越高），被调度的次数会越多 基于优先级（priority-based） 调度选择是确定的（deterministic） 避免stride溢出的方法： uint32存储、int32相减比较 最大步进值-最小步进值&lt;无符号整数/2 具体可参见Piazza帖子https://piazza.com/class/i5j09fnsl7k5x0?cid=357 29. 文件系统（15分） （1） 试以图示描述ucore操作系统中的SFS文件系统的文件组织方式。 呃，这个怎么描述，不会啊。。。 总之据说是链式分配…… 2018.5.25 UPD： 在ssh同学的提醒下，我想起来SFS使用的是索引分配这回事了…… （2） 下面是SFS的磁盘索引节点数据结构定义。 12345678struct sfs_disk_inode &#123; uint32_t size; uint16_t type; uint16_t nlinks; uint32_t blocks; uint32_t direct[SFS_NDIRECT]; uint32_t indirect;&#125;; 假定ucore里SFS_NDIRECT的取值是16，而磁盘上数据块大小为1KB。请计算这时ucore支持的最大文件大小。请给出计算过程。（这样可给步骤分） 以下内容摘自ucore docs Lab8： SFS中的磁盘索引节点代表了一个实际位于磁盘上的文件。首先我们看看在硬盘上的索引节点的内容： 12345678struct sfs_disk_inode &#123; uint32_t size; // 如果inode表示常规文件，则size是文件大小 uint16_t type; // inode的文件类型 uint16_t nlinks; // 此inode的硬链接数 uint32_t blocks; // 此inode的数据块数的个数 uint32_t direct[SFS_NDIRECT]; // 此inode的直接数据块索引值（ 有SFS_NDIRECT个） uint32_t indirect; // 此inode的一级间接数据块索引值&#125;; 通过上表可以看出，如果inode表示的是文件，则成员变量direct[]直接指向了保存文件内容数据的数据块索引值。indirect间接指向了保存文件内容数据的数据块，indirect指向的是间接数据块（indirect block），此数据块实际存放的全部是数据块索引，这些数据块索引指向的数据块才被用来存放文件内容数据。 默认的，ucore里SFS_NDIRECT是12，即直接索引的数据页大小为12 * 4k = 48k；当使用一级间接数据块索引时，ucore 支持最大的文件大小为 12 * 4k + 1024 * 4k = 48k + 4m。数据索引表内，0表示一个无效的索引，inode里blocks表示该文件或者目录占用的磁盘的block的个数。indiret为0时，表示不使用一级索引块。（因为 block 0用来保存super block，它不可能被其他任何文件或目录使用，所以这么设计也是合理的） 显然，在题设中，最大可能的文件大小为使用一级间接数据块索引时，为(16 + 1KB/4B) * 1KB = 272KB。 【原理】线程的属性与特征分析 ↩︎","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《英诗金库》I-53：Prothalamion, by E. Spenser","slug":"2018-05-09-《英诗金库》I-53：Prothalamion-by-E-Spenser","date":"2018-05-09T01:24:35.000Z","updated":"2018-05-09T01:24:35.000Z","comments":true,"path":"post/prothalamion-by-e-spenser/","link":"","permalink":"https://zhanghuimeng.github.io/post/prothalamion-by-e-spenser/","excerpt":"","text":"作品基本信息 作品名称：Prothalamion 作者：Edmund Spenser（爱德蒙·斯宾塞） 出版年代：1599 编注：此诗选自《皆大欢喜》第二幕第七场，诗中将大自然的善与人类的恶进行了对照。 作品原文 Calm was the day, and through the trembling air Sweet-breathing Zephyrus1 did softly play— A gentle spirit, that lightly did delay Hot Titan’s beams, which then did glister fair; When I (whom sullen care, Through discontent of my long fruitless stay In princes’ court, and expectation vain Of idle hopes, which still do fly away Like empty shadows, did afflict my brain) Walk’d forth to ease my pain Along the shore of sliver-streaming Thames; Whose rutty2 bank, the which his river hems, Was painted all with variable flowers, And all the meads adorn’d with dainty gems Fit to deck maidens’ bowers, And crown their paramours3 Against the bridal day, which is not long4; Sweet Thames! run softly, till I end my song. There in a meadow by the river’s side A flock of nymphs I chanced to espy, All lovely daughters of the flood thereby5, With goodly greenish locks all loose untied As each had been a bride; And each one had a little wicker basket Made of fine twigs, entrailed6 curiously, In which they gather’d flowers to fill their flasket7, And with fine fingers cropt full feateously8 The tender stalks on high. Of every sort which in that meadow grew They gather’d some; the violet, pallid blue, The little daisy that at evening closes, The virgin lily and the primrose true, With store of vermeil9 roses, To deck their bridegrooms’ posies Against the bridal day, which was not long: Sweet Thames! run softly, till I end my song. With that I saw two swans of goodly hue Come softly swimming down along the lee10; Two fairer birds I yet did never see; The snow which doth the top of Pindus strow Did never whiter show, Nor Jove himself, when he a swan would be For love of Leda, whiter did appear; Yet Leda was (they say) as white as he, Yet not so white as these, nor nothing near; So purely white they were, That even the gentle stream, the which them bare, Seem’d foul to them, and bade his billows spare To wet their silken feathers, lest they might Soil their fair plumes with water not so fair, And mar their beauties bright, That shone as Heaven’s light Against their bridal day, which was not long; Sweet Thames! run softly, till I end my song. Eftsoons11 the nymphs, which now had flowers their fill12, Ran all in haste to see that silver brood As they came floating on the crystal flood; Whom when they saw, they stood amazed still Their wondering eyes to fill; Them seem’d13 they never saw a sight so fair Of fowls, so lovely, that they sure did deem Them heavenly born, or to be that same pair Which through the sky draw Venus’ silver team; For sure they did not seem To be begot of any earthly seed, But rather angels, or of angels’ breed; Yet were they bred of summer’s heat, they say, In sweetest season, when each flower and weed The earth did fresh array; So fresh they seem’d as day, Even as their bridal day, which was not long: Sweet Thames! run softly, till I end my song. Then forth they all out of their baskets drew Great store of flowers, the honour of the field, That to the sense did fragrant odours yield, All which upon those goodly birds they threw And all the waves did strew, That like old Peneus’ waters they did seem When down along by pleasant Tempe’s shore Scatter’d with flowers, through Thessaly they stream, That they appear, through lilies’ plenteous store, Like a bride’s chamber-floor. Two of those nymphs meanwhile, two garlands bound, Of freshest flowers which in that mead they found, The which presenting all in trim array, Their snowy foreheads therewithal they crown’d; Whilst one did sing this lay Prepared against that day, Against their bridal day, which was not long: Sweet Thames! run softly, till I end my song. ‘Ye gentle birds! the world’s fair ornament, And Heaven’s glory, whom this happy hour Doth lead unto your lovers’ blissful bower, Joy may you have, and gentle heart’s content Of your love’s couplement; And let fair Venus, that is queen of love, With her heart-quelling son upon you smile, Whose smile, they say, hath virtue to remove All love’s dislike, and friendship’s faulty guile For ever to assoil. 译文 戴镏龄 译 宁静的日子呀，阵阵清风 轻微地吹拂，在空中飘荡， 大气柔和，使晴空的骄阳&lt;&gt; 明媚温煦，不致烧灼碧空； 我正感不受用， 由于淹留王廷常是失意， 期望终成梦想，无从实现，&lt;&gt; 冀求的东西都徒然飞逝， 无影无踪，心情苦不堪言， 于是散步排遣， 沿着清凌凌的泰晤士河， 两岸上发出稠密的枝柯， 各种奇卉，无不鲜花怒放， 青草地上珠光宝气繁多， 宜于装饰闺房， 插在情人头上， 迎接佳期，屈指就在目下， 可爱的河，轻轻流到歌罢。 河边上呈现出一块草坪， 那儿我瞥见仙女一大群， 好姑娘，在邻近川泽成长， 头上飘散着美丽的青鬓， 好象新人出聘。 她们都携着一只小柳筐， 细条做料子，精工编织成， 用来采集花枝，满满盛装， 纤纤手指，摘取巧妙认真， 顶部嫩的花梗。 草原上这样那样花灿烂， 每样采一些，紫罗兰淡蓝， 黄昏时合上眼睛的雏菊， 以及百合纯洁，樱草烂漫， 嫣红玫瑰成束， 献作新郎礼物， 迎接佳期，屈指就在目下， 可爱的河，轻轻流到歌罢。 接着有漂亮的天鹅一双，&lt;&gt; 飘飘然在水上顺流下游， 平生初见，最美的鸟两头， 雪洒在坪达山的高峰上，&lt;&gt; 输掉白的光芒； 宙父变做天鹅追求妮黛， 也比不上这对赛粉欺银；&lt;&gt; 论白，宙父、妮黛难分好坏， 但是都难和这一双接近， 她们异常白净。 轻柔的流水，负载着她们， 似嫌形秽，戒浪花莫溅喷 她们的洁羽，那样就必然 使浑水给她们带来污痕， 让太阳般美颜 因此添上缺陷， 迎接佳期，屈指就在目下， 可爱的河，轻轻流到歌罢。 仙女采花不久，收获丰满， 奔去看这对洁白的俦&lt;&gt;侣， 正泛泛而来，清水上漂浮， 姑娘见了，无不感到茫然， 惊得直瞪两眼； 这样的美禽，似从未见过， 多可爱呀，一定生在天堂， 或是给爱神挽车的双鹅，&lt;&gt; 挽她的车穿过云霄之上； 她们绝对不象 我们这个尘世间的产物， 而是天使，或是同一种族。 据说她们是在夏季出生， 和煦时节，花草枝叶扶疏， 大地新装披身， 好似旭日东升， 恰似佳日，屈指就在目下， 可爱的河，轻轻流到歌罢。 仙女从筐里取出许多花， 这些都是田野上的光辉， 发散出扑鼻的阵阵香味； 她们把花撒向好鸟身上， 水波吐秀流芳， 象泌罗斯江水流声活活，&lt;&gt; 沿着丹丕的可喜山谷间， 满载花枝，从帖撒利流过； 有数不尽的百合花，乍看， 象香闺的铺板。 这时其中两位仙女挑选 我的感想 [1] 参考文献 [1] As You Like It. https://en.wikipedia.org/wiki/As_You_Like_It 脚注 1Zephyrus: ‘the west wind.’（西风。） 2rutty: ‘abounding in ruts.’（查词典，“rutty”一词为“遍地车辙的”之义，但看译文，此处似乎译作“有很多枝干”的意思了？） 3paramours: ‘lovers’.（情人们。） 4is not long: ‘is close at hand.’（近在眼前了。） 5the flood thereby: ‘the stream which ran beside them.’（他们身边流过的小溪。） 6entrailed: ‘entwined.’（相互缠绕的。） 7flasket: ‘a long shallow basket’ (Johnson); the word is a diminutive of ‘flask.’（长而浅的篮子；对“flask”的爱称。） 8full feateously: ‘very skillfully or elegantly.’（非常灵巧而优雅地。） 9vermeil: a poetic form of ‘vermilion.’（“朱红色”的另一种写法。） 10the lee: here and in L 115 below, Spenser uses this word for ‘stream’ or ‘current.’（在此处和下面的第115行，斯宾塞用这个词来表示“溪流”或“水流”之义。） 11Eftsoon: ‘soon after.’（很快。） 12had flowers their fill: ‘flowers, as many as they wanted.’（已经拿了尽可能多的花朵。） 13Them seem’d: ‘it seemed to them.’（在她们看来。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"},{"name":"E.Spencer","slug":"E-Spencer","permalink":"https://zhanghuimeng.github.io/tags/E-Spencer/"}]},{"title":"《英诗金库》I-52：Pack, clouds, away, and welcome day, by T. HeyWood","slug":"2018-05-06-《英诗金库》I-52：Pack-clouds-away-and-welcome-day-by-T-HeyWood","date":"2018-05-06T00:23:04.000Z","updated":"2018-05-06T00:23:04.000Z","comments":true,"path":"post/pack-clouds-away-and-welcome-day-by-t-heyWood/","link":"","permalink":"https://zhanghuimeng.github.io/post/pack-clouds-away-and-welcome-day-by-t-heyWood/","excerpt":"","text":"作品基本信息 作品名称：Pack, clouds, away, and welcome day 作者：Thomas Heywood（托马斯·海伍德） 出版年代：1608 编注：海伍德（Thomas Heywood，1570?-1641），英国剧作家。本诗选自他以罗马神话为题材写成的戏剧《鲁克丽丝受辱记》第四幕第六场。 作品原文 Pack, clouds, away, and welcome day, With night we banish sorrow; Sweet air blow soft, mount lark aloft To give my Love good-morrow1! Wings from the wind to please her mind Notes from the lark I’ll borrow; Bird prune thy wing, nightingale sing, To give my Love good-morrow; To give my Love good-morrow Notes from them all I’ll borrow. Wake from thy nest, Robin-red-breast, Sing birds in every furrow; And from each bill, let music shrill Give my fair Love good-morrow! Blackbird and thrush in every bush, Stare2, linnet, and, cock-sparrow, You pretty elves, amongst yourselves Sing my fair Love good-morrow! To give my Love good-morrow Sing birds in every furrow! 译文 戴镏龄 译 云，散开吧，迎接白天， 夜尽了，驱走忧伤； 朝气轻吹，云雀升起， 给我爱早安送上！ 我要借云雀的歌声， 趁风娱她的心肠； 鸟儿整翅，流莺请啭， 给我爱早安送上！ 要借大家的歌声， 给我爱早安送上。 知更鸟从巢里醒起， 田沟上鸟语响亮； 每张鸟喙鸣声清新， 给我爱早安送上！ 枝头的乌鸦和画眉， 八哥、红鸟、麻雀郎， 可爱的小精灵们，大家 给我爱早安送上！ 田沟上鸟语响亮， 给我爱早安送上。 我的感想 这次又可以说很多东西了。这首诗倒是很欢快，但是看到《鲁克丽丝受辱记》这个来源，就觉得哪里不太对劲。 托马斯·海伍德 海伍德是一位著名的英国剧作家、演员和文学家。他的主要贡献是在伊丽莎白一世晚期和詹姆斯一世时期的剧院里上演的剧本。他最知名的作品是一部家庭悲剧，《被善意所杀的女人》（A Woman Killed with Kindness），这部悲剧最初上演于1603年。他是一位多产的作家，据说创作了220部戏剧，不过现在只有一小部分留下来了。很可惜，The Rape of Lucrece 在维基百科上并没有词条。[1] 《鲁克丽丝受辱记》 总之据说是根据莎士比亚的作品改编的。我找到了一个似乎是古代拼写的版本[2]，不过没有分场和幕，非常难看。随后我又在Internet Archive上找到了现代拼写的版本[3]，还有一部分介绍。至于这个剧本的全部内容，我觉得可以开一篇新文章了。（现在还没写完，如果写完了会补上）简单来说，它的剧情和莎士比亚的《鲁克丽丝受辱记》基本类似，但是扩展了很多额外的情节；剧本以塞克斯图斯（即塔昆，不过此剧本中称他为Sextus，所以姑且换个称呼）和布鲁图斯在决斗中双双被杀结束。 这首诗选自第四幕第六场，此时塞克斯图斯刚刚从柯拉廷城堡中仓皇逃出，次日清早，众人在阿狄亚城前时，柯拉廷唱起了这首歌。听起来实在是太过讽刺了。大概是强调了一种悲剧的氛围吧。 参考文献 [1] Thomas Heywood. https://en.wikipedia.org/wiki/Thomas_Heywood [2] The rape of Lucrece a true Roman tragedie. https://quod.lib.umich.edu/e/eebo/A03244.0001.001/1:3?rgn=div1;view=fulltext [3] Thomas Heywood. https://archive.org/details/heywood00heywiala 脚注 1good-morrow: ‘good morning.’（早上好。） 2Stare: ‘starling,’ which is a diminutive of the former.（“stare”是对椋鸟的爱称。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"},{"name":"T.Heywood","slug":"T-Heywood","permalink":"https://zhanghuimeng.github.io/tags/T-Heywood/"}]},{"title":"《英诗金库》I-51：Cupid and Campaspe, by J. Lyly","slug":"2018-05-05-《英诗金库》I-51：Cupid-and-Campaspe-by-J-Lyly","date":"2018-05-05T01:04:30.000Z","updated":"2018-05-05T01:04:30.000Z","comments":true,"path":"post/cupid-and-campaspe-by-j-lyly/","link":"","permalink":"https://zhanghuimeng.github.io/post/cupid-and-campaspe-by-j-lyly/","excerpt":"","text":"作品基本信息 作品名称：Cupid and Campaspe（爱神和康帕丝） 作者：John Lyly（约翰·黎里） 出版年代：1584 编注：黎里（John Lyly，1554?-1806），英国文艺复兴时代的剧作家，他第一个用散文体代替诗体创作喜剧。本诗选自喜剧《康帕丝》第三幕第五场，诗中形象而活泼地描绘了美和爱的魅力，这种魅力甚至支配了爱神。 作品原文 Cupid and my Campaspe play’d At cards for kisses; Cupid paid: He stakes his quiver, bow, and arrows, His mother’s doves, and team of sparrows; Loses them too; then down he throws The coral of his lip, the rose Growing on’s1 cheek (but none knows how); With these, the crystal2 of his brow, And then the dimple of his chin; All these did my Campaspe win: At last he set3 her both his eyes— She won, and Cupid blind did rise. O Love! has she done this to thee? What shall, alas! become of me? 译文 戴镏龄 译 爱神和康帕丝斗牌4 赌接吻，爱神被击败； 他又赌箭筒，弓和矢， 母亲的麻雀和鸽子；5 输了，摔下嘴唇珊瑚， 两颊上的玫瑰花株， 泛起的那无名面红； 加上眉宇晶亮玲珑， 还有下巴上的酒涡， 通通被康帕丝赢走。 最后，他拿两眼去赌， 又输了，他变成矇瞽6， 爱神，她待你是这样？ 哎，什么是我的下场？ 我的感想 这首诗可聊的东西又非常的多而庞杂，只能慢慢说了，看来要花去今晚的不少时间。（虽然明天还有重要的事情，但是先娱乐一下再说……） 约翰·黎里其人 约翰·黎里[1]现在似乎不是很有名了（而且这首诗在网上也没有什么人讨论），不过可以从维基百科看出，他是个当时很重要的剧作家和作家，而且风格还被命名了，叫做“绮丽体”（euphuism）。这听起来就很浮夸了，是人们通常会轻视的风格类型。不过，看了维基之后，我发现，他这么写是意有所指的。（不过这部分来自剧本的维基，之后再说） 生平实在是懒得（或者说没时间）翻译了。粗粗看了几眼，发现了一点有趣的东西。 After he left Oxford, where he had the reputation of “a noted wit”, Lyly seems to have attached himself to Lord Burghley. “This noble man”, he writes in the Glasse for Europe, in the second part of Euphues (1580), “I found so ready being but a straunger to do me good, that neyther I ought to forget him, neyther cease to pray for him, that as he hath the wisdom of Nestor, so he may have the age, that having the policies of Ulysses he may have his honor, worthy to lyve long, by whom so many lyve in quiet, and not unworthy to be advaunced by whose care so many have been preferred.” 黎里在此处狂热地赞美了伯利勋爵（Lord Burghley）。实际上，他就是威廉·塞西尔，之前提到过的维尔的抚养者兼岳父。之后黎里似乎还和维尔闹了一点别扭。这可真是非常有趣了。 后来，总之，黎里的剧本对莎士比亚的剧作，特别是浪漫喜剧，起到了很大的影响。 康帕丝 传说中，康帕丝是亚历山大大帝的情妇。古代被认为最杰出的画家阿培里兹（Apelles）为她画像。老普林尼在《自然史》中声称，接下来发生了这样的事情：亚历山大看到了肖像惊人的美丽，意识到画家比他更能欣赏康帕丝的美丽，也更爱她；于是便留下肖像，却将康帕丝让给阿培里兹。当然，这整件事基本都是传说。后来康帕丝成为了文学作品中情妇的代名词。[2] 我对这个故事的看法是：嗯，除了又一次感慨老普林尼的不靠谱之外，我觉得亚历山大和阿培里兹都没怎么尊重康帕丝，不过这样就又转到女权话题了。当然，这个故事提出了一个哲学问题：创作者的地位是否一定高于欣赏者？或者不如先问，这个故事中的画家到底能不能算是一位创作者？他能够画出康帕丝惊人的美，是因为他的技艺高超，因为他深爱绘画的对象，还是因为康帕丝本人太美了，而他的画只是反映出了这一特质？这种描摹者和被描摹对象的关系是否是正常的？唉，在这些问题中，康帕丝都是完全的客体，与一株漂亮的植物无异，真是令人感到不适。 《康帕丝》的剧情 这部剧本没有太多逻辑和剧情可言（据说是这样的），它的可取之处主要在于华丽的语言。总之，发生了这样的事：除了上面的传说之外，亚历山大还和第欧根尼、柏拉图、亚里士多德等哲学家探讨了许多问题。不过，至少康帕丝不再是完全的植物了：她也爱上了阿培里兹。亚历山大成全了他们，然后继续征战去了。 黎里在《康帕丝》中没有进行任何道德或伦理说教——因而突破了早期戏剧的“道德剧”（morality play）传统。和他之后的大部分剧作也不同的是，《康帕丝》也避开了讽喻。事实上，《康帕丝》是一个纯粹地为娱乐而讲述的浪漫历史故事。黎里对中世纪思维模式的这种背离为之后的（且更好的）作家提供了一种新的模板。这部剧本被称为当时的“第一部浪漫戏剧”。[3] 分析 我只在雅虎问答[4]上找到了一篇普通的分析，大意和这首诗的编注相同： 爱神为了赢得康帕丝的吻，甚至愿意失去自己身上神性的部分 连爱神都会屈服于爱的魅力，我这种凡人当然对爱更无能为力了 英国贵族女性一直都很喜欢打牌 我倒是觉得，说“连爱神都会屈服于爱的魅力”这种话，虽然和神话是符合的，却不太符合逻辑：爱神本身是“爱”的人格化，那堕入爱情的爱神算是什么呢？对此，我的看法是，爱神代表了一种更加理性、更加神圣的爱，而他屈服于的这种“爱”是感性的痴迷和疯狂。（这听起来像是《会饮》里的分析了，什么有两个爱神之类的。）当然也可以说，把爱神作为主角之一只是为了强调爱情的魅力极其的大。 实际上，我从欢快活泼的表象中看到了疯狂、恐怖和残忍。疯狂上面已经说过了。至于恐怖……丢掉眼睛难道还不算恐怖吗？至少在我的想象中，这是令人惧怕的。最糟糕的是，康帕丝要这些东西做什么呢？爱神身上所有美的部分，甚至包括眼睛……如果她是需要小美人鱼声音的邪恶巫婆，那这倒是可以理解；但她已经非常美丽了，拿走这些，似乎只是为了在赌博中证明自己的美，是一种纯粹的残忍。或者说，诗人内心中认为女性都是这样残忍的，她们会玩弄别人的感情而不自知。 这些分析大概太阴暗了。事实上，之所以会有这种想法，是因为这首诗让我想起了王尔德的《快乐王子》。王子失去了他的眼睛、剑柄和身上覆盖的金叶子，但那是为了帮助穷人；康帕丝是为了什么呢？但是，即使快乐王子的行为更合理，这个童话仍然让我感到非常不适。我想了很久，但是仍然不知道该如何表达，不妨先算了吧，已经快凌晨三点了。 参考文献 [1] John Lyly. https://en.wikipedia.org/wiki/John_Lyly [2] Campaspe. https://en.wikipedia.org/wiki/Campaspe [3] Campaspe (play). https://en.wikipedia.org/wiki/Campaspe_(play) [4] Can anyone tell me some literary critiques of this poem. https://au.answers.yahoo.com/question/index?qid=20071110080625AARalD8&amp;guccounter=1# 脚注 1on’s: ‘on his.’ 2crystal: ‘transparent clearness.’（透明清澈。） 3set: ‘staked.’（赌上） 4爱神指维纳斯之子丘比特（Cupid）；康帕丝（Campaspe，又译作坎巴斯帕）传说是古希腊亚历山大皇帝的爱妃，以美貌著称。——译者 5麻雀和鸽子等是献给维纳斯的鸟，为她拉车，此外，还有燕子和天鹅。——译者 6矇瞽（méng gǔ），盲人。","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"},{"name":"J.Lyly","slug":"J-Lyly","permalink":"https://zhanghuimeng.github.io/tags/J-Lyly/"}]},{"title":"《英诗金库》I-50：Tell me where is fancy bred, by W. Shakespeare","slug":"2018-05-04-《英诗金库》I-50：Tell-me-where-is-fancy-bred-by-W-Shakespeare","date":"2018-05-04T00:30:39.000Z","updated":"2018-05-04T00:30:39.000Z","comments":true,"path":"post/tell-me-where-is-fancy-bred-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/tell-me-where-is-fancy-bred-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Madrigal（情歌） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1596 编注：此诗选自《威尼斯商人》第三幕第二场。标题《情歌》系原编者所加。 作品原文 Tell me where is Fancy1 bred, Or in the heart, or in the head? How begot, how nourishèd? Reply, reply. It is engender’d in the eyes, With gazing fed; and Fancy dies2 In the cradle where it lies: Let us all ring Fancy’s knell; I’ll begin it, –Ding, dong, bell. –Ding, dong, bell. 译文 朱生豪 译 告诉我爱情生长在何方？ 还是在脑海？还是在心房？ 它怎样发生？它怎样成长？ 回答我，回答我。 爱情的火在眼睛里点亮， 凝视是爱情生活的滋养， 它的摇篮便是它的坟堂。 让我们把爱的丧钟鸣响。 玎珰！玎珰！ 玎珰！玎珰！ 我的感想 本来看了这首诗之后没有什么感想，只是觉得“Ding, dong, bell”听起来很像Full Fathom Five里面的丧钟。不过其实这首诗要欢乐得多。 …… 因为我发现了一首这首诗的非常棒的改编歌曲！（至少是我觉得很棒啦……）就是Matthew Harris[1]的改编版本。在youtube上有一个国立台湾大学的演唱版本[2]，我认为非常棒。网易云音乐上也有一个版本[3]，虽然没有那么好听，不过胜在方便，所以我现在正在单循着这首歌。 背景简介我就直接摘录别人的说法了。 本曲出自於《威尼斯商人》(The Merchant of Venice)，第三幕之第二景，是莎劇中涉及音樂較多的一齣戲劇。女主角波西亞(Portia)繼承了父親的龐大的遺產，追求者絡繹不絕；波西亞的父親臨終前規定求婚者必須從三個分別由金、銀、鉛製成的盒子中，挑出一個內藏波西亞畫像的，才能與她成婚。 這日，波西亞的意中人巴薩尼歐(Bassanio)前來求婚，但礙於家規，波西亞不能向巴薩尼歐吐露箱內實情，心中焦躁可想而知，便讓家僕哼起這首《告訴我愛情來自何方》作為答案的暗示。 歌詞中的fancy意指對華美外表的迷戀，暗示巴薩尼歐勿以貌取物，因為美麗的事物總是倏忽而逝。在金、銀、鉛三個盒子中，只有鉛盒最為樸實無華；此外前三行的末字的尾韻分別為bred[εd]、head[εd]、nourished[εd]，和鉛(lead)一字不謀而合！聰明的巴薩尼歐自能領會其弦外之音，毫不猶豫的選擇了鉛盒，抱得美人歸。[4] 先说说我直接的感想吧。我觉得，合唱和轮唱为这首歌添上了一种神圣而欢乐的氛围。听了这首歌，我才想到，鲍西亚让仆人唱起这首歌时，内心应该是充满着急切和爱情的甜蜜的。“Reply, Reply”就像是对巴萨尼奥的急切的提示：我对你的爱情已经在我的眼中点亮了，请你切勿以貌取物，选中错误的盒子，辜负我的一片苦心。这听起来固然很美，可是却带上了一丝嘲讽：你们两人之间的爱情也就是这么迅速点亮起来的啊（不管是在脑海还是心房，都是通过眼睛，这点没什么问题）。我想鲍西亚自己也明白这一点，“让我们把爱的丧钟鸣响”。然而，这么一想，即使她知道爱情是如此易变的，仍然愿意勇敢地投身其中。 ……以上全部都是脑补。稍微翻了翻剧本，鲍西亚和巴萨尼奥两人确实是一见钟情的。不过我想，他们是因为性情投合，三观合拍而迅速相恋的（而不是看脸），至少为他们我就不用担心了。但是我觉得这首歌仍然是带有一点忧郁的。即使看的是个人品质，那仍然是通过眼睛的啊，有可能会看错的。 不妨在此翻译一个更严肃的分析。 就像很多其他的莎士比亚的诗歌那样，这首歌在表面上是浪漫迷人的，潜台词却是苦涩而反讽的。此处“fancy”一词意为“爱”，却在“take a fancy”（喜欢上，爱上）的意义中暗示着肤浅的爱慕和痴心。这首歌提出了一个哲学问题：爱情（fancy）到底从何而来？爱情到底是感性的（“在脑海”）还是理性的（“在心房”）？这首歌对此的回答是：爱情来源于眼睛——既不是脑海也不是心房。然而，爱情也会在那里消亡。“lie”一词具有双重含义，暗示着，爱情既居住在它的“摇篮”（研究）里，又是具有欺骗性的，因为这样的爱情是基于外在的美貌，而非内心的品质的。这首歌又进一步扩展了问题：当人们相爱，爱情是如何维持下去的呢？歌中对此的回应不多，但它确实对浪漫爱情短暂的性质进行了评价，声称“它的摇篮便是它的坟堂”。“丧钟”一词特指了葬礼时鸣响的钟声，表示有人死去了。在这里，被哀悼的人是人格化的爱情；丧钟为爱情的“死亡”而敲响。[5] 参考文献 [1] Matthew Harris. http://matthewharrismusic.com/news.html [2] Tell Me Where is Fancy Bred (Matthew Harris) - National Taiwan University Chorus. https://www.youtube.com/watch?v=lQ59JqWP2aU [3] Shakespeare Songs: Tell Me Where Is Fancy Bred. https://music.163.com/#/song?id=538751916 [4] Tell Me Where is Fancy Bred《告訴我愛情來自何方》. http://blog.xuite.net/kiki79426/wretch/104895822-Tell+Me+Where+is+Fancy+Bred《告訴我愛情來自何方》 [5] Tell Me Where is Fancy Bred. http://shakesongs.com/tell-me-where-is-fancy-bred/ 脚注 1Fancy: ‘love.’ 2Fancy dies, etc.: love, which is born in the eyes, may die there before coming to maturity; which means no more than that the eyes can show the birth and speedy death of love.（爱情生于眼中，也可能会在成熟之前在眼中消亡；意思是说，除了眼睛，没有什么东西能够更深刻地反映出爱情的发生和迅速的消亡。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-49：No longer mourn for me when I am dead, by W. Shakespeare","slug":"2018-05-03-《英诗金库》I-49：No-longer-mourn-for-me-when-I-am-dead-by-W-Shakespeare","date":"2018-05-03T02:14:17.000Z","updated":"2018-05-03T02:14:17.000Z","comments":true,"path":"post/no-longer-mourn-for-me-when-i-am-dead-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/no-longer-mourn-for-me-when-i-am-dead-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：The Triumph of Death（死的胜利） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎士比亚十四行诗第七一首。 作品原文 No longer mourn for me when I am dead Than you shall hear1 the surly sullen bell Give warning to the world, that I am fled From this vile world, with vilest worms to dwell; Nay, if you read this line, remember not The hand that writ it; for I love you so, That I in your sweet thoughts would be forgot If thinking on me then should make you woe2. O if, I say, you look upon this verse When I perhaps compounded3 am with clay, Do not so much as my poor name rehearse, But let your love even with my life decay; Lest the wise world4 should look into your moan, And mock you with me after I am gone. 译文 梁宗岱 译 我死去的时候别再为我悲哀， 当你听见那沉重凄惨的葬钟 普告给全世界说我已经离开 这龌龊世界去伴最龌龊的虫： 不呀，当你读起这诗，别再记起 那写它的手；因为我爱到这样， 宁愿被遗忘在你甜蜜的心里， 如果想起我会使你不胜哀伤。 如果呀，我说，如果你看见这诗， 那时候或许我已经化作泥土， 连我这可怜的名字也别提起， 但愿你的爱与我的生命同腐。 免得这聪明世界猜透你的心， 在我死去之后把你也当作笑柄。 我的感想 我还是挺喜欢这首诗的。在youtube上有一个BBC出的朗诵视频[1]，感觉挺不错的。而且还有很多其他的视频，似乎这首诗的人气还不错。 到底要不要感慨这首诗中的深情呢？这样的深情到底是真实的还是一种写作技巧呢？在读了好多莎士比亚的诗之后，我开始起了这样的怀疑。不过似乎大部分人[2]还是认为，Fair Youth系列的诗表露的是一种真实的感情，是自传式的诗歌。 即使这样安慰了自己，我心里仍然对莎士比亚起了一层隔膜，因为我开始逐渐意识到，我很难用他的诗歌来表达自己的感情，或者说，无法和我自己的感受完全对位起来；因为这是只有莎士比亚才能写出来的诗。 O! none, unless this miracle have might, That in black ink my love may still shine bright. …Sonnet 65. 他的生命、爱情和诗歌（还有剧作，嗯）是紧密地结合在一起的，这之间碰撞出了奇妙的结果，也许值得大书特书地来分析一番。他到底如何看待自己的爱情？为何要把自己的爱人写在诗中？是为了奉承、为了感动、为了记录，还是为了永恒？……我不知道。 关于这首诗的一点更正式的分析是这样的。第71-74首诗通常被分为一组，它们反映了诗人对自己有限的生命的思考。在和他的爱友的关系中，诗人年龄更大，而且他相信自己会更早去世，因此他写下这首诗用来安慰他的朋友。在读过这么多关于时间能摧毁一切的十四行诗之后，我们发现，很显然，莎士比亚深受关于失去和死亡的忧郁情绪的困扰。在其他的很多诗中，诗人在他的爱友身上找到了安慰，他是诗人心灵和情感的救赎者。但是即便如此，诗人仍然无法摆脱死亡带来的悲哀之感。这首诗中表现出的无助（“with vilest worms to dwell”）似乎暗示着，诗人在写这首诗的时候的信心是很缺乏的。而且，最后两行显示了诗人对他和这位理想化了的年轻人之间关系的不安和焦虑，因为他害怕他们的朋友会嘲笑他的爱人对他的怀念。这似乎暗示着这位年轻人缺乏良好的判断力。[3] 读了这个分析之后，我对这首诗的好感增加了。之前我觉得最后两句是败笔，但这样分析一番，反倒觉得这两句反映了莎士比亚自己的恐惧和弱点。我之前只是觉得对“wise world”的注释很有趣。世界真的明智到了不会为逝去的东西伤心吗？我想，大部分人都是按照没有昨日，也没有死亡的方式每天忙忙碌碌的生活的。怀旧往往发生在人的情绪最脆弱的时候。 参考文献 [1] ‘No longer mourn for me when I am dead’ - Shakespeare’s Sonnet 71 | Doctors - BBC. https://www.youtube.com/watch?v=BybOQ3jl3yI [2] Are Shakespeare’s Sonnets Autobiographical? http://www.shakespeare-online.com/sonnets/sonnetsautobio.html [3] SONNET 71 Analysis. http://www.shakespeare-online.com/sonnets/71detail.html 脚注 1No longer … Than you shall hear: ‘only so long as you hear.’（到你听到……为止。） 2woe: ‘sorrowful.’ Its use as an adjective, though now obsolete, is common in Spenser.（“woe”此处意为悲伤的；该词作为形容词的用法常见于斯宾塞的作品，现在已经废弃了。） 3compounded: ‘united.’（融为一体。） 4wise world: too wise, that is, to grieve over what is gone.（太聪明了，以至于不会为逝去的东西而伤心。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-48：If thou survive my well-contented day, by W. Shakespeare","slug":"2018-05-02-《英诗金库》I-48：If-thou-survive-my-well-contented-day-by-W-Shakespeare","date":"2018-05-02T02:06:10.000Z","updated":"2018-05-02T02:06:10.000Z","comments":true,"path":"post/if-thou-survive-my-well-contented-day-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/if-thou-survive-my-well-contented-day-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Post Mortem（死后） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第三二首。诗人希望他的爱友保存他的诗，因为他的诗充满了真实的感情。 作品原文 If thou survive my well-contented1 day When that churl2 Death my bones with dust shall cover, And shalt by fortune once more re-survey These poor rude lines of thy deceased lover3; Compare them with the bettering of the time, And though they be outstripp’d by every pen, Reserve them4 for my love, not for their rhyme5 Exceeded by the height of happier men. O then vouchsafe me but this loving thought— 'Had my friend’s muse grown with this growing age, A dearer birth than this his love had brought To march in ranks of better equipage6: But since he died, and poets better prove, Theirs for their styles I’ll read, his for his love.’ 译文 屠岸 译 如果我已经满足，让粗鄙的死 把黄土盖上我骨头，而你还健康， 并且，你偶尔又重新翻阅我的诗—— 你已故爱友的粗糙潦草的诗行， 请拿你当代更好的诗句来比较； 尽管每一句都胜过我的作品， 保存我的吧，为我的爱，论技巧—— 我不如更加幸福的人们高明。 呵，还望你多赐厚爱，这样想： “如果我朋友的诗才随时代发展， 他的爱一定会产生更好的诗章， 和更有诗才的行列同步向前： 但自从他一死，诗人们进步了以来， 我读别人的文笔，却读他的爱。” 我的感想 总之我很喜欢这首诗。我觉得它具有一种谦逊而自我怀疑的品质（写诗的人可是莎士比亚本人！），而且具有一种奇异的自限性的魔力。他的预言已经失效了。在这个他的爱友也已经逝去的时代里，人们打开他的诗，主要是读他的文笔，却不常读他的爱。可是这首诗使我发现，莎士比亚毕竟是一个真实的人，有着真挚的感情。 我真的很喜欢这首诗。 找到了一篇分析[1]。可以看看。 参考文献 [1] A Short Analysis of Shakespeare’s Sonnet 32: ‘If thou survive my well-contented day’. https://interestingliterature.com/2017/04/03/a-short-analysis-of-shakespeares-sonnet-32-if-thou-survive-my-well-contented-day/ 脚注 1well-contented: the epithet is transferred from the poet, who is quite content to die, to the day of his death.（这一修饰词指的是诗人自己，他满意于死亡了。） 2churl: a word used from early times as the opposite of noble or gentle. Death is no gentleman, for he is quite regardless of people’s feelings.（这个词在早些时候被用作贵族或绅士的反义词来使用。死神不是一位绅士，因为他几乎全不在意人们的感情。） 3lover: in the seventeenth century this word had not its present narrow meaning, but was applied to anyone who loved another.（在十七世纪，“lover”这个词的词义还没有现在这么狭隘，可以用于任何相爱的两个人。） 4Reserve them: ‘keep them in your possession.’（把它们留在你的身边。） 5rhyme: in the wide sense, ‘verses.’（泛指一切诗歌。） 6ranks of better equipage: ‘better equipped ranks,’ i.e. making a fairer show of poetic ability.（“在更好的队伍中”，即展示出更好的诗才。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"《英诗金库》I-47：Call for the robin redbreast and the wren, by J. Webster","slug":"2018-04-30-《英诗金库》I-47：Call-for-the-robin-redbreast-and-the-wren-by-J-Webster","date":"2018-04-30T01:22:30.000Z","updated":"2018-04-30T01:22:30.000Z","comments":true,"path":"post/call-for-the-robin-redbreast-and-the-wren-by-j-webster/","link":"","permalink":"https://zhanghuimeng.github.io/post/call-for-the-robin-redbreast-and-the-wren-by-j-webster/","excerpt":"","text":"作品基本信息 作品名称：A Land Dirge（考奈丽雅挽歌1） 作者：John Webster（约翰·韦伯斯特） 出版年代：1612 编注：约翰·韦伯斯特（John Webster，1580-1625）英国诗剧作家，著名作品有《白魔》和《马尔菲公爵夫人》，这两部都是悲剧，诗风峭拔，颇见功力，有人说他仅次于莎士比亚。 作品原文 Call for the robin-redbreast and the wren, Since o’ver shady groves they hover And with leaves and flowers do cover The friendless bodies of unburied men. Call unto his funeral dole2 The ant, the field-mouse, and the mole, To rear him hillocks that shall keep him warm Adn (when gay tombs are robb’d) sustain no harm; But keep the wolf far thence, that’s foe to men, For with his nails he’ll dig them3 up again. 译文 卞之琳 译 招唤知更雀和鹪鹩一齐来帮一手， 它们在树丛里跳去跳来， 唤来用树叶和花朵去掩盖 无亲无故的没有人掩埋的尸首。 唤来参加他的丧礼—— 野地的耗子、土拨鼠、蚂蚁， 给他翻上些土堆让他温暖， 逢陵墓盗挖的时候，不至于遭难； 要赶走豺狼，那是人类的仇敌， 它们会用爪子挖掘得一片狼藉。 我的感想 [1] 这次查找了很多的资料，感想也很繁复，所以还是分成几块来说好了。 韦伯斯特，《白魔》，以及《马尔菲公爵夫人》 不得不承认，在读到这首诗之前，我从未听说过韦伯斯特这个人（当然不是说韦伯斯特大辞典……但是没关系，现在就听说过了）。不过，他的剧作显然在国内不太知名，而他本人也没有什么戏剧性可言——或者不如说，由于他在当时不太知名，他的生命历程、生活经历乃至于生卒年月都已经湮没在历史长河中了。[1]保留下来的主要还是几部剧作。《白魔》（The White Devil）和《马尔菲公爵夫人》（The Dutchess of Malfi）被认为是十七世纪早期英语戏剧的杰作。 如果简单概括一下这两部作品的剧情，就会变成这样： 《马尔菲公爵夫人》：改编自意大利真实发生的故事；孀居的马尔菲夫人与管家秘密结婚并育有三子（此处韦伯斯特犯了一点错误，孩子的数量在剧中前后并不统一），此举激怒了公爵夫人的两个兄弟，他们残忍地杀害了公爵夫人和两个孩子，最终自己也面对复仇难逃一死，大家全都死光。 《白魔》：同样改编自意大利真实发生的故事；布拉凯诺公爵爱上了美丽的维多利亚，为了与她结婚，公爵设计杀死了自己的妻子和维多利亚的丈夫，因此遭到了公爵夫人的哥哥和爱慕者的复仇，最终大家全部死光。[2] ……说实话，这听起来挺无聊的。我知道韦伯斯特在分类上属于詹姆斯一世时期，而这个时期的戏剧又全是些充满暴力的复仇悲剧，所以这是时代特点。但这一整个时代都可以说是有点无聊了。复仇来，复仇去，最后剧中人物全部死光，好像为死而死一样。 《白魔》的剧情 这次我稍微认真读了一下《白魔》的故事情节，真是令人脑壳疼：一部分原因是看不惯意大利人名，另一部分原因就是，这个复仇故事真是相当的绕啊。几乎很难把全部有用的剧情简短地概括起来，因为剧本中每时每刻都不停地有人密谋和复仇。下面我尝试按照每一幕来概括一下。（参考了[3]）不过，理解了剧情的发展之后，就会觉得仿佛在看八卦一般，还是挺有意思的。 第一幕 第一场 剧本发生在罗马。洛多维科（Lodovico）子爵和他的两个朋友，安东内利（Antonelli）和卡斯帕罗（Gasparo）上场。安东内利和卡斯帕罗告诉洛多维科，他因为犯罪从意大利被流放了，而且他的贵族朋友们正在嘲笑他。卡斯帕罗说，洛多维科被流放是因为他在罗马谋杀了几个人；当洛多维科追问为何法官不直接处决他时，卡斯帕罗解释说，那是因为法庭想避免进一步的流血事件。洛多维科抱怨说，其他坏人逃脱了惩罚，比如正在和维多利亚（Vittoria）幽会的布拉凯诺（Brachiano）公爵。安东内利尝试安抚洛多维科，洛多维科却威胁要把他的敌人撕成碎片。洛多维科最后还是接受了现实，决定离开。在离开之前，他给了安东内利和卡斯帕罗一些钱，让他们继续帮助自己疏通。 第二幕 这一幕开始时出场的人物有布拉凯诺公爵，维多利亚的丈夫卡米罗（Camillo）和维多利亚的哥哥弗拉米尼奥（Flamineo）。维多利亚对布拉凯诺到达罗马表示欢迎，随后便和卡米罗退场。弗拉米尼奥告诉布拉凯诺，维多利亚已经爱上了布拉凯诺；她的女仆摩尔人赞可（Zanche）会在中间牵线。他同时指责女性会通过操纵男性的欲望来获得好处。当布拉凯诺询问卡米罗怎么办的时候，弗拉米尼奥声称卡米罗已经因为梅毒而不举了。听到卡米罗返回之后，弗拉米尼奥让布拉凯诺藏在衣橱里，这样弗拉米尼奥就可以欺骗卡米罗了。 卡米罗承认自己已经很久没有与维多利亚同寝过，而且他很怀疑布拉凯诺的动机，不想戴绿帽子。弗拉米尼奥挖苦地建议他把维多利亚锁起来。当卡米罗请求严肃的忠告时，弗拉米尼奥声称，女性在最自由的时候才是最贞洁的；而卡米罗的嫉妒心使得他无中生有了一些威胁。 维多利亚上场之后，弗拉米尼奥让卡米罗远远看着他说服自己的妹妹和卡米罗同寝。弗拉米尼奥首先小声和维多利亚嘲讽了卡米罗的性能力，随后在大声赞美卡米罗的同时小声向维多利亚诋毁他；最后他大声告诉维多利亚，她将与“一位大人”同寝；卡米罗以为这是说他，但实际上是在暗示布拉凯诺。维多利亚悄声问弗拉米尼奥如何摆脱卡米罗，于是弗拉米尼奥告诉卡米罗，维多利亚几乎已经准备好了，但他应该在今夜拒绝她，这样她在下一夜的欲望就会更加高涨。卡米罗感谢弗拉米尼奥的忠告，并且决定晚上把自己锁在房间里，于是便离开了。 TODO：因为最近在现实世界中需要为未来着想，所以需要发奋工作和学习，一段时间内都不会再添加更多的感想了，只会把诗摘录下来。 参考文献 [1] John Webster. https://en.wikipedia.org/wiki/John_Webster [2] 情欲与复仇：英国詹姆斯一世时期悲剧. http://dushu.qq.com/read.html?bid=818831&amp;cid=5 [3] The White Devil Summary and Analysis. https://www.gradesaver.com/the-white-devil/study-guide/summary-act-1 脚注 1这首挽歌是韦伯斯特1612年发表的悲剧《白魔》中考奈丽雅（Cornelia）的歌词。查尔斯·兰姆在《英国戏剧诗人范例》一书中说：“我从未见过什么能比得上这首挽歌的，除了《风暴》里那首使斐迪南想起他父亲淹死的小曲。正如那首是关于水的，轻盈似水；这首是关于土的，泥土气重。两者都感觉那么强烈，似乎融进了所思考的原素。”——译者 2dole: 'lament, ’ from the Lat. dolor. 3them: the ‘men’ of the previous line.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"J.Webster","slug":"J-Webster","permalink":"https://zhanghuimeng.github.io/tags/J-Webster/"},{"name":"卞之琳","slug":"卞之琳","permalink":"https://zhanghuimeng.github.io/tags/卞之琳/"}]},{"title":"OSTEP第29章总结：Lock-Based Concurrent Data Structures","slug":"2018-04-26-OSTEP第29章总结：Lock-Based-Concurrent-Data-Structures","date":"2018-04-26T15:10:37.000Z","updated":"2018-04-26T15:10:37.000Z","comments":true,"path":"post/ostep-ch-29-summary-lock-based-concurrent-data-structures/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-29-summary-lock-based-concurrent-data-structures/","excerpt":"","text":"本章主要介绍了如何以锁为基础，将常见的数据结构改造为线程安全的。 一种通用的解决方法 性能：缩放（scaling）问题 并发计数器 并发链表 并发队列 并发哈希表 最后强调了几点经验教训： 在控制流变化的时候不要忘记释放锁（见并发链表的错误实现） 提高并发性不等于提升性能（见交替上锁的链表） 在编写多线程应用时，正确性比效率更重要，需要避免过早优化（premature optimization） 一种通用的解决方法 很容易想到，使常见的数据结构线程安全的最简单的方法，就是在对该数据结构执行任何操作之前都上锁，执行完之后再释放锁。 以计数器为例。一个普通的计数器的实现如下： 12345678910111213141516171819typedef struct __counter_t &#123; int value;&#125; counter_t;void init(counter_t *c) &#123; c-&gt;value = 0;&#125;void increment(counter_t *c) &#123; c-&gt;value++;&#125;void decrement(counter_t *c) &#123; c-&gt;value--;&#125;int get(counter_t *c) &#123; return c-&gt;value;&#125; 直接在计数器上加入一个操作锁，此时程序如下： 12345678910111213141516171819202122232425262728typedef struct __counter_t &#123; int value; pthread_mutex_t lock;&#125; counter_t;void init(counter_t *c) &#123; c-&gt;value = 0; Pthread_mutex_init(&amp;c-&gt;lock, NULL);&#125;void increment(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); c-&gt;value++; Pthread_mutex_unlock(&amp;c-&gt;lock);&#125;void decrement(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); c-&gt;value--; Pthread_mutex_unlock(&amp;c-&gt;lock);&#125;int get(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); int rc = c-&gt;value; Pthread_mutex_unlock(&amp;c-&gt;lock); return rc;&#125; 这样的实现方法显然是简单且正确的。 性能：缩放（scaling）问题 上述简单粗暴的实现显然会降低并发性，因为有些操作完全是可以并行执行的（如多个get操作）。对于这一问题，给出一形式化的定义如下： 完全缩放（perfect scaling）：对于一个线程安全的数据结构，如果需要访问它的线程数量小于系统中处理器的数量，且满足多个线程并发访问该数据结构的运行时间不多于只有单个线程访问该数据结构时的运行时间，则称该数据结构是完全缩放的。 实验结果表明，上述实现方法完全做不到完全缩放，多线程并发访问的时间随线程数量而线性增加（在线程数&lt;CPU数的前提下）。这是符合逻辑的。 并发计数器 我个人认为精确的计数器实现是很难（或者说不可能？）做到完全缩放的，因为这些操作本身已经足够简单，很难再有并行优化的余地。书中给出了一种不精确的计数器的实现，称为“sloppy counter”。 这一计数器的基本思想如下： 每个CPU拥有一个本地计数器，除此之外，有一个全局计数器；每个计数器各有一个锁 当某个CPU上运行的线程需要执行increment操作时，获得本地计数器的锁，执行操作，并释放锁 当某个本地计数器的值达到阈值S时，则获得该计数器和全局计数器的锁，全局计数器+=本地计数器，本地计数器清零；释放锁 全局计数器中存放的是计数器的一个估计值，读取时需要先获得全局计数器的锁。可以通过获得全部锁来获得计数器当前的真实值，但这一操作显然是非缩放的 下面是一个S=5，4个线程的执行示例： 可以看出，S的值越小，该实现方法越类似于直接加锁的实现（当S=1时基本退化为直接加锁的实现）；S的值越大，该方法的缩放性越强，性能越好，但全局计数器的值就会偏离真实值更远。 下面给出一种简单的代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344typedef struct __counter_t &#123; int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // local count (per cpu) pthread_mutex_t llock[NUMCPUS]; // ... and locks int threshold; // update frequency&#125; counter_t;// init: record threshold, init locks, init values// of all local counts and global countvoid init(counter_t *c, int threshold) &#123; c-&gt;threshold = threshold; c-&gt;global = 0; pthread_mutex_init(&amp;c-&gt;glock, NULL); int i; for (i = 0; i &lt; NUMCPUS; i++) &#123; c-&gt;local[i] = 0; pthread_mutex_init(&amp;c-&gt;llock[i], NULL); &#125;&#125;// update: usually, just grab local lock and update local amount// once local count has risen by ’threshold’, grab global// lock and transfer local values to itvoid update(counter_t *c, int threadID, int amt) &#123; int cpu = threadID % NUMCPUS; pthread_mutex_lock(&amp;c-&gt;llock[cpu]); c-&gt;local[cpu] += amt; // assumes amt &gt; 0 if (c-&gt;local[cpu] &gt;= c-&gt;threshold) &#123; // transfer to global pthread_mutex_lock(&amp;c-&gt;glock); c-&gt;global += c-&gt;local[cpu]; pthread_mutex_unlock(&amp;c-&gt;glock); c-&gt;local[cpu] = 0; &#125; pthread_mutex_unlock(&amp;c-&gt;llock[cpu]);&#125;// get: just return global amount (which may not be perfect)int get(counter_t *c) &#123; pthread_mutex_lock(&amp;c-&gt;glock); int val = c-&gt;global; pthread_mutex_unlock(&amp;c-&gt;glock); return val; // only approximate!&#125; 并发链表 书中给出了一种错误的实现，在此不再摘录了。该错误的问题在于，如果获得锁之后未能成功进行相应操作，则直接返回，忘记释放锁了。我们可以从中得出如下教训： 不要扩大锁覆盖的范围，只覆盖关键区就可以了 安排好代码的执行顺序，对于有多个出口点的代码，最好将出口点汇总在一起，这样不容易忘记释放锁；在具体实现的时候，可以记录返回值，并配合goto语句 下面是正确的实现： 12345678910111213141516171819202122232425262728293031323334353637void List_Init(list_t *L) &#123; L-&gt;head = NULL; pthread_mutex_init(&amp;L-&gt;lock, NULL);&#125;void List_Insert(list_t *L, int key) &#123; // synchronization not needed node_t *new = malloc(sizeof(node_t)); if (new == NULL) &#123; // 这是原先出错的位置，现在已移出上锁区域 perror(\"malloc\"); return; &#125; new-&gt;key = key; // just lock critical section pthread_mutex_lock(&amp;L-&gt;lock); new-&gt;next = L-&gt;head; L-&gt;head = new; pthread_mutex_unlock(&amp;L-&gt;lock);&#125;int List_Lookup(list_t *L, int key) &#123; int rv = -1; pthread_mutex_lock(&amp;L-&gt;lock); node_t *curr = L-&gt;head; while (curr) &#123; if (curr-&gt;key == key) &#123; rv = 0; break; &#125; curr = curr-&gt;next; &#125; // 出口点集合 pthread_mutex_unlock(&amp;L-&gt;lock); return rv; // now both success and failure&#125; 链表的缩放性 显然上述实现并不具有完全缩放性。另一种想法是采用交替上锁（hand-over-hand locking）技术：为每个结点都初始化一个锁，需要访问结点时，则获取该结点对应的锁。这个想法虽然听起来很好，极大地增加了并发性，但在实际操作中效率很低，因为请求/释放锁的操作耗时太多。如果采取一种混合策略（如每n\\sqrt{n}n​个结点上一个锁），就可以在并发性和效率之间取得一种平衡。 并发队列 书中给出了一种比较巧妙的实现。一般来说，入队操作只会访问队头，出队操作只会访问队尾，因此可以对这两种操作分别建立一个锁，一个队头锁，一个队尾锁；在进行操作时分别上锁。 代码中的细节是，为了将两种操作分离开，在队列的头部增加了一个伪结点；所以出队的时候返回的是队头的下一个结点的值；然后删除队头，它原来的下一个结点成为队头，也成为伪结点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546typedef struct __node_t &#123; int value; struct __node_t *next;&#125; node_t;typedef struct __queue_t &#123; node_t *head; node_t *tail; pthread_mutex_t headLock; pthread_mutex_t tailLock;&#125; queue_t;void Queue_Init(queue_t *q) &#123; node_t *tmp = malloc(sizeof(node_t)); tmp-&gt;next = NULL; q-&gt;head = q-&gt;tail = tmp; pthread_mutex_init(&amp;q-&gt;headLock, NULL); pthread_mutex_init(&amp;q-&gt;tailLock, NULL);&#125;void Queue_Enqueue(queue_t *q, int value) &#123; node_t *tmp = malloc(sizeof(node_t)); assert(tmp != NULL); tmp-&gt;value = value; tmp-&gt;next = NULL; pthread_mutex_lock(&amp;q-&gt;tailLock); q-&gt;tail-&gt;next = tmp; q-&gt;tail = tmp; pthread_mutex_unlock(&amp;q-&gt;tailLock);&#125;int Queue_Dequeue(queue_t *q, int *value) &#123; pthread_mutex_lock(&amp;q-&gt;headLock); node_t *tmp = q-&gt;head; node_t *newHead = tmp-&gt;next; if (newHead == NULL) &#123; pthread_mutex_unlock(&amp;q-&gt;headLock); return -1; // queue was empty &#125; *value = newHead-&gt;value; q-&gt;head = newHead; pthread_mutex_unlock(&amp;q-&gt;headLock); free(tmp); return 0;&#125; 并发哈希表 并发哈希表的实现借用了上述并发链表的实现，这一实现是比较简化的。由于不同的槽对应的链表的操作是可以并行的（相当于每个槽对应一个锁），因此这一实现的并发性是比较高的。 12345678910111213141516171819202122#define BUCKETS (101)typedef struct __hash_t &#123; list_t lists[BUCKETS];&#125; hash_t;void Hash_Init(hash_t *H) &#123; int i; for (i = 0; i &lt; BUCKETS; i++) &#123; List_Init(&amp;H-&gt;lists[i]); &#125;&#125;int Hash_Insert(hash_t *H, int key) &#123; int bucket = key % BUCKETS; return List_Insert(&amp;H-&gt;lists[bucket], key);&#125;int Hash_Lookup(hash_t *H, int key) &#123; int bucket = key % BUCKETS; return List_Lookup(&amp;H-&gt;lists[bucket], key);&#125; 作业 没写。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"《英诗金库》I-46：Full Fathom Five, by W. Shakespeare","slug":"2018-04-26-《英诗金库》I-46：Full-Fathom-Five-by-W-Shakespeare","date":"2018-04-26T01:10:09.000Z","updated":"2018-06-17T14:08:00.000Z","comments":true,"path":"post/full-fathom-five-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/full-fathom-five-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：A Sea Dirge（海的挽歌） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1612 编注：此诗选自《暴风雨》第一幕第二场。标题《海的挽歌》系原编者所加。 作品原文 Full fathom five thy father lies: Of his bones are coral made; Those are pearls that were his eyes: Nothing of him that doth fade1 But doth2 suffer a sea-change Into something rich and strange. Sea-nymphs hourly ring his knell: Hark! now I hear them, — Ding, dong, bell. 译文 朱生豪 译 五寻的水深处躺着你的父亲， 他的骨骼已化成珊瑚； 他眼睛是耀眼的明珠； 他消失的全身没有一处不曾 受到海水神奇的变幻， 化成瑰宝，富丽而珍怪。 海的女神时时摇起她的丧钟， 叮！咚！ 听！我现在听到了叮咚的丧钟。 我的感想 这肯定是我最熟悉的一首莎士比亚的诗了，因为我总在听它的一首改曲（Méav的Full Fathom Five，来自专辑《Silver Sea》[1]），非常好听，我认为是我听过的著名诗歌改编的流行曲中的佼佼者。为什么这首歌给人的观感非常好是值得思考的。我觉得可能有以下几点： 歌词短小精悍。即使是一首普通的十四行诗，其信息量也超过很多流行歌曲了。如果直接全部唱成歌，会使人感到非常烦躁。 唱腔空灵好听，而且符合这首歌的内容特点。轮唱增强了这一特点。 配器简洁明快，而且在适当的时候衬托了气氛。 旋律写的好。其实大部分乐句都在重复同一个旋律（伴奏中最明亮的拨弦乐器更是几乎在一直重复那五个音），听过一遍之后就容易魔音入脑。 莎士比亚的歌词写得好。虽然这是一句废话，但这首歌真的很棒…… 好的，下面来讲讲我为什么觉得歌词写得特别棒。嗯，比如，每次有人要举头韵（alliteration）的例子，“Full Fathom Five”一般都会出现。这个短语后来干脆成了一个习语，指那些像诗中的父亲那样沉没于水中无法找回的东西。[2]（在现代潜水技术发明之前，五英寻的水太深了。）在这首诗中，头韵成功地唤起了我们的注意力。 接下来的中间部分的意象塑造得非常棒。父亲确实死去了（当然在剧情里其实并没有死，但是此处姑且把他看做是一个死亡的例子），可是这一死亡并非可怖的，而是为他带来了一场“sea-change”，使得他身上那些速朽的事物蜕变成了美丽而不朽的珍宝。这和上一首诗（Fidele）中的阴郁形成了鲜明的对比，为我们带来了死神可能具有的另一种面目。对于我们这些普通人来说，这大概算是一种安慰：死亡也许只是一场蜕变而已。但对于作者本人而言，这已经远不止是一种慰藉，因为他所写下的文字成真了。作者本人逝世之后，他的作品仍然被我们当做珍宝所传颂着，成为了人类最宝贵的精神遗产之一。或许，这也是作者生前对自己的一种期许吧。丧钟时时鸣响，但死亡带来的恐惧和哀伤已经逝去；留下来的只有这些美丽的诗句。（丧钟总会响起来的，比如2016年的莎士比亚逝世400周年的纪念活动……） 网上能找到一大片这首诗的翻译，大概是因为这首诗很棒，很有名，词汇并不艰深，而且并不太长所导致的。但是其中并没有特别亮眼的，因为原诗已经足够好读而且足够棒了，翻译至少需要达到和原文一样棒的水平才能抢眼。所以我只选了一个译成四言诗的版本。 海水荡漾，五浔乃翁。 珊瑚为躯，珍珠为眸。 沧海桑田，而今犹在。 化为异宝，绚丽多彩。 海之女神，鸣钟引魂。 叮咚叮咚，悠远缠绵。[3] 如果是作为这首诗唯一的翻译的话，我并不太赞许这种做法，主要原因有以下几点： 语言风格不相符。我觉得这首诗的原文并不太像中古英语（或者说把“thy”换成“your”，“doth”换成“does”就可以直接无缝对接现代英语了，当然这么讲并不专业……），没有必要译成诗经体的形式。 为了凑字，有些地方翻译得并不准确。比如，“sea change”并不直接等同于“沧海桑田”，原文中也没有讲过钟声“悠远缠绵”，这就属于译者的自由发挥了。 有些地方的语义不太正确。比如“五浔乃翁”一句，如果没有背景，很难想象这一句说的是“你的父亲在五英寻深的水底”。 但是作为一种尝试还是有点意思的。 “sea-change” 2018.06.17 UPD：今天居然在《计算机系统结构》这门课的课件里也见到了这个习语。 这里的“sea-change”指的是单处理器时代的消亡和并行结构的兴起。说实话，我现在对这个问题的体会并不是很深：本学期的《操作系统》面对的主要还是一个单处理器系统（uCore），虽然体会到了同步互斥问题的难度，不过这个问题是单处理器时代进行上下文切换的时候就已经存在的，很难说和多核结构有什么极大的关系。我打算今年暑假的时候去做一下MIT6.824的并行系统实验，大概会对这个问题有更深刻的理解。 参考文献 [1] Full Fathom Five. http://www.celticlyricscorner.net/meav/full.htm [2] Ariel’s Song. https://en.wikipedia.org/wiki/Ariel’s_Song [3] 单曲Full Fathom Five. https://music.163.com/#/song?id=20152470 脚注 1Nothing of him that doth fade, etc.: i.e. every perishable part of him is undergoing a change.（他身上每个速朽的部分都在经历变化。） 2But doth: ‘which does not.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-45：Fear no more the heat o' the sun, by W. Shakespeare","slug":"2018-04-25-《英诗金库》I-45：Fear-no-more-the-heat-o-the-sun-by-W-Shakespeare","date":"2018-04-25T00:58:01.000Z","updated":"2018-06-26T16:46:00.000Z","comments":true,"path":"post/fear-no-more-the-heat-o-the-sun-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/fear-no-more-the-heat-o-the-sun-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Fidele（斐苔尔） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗选自《辛白林》第四幕第二场。原诗共四节，原编者删去了最末一节并加标题《斐苔尔》。（但是我又擅自加上去了，因为我很喜欢最后一段。） 作品原文 Fear no more the heat o’ the sun Nor the furious winter’s rages; Thou thy worldly task hast done, Home art gone and ta’en thy wages: Golden1 lads and girls all must, As chimney-sweepers, come to dust. Fear no more the frown o’ the great, Thou art past the tyrant’s stroke; Care no more to clothe and eat; To thee the reed is as the oak2: The sceptre, learning, physic, must All follow this, and come to dust. Fear no more the lightning-flash Nor the all-dreaded thunder-stone3; Fear not slander, censure rash; Thou hast finish’d joy and moan: All lovers young, all lovers must Consign to thee4, and come to dust. No exorcisor harm thee! Nor no witchcraft charm thee! Ghost unlaid forbear thee! Nothing ill come near thee! Quiet consummation have, And renowned be thy grave! 译文 朱生豪 译 不用再怕骄阳晒蒸， 不用再怕寒风凛冽； 世间工作你已完成， 领了工资回家安息。 才子娇娃同归泉壤， 正象扫烟囱人一样。 不用再怕贵人嗔怒， 你已超脱暴君威力； 无须再为衣食忧虑， 芦苇橡树了无区别。 健儿身手，学士心灵， 帝王蝼蚁同化埃尘。 不用再怕闪电光亮， 不用再怕雷霆暴作； 何须畏惧谗人诽谤， 你已阅尽世间忧乐。 无限尘寰痴男怨女， 人天一别，埋愁黄土。 没有巫师把你惊动！ 没有符咒扰你魂魄！ 野鬼游魂远离坟冢！ 狐兔不来侵你骸骨！ 瞑目安眠，归于寂灭； 墓草长新，永留追忆！ 紫蓉 译 再也無需畏懼炙熱的太陽， 抑或盛怒冬日的嘶狂； 你已卸下塵世的重擔， 歸返家園，領得了報償。 黃金歲月的少年少女們， 一如掃煙囪者，終將化土化塵。 再也無需畏懼高位者的蹙眉， 你已安然遠離暴君的皮鞭， 再也無需擔憂衣食的短缺， 對你而言，橡樹無異於蘆葦。 王權、知識、醫學，終將入墳， 皆依循此路，而化土化塵。 再也無需畏懼閃電的疾光， 抑或可怖雷石來自四面八方； 不再畏懼頻頻的責難與誹謗， 你已嚐盡了快樂，終結了悲傷。 年少的戀人，所有的戀人， 終將委身於你，而化土化塵。 巫術無法傷害你！ 魔咒無法施予你！ 逃逸的幽靈遠離你！ 邪惡無法靠近你！ 你已擁有寧靜的結局， 而尊譽降臨你的墓地！ （来自网友翻译[1]） 我的感想 《辛白林》这部剧本不太有名，大概是因为其中的故事过于芜杂，乱七八糟的，感觉像是《李尔王》、《奥赛罗》、《白雪公主》和《俄狄浦斯王》的混合体。维基上说，《辛白林》故事的取材的来源包括了拉斐尔·霍林斯赫德的《英格兰、苏格兰和爱尔兰编年史》和谢菲（Geoffrey of Monmouth ）的《不列颠诸王史》（Historia Regum Britanniae ），部分情节可能参考了薄迦丘的《十日谈》，极为普及的如白雪公主、灰姑娘等的欧洲童话和1589年的一个佚名作家的剧本《爱情和命运获胜传奇》。[2] 这可真是乱七八糟。所以我决定不把剧情全部贴出来了，因为这和这首诗的关系不大。 啊，我好喜欢这首诗啊，甚至想背下来。 我有时候也想，每天都在以一个很不专业的角度来读这些诗，到底是为了什么？没有人需要这些内容，甚至可能会误导其他人；我似乎也没有得到多少快乐（熬很多夜……）。但是在深夜读到这首诗之后，我觉得我被拯救了。那种直击心灵的感觉……可能这就是读很多诗的意义，在读不那么喜欢的诗的时候锻炼自己的欣赏水平，然后在读到这样的诗时，赶紧，抓住它。 好吧，废话似乎已经说得有点多了，还是分析一下这首诗吧。 背景资料还是需要一点的。简单来说，从唱这首歌的人的角度来看，发生的事是这样的：两个年轻人在一个洞穴中发现了一个落难的男孩，三人一见如故。但男孩因为旅途困顿很快死去，于是他们为这孩子唱了这首挽歌，并且用花朵覆盖在他的身上，将他埋葬。（实际发生的剧情请见维基百科）从这个角度来看，生命真是无常。 挽歌是唱给生者的，而不是死者的；至多可以说是唱给生者对死者的想象的。歌中既显示了死亡宁静的一面，又指出了死亡可怖的一面。宁静的一面大概来自理性的推测：显然，死者不会再像生者一样受到压迫和伤害，也不必再为衣食和功名来忙碌，他安息了。这是歌中前三段所讲的事情。有趣的是，我试图为每一段概括出一个“死亡为我们带来什么”主题，却发现这样很难概括出什么有逻辑的东西，每段中大概都讲了三件不同的事情，每句一件事。但是，如果进行平行比较，每段的结构大致是相同的。 第一段 第二段 第三段 主题1 自然的可怖 权力的压迫 自然的可怖 主题2 为生计奔忙 为生计奔忙 人言可畏 主题3 青春易逝 知识易逝 爱情易逝 这样可以重新横向概括为三个主题：威权的压迫、生活和社交的忙碌，以及美好的消逝。当然这些概括都不能说是非常全面准确的，只是一个说法而已。 可怖的一面则来自对死亡未知的恐惧。死者也许是去往另一个世界了，可是那个世界是生者完全无法了解的，甚至有可能比活着的世界还更加危险恐怖。最后一段就显示出了生者的这种恐惧：他们为死者可能遭受的痛苦而祈祷。这一段不由得让我想起《楚辞·招魂》： 魂兮归来！东方不可以讬些。 长人千仞，惟魂是索些。 十日代出，流金铄石些。 彼皆习之，魂往必释些。 归来兮！不可以讬些。 最后评价一下翻译吧。我从主观上对朱生豪的译文有两点不满意的： 原诗中不断重复的“come to dust”体现得不是很好。（并没有明确地译出来，而是融合在翻译中了。这一点不一定算是缺点，因为这可能并不符合中文诗的一般写作特点，但是我就想看到这种重复。） “无限尘寰痴男怨女，/人天一别，埋愁黄土。”一句有种琼瑶小说/《红楼梦》既视感。原文是“All lovers young, all lovers must/Consign to thee, and come to dust.”。不过，通过看注释可以发现，紫蓉这句话根本就是译错了，所以大概确实不好翻译吧。 其余部分都挺好的。可以看出，紫蓉的译文更“literal”（逐字翻译），但朱生豪的译文显得更自由一些。我无法评价两者的好坏，不过有一点我认为紫蓉处理得更好，就是最后部分中咒语（或者说祈祷？大概）的语气。我觉得“巫術無法傷害你！魔咒無法施予你！”比“没有巫师把你惊动！没有符咒扰你魂魄！”更符合原文的语气，不过，这当然也是我的个人看法了。 2018.6.26 UPD： 期末考试之前的某天晚上听歌的时候，偶然在Loreena Mckennitt的《The Visit》专辑中找到了这首歌的改编版[3]。我以前好像还算是个她的狂热粉丝呢，怎么对这种事情毫无印象。这首歌名为《Cymbeline》，大概我那个时候还对莎士比亚一无所知，所以也没有好好听吧。总之从某种意义上来说，很棒的一首歌。（不过就是中东气息多了点……？） 参考文献 [1] 莎劇《辛白林》︰葬禮之歌. http://blog.xuite.net/vistara/wretch/104151975-莎劇《辛白林》︰葬禮之歌 [2] 辛白林. https://zh.wikipedia.org/wiki/辛白林 [3] Cymbeline by Loreena Mckennitt. http://music.163.com/song?id=2923344&amp;userid=261028414 脚注 1Golden: ‘resembling gold, either in beauty or value.’ Cf. the Golden Age, the Golden Legend, the Golden Treasury, etc.（像金子一样美丽，或像金子一样贵重。参见黄金时代，黄金传奇，英诗金库。） 2the reed is as the oak: i.e. all earthly things, whether strong or weak, are equally unimportant.（所有地上的事物，无论强大还是弱小，都一样无足轻重。） 3thunder-stone: ‘thunderbolt.’（雷电。） 4Consign to thee: ‘seal the same contract with thee.’（和你签订相同的合约。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-44：Come away, come away, death, by W. Shakespeare","slug":"2018-04-24-《英诗金库》I-44：Come-away-come-away-death-by-W-Shakespeare","date":"2018-04-24T00:29:53.000Z","updated":"2018-04-24T00:29:53.000Z","comments":true,"path":"post/come-away-come-away-death-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/come-away-come-away-death-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Dirge of Love（爱的挽歌） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1600 编注：此诗选自《第十二夜》第二幕第四场。 作品原文 Come aray, come away, Death, And in sad cypres let me be laid; Flay away, fly away, breath; I am slain by a fair cruel maid. My shroud of white, stuck all with yew, O prepare it! My part of death, no one so true Did share it. Not a flower, not a flower sweet On my black1 coffin let there be strown; Not a friend, not a friend greet My poor corpse, where my bones shall be thrown: A thousand thousand sighs to save, Lay me, O where Sad true lover never find2 my grave, To weep there. 译文 朱生豪 译 过来吧，过来吧，死神！ 让我横陈在凄凉的柏棺3的中央； 飞去吧，飞去吧，浮生！ 我被害于一个狠心的美貌姑娘。 为我罩上白色的殓衾铺满紫衫； 没有一个真心的人为我而悲哀。 莫让一朵花儿甜柔， 撒上了我那黑色的、黑色的棺材； 没有一个朋友迓候 我尸身，不久我的骨骼将会散开。 免得多情的人们千万次的感伤， 请把我埋葬在无从凭吊的荒场。 紫蓉 译 快來吧，快來吧，死亡， 讓我臥於悲傷的柏樹棺木裡； 快走吧，快走吧，氣息； 我喪命於美麗狠心的少女手裡。 我白色的屍衣鋪滿了杉樹枝， 啊，備妥吧！ 無人如我這般真誠地 為愛而逝。 別讓一朵花，別讓一朵甜美的花 拋擲於我黝黑的棺木上； 別讓一位朋友，別讓一位朋友拜訪 我可悲的遺體，我遭棄的屍骨： 別虛擲千百個千百個嘆息， 將我掩埋，啊，讓悲傷 真心的戀人永不見我的墳， 於那兒哭泣！ （来自网友翻译[1]） 吴兴禄 译 無常爾來矣﹐置我於柩床。一息已云絕﹐殺我乃姣娘。 麻絰及紫杉﹐速備慎毋忘。無人愛我深﹐乃肯殉我亡。 竟無一好花﹐撒余靈柩旁。竟無一良朋﹐弔余埋骨場。 不須為余泣﹐葬余在遐荒。親友無覓處﹐免其徒哀傷。 （来自网友翻译[2]） 我的感想 说实话，将这些诗歌收录在这里，本意是想收集各种各样的英文诗翻译并且进行对比的，毕竟诗歌本身好找，翻译却没那么好找。又有谁真要听我这样一位业余爱好者对这些诗妄加的评论呢？今天竟然真的有了这样的机会，我却开始犹豫了，把这些不知名的译者（显然，并不是所有诗的不同翻译版本都是不知名的，只不过我找到的大概都是网友翻译的）的译文和朱生豪的翻译摆在一起真的好吗？还是我被这位翻译家的鼎鼎大名迷惑了心智，变得对其他人太过傲慢了？ 最后还是加了，虽然网名看起来有点尴尬。大不了再删除呗。 《第十二夜》的背景故事是人们所耳熟能详的了。故事主要叙述了几个相关人物的爱情故事。主要的剧情是：薇奥拉（Viola）和西巴斯辛（Sebastian）是孪生兄妹，两人长得很像，却在一次船难中分开了，两人都以为对方已经在船难中丧身。薇奥拉决定化妆成西萨里奥（Cesario），到伊利里亚（Illyria）当地的奥西诺公爵（Duke Orsino）的门下充当男仆。而当时奥西诺公爵疯狂地爱上了刚刚失去了哥哥的奥丽维娅伯爵小姐（Olivia）。已经爱上奥西诺的薇奥拉被公爵指派向奥丽维娅传达爱慕之意，但是被奥丽维娅拒绝了。奥丽维娅此时却又爱上了传口信的薇奥拉，当奥丽维娅向薇奥拉表达爱意时，薇奥拉明确地拒绝了。可是随后西巴斯辛出现，并巧遇奥丽维娅。奥丽维娅再次向西巴斯辛（她以为是薇奥拉）求爱，对奥丽维娅一见钟情的西巴斯辛立刻同意结婚，四个人最终相遇，才使得谜团解开，奥丽维娅与西巴斯辛结婚，而奥西诺也察觉到薇奥拉对自己的爱情，两人也最终结合。[3] 好吧，虽然我看过现代改编的电影《She’s the Man》，但其实我还没有细读这部喜剧，有时间会去读的。这首歌就来自《第十二夜》的第二幕第四场。此时，公爵正在追求奥丽维娅而不得，于是他召来奥丽维娅的弄人费斯特唱歌排解忧愁。公爵本人对这首歌是这么评价的：“啊，朋友！来，把我们昨夜听的那支歌儿再唱一遍。好好听着，西萨里奥。那是个古老而平凡的歌儿，是晒着太阳的纺线工人和织布工人以及无忧无虑的制花边的女郎们常唱的；歌里的话儿都是些平常不过的真理，搬弄着纯朴的古代的那种爱情的纯洁。”而费斯特唱完之后，对公爵这样说：“好，忧愁之神保佑着你！但愿裁缝用闪缎给你裁一身衫子，因为你的心就像猫眼石那样闪烁不定。”这两个人的话真是充满了讽刺。这首歌看似悲伤，唱的人和听的人却全没有认真对待的意思，而是把它看作是随意搬弄感情，而爱情本身也是飘忽不定的——不错，此时奥丽维娅已经疯狂地爱上了西萨里奥，可是随后又迅速地把西巴斯辛当成了替代品；公爵一边嘲讽着自己一边疯狂地追求奥丽维娅，可是之后又对与薇奥拉结合感到相当满意。 网上有一篇评论[4]详细地论述了这部剧本中死亡的形象。总之，就是死亡的阴影看似无处不在（海难、薇奥拉和西巴斯辛互相以为对方死了、奥丽维娅的哥哥，以及这首诗中为爱情要死要活的公爵），但实际上却没有什么威力（海难中死去的人没有多加描写，薇奥拉和西巴斯辛都活得好好的，奥丽维娅已经准备好投入新生活，公爵也迅速移情别恋）。这一点倒是很有趣。 似乎是时候比较一下翻译了。我冒昧地觉得，紫蓉的译文读起来更顺口，大概是因为押韵更多。吴兴禄的译文更有特点（五言诗，看起来很有乐府风格），值得赞赏，但似乎在某些地方与原义不相符合。比如“竟無一好花﹐撒余靈柩旁。竟無一良朋﹐弔余埋骨場。”这两句，我认为原义是自暴自弃，不希望美好的东西与自己的死亡产生联系；但此处却变成哀叹无人哀悼自己了。有趣的是，原诗中“My part of death, no one so true/Did share it.”一句，三种译文的理解均不同。朱生豪译作“没有一个真心的人为我而悲哀。”，将“share my part of death”解作“为我的死亡感到悲伤”之义。而紫蓉译为“無人如我這般真誠地/為愛而逝。”，认为此处的“share”是比较之意。而最后一种译法“無人愛我深﹐乃肯殉我亡。”在理解上最为直接，“share my part of death”即“与我同生共死”。究其原因，还是对“share”的程度理解不同。我觉得这三种说法各有道理，真是非常有趣。 参考文献 [1] 莎劇〈第十二夜〉︰Come away, death. http://blog.xuite.net/gardenofpoems/vistara/124303372-莎劇〈第十二夜〉︰Come+away%2C+death [2] Dirge of Love 愛之輓歌. http://blog.sina.com.cn/s/blog_3fc68e3b0100mj36.html [3] 第十二夜. https://zh.wikipedia.org/wiki/第十二夜 [4] Twelfth Night: Come away, come away, death. https://agoldoffish.wordpress.com/2010/08/16/twelfth-night-come-away-come-away-death/ 脚注 1black: i.e. covered with a black pall.（笼罩着黑云。） 2never find: this is subjunctive, = ‘may never find.’（虚拟语气。） 3此处“柏棺”原文为Cypress，自来注家均肯定应作Crape（丧礼用之黑色皱纱）解释；按字面解Cypress为一种杉柏之属，径译“柏棺”，在语调上似乎更为适当，故仍将错就错，据字臆译。——译者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-43：Madrigal, by W. Drummond","slug":"2018-04-22-《英诗金库》I-43：Madrigal-by-W-Drummond","date":"2018-04-22T23:56:33.000Z","updated":"2018-04-22T23:56:33.000Z","comments":true,"path":"post/madrigal-by-w-drummond/","link":"","permalink":"https://zhanghuimeng.github.io/post/madrigal-by-w-drummond/","excerpt":"","text":"作品基本信息 作品名称：Madrigal（小曲） 作者：William Drummond（威廉·德拉蒙德） 出版年代：1616 编注：无 作品原文 My thoughts hold mortal strife I do detest my life, And with lamenting cries, Peace to my soul to bring1, Oft call that prince which here doth monarchize2: — But he, grim grinning King, Who caitiffs scorns, and doth the blest3 surprise, Late having deck’d with beauty’s rose his tomb, Disdains to crop a weed and will not come. 译文 曹明伦 译 我的心进行着殊死的战争， 我实在憎恶我的生命， 为使我的灵魂得到安息， 我发出阵阵悲哀的呼声， 我时常呼唤那位君主，那位至高无上的死神： ——可他，冷酷狰狞的君王哟， 他鄙视懦夫弱汉，给人意外之幸运， 他只用美人的蔷薇去装点他的墓碑， 不屑为刈一株小草而屈尊光临。 我的感想 这又是一首德拉蒙德的诗了。之前曾经读过《Summons to Love》和《To His Lute》，感觉还是不错的。但这首诗实在是很丧了。据说这一类主题在英文诗中被称为Taedium vitae（weariness of life，厌世感）。如果用比较平实的语言把这首诗重新叙述一遍，那就变成了：“我真是活够了。我希望自己能够以某种有尊严的方式死掉。可是死神好像更愿意带走那些美好的人，而让我这一类没用的家伙继续苟活于世。”[1]真是够惨烈了，很符合当下很多像我一样的年轻人的感受。 翻看了一点德拉蒙德的作品[2]，里面有些十四行诗真是丧。但是，看了看维基百科中对他作品的评价[3]之后，又发现并不是他的所有作品都是这样的。 不如首先讲一下他的人生？但其实德拉蒙德的生平并没有什么显著的特点，没有极其重大的事件，只有一些普普通通的故事罢了。总之，他生于1585年，在爱丁堡大学获得了文学硕士学位，随后在布尔日和巴黎学习了两年法律。在1610年，德拉蒙德24岁时，他的父亲去世了，于是他成为了霍桑登的地主（laird of Hawthornden，这大概是一个爵位，可能是这么翻译吧……）此时他已经对文学展现出了浓厚的兴趣，特别是富有想象力的作品和当代的诗歌。 ……（剩下还有很多，懒得翻译维基了） 德拉蒙德最重要的作品是散文《Cypresse Grove》和其他诗歌。《Cypresse Grove》的主要内容是论述恐惧死亡是何等愚蠢，其中列举了非常多的例子，而且音乐性很强。德拉蒙德的诗中并没有显示出明显的苏格兰元素，他的灵感主要来自于英国和意大利诗人。很明显，他是斯宾塞的追随者，但在那些诉诸美感的句子中，仍然带有一丝忧郁的沉思——这种倾向因为他的初恋（Mary Cunningham）的早逝而加重了。德拉蒙德被称为“苏格兰的彼特拉克”，是当时的彼特拉克模仿者中的最高水平。 参考文献 [1] Madrigal. http://www.johnderbyshire.com/Readings/madrigal.html [2] Poet’s Corner, William Drummond of Hawthronden. http://www.theotherpages.org/poems/hawth01.html [3] William Drummond of Hawthornden. https://en.wikipedia.org/wiki/William_Drummond_of_Hawthornden 脚注 1to bring: ‘in order that I may bring.’（为了给我的灵魂带来安慰。） 2monarchize: the only entirely independent sovereign in the world is Death.（死神是世界上唯一一位完全独立的君主。） 3blest: ‘fortunate, happy.’（幸运的，快乐的。）","categories":[],"tags":[{"name":"W.Drummond","slug":"W-Drummond","permalink":"https://zhanghuimeng.github.io/tags/W-Drummond/"},{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"曹明伦","slug":"曹明伦","permalink":"https://zhanghuimeng.github.io/tags/曹明伦/"}]},{"title":"《英诗金库》I-42：Blow, blow, thou winter wind, by W. Shakespeare","slug":"2018-04-22-《英诗金库》I-42：Blow-blow-thou-winter-wind-by-W-Shakespeare","date":"2018-04-22T01:06:37.000Z","updated":"2018-04-22T01:06:37.000Z","comments":true,"path":"post/blow-blow-thou-winter-wind-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/blow-blow-thou-winter-wind-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Blow, blow, thou winter wind 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1599 编注：此诗选自《皆大欢喜》第二幕第七场，诗中将大自然的善与人类的恶进行了对照。 作品原文 Blow, blow, thou winter wind, Thou are not so unkind1 As man’s ingratitude; Thy tooth is not so keen Because thou art not seen, Although thy breath be rude. Heigh ho! sing heigh ho! unto the green holly: Most friendship is feigning, most loving mere folly: Then, heigh ho! the holly; This life is most jolly. Freeze, freeze, thou bitter sky, That dost not bite so nigh2 As benefits forgot: Though thou the waters warp3, Thy sting is not so sharp As friend remember’d not4. Heigh ho! sing heigh ho! unto the green holly: Most friendship is feigning, most loving mere folly: Then, heigh ho! the holly! This life is most jolly. 译文 朱生豪 译 不惧冬风凛冽， 风威远难遽5及 人世之寡情； 其为气也虽厉， 其牙尚非甚锐， 风体本无形。 噫嘻乎！且向冬青歌一曲： 友交皆虚妄，恩爱痴人逐。 噫嘻乎冬青！ 可乐惟此生。 不愁冱6天冰雪， 其寒尚难遽及 受施而忘恩； 风皱满池碧水， 利刺尚难比 捐旧之友人。 噫嘻乎！且向冬青歌一曲： 友交皆虚妄，恩爱痴人逐。 噫嘻乎冬青！ 可乐惟此生。 我的感想 我记得《皆大欢喜》中已经有两首诗被收录在英诗金库里了，包括《Under the Greenwood Tree》和《It Was a Lover and his Lass》。因此对这部作品的剧情已经比较熟悉了。这的确是一部音乐喜剧，有名的歌曲选段还有《What Shall He Have That Killed the Deer》[1]。 ……结果竟然想不出什么可说的了。不过，即使无视背景，这首诗也是相当容易理解的（甚至会觉得这一主题有些中国诗人也会写）。在相似的心境之下，读这首诗应该会有非常深刻的体会和同感，但平时看起来就太悲观了。 参考文献 [1] As You Like It. https://en.wikipedia.org/wiki/As_You_Like_It 脚注 1unkind: ‘unnatural.’（不自然的。） 2bite so nigh: ‘so deeply.’ 3warp: now meaning to bend, had originally the idea of changing or turning; the effect of the wind is to change the appearance of the water either by ruffling its surface or by freezing it.（“warp”现在的意思是扭曲，弯曲；它最初有改变和旋转的意思。风对水的影响是通过使水面波动或结冰而表现出来的。） 4friend remember’d not: ‘the forgetting of one friend by another.’（一位朋友忘掉了另一位。） 5遽（jù）：匆忙，急；惊慌。 6冱（hù）：冻，凝聚；闭塞。","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-41：If women could be fair and yet not fond, by E. Vere","slug":"2018-04-21-《英诗金库》I-41：If-women-could-be-fair-and-yet-not-fond-by-E-VERE","date":"2018-04-21T01:23:19.000Z","updated":"2018-04-21T01:23:19.000Z","comments":true,"path":"post/if-women-could-be-fair-and-yet-not-fond-by-e-vere/","link":"","permalink":"https://zhanghuimeng.github.io/post/if-women-could-be-fair-and-yet-not-fond-by-e-vere/","excerpt":"","text":"作品基本信息 作品名称：A Renunciation（死心断念） 作者：Edward Vere（爱德华·维尔） 出版年代：1812 编注：维尔（Edward Vere，1550-1604），英国贵族诗人，世袭牛津伯爵。 作品原文 If women could be fair, and yet not fond1, Or that2 their love were firm, not fickle still, I would not marvel that they make men bond3 By service long to purchase their good will; But when I see how frail those creatures are, I muse that men forget themselves so far. To mark the choice they make, and how they change, How oft from Phoebus they do flee to Pan; Unsettled still, like haggards4 wild they range, These gentle birds that fly from man to man; Who would not scorn and shake them from the fist5, And let them fly, fair fools, which way they list? Yet for disport6 we fawn and flatter both, To pass the time when nothing else can please, And train them to our lure7 with subtle oath, Till, weary of their wiles, ourselves we ease8; And then we say when we their fancy try9, To play with fools, O what a fool was I! 译文 戴镏龄 译 假如女人漂亮而不愚蠢， 或是爱情专一而又坚定， 毫不奇怪，这会使得男人 对她们效忠，买她们的心； 当我发见她们意志不坚， 我慨叹男人也行为失检。 她们选定对象，却又变更， 从漂亮张三，到丑怪李四；10 永远无常，野鹰一般飞腾， 是驯顺的鸟，却逢人追驰； 谁瞧得起她们，留在手上， 不让漂亮蠢货任意飘荡？ 为了取乐，我们奉承低头， 不妨消磨时间，趁此排遣， 并用诡誓引诱她们上钩， 到厌腻她们诡诈，给摔开； 试过她们的风情，我们说， 玩弄傻货，自己何等傻货！ 我的感想 这首诗本身没有什么可圈可点的地方。物化和贬低女性这个就不说了。似乎这首诗和上一首《The Unfaithful Shepherdess》，都是出自威廉·伯德的乐谱集中的歌词，不过这一首来自《Psalmes, Sonets and Songs》[1]，当时也属于作者不明的那一类。同样地，我也在网上找到了这首歌的一个演唱版本[2]，并不难听，不过录制得不好。 一位名为Steven May的研究者认为这首诗可能是维尔所作的[3]。看起来编著者似乎认同了这种观点。这位第十七代牛津伯爵倒是一个很有趣的人。他来自一个古老的家庭，父亲早逝，随后伊丽莎白一世成为了他的监护人，并将他安排在威廉·塞西尔（William Cecil）家中居住。他后来娶了塞西尔的女儿安妮，生了五个孩子，却在拒绝承认第一个孩子是他的之后与她分居五年。维尔是一个出色的马术家，曾经在意大利和法国四处旅行。他是在伊丽莎白的宫廷中最开始撰写情诗的人之一，并因其剧作受到赞誉，虽然他的剧本没有流传到现在。由于维尔对文学、宗教、音乐和医学方面的作品的慷慨赞助，有许多作品是题献给他的。他也赞助了很多剧团、音乐家、杂技演员和动物。 在1580年左右，维尔使得女王的一位宫女（Maid of honour）Anne Vavasour怀孕，这导致他被驱逐出宫廷，也导致了他的随从与Vavasour的叔叔之间激烈的街头斗殴。在1583年，维尔回到了女王身边，但已经失去了晋升的机会。在1586年，女王给予维尔一笔1000英镑的年费，用来缓解他的铺张浪费和将能带来收入的土地为快钱而卖掉而导致的财务危机。在他的妻子去世后，他娶了Elizabeth Trentham，并生下了唯一的儿子，亨利·德·维尔。他于1604年去世，此时他已经挥霍掉了大部分继承的地产。[4] 总的来说，这是一位有一定个人魅力和才华，但是缺乏节制，挥霍无度的人。不过，最有趣的还是，有种理论认为，他才是莎士比亚作品的真实作者——他们认为，莎士比亚这个人确实是存在的，但他的教育背景和生活经历与作品并不匹配，因此作者另有其人。这一理论几乎没有任何历史证据的支持，而是通过阴谋论来构建的，大部分严肃的研究者并不认同此说；但大众对于这一理论的兴趣持续高涨。[5]我没有更深入地去了解这一理论，不过听上去脑洞还真是不小。 参考文献 [1] Psalmes, Sonets and Songs (Byrd, William). http://cn.imslp.org/wiki/Psalmes,_Sonets_and_Songs_(Byrd,\\_William) [2] William Byrd - If Women Could Be Fair. https://www.youtube.com/watch?v=gjCHiiyGodc [3] Woman’s Changeableness. https://en.wikisource.org/wiki/Woman’s_Changeableness [4] Edward de Vere, 17th Earl of Oxford. https://en.wikipedia.org/wiki/Edward_de_Vere,_17th_Earl_of_Oxford [5] Oxfordian theory of Shakespeare authorship. https://en.wikipedia.org/wiki/Oxfordian_theory_of_Shakespeare_authorship 脚注 1fond: ‘foolish.’ 2Or that: ‘if that’ is often found for ‘if’. If the subordinate sentence contains two clauses, the second is often introduced by ‘that’ alone.（“if that”经常被用于代替“if”。如果同时有两个if从句，第二个从句通常只由“that”引导，省略“if”。） 3bond: ‘whether we be bond or free.’（无论我们是被奴役还是自由。） 4haggards ‘whild hawks.’（野鹰。） 5from the fist: where the hawk was carried in the mediaeval sport of hawking.（在中世纪的鹰猎活动中，鹰是站在拳头上的。） 6disport: ‘sport.’（运动。） 7lure: another hawking metaphor; a lure was a bunch of feathers used to recall the bird to the falconer.（另一个与鹰猎相关的隐喻：诱饵是一捆羽毛，用来将鹰召回到鹰猎者的身边。） 8ourselves we ease: ‘we relieve ourselves of them.’（我们摆脱了她们。） 9when we their fancy try: ‘when we make trial of their love.’（当我们试验她们的爱时。） 10此行原诗分别用希腊神话中的太阳神（Phoebus）和潘神（Pan）比喻美男子和相貌丑陋的男人。——译者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"},{"name":"E. Vere","slug":"E-Vere","permalink":"https://zhanghuimeng.github.io/tags/E-Vere/"}]},{"title":"《英诗金库》I-40：The Unfaithful Shepherdess, by Anonymous","slug":"2018-04-20-《英诗金库》I-40：The-Unfaithful-Shepherdess-by-Anonymous","date":"2018-04-20T01:02:44.000Z","updated":"2018-04-20T01:02:44.000Z","comments":true,"path":"post/the-unfaithful-shepherdess-by-anonymous/","link":"","permalink":"https://zhanghuimeng.github.io/post/the-unfaithful-shepherdess-by-anonymous/","excerpt":"","text":"作品基本信息 作品名称：The Unfaithful Shepherdess（不忠实的牧羊女） 作者：Anonymous（无名氏）（由威廉·伯德收录在乐谱《Songs of Sundry Natures》中） 出版年代：1589 编注：无 作品原文 While that the sun with his beams hot Scorchèd the fruits in vale and mountain, Philon the shepherd, late forgot1, Sitting beside a crystal fountain, In shadow of a green oak tree Upon his pipe this song play’d he: Adieu Love, adieu Love, untrue Love, Untrue Love, untrue Love, adieu Love; Your mind is light, soon lost for new love. So long as I was in your sight I was your heart, your soul, and treasure; And evermore you sobb’d and sigh’d Burning in flags beyond all measure: —Three days endured your love to me, And it was lost in other three! Adieu Love, adieu Love, untrue Love, Untrue Love, untrue Love, adieu Love; Your mind is light, soon lost for new love. Another Shepherd you did see To whom your heart was soon enchainèd; Full soon your love was leapt from me, Full soon my place he had obtainèd. Soon came a third, your love to win, And we were out and he was in. Adieu Love, adieu Love, untrue Love, Untrue Love, untrue Love, adieu Love; Your mind is light, soon lost for new love. Sure you have made me passing glad2 That you your mind so soon removèd, Before that I the leisure had To choose you for my best belovèd: For all your love was past and done Two days before it was begun: — Adieu Love, adieu Love, untrue Love, Untrue Love, untrue Love, adieu Love; Your mind is light, soon lost for new love. 译文 曹明伦 译 太阳炽烤着幽谷和山岗， 使果实枯萎，草木焦黄， 新近失恋的牧羊人菲朗， 坐在一条清彻晶莹的溪旁， 在一颗橡树的阴影之中， 他吹出的笛声婉转悠扬： 告别了，姑娘，不忠实的姑娘； 你的心儿是那样轻飘， 新欢使你倾刻将旧情淡忘。 当我在你身边的那些时光， 我是你的爱人、灵魂和宝藏， 你常常是这样叹息、泣诉， 你的情焰曾发射过度的光芒： 可你对我的爱情只延续了三天， 另外三天爱情的火焰就死亡！ 告别了，姑娘，不忠实的姑娘； 你的心儿是那样轻飘， 新欢使你倾刻将旧情淡忘。 你看见了另一位牧羊少年， 你的心儿立刻把他迷上， 你的爱情倏然离我而去， 他代替我做了你的情郎。 很快第三位少年赢得了你的爱。 你俩双双而去，把我们丢在一旁。 告别了，姑娘，不忠实的姑娘， 你的心儿是那样轻飘， 新欢使你倾刻将旧情淡忘。 你的确使我心花怒放， 高兴你这么快就改弦易张， 当我还来不及有空暇考虑 选择你做我未来的新娘： 尽管你三天前才开始的爱情 现在已飘然而去，不知何方：—— 告别了，姑娘，不忠实的姑娘， 你的心儿是那样轻飘， 新欢使你倾刻将旧情淡忘。 我的感想 这首诗的内容是很好懂的。有一位负心薄幸的牧羊姑娘，她不断地爱上又抛弃着牧羊人们，诗中的主角菲朗就是其中之一。在被抛弃后，他吹着笛子（然而笛子是不能边吹边唱歌的，不妨认为他吹一段唱一段好了）唱出了这首歌谣。在悲伤中带着一丝诙谐轻松，不失为一首有趣的诗。 很容易注意到，这首诗的音乐性很强，比如每节结尾处重复的aab/bba结构。事实上这首诗来自威廉·伯德（William Byrd）[1]的乐谱集《Songs of Sundry Natures》，是其中第17首作品的歌词，这首歌是四声部合唱的。[2]但是我并没有查找到关于这首歌词是如何被采编到其中的资料，可能这是一首伊丽莎白一世时期比较有名的诗/民歌吧。伯德的维基百科中讲到了这部作品的特点，但似乎没有特别说到这首歌词，所以似乎也没有什么好讲的了。 其他的一些作曲家也改编过这首诗，包括罗杰·奎尔特（Roger Quilter）[3]。我找到了一份奎尔特的改编版本的演唱[4]，虽然很歌剧风格，但是里面有一些段落（特别是副歌）出乎意料的好听，如果改编一下的话，大概会更符合现代人的口味，变得流行起来。虽然这可能就违背原作者的意图了。 参考文献 [1] William Byrd. https://en.wikipedia.org/wiki/William_Byrd [2] Songs of Sundry Natures (Byrd, William). http://cn.imslp.org/wiki/Songs_of_Sundry_Natures_(Byrd%2C_William) [3] While that the sun with his beams hot. http://www.lieder.net/lieder/get_text.html?TextId=1334 [4] The Faithless Shepherdess by Roger Quilter - Lauren Lutz (New Recording). https://www.youtube.com/watch?v=0grI9cG_tNM 脚注 1late forgot: lately deserted by his mistress.（最近被他的情人抛弃了。） 2passing glad: ‘surpassingly glad.’（极其高兴。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"曹明伦","slug":"曹明伦","permalink":"https://zhanghuimeng.github.io/tags/曹明伦/"}]},{"title":"《英诗金库》I-39：O me! what eyes hath Love put in my head, by W. Shakespeare","slug":"2018-04-19-《英诗金库》I-39：O-me-what-eyes-hath-Love-put-in-my-head-by-W-Shakespeare","date":"2018-04-19T01:15:09.000Z","updated":"2018-04-19T01:15:09.000Z","comments":true,"path":"post/o-me-what-eyes-hath-love-put-in-my-head-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/o-me-what-eyes-hath-love-put-in-my-head-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Blind Love（盲目的爱） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第一四八首。 作品原文 O me! what eyes hath love put in my head Which have no correspondence with true sight: Or if they have, where is my judgement fled That censures1 falsely what they see aright? If that be fair whereon my false eyes dote, What means the world to say it is not so? If it be not, then love doth well denote Love’s eye is not so true as all men’s: No, How can it? O how can love’s eye be true, That is so vex’d with watching and with tears? No marvel then though I mistake my view: The sun itself sees not till heaven clears. O cunning Love! with tears thou keep’st me blind, Lest eyes well-seeing thy foul faults should find! 译文 梁宗岱 译 唉，爱把什么眼睛装在我脑里， 使我完全认不清真正的景象？ 说认得清吧，理智又窜向哪里， 竟错判了眼睛所见到的真相？ 如果我眼睛所迷恋的真是美， 为何大家都异口同声不承认？ 若真不美呢，那就绝对无可讳， 爱情的眼睛不如一般人看得真： 当然喽，它怎能够，爱眼怎能够 看得真呢，它日夜都泪水汪汪？ 那么，我看不准又怎算得稀有？ 太阳也要等天晴才照得明亮。 狡猾的爱神！你用泪把我弄瞎， 只因怕明眼把你的丑恶揭发。 我的感想 那么还是来简单概述一下这首诗都在说什么吧。爱情使得作者的眼睛变得盲目，无法看清真实的景象。但是他又怀疑，可能眼睛其实能够看清真相，但是他的判断力出了问题。为什么他会怀疑自己心中的真相出了问题呢？那是因为，虽然他认为自己的爱人是美好的，可世人完全都不这样认为。那么，如果他看到的真的是假象的话，这就说明，爱情会使人变得盲目。但或许这也不是爱情的问题，问题还是在于这份爱的对象，她使得作者的感情总是十分激动，眼里总是含着泪水，所以可能既不是爱情出了问题，也不是眼睛出了问题，只是单纯因为眼睛被某些东西所困扰才无法认清事物。这很正常，就像太阳在阴天也无法照亮地面一样。所以，他把自己的痛苦全都归咎给了爱情：爱神让他爱上了一个糟糕的人，而爱情又使得他的判断力下降，无法看出爱人的丑恶之处。 开始时我读这首诗觉得很无聊，于是去查了更多资料，终于发现了它的趣味所在。看来很多诗还是要放在作者整本作品的整体思路下来看才更有意思，但这样阅读的话，我的精力恐怕就不是很够。虽然莎士比亚的十四行诗足够有名，但我今天才对它的整体结构稍微有了一些了解。 这154首诗大致可以分成三个部分： Fair Youth部分：第1-126首诗 The Dark Lady部分：第127-154首诗 The Rival Poet部分：第78-86首诗 这三个人在现实中分别是谁都不确定。[1]（说起来，之前的《夜莺》的作者就是The Rival Poet的可能人选之一）。 而这首诗（148）属于The Dark Lady部分中的一个小组（147-50），诗人在其中描述了他对这段爱情的看法：它是疯狂的、不理性的，他正试图解决自己的迷茫。这四首诗中充满了阴郁，可能是由于爱人的不忠，也可能暗指着放纵的性和性病（梅毒之类的）。[2]于是我去翻了翻剩下的三首诗，以及第151首，都非常的有趣。 147：这种疯狂的爱情像一场重病，欲望折磨着我，连理智都无法医治；她的外表很美丽，内心却漆黑得像地狱。[3] 149：你是多么的残忍，即使我为你付出了那么多，对你言听计从，可是你却是这样糟糕的人？但我仍然爱你，因为爱情使我瞎了。[4] 150：你真是个糟透了的人，但是你越糟糕，我就越爱你；我爱的东西全都是别人所憎恨的。[5] 151：我想上你。（这个表述不太严肃。不过这首诗中的确充满了性暗示，甚至被认为是“最淫秽的一首诗”。虽然可以用更文雅地词汇来谨慎地分析，但作者想表达的意思差不多就是这样。）[6] 总之，这首诗虽然看起来比较平常，但其实可能隐藏了很多性暗示也说不定。可惜我看不出来……有位给这首诗写了详细解析的作者这样说： Shakespeare is known to have some R rated things in his writings, so some of this may have R rated references, but I’m taking a more PG approach.[7] 好想知道这首诗里面哪些部分R级了耶！ 参考文献 [1] Shakespeare’s sonnets. https://en.wikipedia.org/wiki/Shakespeare’s_sonnets [2] Sonnet CXLVIII. http://www.shakespeares-sonnets.com/sonnet/148 [3] Sonnet 147. https://en.wikipedia.org/wiki/Sonnet_147 [4] Sonnet 149. https://en.wikipedia.org/wiki/Sonnet_149 [5] Sonnet 150. https://en.wikipedia.org/wiki/Sonnet_150 [6] Sonnet 151. https://en.wikipedia.org/wiki/Sonnet_151 [7] What is a deeper meaning of “Sonnet 148” by Shakespeare? https://www.quora.com/What-is-a-deeper-meaning-of-Sonnet-148-by-Shakespeare 脚注 1censures: ‘estimates’ —without the modern idea of blaming.（此处意为“估计”，没有现代“指责”的含义。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"OSTEP第28章总结：Locks","slug":"2018-04-18-OSTEP第28讲总结：Locks","date":"2018-04-18T16:51:47.000Z","updated":"2018-04-18T16:51:47.000Z","comments":true,"path":"post/ostep-ch-28-summary-locks/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-28-summary-locks/","excerpt":"","text":"本章主要介绍了锁的基础知识，以及各种锁的实现方法和评价标准： 硬件支持 关中断 TS指令实现自旋锁 CS指令实现自旋锁 LL/SC指令实现自旋锁 FA指令实现无饥饿的自旋锁 硬件和OS支持 从自旋锁到yield 使用队列和睡眠 Linux中的实际例子 两阶段锁 锁的基本定义和用法 锁是一个变量。在任意时刻，该变量中都存储着锁的状态： 可获得（或者说释放，开锁的，说明没有线程持有该锁） 不可获得（未被释放，上锁的，说明有一个线程持有该锁，很可能处于关键区内） 锁的使用方法： 12345lock_t mutex; // some globally-allocated lock &apos;mutex&apos;...lock(&amp;mutex);balance = balance + 1; // 关键区unlock(&amp;mutex); lock()的语义： 尝试获得锁 如果该锁未被获得，则获得该锁，进入关键区，该线程成为锁的拥有者 如果该锁已被获得，则在锁被释放之前始终阻塞，防止多个线程同时进入关键区 unlock()的语义： 释放线程当前持有的锁 如果还有其他线程在等待锁，则通知其中一个进程开始运行，获得锁，并进入关键区 锁能够帮助程序员更多地获得对线程的控制权。 锁的评价标准 基本要求：提供互斥访问功能 公平性：是否会出现线程饥饿的状况？ 性能：不同场景下的时间开销 单线程获取并释放锁 多线程请求同一个锁 多CPU上的多线程请求同一个锁 锁的实现方法 本章中给出了一种单纯用现有非特权指令（加载和存储）实现锁的方法，但是失败了。当然，其实这样是可以成功的（Dekker和Peterson算法），也做过一些研究，但是这些算法对硬件也有一些假设，而且人们已经发现，在硬件中提供一些支持会方便很多。所以就不赘述了。 用硬件原语实现锁 关中断 代码实现如下： 123456void lock() &#123; DisableInterrupts();&#125;void unlock() &#123; EnableInterrupts();&#125; 优点：简单 缺点： 需要线程执行特权指令，可能被滥用，OS无法得到控制权 不适用于多处理器系统 关中断太久可能导致重要的中断请求被丢失 效率低，因为现代CPU开关中断的速度比较慢 目前这一方法主要用于OS本身的原子性操作，因为这样就不存在滥用问题。 使用TS（Test-And-Set）指令实现自旋锁 TS指令原子地完成以下操作： 读出某个地址处的值 将新的值写入该地址 返回旧值 用代码表示如下： 12345int TestAndSet(int *old_ptr, int new) &#123; int old = *old_ptr; // fetch old value at old_ptr *old_ptr = new; // store &apos;new&apos; into old_ptr return old; // return the old value&#125; 可以利用TS指令实现自旋锁： 1234567891011121314151617typedef struct __lock_t &#123; int flag;&#125; lock_t;void init(lock_t *lock) &#123; // 0 indicates that lock is available, 1 that it is held lock-&gt;flag = 0;&#125;void lock(lock_t *lock) &#123; while (TestAndSet(&amp;lock-&gt;flag, 1) == 1) ; // spin-wait (do nothing)&#125;void unlock(lock_t *lock) &#123; lock-&gt;flag = 0;&#125; 工作原理是： flag变量表示锁是否被持有，0表示空闲 在lock()函数中，不断使用TS指令测试锁是否空闲，空闲则获得锁并将flag置为1；不空闲则自旋等待 在unlock()函数中，只需简单地将flag置为0 对自旋锁的评价 正确性：显然是正确的 公平性：无法保证，可能会导致饥饿 性能： 单CPU系统：性能很差 多CPU系统：还不错（如果线程的数量大致与CPU相等） 使用CS（Compare-And-Swap）指令实现自旋锁 CS指令原子地完成以下操作： 读出某个地址处的值 判断它是否与期望的值相等，如果相等，则更新该地址处的值为某给定的值 返回该地址处原有的值 用代码表示如下： 123456int CompareAndSwap(int *ptr, int expected, int new) &#123; int actual = *ptr; if (actual == expected) *ptr = new; return actual;&#125; 与TS指令类似，可以利用CS指令实现自旋锁（其他函数与TS指令的实现相同）： 1234void lock(lock_t *lock) &#123; while (CompareAndSwap(&amp;lock-&gt;flag, 0, 1) == 1) ; // spin&#125; 工作原理也类似。 用LL（Load-Linked）和SC（Store-Conditional）指令实现自旋锁 这两个指令是MIPS架构下提供的。LL指令类似于普通的加载指令，把某个值从内存中加载到寄存器中；但它会标记这个地址，SC指令更新该地址处的值时，仅在上次LL过后该值还没有被修改过时才会成功。 用代码描述如下： 123456789101112int LoadLinked(int *ptr) &#123; return *ptr;&#125;int StoreConditional(int *ptr, int value) &#123; if (no one has updated *ptr since the LoadLinked to this address) &#123; *ptr = value; return 1; // success! &#125; else &#123; return 0; // failed to update &#125;&#125; 锁的实现方法： 12345678910111213void lock(lock_t *lock) &#123; while (1) &#123; while (LoadLinked(&amp;lock-&gt;flag) == 1) ; // spin until it&apos;s zero if (StoreConditional(&amp;lock-&gt;flag, 1) == 1) return; // if set-it-to-1 was a success: all done // otherwise: try it all over again &#125;&#125;void unlock(lock_t *lock) &#123; lock-&gt;flag = 0;&#125; 如果两个线程同时在请求这个锁，则先执行SC指令的线程可以获得锁，另一个线程执行SC指令时就会返回0，需要重新进入请求状态。 用FA（Fetch-And-Add）指令实现标签锁（ticket lock） FA指令原子地完成以下任务： 读出某个地址处的值 将这个值+1 重新写回该地址处 返回原来的值 用代码描述如下： 12345int FetchAndAdd(int *ptr) &#123; int old = *ptr; *ptr = old + 1; return old;&#125; 用该指令可以实现一个思路稍有不同的锁： 12345678910111213141516171819typedef struct __lock_t &#123; int ticket; int turn;&#125; lock_t;void lock_init(lock_t *lock) &#123; lock-&gt;ticket = 0; lock-&gt;turn = 0;&#125;void lock(lock_t *lock) &#123; int myturn = FetchAndAdd(&amp;lock-&gt;ticket); while (lock-&gt;turn != myturn) ; // spin&#125;void unlock(lock_t *lock) &#123; lock-&gt;turn = lock-&gt;turn + 1;&#125; 其中，ticket变量表示曾经请求过锁的线程的个数，turn变量表示当前（应该）是第几个等待线程持有锁。lock()函数中，通过FA指令为本线程获得“排位”（myturn），并等待前面的线程执行完毕。unlock()函数中，只需简单地将turn变量+1（轮到下一个线程了）。 这个实现方法的优点是，不存在饥饿问题，请求同一个锁的线程按请求顺序获得锁。（但是这样会不会有死锁问题？？） 用硬件原语和OS的支持实现锁 直接把自旋改为yield 代码实现如下： 123456789101112void init() &#123; flag = 0;&#125;void lock() &#123; while (TestAndSet(&amp;flag, 1) == 1) yield(); // give up the CPU&#125;void unlock() &#123; flag = 0;&#125; 得不到锁的线程不再自旋，而是主动放弃控制权。虽然减少了自旋浪费的时间片，不过仍然耗费了一些切换上下文的时间。 利用队列和睡眠实现锁 现在改为由OS控制当前的锁被释放之后，哪一个线程能够获得锁。为此引入睡眠机制： park()系统调用：将调用线程睡眠 unpark(ThreadID)系统调用：唤醒某个进程 下面是一个使用队列、TS指令、yield、自旋和睡眠机制的代码实现： 1234567891011121314151617181920212223242526272829303132333435typedef struct __lock_t &#123; int flag; int guard; queue_t *q;&#125; lock_t;void lock_init(lock_t *m) &#123; m-&gt;flag = 0; m-&gt;guard = 0; queue_init(m-&gt;q);&#125;void lock(lock_t *m) &#123; while (TestAndSet(&amp;m-&gt;guard, 1) == 1) ; //acquire guard lock by spinning if (m-&gt;flag == 0) &#123; m-&gt;flag = 1; // lock is acquired m-&gt;guard = 0; &#125; else &#123; queue_add(m-&gt;q, gettid()); setpark(); // avoid wakeup/waiting race m-&gt;guard = 0; park(); &#125;&#125;void unlock(lock_t *m) &#123; while (TestAndSet(&amp;m-&gt;guard, 1) == 1) ; //acquire guard lock by spinning if (queue_empty(m-&gt;q)) m-&gt;flag = 0; // let go of lock; no one wants it else unpark(queue_remove(m-&gt;q)); // hold lock (for next thread!) m-&gt;guard = 0;&#125; 该锁的内部嵌套了一个用TS指令实现的自旋锁，对应的变量是guard，保护的关键区是对锁的内部状态的修改和更新过程。 lock()函数： 首先尝试进入关键区 如果能获得锁，则离开关键区 如果不能获得锁，则把自己加入队列中，离开关键区，然后放弃CPU（注意，如果先放弃CPU，则guard永远不会变成0，别的进程就无法获得和释放锁了） unlock()函数： 首先尝试进入关键区 如果等待队列为空，则直接放弃锁，并离开关键区 否则从队列中唤醒一个线程（注意，此时flag并不会被置为0，因为被唤醒的线程此时回到了park()执行完毕的地方，它已经离开了关键区，因此也不应该尝试把flag设为1；因此，我们直接把锁交给下一个线程，重甲不进行释放） 另一个可能存在的问题是，如果没有setpark()一句，且请求锁的线程在park()之前被打断，那么如果此时锁被释放了，重新被唤醒的请求线程会继续执行park()，并永远沉睡下去。setpark()可以解决这个问题：在调用它之后，如果线程在调用park()之前被打断，且其他的线程对它调用了unpark()，那么该线程随后对park()的调用会立即返回。 一个实际的锁的实现 这个实现利用了Linux中的两个函数： futex_wait(address, expected)：如果address处的值与expected相等，则睡眠，否则返回 futex_wake(address)：唤醒一个在该地址的队列中等待的线程 这个实现中，一个整数（mutex）用于跟踪锁是否被持有（最高位）和等待该锁的线程数（其他所有位）。所以，如果mutex为负数，则锁被持有。 1234567891011121314151617181920212223242526272829void mutex_lock (int *mutex) &#123; int v; /* Bit 31 was clear, we got the mutex (this is the fastpath) */ if (atomic_bit_test_set (mutex, 31) == 0) return; atomic_increment (mutex); while (1) &#123; if (atomic_bit_test_set (mutex, 31) == 0) &#123; atomic_decrement (mutex); return; &#125; /* We have to wait now. First make sure the futex value we are monitoring is truly negative (i.e. locked). */ v = *mutex; if (v &gt;= 0) continue; futex_wait (mutex, v); &#125;&#125;void mutex_unlock (int *mutex) &#123; /* Adding 0x80000000 to the counter results in 0 if and only if there are not other interested threads */ if (atomic_add_zero (mutex, 0x80000000)) return; /* There are other threads waiting for this mutex, wake one of them up. */ futex_wake (mutex);&#125; mutex_lock函数： 如果该锁空闲，则返回 否则等待线程数+1，并开始循环 在每次循环中，如果发现该锁空闲，则获得该锁（使用的是TS指令），等待线程数-1，并返回 如果发现该锁不空闲，在等待之前重新进行一次检查，如果发现锁空闲则继续循环；否则开始睡眠 mutex_unlock函数： 将最高位置0的同时检查是否有其他线程在等待，如果没有，则直接返回 如果有，则唤醒一个等待中的线程 其中，在尝试睡眠的过程中，futex_wait函数的特性保证了“wakeup/waiting race”不会发生：首先读出mutex处的值，确保此时锁不空闲；即使此时被打断，mutex处的值被修改，futex_wait也会因为两个值不相等而返回，不会永远进入睡眠状态。 两阶段锁 这个锁的原理是混合了自旋锁和队列睡眠机制。好像没有什么好说的。 作业 没有做。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"《英诗金库》I-38：My lute, be as thou wert when thou didst grow, by W. Drummond","slug":"2018-04-18-《英诗金库》I-38：My-lute-be-as-thou-wert-when-thou-didst-grow-by-W-Drummond","date":"2018-04-18T01:33:51.000Z","updated":"2018-04-18T01:33:51.000Z","comments":true,"path":"post/my-lute-be-as-thou-wert-when-thou-didst-grow-by-w-drummond/","link":"","permalink":"https://zhanghuimeng.github.io/post/my-lute-be-as-thou-wert-when-thou-didst-grow-by-w-drummond/","excerpt":"","text":"作品基本信息 作品名称：My lute, be as thou wert when thou didst grow 作者：William Drummond（威廉·德拉蒙德） 出版年代：1616 编注：无 作品原文 My lute, be as thou wert when thou didst grow With thy green mother in some shady grove, When immelodious winds but made thee move, And birds their ramage1 did to thee bestow. Since that dear Voice which did thy sounds approve, Which wont2 in such harmonious strains to flow, Is reft from Earth to tune those spheres above, What art thou but a harbinger of woe? Thy pleasing notes be pleasing notes no more, But orphans’ wailings to the fainting ear; Each stroke a sigh3, each sound draws forth a tear; For which be silent as in woods before: Or if that any hand to tough thee deign, Like widow’d turtle4 still5 her loss6 complain. 译文 李霁野 译 我的琵琶，还去到矮丛下面， 同你绿色母亲在原来地方， 那时噪声的风使你摇晃， 鸟儿将狂野的歌落在你的身边。 那亲爱的声音曾经将你的声调赞赏， 那声音一贯是和谐流利， 你除了传送哀愁，还能做什么呢， 现在它已经离开大地，到了天上？ 使人喜悦的音调已不再使人喜悦， 听力衰微的耳朵听来只是孤儿哀泣； 每一声响只使人流泪叹气； 因此象以前在林间一样保持沉默。 假如有人要用手抚摸你， 象失偶的鸽子，永远悲叹她逝去。 我的感想 这首诗讲述了一个悲伤的故事。作者曾经弹着这把琉特琴和一位女性（不好说是否是恋人或家人朋友）一起谈天。如今，这位女性已经去世，这把琴也就不再能给人带来喜悦，而是传递着怀念和悲伤。因此他不愿再弹奏这把琴了。 我最喜欢的是第一节的景物描写。虽然从诗中看来，这种从前的沉默在现在悲伤的境况下反而是较好的，但这一场景也充满着孤独与忧郁。或者说，这一忧郁是从现在场景回想的结果。尚未被制成琉特琴之前，周围的景象也是粗粝的，但树木是愚钝的，对此恐怕无所感受。变成了琴，它的音色变得优美，讲述着人的喜悦，可是这终究是有期限的，欢乐还是变成了哀愁。这隐喻了叙事者的感情和心理的变化过程。虽然希望回到不那么痛苦的过去，可是回不去了；以现在拥有的感情来看，过去的生活也不算美好，因为已经知道什么是快乐了。所以终究是回不去了。 参考文献 脚注 1ramage: ‘the sond of birds,’ from the French ramage, with th same meaning. 2wont, now used only as an adjective, was formerly the past tense of won, or wone, meaning to dwell, to be accustomed. 3Each stroke a sigh: ‘each touch of the strings a sigh.’ 4turtle: ‘turtledove.’ 5still: ‘continually.’ 6her loss: ‘the loss of her,’ i.e. the owner of the ‘dear Voice.’","categories":[],"tags":[{"name":"W.Drummond","slug":"W-Drummond","permalink":"https://zhanghuimeng.github.io/tags/W-Drummond/"},{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"李霁野","slug":"李霁野","permalink":"https://zhanghuimeng.github.io/tags/李霁野/"}]},{"title":"《操作系统》2018年期中考试总结","slug":"2018-04-17-《操作系统》2018年期中考试总结","date":"2018-04-17T11:03:30.000Z","updated":"2018-04-17T11:03:30.000Z","comments":true,"path":"post/os-mooc-2018-midterm-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-2018-midterm-summary/","excerpt":"","text":"考试题来自2018年春季学期操作系统课期中考试。 对错题 进程执行系统调用，从用户态切换到内核态执行时，将切换页表和栈。（×） 从用户态切换到内核态执行时并不切换页表。大概是因为直接使用了映射的内核空间。 进程切换的具体执行过程发生在内核态。（√） 显然uCore中确实是这么实现的。而且进程切换需要特权指令（如写CR3寄存器），因此必须在内核态下进行。 OS不能让运行在OS内核空间的内核线程和用户线程之间进行进程切换。（×） 事实上是可以的。Lab5中，就是在创建了用户进程之后，从内核线程切换到用户进程的。 OS在建立页表并使能页机制时，需要特权指令才能最终完成。（√） 对于X86和MIPS架构，使能页机制的指令都是特权指令。 如果用户态进程一直执行死循环将导致OS内核一直无法控制CPU。（×） 只要硬件提供了硬件中断的支持，OS就可以中断该用户态进程了。 二次机会（时钟）页面替换算法有Belady异常现象。（√） （从未听说过二次机会这个名字。）时钟算法和扩展的时钟算法都有Belady现象。反例来自Piazza。 因如果所有页的访问位都为1时，clock算法将退化为FIFO，可以构造如下序列 1a,b,c,d,a,b,e,a,b,c,d,e 当物理页帧为3时，缺页次数为9次，当物理页帧为4时，缺页次数为10次。 OS内核会直接杀死产生内存访问异常的用户进程。（×） 显然，内存访问异常有多种情况，权限错误，地址不合法，或者是缺页。访问越界这种情况确实会导致OS杀死进程（SEGMENTATION FAULT==），但缺页异常下肯定不是杀死这个进程，而是将缺的页换入，重新执行产生缺页异常的指令。 由于栈的原因，在OS内核中不能执行系统调用（syscall）来获得OS内核的服务。（×） 系统调用可以在同特权级下进行，此时不进行栈的切换。 对于子进程而言，fork()执行不成功后的返回值&lt;0。（√） 我觉得这道题的脑回路很奇异。按照一般的想法，父进程执行fork()之后，如果成功，则创建子进程，父进程处fork()的返回值为子进程的PID，子进程处fork()的返回值为0。如果父进程执行fork()不成功，则返回负值，此时也就没有子进程了。所以这道题不知如何选。 而老师解释说，这道题目说的是“fork出来的子进程再次进行fork的情况”。这就只不过是普通的fork()而已了。 如果不考虑执行性能，ucore on x86-32可实现LRU页替换算法。（√） 因为有人真的实现了，所以是对的。大致的思路是，强制每次页访问都触发一个页访问异常，利用这个页访问就可以知道究竟发生了什么样的访存操作，以及这些操作的先后次序。这样的方案能够得到准确的LRU信息。 填空题 小强同学认真上课听讲，参与讨论，并完成了从lab0~lab3的所有实验，在学习过程中，了解和学到了很多知识。下面是他的学习心得，请补充完整。 1 小强发现完成实验需要在Linux下操作很多命令行工具，于是他认真学习了lab0中的知识，了解到Linux中在命令行模式下可以通过执行命令（1.1）来显示当前目录的路径，如果我们编写的程序有语法错误，编译器（1.2）会报错，根据错误信息，我们可以修改我们的程序，可以通过硬件模拟器工具（1.3）来执行我们的ucore操作系统。 pwd gcc qemu (system i386) 这些都很简单，做了实验的人应该都会（虽然pwd其实很少用，因为prompt前面一般都会显示路径……） 2 在完成lab 1的过程中，通过分析硬件模拟器工具对CPU状态的输出信息，可了解到基于80386的计算机在加电后执行BIOS代码时处于（2.1）模式。而os lab 1中的bootloader通过建立（2.2）表可让计算机进入（2.3）模式，从而可以充分利用80386 CPU提供的保护能力和32位内存寻址空间。os lab 1中的ucore os为了能够对异常／中断等进行有效管理，需要建立（2.4）表，才能使能中断，让ucore os进行进一步的中断处理。在学习80386特权级时，对CPL、RPL和DPL需要满足如下两个公式确保系统安全：访问（2.5）时，CPL&lt;=DPL[门] &amp; CPL&gt;=DPL[段]；访问（2.6）时，MAX(CPL, RPL)&lt;=DPL。 8086模式/实模式 段表/GDT表/全局描述符表 保护模式 中断描述符表/IDT表 中断门 段 3 1.3在完成lab2的过程中，需要了解x86-32的内存大小与布局，页机制，页表结构等。硬件模拟器提供了128MB的内存，并设定页目录表的起始地址存放（3.1）寄存器中，页目录表和页表的地址按（3.2）字节对齐。在一个页目录表占用（3.3）个Byte，一个页表占用（3.4）个Byte。ucore 通过x86-32 CPU中的（3.5）寄存器可以获得发生页面访问错误时的线性地址。 CR3 4K 4K 4K CR2 4 在完成lab3的过程中，ucore操作系统在页机制基础上，并利用异常机制建立了虚存管理策略与机制。如果一个页（4KB/页）被置换到了硬盘某8个连续扇区（0.5KB/扇区），该页对应的页表项（PTE）的最低位——present（存在位）应该为（4.1），表示虚实地址映射关系不存在，而原来用来表示页帧号的高（4.2）位，恰好可以用来表示此页在硬盘上的起始扇区的位置（其从第几个扇区开始）。 0 20 5 在学习进程的概念中，了解到在支持多进程的操作系统（包括ucore)中，每个进程有两个堆栈，分别是（5.1）栈和（5.2）栈。操作系统通过建立（5.3）这个核心数据结构来支持对进程的管理。对于进程的三状态模型，是指进程在执行过程中会具有（5.4），（5.5），（5.6）三种状 态。在操作系统具有进程地址空间为单位的swap in/out虚存管理机制，可建立进程的五状态模型，将增加（5.7），（5.8）。 内核 用户 PCB/进程控制块 就绪态 运行态 等待态 就绪挂起态 就绪等待态 问答题 fork 在Linux环境下，下列程序调用magic函数的次数是多少？如果一个程序死循环调用fork()系统调用，会出现什么情况？请说明原因。 123456789#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;main()&#123; int i; for (i = 0; i &lt; 10; i++) fork(); magic();&#125; 如上图，最终会得到210=10242^10 = 1024210=1024个进程，即进行fork()系统调用1024次。 一个程序死循环调用fork()系统调用，则被称为“fork()炸弹”，因为进程会以指数级别增加。在实际的机器上尝试fork()炸弹的后果是：机器不会死机，但是无法创建新的程序了，因为进程控制块资源耗尽了。这不会导致失去对电脑控制权，仍然可以通过Ctrl+C终止程序。 用户线程 用户线程是指由一组用户线程管理库函数来完成线程的管理功能，包括线程的创建、终止、同步和调度等。假设处于仅通过用户线程管理库管理用户线程的操作系统环境，请回答下列问题： 操作系统内核是否需要知道用户线程的存在？请说明理由。 用户线程管理库实现的线程切换是否需要进入内核态，通过操作系统内核来完成？请说明理由。 用户态线程管理库是否可以随时打断用户态线程，完成线程调度与切换？请阐述理由或方法。 OS内核不需要知道用户库维护的线程的存在，如果它知道，也就没有用户线程的意义了，变成了内核线程。 线程切换不需要进入内核态，因为线程的页表是共享的，其他现场信息不需要特权指令来保存，所以可以在用户态切换。 能，因为OS可以通知线程管理库发生中断（发出软件中断）。也可以回答不能，因为在用户态不能实现中断。重点是自圆其说。 页表访问时间 在一个只有一级页表的请求页式存储管理系统中，假定页表内容如下表： 页号 页框（Page Frame）号 有效位（存在位） 0 123H 1 1 N/A 0 2 254H 1 页面大小为4KB，一次内存的访问时间是100ns，一次快表（TLB）的访问时间是10ns，处理一次缺页的平均时间为1e7ns（己经包含更新TLB和页表的时间），进程的驻留集大小固定为2，采用最近最少使用置换算法(LRU)和局部淘汰策略。假设： TLB初始为空； 地址转换时先访问TLB，若TLB没有命中，再访问页表（忽略访问页表之后的TLB更新时间）； 有效位为0表示页面不在内存，产生缺页中断，缺页中断处理后，返回到产生缺页中断的指令处重新执行。 设有虚地址访问序列2362H，1565H，25A5H，请问： 依次访问上述三个虚地址，各需要多少时间？给出计算过程？ 基于上述访问序列，虚地址1565H的物理地址是多少？请说明理由。 首先访问2362H，页号为2H，偏移量为362H。查找TLB未命中（10ns），查找页表得到页框号为254H（100ns），更新TLB（略），计算出物理地址为254362H，访存（100ns），总时间为210ns。 然后访问1565H，页号为1H，偏移量为565H。查找TLB未命中（10ns），查找页表发现缺页（100ns），根据LRU算法，将第0页换出，将第1页换入到页号为123H的物理页帧，更新TLB和页表（1e7ns），访存（100ns），总时间约为1e7ns。 最后访问25A5H，页号为2H，偏移量为5A5H。查找TLB命中（10ns），计算出物理地址为2545A5H，访存（100ns），总时间为110ns。 由于第1页现在位于页号为123H的物理页帧中，因此虚地址1565H的物理地址是123565H。 RISC-V页表 2017年图灵奖得主John L. Hennessy和David A. Patterson提出了RISC-V架构的32位小端序CPU设计，它有34位地址总线，使用32位页式存储管理。该计算机的页面大小为4KiB，一个页表大小为4KiB，其中每一个页表项(Page Table Entry，PTE)大小为4B，虚拟地址、物理地址和PTE的结构如下图所示。 如上图所示，一个虚拟地址由虚拟页号(Virtual Page Number，VPN)和页内偏移组成，物理地址由物理页号(Physical Page Number，PPN)和页内偏移组成，PTE由PPN和一些控制位组成，其中R/W/X三个域分别表示对应页的读/写/执行权限，它们的不同组合可以表示不同的属性，如下表所示： X W R Meaning 0 0 0 This PTE points to next level of page table. 0 0 1 Read-only page. 0 1 0 Reserved for future use. 0 1 1 Read-write page. 1 0 0 Execute-only page. 1 0 1 Read-execute page. 1 1 0 Reserved for future use. 1 1 1 Read-write-execute page. 请回答下列问题： 32-bit的RISC-V架构CPU使用34位物理地址而不是32位物理地址，这样做的好处是什么？ 设页目录基址为0x90000000，部分物理内存的内容如下图所示，试给出虚拟地址0x3A69A4D2和0x3A8EB00C所对应的物理地址和它们所在页的类型。请写出计算过程。 第一题的答案是显然的：34位物理地址可以寻址16G的内存，这显然是好的。 第二题就比较复杂了。首先计算出两个虚拟地址对应的各项。由于单个页表项的大小是4B，可以通过VPN[1]计算出页表项所在的地址为0x90000000+4*VPN[1]，并读出页表项（注意是小端存储）。 虚拟地址 VPN[1] VPN[0] offset PTE地址 PTE 0x3A69A4D2 0xE9 0x29A 0x4D2 0x900003A4 0x28000001 0x3A8EB00C 0xEA 0xEB 0x00C 0x900003A8 0x3EB0000F 可以发现，0x28000001的XWR=000，因此它是一个一级页表项，指向的是一个二级页表，它的基地址是0xA0000000。二级页表项的地址=0xA0000000+4*VPN[0]=0xA0000A68，读出二级页表项为0x37AB6C09，它指向一个可执行的页，页的基地址为0xDEADB000。物理地址=页基地址+偏移量=0xDEADB000+0x4D2=0xDEADB4D2。 而0x3EB0000F的XWR=111，也就是说，它指向一个可写可读可执行的页。不妨进行大胆的猜测：这个页的大小是4MB，虚拟地址中的VPN[0]和offset共同作为页内的偏移量；而页表项中的PPN[1]就是页基址的高12位。由此可得，页基址=0xFAC00000，物理地址=页基址+偏移量=0xFAC00000+0xEB00C=0xFACEB00C。 关于RISC-V内存管理的更多内容可以参见wiki或RISC-V的文档，不过我一时是懒得去读了。 总结 我觉得今年的题目比去年的难度更大，特别是最后一题，如果没有仔细阅读过硬件内存管理部分，很难想象到一级页表项管理的页是特殊的，大小为4MB。其余的部分都比较基础了。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《英诗金库》I-37：Love's Farewell, by D. Drayton","slug":"2018-04-17-《英诗金库》I-37：Love-s-Farewell-by-D-Drayton","date":"2018-04-17T01:15:24.000Z","updated":"2018-04-17T01:15:24.000Z","comments":true,"path":"post/love-s-farewell-by-d-drayton/","link":"","permalink":"https://zhanghuimeng.github.io/post/love-s-farewell-by-d-drayton/","excerpt":"","text":"作品基本信息 作品名称：Love’s Farewell（爱的告别） 作者：Michael Drayton（迈克尔·德雷顿） 出版年代：1593 编注：迈克尔·德雷顿（Michael Drayton，1563—1631），英国诗人。这首十四行诗系他1593年出版的诗集《意念，牧人之歌》第六一首。 作品原文 Since there’s no help, come let us kiss and part, — Nay I have done, you get no more of me; And I am glad, yea, glad with all my heart, That thus so cleanly1 I myself can free; Shake hands for ever, cancel all our vows, And when we meet at any time again, Be it not seen in either of our brows That we one jot of former love retain. Now at the last gasp of love’s latest breath, When, his pulse failing, passion speechless lies, When faith is kneeling, by his bed of death, And innocence is closing up his eyes, —Now if thou would’st, when all have given him over, From death to life thou might’st him yet recover! 译文 李霁野 译 既然没有办法了，让我们亲吻分离， 我为你做过的，你再也不能从我得去； 我欢喜，是呀，我满心欢喜， 我这样完全摆脱了自己。 握手永别，取消我们所有的誓言， 而且无论何时再见， 不要显在我们各自的眉间 我们保存了我们前恋的一星一点。 现在爱的临终呼吸发出最后喘息， 他的脉搏衰微，热情安卧无语， 信仰跪在他的死榻一隅， 无辜在将他的双眼合起，—— 假如你愿，在一切抛弃他的瞬间， 你仍然可以使他从死里生还！ 我的感想 德雷顿[1]这人还是很有名的（但请注意不要把他和约翰·德莱顿[2]搞混了）。读了读他的生平：德雷顿是一位英国诗人，大致生活在伊丽莎白一世到詹姆斯一世的时代。诗歌生涯大致可以分为三个阶段，其中第一阶段和第三阶段比较多产，且更贴近伊丽莎白一世时期著作的风格。 概述一下这首诗的内容。在第一节和第二节中，叙述者表明，他处于一段即将破裂的二人关系中，这段感情似乎完全无法维持下去了，他准备和平分手，并很高兴自己能摆脱这段关系，并获得自由，两人永远不会再相爱。可是在第三节中，叙述者的口吻改变了。他把自己的爱情比作一个垂死的人，表示，只要对方能够回心转意，自己的爱情仍会死灰复燃。诗就在这里结束了。他们最后复合了吗？ 这首诗中表现出的情感是十分复杂的，或者说可以有多种理解方式。这真是很有趣。我最初的理解方式是，叙述者一直都爱着他的对象，而他的对象不再爱他了。那些“I am glad”、“I myself can free”什么的，都是他无奈之下说出的气话。提议和平分手只是为了留下最后的体面。到第二节的时候，虽然他的话语是绝情的，但我觉得弦外之音是，他希望自己能够做到这样绝情，但是做不到。第三节的时候他就已经不再嘴硬，而是开始恳求了：请给我们的爱情一点希望吧！我曾经那么爱你，可是这份爱再也得不到回应了，它即将死去。可是，如果你仍愿意回应这份爱，我的爱情就会立刻燃起希望。在这种理解下，爱的“死”大概不是直接的消亡，而是彻底失去了希望。 不过查资料的时候我又看到了另一种解释方法。在这种解释中，叙述者和他的爱人在爱情中是互相厌倦的，因此才会如此平和地在第一段中说出要和平分手这种话，分手时还要亲吻握手。但是，从第三段开始，叙述者又后悔了。他想起了自己曾在爱情中付出的热情、信仰和天真，不希望这段感情就此逝去。于是他在最后又诚恳地请求爱人，重新考虑一下，我们还能重新开始。[4]不过我不太同意这种解释的地方在于，在第二段中叙述者提议的行为是相当绝情的，和这种感情状态不太匹配；除非他们都在游戏人生。 下面来一段当代人比较喜欢的解释（我随便脑洞的）。叙述者仍然爱着他的爱人，但他的爱人已经厌倦了。他决定最后恳求一次，但不是卑躬屈漆地请求。如果对方不愿接受，那我们就和平分手，让我心中的爱逐渐逝去。但是，如果对方愿意的话，他还愿意继续爱下去。他只是把自己的心意摆在面前，请求对方接受罢了。（此处听起来实在像是某篇知乎问答中讲的令狐冲和任盈盈的爱情观了。翻了半天都没找到原答案，只好把引文粘在下面。当然这个诠释真的很……现代……了） 令狐冲和任盈盈在感情上是真正的一类人。任盈盈可以为令狐冲孤身上少林，但当他在面临抉择的时候，要让她站到他面前去，她却是万万不愿意的。 同样的，令狐冲可以为小师妹不计生死相救，可以以身饲剑只为她欢喜，但要让他俯首乞怜，哀恳她回心转意，他却是死也做不出来的。他们的「争取」，是把心意敞敞亮亮的放在对方面前，不是跪着求对方接受它。 「两情相悦，贵乎自然」，强求无味，更惹伤心。他们只是在这一点上，比别人想的更明白通透罢了 不过，无论上述哪种解释更好，我都挺喜欢第三节的描写的。换句话说，不就是在这段感情中，激情支配着我的心跳和话语，信念激励着我不断坚持，纯真让我的双眼不断发现你的美么。看来作者心目中完美的爱情是需要激情、信念和纯真的。这很有趣了。如果我也拥有一段由这些要素构成的爱情，那至少它曾经是很美好的。 参考文献 [1] Michael Drayton. https://en.wikipedia.org/wiki/Michael_Drayton [2] John Dryden. https://en.wikipedia.org/wiki/John_Dryden [3] Michael Drayton Critical Essays. https://www.enotes.com/topics/michael-drayton/critical-essays [4] give me the summary of poem “Lover’s Farewell” by M. drayton. http://www.gradesaver.com/allen-ginsbergs-poetry/q-and-a/give-me-the-summary-of-poem-lovers-farewell-by-m-drayton-57457 脚注 1cleanly: ‘entirely.’（彻底地，完全地。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"李霁野","slug":"李霁野","permalink":"https://zhanghuimeng.github.io/tags/李霁野/"},{"name":"D.Drayton","slug":"D-Drayton","permalink":"https://zhanghuimeng.github.io/tags/D-Drayton/"}]},{"title":"OSTEP第27章总结：Interlude: Thread API","slug":"2018-04-16-OSTEP第27章总结：Interlude-Thread-API","date":"2018-04-16T19:43:44.000Z","updated":"2018-04-16T19:43:44.000Z","comments":true,"path":"post/ostep-ch-27-summary-interlude-thread-api/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-27-summary-interlude-thread-api/","excerpt":"","text":"本章主要介绍了POSIX标准下的线程API，包括： 创建线程 等待线程结束 创建和使用互斥锁 创建和使用条件变量 创建线程 12345intpthread_create( pthread_t * thread, const pthread_attr_t * attr, void * (*start_routine)(void*), void * arg); 4个参数的含义如下： thread：指向struct pthread_t类型的变量的指针，我们需要这一变量用来控制线程，因此需要把它的指针传递过去进行初始化 attr：指定线程的属性，如栈的大小和线程的调度优先级；属性是通过调用pthread attr_init()进行初始化的 start_routine：指定线程运行的函数，它只有一个void*类型的参数，返回值也是void*类型 arg：在进程执行的时候传递给函数的参数 例子： 123456789101112131415161718192021222324#include &lt;pthread.h&gt;typedef struct __myarg_t &#123; int a; int b;&#125; myarg_t;void *mythread(void *arg) &#123; myarg_t *m = (myarg_t *) arg; printf(&quot;%d %d\\n&quot;, m-&gt;a, m-&gt;b); return NULL;&#125;intmain(int argc, char *argv[]) &#123; pthread_t p; int rc; myarg_t args; args.a = 10; args.b = 20; rc = pthread_create(&amp;p, NULL, mythread, &amp;args); ...&#125; 等待线程结束 1int pthread_join(pthread_t thread, void **value_ptr); 参数说明： thread：等待哪一个线程结束；这个变量是通过调用pthread_create()来初始化的 value_ptr：指向将会得到的返回值的指针 使用示例 1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;assert.h&gt;#include &lt;stdlib.h&gt;typedef struct __myarg_t &#123; int a; int b;&#125; myarg_t;typedef struct __myret_t &#123; int x; int y;&#125; myret_t;void *mythread(void *arg) &#123; myarg_t *m = (myarg_t *) arg; printf(&quot;%d %d\\n&quot;, m-&gt;a, m-&gt;b); myret_t *r = Malloc(sizeof(myret_t)); r-&gt;x = 1; r-&gt;y = 2; return (void *) r;&#125;intmain(int argc, char *argv[]) &#123; pthread_t p; myret_t *m; myarg_t args = &#123;10, 20&#125;; Pthread_create(&amp;p, NULL, mythread, &amp;args); Pthread_join(p, (void **) &amp;m); printf(&quot;returned %d %d\\n&quot;, m-&gt;x, m-&gt;y); free(m); return 0;&#125; 在上述代码中，创建了一个线程，传入了一些参数，在该线程返回之后，得到了它的返回值。当然，我们并不是总需要把参数和返回值包装成struct的。值得注意的是，不要返回指向在线程的调用栈上分配的内存的指针（而改为使用malloc()在堆上分配内存），因为在线程返回之后，它的栈就会被回收。 当然，在这个例子中，调用pthread_create()之后立刻调用pthread_join()的做法是没有什么意义的，因为函数调用也可以达到相同的效果。 并不是所有多线程程序都会用到join函数。有些多线程服务器可能会创建一些工作线程，然后让主线程不断接收请求并传递给其他线程。 互斥锁 最基本的一对上锁/解锁API是： 12int pthread_mutex_lock(pthread_mutex_t *mutex);int pthread_mutex_unlock(pthread_mutex_t *mutex); 较高级的API包括： 12345// 在无法获得锁时返回错误int pthread_mutex_trylock(pthread_mutex_t *mutex);// 在试图获得锁而不成功一段时间后返回错误int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout); 使用示例 1234pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;pthread_mutex_lock(&amp;lock);x = x + 1; // or whatever your critical section ispthread_mutex_unlock(&amp;lock); 上述代码的含义是： 如果调用pthread_mutex_lock()时没有其他线程持有锁，则该线程可以获得锁并进入关键区 如果有其他的线程正在持有锁，则试图获得锁的进程将会阻塞，直到其他进程将锁释放，该进程获得锁为止 注意几点： 只有拥有锁的线程才能调用pthread_mutex_unlock() 需要检查上锁和开锁时可能发生的错误，最简单的方法是assert返回值 除了静态初始化方法（使用PTHREAD_MUTEX_INITIALIZER进行默认初始化） 修改为动态初始化的示例如下： 1234567pthread_mutex_t lock;int rc = pthread_mutex_init(&amp;lock, NULL);assert(rc == 0); // always check success!pthread_mutex_lock(&amp;lock);x = x + 1; // or whatever your critical section ispthread_mutex_unlock(&amp;lock);pthread_mutex_destroy(&amp;lock); 条件变量 12int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);int pthread_cond_signal(pthread_cond_t *cond); 需要在线程之间传递信号的时候（比如某个线程等待另一个完成），条件变量是很重要的。条件变量需要一个与它相关的锁。调用上述函数的前提是持有该锁。 pthread_cond_wait()函数的功能是，将调用该函数的线程睡眠，直到其他线程发出信号为止。通常的用法如下： 123456pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;pthread_cond_t cond = PTHREAD_COND_INITIALIZER;Pthread_mutex_lock(&amp;lock);while (ready == 0)Pthread_cond_wait(&amp;cond, &amp;lock);Pthread_mutex_unlock(&amp;lock); 上述代码在初始化之后，对ready变量进行检查，如果不满足要求，则继续睡眠，等待再次被唤醒。 在其他线程中唤醒该线程的代码如下： 1234Pthread_mutex_lock(&amp;lock);ready = 1;Pthread_cond_signal(&amp;cond);Pthread_mutex_unlock(&amp;lock); 值得注意的是： 在发出信号和修改全局变量ready时，为了防止竞争条件，我们总是确保已经获得了锁 wait函数的第二个参数是锁，但signal函数的参数没有锁。这是因为wait函数在使线程进入睡眠的同时也释放了锁（否则其他线程就不可能获得锁并唤醒该线程）；在被唤醒之前，wait函数会重新获得锁 等待的线程会通过while循环检查条件是否满足，而不是if语句；这样做是最安全的，因为有些pthread的实现会使得条件未满足时线程仍被唤醒，因此唤醒只是一种提示 作者指出，最好不要自己尝试造轮子来实现条件变量的功能。 线程API使用指南 简化操作：线程之间复杂的互动会导致bug。 减少线程之间的互动 记得初始化锁和条件变量 检查返回值 小心传参的方式，不要返回指向线程栈上的指针 每个线程都拥有自己的栈，只有堆中的变量才是全局的 一定要通过条件变量在线程之间传递信号 多看手册 作业 仍然没做，这次的作业比较复杂，似乎要用到valgrind，还要配置一些环境。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第26章总结：Concurrency: An Introduction","slug":"2018-04-16-OSTEP第26章总结：Concurrency-An-Introduction","date":"2018-04-16T15:17:58.000Z","updated":"2018-04-16T15:17:58.000Z","comments":true,"path":"post/ostep-ch-26-summary-concurrency-an-introduction/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-26-summary-concurrency-an-introduction/","excerpt":"","text":"本章对多线程程序面临的两个问题（竞争条件和等待）进行了初步介绍。包括以下关键词： 关键区（critical section）：访问共享资源（通常是变量或数据结构）的代码段。 竞争条件（race condition）：多个线程几乎同时访问关键区并尝试修改数据时会出现的状况，结果很难预测。 不确定（indeterminate）程序：包含竞争条件的程序，每次的运行结果是不确定的。 互斥访问（mutual exclusion）：保证一次最多有一个进程能进入关键区，防止竞争出现。 为何需要线程 首先比较一下线程与进程。 相同点： PC：指令指针 通用寄存器 上下文切换：需要保存寄存器的状态 需要TCB（线程控制块）保存线程的状态 不同点： 不需要切换地址空间（页表） 单线程进程通常只有一个栈（位于地址空间的底部，向低地址增长），而多线程进程的每个线程都需要一个栈 需要线程的两个主要原因包括： 并行性（parallelism）：对于多CPU计算机，如果将每个线程分配给不同的CPU，则可以提高程序效率 防止慢速I/O导致程序阻塞：由于I/O是很慢的，当某个线程等待I/O结果而被阻塞时，其他线程就可以继续运行 虽然上述应用场景也可以用进程来实现，但线程有着可以方便地共享数据这一优势。 多线程的问题 书中首先举了一个例子，用来说明，多线程程序中线程的执行顺序是不可控的，因此可能会出现各种各样的问题。 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt;#include &quot;mythreads.h&quot;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;void *mythread(void *arg) &#123; printf(&quot;%s\\n&quot;, (char *) arg); return NULL;&#125;intmain(int argc, char *argv[])&#123; if (argc != 1) &#123; fprintf(stderr, &quot;usage: main\\n&quot;); exit(1); &#125; pthread_t p1, p2; printf(&quot;main: begin\\n&quot;); Pthread_create(&amp;p1, NULL, mythread, &quot;A&quot;); Pthread_create(&amp;p2, NULL, mythread, &quot;B&quot;); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(&quot;main: end\\n&quot;); return 0;&#125; 在上述代码中，主程序会创建两个线程，每个线程都会运行函数mythread()，但是参数不同。创建线程之后，它可能立刻开始运行或进入就绪态（取决于调度器）。当然，在多处理器系统上，也可能有多个线程同时运行。 创建了两个线程（T1和T2）之后，主程序调用pthread_join()，等待线程运行结束。T1和T2都结束之后，主线程会重新开始运行，打印信息并退出。如上所述，执行过程涉及了三个线程：T1、T2和主线程。 事实上线程的执行过程有各种不同的可能性，比如： 主线程创建完两个线程之后，切换到T1，然后再切换到T2，最后回到主线程 先打印A，后打印B 主线程创建完T1之后，T1开始运行，结束之后，回到主线程，创建T2，T2开始运行，最后回到主线程 先打印A，后打印B 主线程创建完T1和T2之后，T2先开始运行，结束之后切换到T1，最后回到主线程 先打印B，后打印A 这种执行的不确定性就是万恶之源了。 共享资源导致的竞争条件 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;stdio.h&gt;#include &quot;mythreads.h&quot;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;int max;volatile int counter = 0; // shared global variablevoid *mythread(void *arg)&#123; char *letter = arg; int i; // stack (private per thread) printf(&quot;%s: begin [addr of i: %p]\\n&quot;, letter, &amp;i); for (i = 0; i &lt; max; i++) &#123; counter = counter + 1; // shared: only one &#125; printf(&quot;%s: done\\n&quot;, letter); return NULL;&#125;intmain(int argc, char *argv[])&#123; if (argc != 2) &#123; fprintf(stderr, &quot;usage: main-first &lt;loopcount&gt;\\n&quot;); exit(1); &#125; max = atoi(argv[1]); pthread_t p1, p2; printf(&quot;main: begin [counter = %d] [%x]\\n&quot;, counter, (unsigned int) &amp;counter); Pthread_create(&amp;p1, NULL, mythread, &quot;A&quot;); Pthread_create(&amp;p2, NULL, mythread, &quot;B&quot;); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(&quot;main: done\\n [counter: %d]\\n [should: %d]\\n&quot;, counter, max*2); return 0;&#125; 上述代码的运行结果是变化的，有时候是正确的： 12345678prompt&gt; gcc -o main main.c -Wall -pthreadprompt&gt; ./mainmain: begin (counter = 0)A: beginB: beginA: doneB: donemain: done with both (counter = 20000000) 有时候是错误的： 1234567prompt&gt; ./mainmain: begin (counter = 0)A: beginB: beginA: doneB: donemain: done with both (counter = 19345221) 而且运行结果还会不断变化。这种性质被称为不确定性（indeterminate）。出现这种情况的原因是，修改共享变量counter的指令不是原子的，因此可能在执行的任意阶段被调度器打断，此时运行结果就会取决于线程的调度顺序。这一状况被称为争用条件（race condition）。下图对此作了很好的说明： 由于多个线程执行这段代码时会导致争用条件发生，我们称这段代码为关键区（critical section）。关键区包含了一段访问共享变量（或者说共享资源）的代码，不能被多于一个进程并发执行。为了正确执行代码，我们此时需要的是互斥访问（mutual exclusion），也就是保证一个线程在关键区内执行时，其他线程都无法进入关键区。 解决问题的方法之一是创造一种更强大的指令，它可以把我们需要完成的任务浓缩在一条指令内执行，这样就不会遭遇中断了。这种性质称为原子性（atomic）。这是一种美好的理想，但是对于一些很复杂却仍然需要保证原子性的操作，这种指令是不太可能实现的。 因此，我们转而尝试通过几条关键指令，实现同步原语（synchronization primitives），进而实现原子性。通过这些同步原语和OS的帮助，我们就可以在多线程代码中安全地访问关键区了。 接下来我们将解决这些问题： 实现同步原语需要怎样的硬件支持？ OS需要提供怎样的支持？ 如何正确高效地实现同步原语？ 程序如何使用这些程序原语以得到希望的结果？ 进程的相互等待问题 多线程面临的另一类问题是，线程有时需要等待其他线程结束或I/O请求完成。为此，我们不仅会学习同步原语的使用，也会学习条件变量（condition variables）。 作业题 暂时没做。作业题程序可见于https://github.com/asnr/ostep/tree/master/concurrency/26_threads_intro。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"OSTEP第25章总结：A Dialogue on Currency","slug":"2018-04-16-OSTEP第25章总结：A-Dialogue-on-Currency","date":"2018-04-16T11:08:53.000Z","updated":"2018-07-17T22:26:00.000Z","comments":true,"path":"post/ostep-ch-25-summary-a-dialogue-on-currency/","link":"","permalink":"https://zhanghuimeng.github.io/post/ostep-ch-25-summary-a-dialogue-on-currency/","excerpt":"","text":"这一章是并发部分的开头，是一篇只有两页的对话，对并发中可能出现的问题进行了简单的讨论，所以并没有太多可以总结的。教授 再一次拿出了桃子作为比喻的工具。 不妨想象桌子上有很多桃子，很多人想要吃它们。他们的动作步骤是这样的： 用眼神确认一个桃子 尝试伸手抓住桃子 吃 这一过程的问题是，两个人可能同时看到一个桃子，而后伸手的人就没有桃子了。 学生 给出的解决方案是，将人排成一队，按顺序拿桃子，但教授指出这样太慢了。 在多线程应用中，每个线程就是吃桃子的人，而资源就是桃子。因为多线程资源访问冲突的问题，OS需要管理线程对资源的请求。 学生 提问，为何不仅仅在用户态下实现多线程。对此，教授 的回答是： OS必须通过提供锁（lock）和条件变量（condition variable）来支持多线程应用 OS本身就是一个多线程的应用，需要控制自己对资源的访问 很好，我很期待接下来的内容。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"},{"name":"OSTEP","slug":"OSTEP","permalink":"https://zhanghuimeng.github.io/tags/OSTEP/"}]},{"title":"《英诗金库》I-36：Madrigal, by W. Shakespeare","slug":"2018-04-16-《英诗金库》I-36：A-Madrigal-by-W-Shakespeare","date":"2018-04-16T00:57:22.000Z","updated":"2018-07-10T02:17:00.000Z","comments":true,"path":"post/madrigal-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/madrigal-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Madrigal（情歌） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1604 编注：此诗选自《一报还一报》第四幕第一场，表达了玛丽安娜被她的未婚夫安哲鲁遗弃后的凄凉心情。标题《情歌》系原编者所加。 作品原文 Take, O, take those lips away That so sweetly were forsworn, And those eyes, the break of day, Lights that do mislead the morn1: But my kisses bring again, Bring again— Seals of love, but seal’d in vain, Seal’d in vain! 译文 朱生豪 译 莫以负心唇， 婉转弄辞巧： 莫以薄幸眼， 颠倒迷昏晓； 定情密吻乞君还， 当日深盟今已寒！ 我的感想 刚才把《一报还一报》（Measures for Measures）又浏览了一遍，感觉很有趣。目前实在懒得概括剧情，不妨参见《莎士比亚故事集》[1]或者维基百科的介绍[2]。剧情本身引发了我的很多思考，但是我觉得这些在这首诗中并非重点。我们还是暂且聚焦于玛丽安娜的遭遇好了，不然又要长篇累牍地搞起莎士比亚分析来了。 （首先赞誉一下翻译，翻得真好。）这首诗（歌）的出场时间是第四幕第一场的开头，在玛丽安娜上场的时候由童儿唱出，可以说是人物主题曲一般定下调子的东西了。剧情中，随后就是乔装打扮的公爵和依莎贝拉上场，给她带来了莫大的希望。后来她再出场就是玛丽安娜向公爵恳求饶安哲鲁一命了。虽然可以想象，她的命运的确很悲惨（五年的痛苦折磨！），但是这一点在剧中并没有大肆渲染，只是在最后公爵声称要处决安哲鲁时会稍微想象到一点她刚刚获得莫大的希望却又马上要被剥夺的痛苦。 这首诗确实写得很不错，不过并没有什么特异的地方，主题反倒是有点烂俗了。不过，我接下来还想谈谈玛丽安娜作为一个文学形象的事情。 我之前比较熟知的是丁尼生的《Mariana》[3]。事实上，我更熟知和喜欢的是《The Lady of Shalott》这首诗，不过有人指出，玛丽安娜是夏洛特在文学形象上的姊妹[citation needed]，所以我也大概了解了一下这首诗。当时读得并不深刻，但只要细读一番，就能体会到那种深刻的困于一地的痛苦。不过，当时我并没有想过，这个形象与莎士比亚剧本中的玛丽安娜到底是否符合。 今天随便翻了翻原著的剧本，突然想到这么一件事：如果让我来写一篇关于玛丽安娜的同人的话，我很大概率会选择她与安哲鲁举行结婚仪式之后却听说安哲鲁立刻要被处决的部分来写，因为这部分的感情变化最为激烈，也最容易代入感情。但是丁尼生显然不是这么想的。他反而选择了她在房子里独居着，受着一成不变的煎熬的部分来写。而且他写得很好，这种痛苦令人感同身受。这就很有趣了。我想，这里面固然夹杂着私货，当然也说明了丁尼生在描写此类题材上的天才。 想到了莱辛的《拉奥孔》中的理论，现在看来，它已经彻底地成为了时代的眼泪。诗中当然可以摹写静态的事物，画中也可以表现动态的痛苦。我大概需要多找些文学批评来看了，可是也没有时间。 参考文献 [1] 一报还一报. https://www.kanunu8.com/book4/8888/198950.html [2] Measure for Measure. https://en.wikipedia.org/wiki/Measure_for_Measure [3] Mariana (poem). https://en.wikipedia.org/wiki/Mariana_(poem) 脚注 1Lights that do mislead the morn: i.e. her eyes are so bright that the morn takes them for the Sun—a common conceit of the period.（他的眸子如此明亮，以至于黎明把它们错当成了太阳——这是当时常见的比喻。以及我觉得这里明显应该是“他”，大概原文又打错了。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-35：Care-charmer Sleep, by S. Daniel","slug":"2018-04-15-《英诗金库》I-35：Care-charmer-Sleep-by-S-Daniel","date":"2018-04-15T00:29:35.000Z","updated":"2018-04-15T00:29:35.000Z","comments":true,"path":"post/care-charmer-sleep-by-s-daniel/","link":"","permalink":"https://zhanghuimeng.github.io/post/care-charmer-sleep-by-s-daniel/","excerpt":"","text":"作品基本信息 作品名称：Care-charmer Sleep, son of the sable Night 作者：Samuel Daniel（塞缪尔·丹尼尔） 出版年代：1592 编注：塞缪尔·丹尼尔（Samuel Daniel，1562-1619），英国宫廷诗人。这首诗系他的十四行诗集《迪莉娅》第五一首。 作品原文 Care-charmer Sleep, son of the sable Night, Brother to Death, in silent darkness born, Relieve my languish, and restore the light; With dark forgetting of my care return. And let the day be time enough1 to mourn The shipwreck of my ill-adventured youth: Let waking eyes suffice to wail their scorn2, Without the torment of the night’s untruth. Cease, dreams, the images of day-desires, To model forth the passions of the morrow;3 Never let rising Sun approve you liars4 To add more grief to aggravate my sorrow: Sill let me sleep, embracing clouds5 in vain, And never wake to feel the day’s disdain. 译文 付勇林 译 驱愁的睡神呵，漆黑的夜神之子， 你，死神的胞弟，在幽暗中诞生， 祛除我的愁思吧，让光明复归故里；6 复归故里，与忧愁悄然辞行。 悠悠白日已足以让我哀吟 人生沉浮，青春时荒谬的冒险： 睁着眼已够去泣诉世人的薄情， 就别让夜的虚伪来将我磨难。 梦啊，你这白日欲望的幻像， 请别再把来日的痛苦产生， 别让东升的朝阳赞赏你说谎 使我旧伤未除又添上了新恨： 还让我睡吧，徒劳地拥抱幻云， 别让我醒来去领受白日的欺凌。 我的感想 作为一名诗人，塞缪尔·丹尼尔的生活似乎很无趣。他生于一个受人尊敬的家庭，并成为了伊丽莎白一世和詹姆斯一世统治时期最成功的作家之一。这首诗来自诗集《迪莉娅》，主题倒是很平常：一个人在追求一个姑娘，并因为她的冷漠而悲伤。这是丹尼尔的第一本公开的著作，出版于1592年。整本书读起来不像是反映了诗人生活中的什么大事或痛苦，而仅仅是在跟随一种诗歌传统而已。[1]事实上， 这本书被献给“To the right honourable the Ladie Mary, Countesse of Pembroke”，虽然我也不知道这位女士是谁。[2] 我觉得这个评价对这首诗十分适当。这个链接里有对这首诗的详细解释（详细到烦）。总之，主题就是，诗人很爱一个女人，但是这个人并不爱他，以至于他觉得十分悲惨，希望到梦里寻求安慰（而不是重复白天的痛苦），甚至想长睡不醒算了。睡神被人格化了，作者祈求他的安慰，但这位神的力量显然是很有限的（即使不带来更多的痛苦，快乐也是虚幻的），所以他悲伤得想死了，也许死神更能解决他的问题。 “Samuel Daniel had an eminently contemplative genius which might have anticipated the sonnet as it is in Wordsworth, but which the fashion of the day confined to the not wholly suitable subject of Love. In the splendid Care-charmer Sleep … he continued, as will be seen, to put his subject under the influence of his prevailing faculty.”（塞缪尔·丹尼尔卓越的冥想天才可能使得他像华兹华斯一样对这首十四行诗有了过高的期望，但当时的风气将这种天才限制在了一个不完全合适的关于爱情的主题上。在这首出色的诗（Care-charmer Sleep）中，他继续将这一主题置于他流行的才能的影响下。） (George Saintsbury, History of Elizabethan Literature, 1887.)[3]我觉得这个评价是比较合理的。这首诗的情感无疑是真实的，但主题却未必需要局限在爱情之下。不过如何看出这首诗是讲爱情的呢？其实，脱离背景之后，看不出来。而且诗的普世性变得更强了。这大概就是它是一首好诗的缘故吧。或者这里说的风气也包括把睡神当成一个神去祈祷这种文风。现代人就不会这么写作了。 我挺喜欢“And let the day be time enough to mourn\\The shipwreck of my ill-adventured youth”这句的，让我想起了Metallica的《The Unforgiven III》这首歌。整体氛围都很像。 整首诗的氛围也让我想起了很多其他的歌，比如这首。 I’ve seen the devil in a smile I found salvation in a vile My happing ending Exists only in my dreams - My Suffering, Dead by Sunrise 还有这首。 Is that a light at the end of the tunnel That I see I see please let it be but don’t Wake me till the morning after Wake me till the morning after Wake me till the morning after Oh I’m so tired there has got to be an end to the pain I feel when I’m awake and alive alive alive alive and I’m dreaming - Morning After, Dead By Sunrise 所以，现代人仍然经常有这样的感情，只是不会再这样写出来了而已。 参考文献 [1] Care-charmer Sleep. http://www.cieliterature.com/care-charmer-sleep/ [2] http://www.potw.org/archive/potw110.html [3] Care-Charmer Sleep, Son of the Sable Night http://www.bartleby.com/331/582.html 脚注 1let the day be time enough, etc.: i.e. let not my sleep be but a continuation of my waking sorrows with all the added exaggerations of dreamland.（请不要在我的梦乡中继续清醒时的不幸，又加上幻境的夸大其词。） 2their scorn: ‘the scorn in which they see I am held.’（它们看到我如何被轻蔑。） 3’And you dreams, which do but re-echo my waking thoughts, come not to anticipate the suffering that I shall encounter next day.’（你们这些梦啊，虽然你们只能重复我白天的想法，也请不要揣测我明天将遭遇的痛苦。） 4Never let rising Sun approve you liars: ‘do not paint things worse than they will prove to be when the next day comes.’（不要把事情描绘得比明天将要发生的还要糟糕。） 5embracing clouds: ‘dreaming in a world of pure fancy.’（在纯粹的幻想世界中的梦境。） 6诗人感到清醒的世界太黑暗，故把睡眠称为“光明复归”。——编注者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"},{"name":"S.Daniel","slug":"S-Daniel","permalink":"https://zhanghuimeng.github.io/tags/S-Daniel/"}]},{"title":"《操作系统》第6讲：“物理内存管理：非连续内存分配”总结","slug":"2018-04-13-《操作系统》第6讲：“物理内存管理：非连续内存分配”总结","date":"2018-04-13T00:48:03.000Z","updated":"2018-04-13T00:48:03.000Z","comments":true,"path":"post/os-mooc-lecture-6-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-6-summary/","excerpt":"","text":"课程内容概述 背景 段机制 页机制 普通页表 快表 多级页表 页寄存器 反置页表 段页式存储管理 背景 6.1 非连续内存分配的需求背景 必须分配连续的会带来很多麻烦 不连续？找到的几率更高，但会带来新问题。比如基本块有多大。 段式：分块大 页式：分块小 设计目标 连续分配的缺点： • 物理内存必须连续 • 存在外碎片和内碎片 • 内存分配的动态修改困难 • 内存利用率较低 非连续分配的设计目标：提高内存利用效率和管理灵活性 • 允许一个程序使用非连续的物理地址空间 • 允许共享代码与数据 • 支持动态加载和动态链接 实现 非连续分配需要解决的问题： • 如何实现虚拟地址和物理地址的转换：不同的逻辑地址可能位于不连续的物理区域中 ○ 软件实现（灵活，开销大） ○ 硬件实现（够用，开销小） • 非连续分配的硬件辅助机制 ○ 如何选择非连续分配中的内存分块大小？内碎片、外碎片问题？ ○ 段式存储管理（segmentation）：块大 ○ 页式存储管理（paging）：块小 段机制 6.2 段式存储管理 段地址空间 进程的段地址空间由多个段组成： • 主代码段 • 子模块代码段 • 公用库代码段 • 堆栈段（stack） • 堆数据（heap） • 初始化数据段 • 符号表等 段式存储管理的目的：更细粒度和灵活的分离域共享 段式地址空间的不连续二维结构 虽然在逻辑地址空间中，是按这一顺序排列的，但在物理地址空间中可以不是这样的。 段访问机制 段的概念： • 段表示访问方式和存储数据等属性相同的一段地址空间 • 对应一个连续的内存“块” • 若干个段组成进程逻辑地址空间 段访问：逻辑地址由二元组（s，addr）表示 • s——段号 • addr——段内偏移 • 从单地址转换成“段基址+段内偏移” 段访问的硬件实现 • 首先从逻辑地址中得到段号和偏移量 • 在段表中查找段号，得到段基址和段长度 • 由MMU来判断偏移量是否合法（偏移量是否大于段长度） • 得到物理地址，在物理内存中查找相应内容 页机制 6.3 页式存储管理 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） • 把物理地址空间划分为大小相同的基本分配单位 • 2的n次方，如512,4096,8192，4k是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） • 把逻辑地址空间也划分为相同大小的基本分配单位 • 帧和页的大小必须是相同的 页面到页帧之间的转换： • 逻辑地址到物理地址的转换 • 页表 • MMU/TLB 帧（Frame） 物理内存被划分成大小相等的帧 此时内存的物理地址可以表示成二元组（f，o），其中f是帧号，o是帧内的偏移量 物理地址的前F位可以换成帧号，后S位可以换成偏移量 • F：帧号，F位，共有2^F个帧 • o：帧内偏移，S位，每帧有2^S字节 • 物理地址=f*2^S + o 基于页帧的物理地址计算实例 假定： • 地址空间为16位 • 页帧大小为9位（512字节） 页（Page） 进程逻辑地址空间被划分为大小相等的页 • 页内偏移=帧内偏移 • 然而页号大小≠帧号大小，因为逻辑地址是连续的，但物理地址不一定是连续的 进程逻辑地址的表示：二元组（p，o） • p：页号（P位，2P个页） • o：页内偏移（S位，每页有2^S字节） 页式存储中的地址映射 如何将页映射到帧？ • 逻辑地址中的页号 • 物理地址中的帧号是不连续的 • 不是所有的页都有对应的帧 这个表就是页表。 页表 页表保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系。 • CPU从逻辑地址中得到页号和偏移量 • 在页表中以页号作为下标查找帧号 • 用帧号和偏移量组成物理地址 普通页表 6.4 页表概述 页表结构 每个进程都有一个页表 • 每个页面对应一个页表项 • 随进程运行状态而动态变化（可以动态调整内存空间大小） • 页表基址寄存器：PTBR，Page Table Base Register 页表项的组成： • 帧号：f • 页表项标志： ○ 存在位（resident bit）：逻辑页面是否存在与之对应的物理帧 ○ 修改位（dirty bit）：对应的页面中的内容是否被修改了 ○ 引用位（clock/reference bit）：在过去一段时间内是否访问过页中的某一个存储单元 页表地址转换实例 有了存在位之后，就会发现，有些逻辑页没有对应的物理帧 页式存储管理机制的性能问题 内存访问性能问题： • 访问一个内存单元需要2次内存访问 • 第一次访问：获取页表项 • 第二次访问：获取数据 页表大小问题： • 页表可能非常大 • 64位机器如果每页1024字节，那么一个页表的大小会是多少？（2^54个页面*8个多字节） 如何处理？ • 缓存（Caching） • 间接（Indirection）访问：切段，多级页表 快表 6.5 快表和多级页表 快表（Translation Look-aside Buffer，TLB） 目标：缓存近期访问的页表项 • TLB使用关联存储（associated ），具备快速访问性能 • 关联存储器：有一组key，可以并行地查找所有表项，得到匹配项 • 因为快表位于CPU中，所以它的速度快、成本高、功耗大 • 如果TLB命中，物理页号可以很快被获取 • 如果TLB未命中，对应的表项被更新到TLB中 多级页表 多级页表 • 通过间接引用将页号分成k级 • 建立页表“树” • 可以有效减少每级页表的长度，但是如果所有的页表项都存在，则多级页表并没有减少存储量 • 不过大部分进程并不会用到所有的逻辑地址空间 在x86架构中，CR3寄存器用于存储PTBR（页表基址） 二级页表实例 页寄存器 6.6 反置页表 减少页表占用的空间的一种做法 大地址空间问题 对于大地址空间（64-bits）系统，多级页表变得繁琐。 比如：5级页表 逻辑（虚拟）地址空间增长速度快于物理地址空间 页寄存器和反置页面的思路： • 不让页表与逻辑地址空间的大小相对应 • 让页表与物理地址空间的大小相对应 页寄存器（Page Registers） 每个帧与一个页寄存器（Page Register）关联，寄存器内容包括： • 使用位（Residence bit）：此帧是否被进程占用 • 占用页号（Occupier）：对应的页号p • 保护位（Protection bits）：约定这一页的访问方式，可读，可写…… 页寄存器示例 • 物理内存大小：40964096=4K4KB=16MB • 页面大小：4096bytes=4KB • 页帧数：4096=4K • 页寄存器使用的空间：8*4096=32Kbytes（假定每个页寄存器占8字节） • 页寄存器带来的额外开销：32K/16M=0.2%（大约） • 虚拟内存的大小：任意 页寄存器方案的特征 优点： • 页表大小相对于物理内存而言很小 • 页表大小与逻辑地址空间大小无关 缺点： • 页表信息对调后，需要根据帧号可找页号 • 在页寄存器中搜索逻辑地址中的页号 页寄存器中的地址转换 CPU生成的逻辑地址如何找对应的物理地址？ • 对逻辑地址进行Hash映射，以减少搜索范围 • 需要解决可能的冲突 用快表缓存页表项后的页寄存器搜索步骤 • 对逻辑地址进行Hash变换 • 在快表中查找对应页表项 • 有冲突时遍历冲突项列表 • 查找失败时，产生异常 快表的限制 • 快表的容量限制 • 快表的功耗限制（StrongARM上快表功耗占27%） 反置页表 反置页表 基于Hash映射值查找对应页表项中的帧号 • 进程标识与页号的Hash值可能有冲突 • 页表项中包括保护位、修改位、访问位和存在位等标识 查找过程： • 从逻辑地址中得到页号 • 根据页号和PID计算出Hash值 • 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号 反置页表的Hash冲突 例子：在页表项中加入next项，指出全部冲突项的列表 段页式存储管理 6.7 段页式存储管理 段页式存储管理的需求 段式存储在内存保护方面有优势，页式存储在内存利用和优化转移到后备存储方面有优势 段式存储和页式存储能否结合？ 段页式存储管理 在段式存储管理基础上，给每个段加一级页表 逻辑地址：段号+若干个页号+页内偏移 物理地址：帧号+页内偏移 • 从逻辑地址中得到段号s和页号p，以及偏移o • 通过段基址（STBR）和s得到对应的段表项 • 访问段表项对应的页表，得到对应的帧号 段页式存储管理中的内存共享 通过指向相同的页表基址，实现进程间的段共享 共享段指向同一个页表 小结 段式、页式、段页式内存分配总结 共同点 • 可以不连续 区别： • 块的大小 问题： • 加入页表或段表 • 页表大小问题 ○ 快表 ○ 多级页表 ○ 反置页表 • 实现细节 练习 选择填空题 描述段管理机制正确的是() 段的大小可以不一致 段可以有重叠 段可以有特权级 段与段之间是可以不连续的 都对。段的大小显然可以不一致（段描述符中给出的大小不同）。段之间可以重叠（没说不能重叠，而且完全扁平模型就是全都映射到全部物理内存。）段可以有特权级（段描述符中的DPL，访问段的最低特权级）。段之间当然也是可以不连续的。 描述页管理机制正确的是() 页表在内存中 页可以是只读的 页可以有特权级 上述说法都不对 前三个都对。当然有的地方不太准确。在80386系统中，一级页表一定在内存中，但二级页表不一定在内存中。PDE和PTE都可以规定访问权限，不过只有U/S（用户/OS权限）和R/W（只读/可读可写）位。 页表项标志位包括() 存在位(resident bit) 修改位(dirty bit) 引用位(clock/reference bit) 只读位(read only OR read/write bit) 都有。当然，还不止这些。 可有效应对大地址空间可采用的页表手段是() 多级页表 反置页表 页寄存器方案 单级页表 前两个是对的。至于为什么页寄存器不行，老师在Piazza上给出了回复： 页寄存器和反置页表很像，但它们的一个区别是进程ID在地址转换中的使用。没有进程ID（也就是说页寄存器方案）时，页表占用的空间仍然是与进程数相关的（也就是每个进程对应一组页寄存器？）。反置页表的大小只与物理内存大小，与并发进程数无关。 采用页寄存器的硬件开销会很大。所以现在的通用CPU（包括64位的CPU）没有采用这种方式，大部分还是多级页表。由于有TLB作为缓存，效率还不错。 简答题 为什么要设计非连续内存分配机制？ 提高分配的灵活性 提高内存的利用效率 方便共享、充分利用内存空间 允许一个程序使用非连续的物理地址空间 允许共享代码与数据 支持动态加载和动态链接 非连续内存分配中内存分块大小有哪些可能的选择？大小与大小是否可变? 大块好管理，小块更灵活。段式存储下，大小是可变的，且块比较大。页式存储下，大小是固定的，且块比较小。 为什么在大块时要设计大小可变，而在小块时要设计成固定大小？小块时的固定大小可以提供多种选择吗？ 固定大小好管理，多种大小比一种大小灵活。可变大小更灵活，通常可变大小也会通过对齐来减少管理难度。小块时如果大小可变，则提供的灵活性没有那么多。 什么是段、段基址和段内偏移？ 段表示访问方式和存储数据的类型等属性相同的一段地址空间。段基址是段的起始地址（线性地址）。段内偏移是地址在段内的偏移量。 段式存储管理机制的地址转换流程是什么？为什么在段式存储管理中，各段的存储位置可以不连续？这种做法有什么好处和麻烦？ 段式存储管理中，地址转换是段基址（段号）加段内偏移。 段反映了程序的存储逻辑结构（数据段和代码段是分开的），程序不会从一个段的基址去访问另一个段，于是不同的段可以不连续。 好处是可以不连续，方便内存管理；麻烦是地址转换稍微复杂了一些。 什么是页（page）、帧（frame）、页表（page table）、存储管理单元（MMU）、快表（TLB, Translation Lookaside Buffer）和高速缓存（cache）？ 页帧（帧、物理页面、Frame、Page Frame）（这是物理的） 把物理地址空间划分为大小相同的基本分配单位 大小一般为2的n次方，如512、4096、8192字节，4KB是常用大小 页面（页、逻辑页面、Page）（这是逻辑的） 把逻辑地址空间也划分为相同大小的基本分配单位 帧和页的大小必须是相同的 页表：保存了逻辑地址（页号）——物理地址（帧号）之间的映射关系 MMU：一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制，在较为简单的计算机体系结构中，负责总线的仲裁以及存储体切换 TLB：为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度 Cache：访问速度比一般随机存取内存（RAM）快的一种RAM，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术 页式存储管理机制的地址转换流程是什么？为什么在页式存储管理中，各页的存储位置可以不连续？这种做法有什么好处和麻烦？ 页式存储管理中，地址转换流程是页号-&gt;物理页帧号加页内偏移。 CPU使用连续的逻辑地址，存储访问时，逻辑地址先分成逻辑页号和页内偏移，然后通过页表定义的对应关系，把逻辑页面转换成物理页号，最后再把物理页号加页内偏移得到物理地址；于是不同的页可以不连续。 好处是可以不连续，方便内存管理中的存储分配和回收；麻烦是地址转换比较复杂（页表项访问开销和页表存储开销），并且频繁进行（每次存储访问会变成两次或更多）。 每个页表项有些什么内容？有哪些标志位？它们起什么作用？ 页表大小受哪些因素影响？ 页大小、地址空间大小、进程数目、页表级数 快表（TLB）与高速缓存（cache）有什么不同？ TLB中缓存的是线性地址&lt;-&gt;物理地址的映射关系，由硬件管理，对软件是透明的。 Cache中缓存的是具体的内存内容，也由硬件管理，对软件是透明的。 为什么快表中查找物理地址的速度非常快？它是如何实现的？为什么它的的容量很小？ 因为它是在多个表项中同步查找有没有对应的线性地址项，所以很快。TLB的硬件是怎么实现的……大概瞎写吧。容量小是因为用电路换时间了（多路并行查找），成本和耗电量比较高。 什么是多级页表？多级页表中的地址转换流程是什么？多级页表有什么好处和麻烦？ 就是套了很多层的页表。地址转换流程就是不断根据每一级的页号和页表基址查找下一级的页表基址（或者查到页表项）。 好处是减小了页表占据的空间（因为程序一般不会用完自己的虚拟地址空间，所以大部分次级页表不需要生成）；麻烦是地址转换变得更加复杂和缓慢了。 页寄存器机制的地址转换流程是什么？ 对CPU访问的逻辑地址进行hash，然后查相应页寄存器。 用快表缓存页表项后的页寄存器搜索步骤 对逻辑地址进行Hash变换 在快表中查找对应页表项 有冲突时遍历冲突项列表 查找失败时，产生异常 反置页表机制的地址转换流程是什么？ 逻辑地址和进程号共同进行hash，然后查相应页寄存器。 查找过程： 从逻辑地址中得到页号 根据页号和PID计算出Hash值 在反置页表中查找对应的页表项，核对页号是否一致，从中找出相应的物理帧号；处理hash冲突 反置页表项有些什么内容？ PID、逻辑页号、标志位（可能还应该有指向下一个hash相同的页表项的指针） 段页式存储管理机制的地址转换流程是什么？这种做法有什么好处和麻烦？ 首先从逻辑地址翻译成线性地址（段机制），再从线性地址翻译成物理地址（页机制）。 好处是……。。。 麻烦是，地址访问过程甚至变得更加复杂和耗时了。 如何实现基于段式存储管理的内存共享？ ……就把需要重用的内存映射到不同的段里…… 如何实现基于页式存储管理的内存共享？ 不同的页表项指向相同的物理页…… 请简要分析64bit CPU体系结构下的分页机制是如何实现的 说明64bit CPU架构的分页机制的大致特点和页表执行过程 正确描述了64bit CPU支持的物理内存大小限制（1分） 正确描述了64bit CPU下的多级页表的级数和多级页表的结构或反置页表的结构（2分） 除上述两点外，进一步描述了在多级页表或反置页表下的虚拟地址–&gt;物理地址的映射过程（3分） 64位的寻址空间能够寻址16EB 的内存大小，对于目前的硬件来说太大了。在X64体系结构下，只实现了48位的虚拟地址。不同于x86体系结构，每级页表寻址长度变成9位，由于在x64体系结构中，普通页大小仍为4KB，然而数据却表示64位长，因此一个4KB页在x64体系结构下只能包含512项内容，所以为了保证页对齐和以页为单位的页表内容换入换出，在x64下每级页表寻址部分长度定位9位。 为了正确翻译x64的线性地址，其页表也从x86的2级变成了4级。翻译过程可参考Intel手册或者以下链接 http://www.cnblogs.com/lanrenxinxin/p/4735027.html 某系统使用请求分页存储管理，若页在内存中，满足一个内存请求需要150ns (10-9s)。若缺页率是10%，为使有效访问时间达到0.5us(10-6s),求不在内存的页面的平均访问时间。请给出计算步骤。 500=0.9150+0.1x （2）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持32KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : VALID | PFN6 … PFN0 PDE格式（8 bit） : VALID | PT6 … PT0 其 VALID1表示，表示映射存在；VALID0表示，表示映射不存在。 PFN6…0:页帧号 PT6…0:页表的物理基址&gt;&gt;5 在物理内存模拟数据文件中，给出了4KB物理内存空间的值，请回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents。 Virtual Address 6c74 Virtual Address 6b22 Virtual Address 03df Virtual Address 69dc Virtual Address 317a Virtual Address 4546 Virtual Address 2c03 Virtual Address 7fd7 Virtual Address 390e Virtual Address 748b 比如答案可以如下表示： (注意：下面的结果是错的，你需要关注的是如何表示) Virtual Address 7570: –&gt; pde index:0x1d pde contents:(valid 1, pfn 0x33) –&gt; pte index:0xb pte contents:(valid 0, pfn 0x7f) –&gt; Fault (page table entry not valid) Virtual Address 21e1: –&gt; pde index:0x8 pde contents:(valid 0, pfn 0x7f) –&gt; Fault (page directory entry not valid) Virtual Address 7268: –&gt; pde index:0x1c pde contents:(valid 1, pfn 0x5e) –&gt; pte index:0x13 pte contents:(valid 1, pfn 0x65) –&gt; Translates to Physical Address 0xca8 --&gt; Value: 16 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，请说明原因。 （3）请基于你对原理课二级页表的理解，并参考Lab2建页表的过程，设计一个应用程序（可基于python、ruby、C、C++、LISP、JavaScript等）可模拟实现(2)题中描述的抽象OS，可正确完成二级页表转换。 链接有上面链接的参考答案。请比较你的结果与参考答案是否一致。如果不一致，提交你的实现，并说明区别。 （4）假设你有一台支持反置页表的机器，请问你如何设计操作系统支持这种类型计算机？请给出设计方案。 (5)X86的页面结构 扩展思考题 阅读64bit IBM Powerpc CPU架构是如何实现反置页表，给出分析报告。 interactive understand VM Virtual Memory with 256 Bytes of RAM：这是一个只有256字节内存的一个极小计算机系统。按作者的[[https://github.com/RobertElderSoftware/recc#what-can-this-project-do|特征描述]]，它具备如下的功能。 CPU的实现代码不多于500行； 支持14条指令、进程切换、虚拟存储和中断； 用C实现了一个小的操作系统微内核可以在这个CPU上正常运行； 实现了一个ANSI C89编译器，可生成在该CPU上运行代码； 该编译器支持链接功能； 用C89, Python, Java, Javascript这4种语言实现了该CPU的模拟器； 支持交叉编译； 所有这些只依赖标准C库。 针对op-cpu的特征描述，请同学们通过代码阅读和执行对自己有兴趣的部分进行分析，给出你的分析结果和评价。 实践题","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第5讲：“物理内存管理：连续内存分配”总结","slug":"2018-04-12-《操作系统》第5讲：“物理内存管理：连续内存分配”总结","date":"2018-04-12T21:44:44.000Z","updated":"2018-04-12T21:44:44.000Z","comments":true,"path":"post/os-mooc-lecture-5-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-5-summary/","excerpt":"","text":"课程内容概述 本节课的内容比较简单。 计算机体系结构和内存层次 地址空间和地址生成 连续内存分配 三种不同的分类策略 碎片整理 伙伴系统 uCore中的连续内存管理实现框架 计算机体系结构和内存层次 讲了一些比较抽象的东西。 计算机体系结构由CPU、内存、I/O设备、总线组成。 CPU中包括： ALU、控制逻辑 寄存器 高速缓存：加快读写速度 存储管理单元（MMU） 内存的特点： 最小访问单位是字节（8bit） 一次可以读/写4字节（32位），有地址对齐问题 内存可以分为如下层次： CPU中： L1缓存 L2缓存 这些缓存都是由硬件（MMU）来控制的，软件看不到 高速缓存未命中：（这之下由操作系统软件来控制） 内存 缺页： 外存（虚拟内存） 操作系统的内存管理 OS内存管理的特点： 每个字节有自己的物理地址 分为内存和外存 每个进程有自己用的内存片，它们自己的地址之间是可以重叠的。 MMU：将逻辑（虚拟）地址空间转换为物理地址空间 OS内存管理的目标： 抽象：逻辑地址空间 保护：独立地址空间 共享：访问相同内存（虽然和保护有一定的矛盾） 虚拟化：更大的地址空间 操作系统采用的内存管理方式： 重定位（relocation）：段地址+偏移 分段（segmentation）：程序的逻辑结构不需要连成一片，而是分成代码、数据、堆栈3块，每一块的空间就减少了；但每段的内容是连续的 分页（paging）：把内存分成最基本的单位 虚拟存储（virtual memory）：目前多数系统（如Linux）采用的是按需页式虚拟存储 内存管理方式的实现是高度依赖硬件的： 与计算机存储架构紧密耦合 MMU（内存管理单元）：处理CPU存储访问请求的硬件 （当然，我很好奇为什么重定位也算是一种内存管理方式。） 静态地址重定位：即在程序装入内存的过程中完成，是指在程序开始运行前，程序中的各个地址有关的项均已完成重定位，地址变换通常是在装入时一次完成的，以后不再改变，故成为静态重定位。 优点：无需硬件支持 缺点：1）程序重定位之后就不能在内存中搬动了；2）要求程序的存储空间是连续的，不能把程序放在若干个不连续的区域中。 动态地址重定位：不是在程序执行之前而是在程序执行过程中进行地址重定位。更确切的说，是在每次访问内存单元前才进行地址变换。动态重定位可使装配模块不加任何修改而装入内存，但是它需要硬件一定位寄存器的支持。 优点：1）目标模块装入内存时无需任何修改，因而装入之后再搬迁也不会影响其正确执行，这对于存储器紧缩、解决碎片问题是极其有利的；2）一个程序由若干个相对独立的目标模块组成时，每个目标模块各装入一个存储区域，这些存储区域可以不是顺序相邻的，只要各个模块有自己对应的定位寄存器就行。 缺点：需要硬件支持。 摘自地址重定位：静态重定位和动态重定位 地址空间和地址生成 一般来说，地址空间至少有3种： 物理地址空间：硬件支持的地址空间 起始地址0 到MAXsys 线性地址空间：CPU看到的地址 起始地址0 大小取决于地址线的宽度 逻辑地址空间：在CPU中运行的进程看到的地址 起始地址0 到MAXprog 也就是用户程序可见的地址 逻辑地址的生成需要经过如下几个过程： 高级语言程序：写出函数 编译：对源代码进行编译，成为汇编源代码，此时仍然用符号来指代函数 汇编：汇编成二进制代码，用具体地址来代替符号了，但是有一些函数还没有找到 链接：加入函数库，找到库函数的地址 重定位：程序加载时进行，视程序实际位置改变符号地址 一般来说，生成地址有几个时机： 编译时（优点：简单） 假设起始地址已知 但如果起始地址改变，就必须重新编译 功能手机一般会有这种情况 加载时 如果加载时起始位置未知，编译器需生成可重定位的代码（relocatable code） 加载时，生成绝对地址 执行时（优点：灵活） 执行时代码可移动 需地址转换（映射）硬件支持（一般是虚拟存储） 连续内存分配 一般分配给一个进程的地址空间是连续的，因此需要进行有效的内存分配。需求是，给进程分配一块不小于指定大小的连续的物理内存区域。定义碎片是过小的不能被利用的空闲内存，分为2类： 外部碎片：分配单元之间的未被使用内存 内部碎片：分配单元内部的未被使用内存（一般是否有内碎片取决于分配单元大小是否要取整） 我们在uCore中进行的是动态分区分配，需要满足以下要求： 当程序被加载执行时，分配一个进程指定大小可变的分区（块） 分区的地址是连续的 一般来说，操作系统需要维护至少2个数据结构，里面存储的内容是： 所有进程的已分配分区 空闲分区（Empty-blocks） 常见的几种连续内存分配策略包括： 最先匹配（First-fit） 最佳匹配（Best-fit） 最差匹配（worst-fit） 总的来说，这些匹配方法各有优劣，至于到底是什么优劣，与使用场景关系很大。 三种不同的分类策略 最先匹配（First Fit Allocation）策略 思路：需要分配n个字节时，使用第一个可用的空间比n大的空闲块 原理和实现： 空闲分区列表按地址顺序排序 分配时搜索第一个合适的分区 释放分区时，检查是否可与邻近的空闲分区合并 优点： 简单 在高地址空间有大块的空闲分区 缺点： 容易产生外部碎片 分配大块时较慢 最佳匹配（Best Fit Allocation）策略 思路：分配n字节内存时，查找并使用不小于n的最小空闲分区 原理和实现： 空闲分区列表按照大小排序 分配时，查找一个合适的分区 释放时，查找并合并邻近的空闲分区（如果找到） 优点： 大部分分配的尺寸较小时，效果很好 可避免大的空闲分区被拆分 可减小外部碎片的大小 相对简单 缺点： 外部碎片较多 释放分区较慢 容易产生很多无用的小碎片 最差匹配（Worst Fit Allocation）策略 思路：分配n字节时，使用尺寸不小于n的最大空闲分区 原理和实现： 空闲分区列表按由大到小排序 分配时，选最大的分区 释放时，检查是否可与邻近的空闲分区合并，进行可能的合并，并调整空闲分区列表顺序 优点： 中等大小的分配较多时，效果最好 避免出现太多的小碎片 缺点： 释放分区较慢 外部碎片较多 容易破坏大的空闲分区，因此难以分配大的分区 碎片整理 上述方法都会产生外碎片。（但是不会产生内碎片，因为是按需分配的）如果碎片太多，就有可能出现，即使空余内存总数足够大，也无法分配出一块连续内存的情况。为此就需要进行碎片整理。碎片整理的定义是通过调整进程占用的分区位置来减少或避免分区碎片。一般有两种碎片整理的方法 紧凑（compaction）通过移动分配给进程的内存分区，以合并外部碎片 进行碎片紧凑的条件：所有的应用程序可动态重定位 需要在应用程序等待时进行移动 需要考虑开销 分区对换（Swapping in/out）：通过抢占并回收处于等待状态进程的分区，以增大可用内存空间 这就让更多进程能够在内存里交替运行 需要解决的问题：交换哪个（些）进程？ swap分区在linux中是耳熟能详的，在早期很有用，但代价很大，因为外存的速度远远慢于内存 有了虚拟页式存储之后，纯粹的分区对换的意义就不大了 伙伴系统 伙伴系统（Buddy System）是一种连续存储分配的办法，它解决了分配位置和碎片的问题。 假定整个可分配的分区大小为2u2^u2u，伙伴系统的分配和释放过程如下： 分配过程： 需要的分区大小为2u−1&lt;s≤2u2^{u-1} &lt; s \\le 2^u2u−1&lt;s≤2u时，把整个块分配给该进程 若s≤2i−1−1s \\le 2^{i-1} - 1s≤2i−1−1，则将大小为2i2^i2i的当前空闲分区划分成两个大小为2i−1−12^{i-1} - 12i−1−1的空闲分区 重复划分过程，直到2i−1&lt;s≤2i2^{i-1} &lt; s \\le 2^i2i−1&lt;s≤2i，并把一个空闲分区分配给该进程 释放过程： 将进程占用的块释放 查看它能否与相邻的空闲块合并（注意边界条件） 如果能合并，则不断合并到不能再合并为止 由分析可知，内碎片的大小最多是2i−1−12^{i-1} - 12i−1−1，没有外碎片。 伙伴系统的具体实现 数据结构： 空闲块按大小和起始地址组织成二维数组（或者说一维数组+一维链表） 第一维：大小；第二维：地址 初始状态：只有一个大小为2u2^u2u的空闲块 分配过程： 由小到大 在空闲块数组中找最小的可用空闲块（只要有合适的空闲块，就不切分大块，这是隐含的一个原则吧） 如果块太大，则对可用空闲块进行二等分，直到得到合适大小的块 释放过程： 把释放的块放入空闲块数组 合并满足合并条件的空闲块，合并条件是： 大小相同，均为2i2^i2i 地址相邻 相邻两块的低地址必须是2^(i+1)的倍数 uCore中的连续内存管理实现框架 这部分就比较简略了。简单来说，uCore定义了一个struct pmm_manager的数据结构，其中保存了各种操作（如分配、释放等）对应的函数指针。因此，可以定义各种不同的管理方法函数，并把函数指针放到该结构体的实例中。这很面向对象了。下面的代码摘自lab2/kern/mm/pmm.h： 1234567891011121314// pmm_manager is a physical memory management class. A special pmm manager - XXX_pmm_manager// only needs to implement the methods in pmm_manager class, then XXX_pmm_manager can be used// by ucore to manage the total physical memory space.struct pmm_manager &#123; const char *name; // XXX_pmm_manager&apos;s name void (*init)(void); // initialize internal description&amp;management data structure // (free block list, number of free block) of XXX_pmm_manager void (*init_memmap)(struct Page *base, size_t n); // setup description&amp;management data structcure according to // the initial free physical memory space struct Page *(*alloc_pages)(size_t n); // allocate &gt;=n pages, depend on the allocation algorithm void (*free_pages)(struct Page *base, size_t n); // free &gt;=n pages with &quot;base&quot; addr of Page descriptor structures(memlayout.h) size_t (*nr_free_pages)(void); // return the number of free pages void (*check)(void); // check the correctness of XXX_pmm_manager&#125;; 然后就可以定义一个default_pmm_manager用来对内存进行管理了（lab2/kern/mm/default_pmm.c）： 123456789const struct pmm_manager default_pmm_manager = &#123; .name = &quot;default_pmm_manager&quot;, .init = default_init, .init_memmap = default_init_memmap, .alloc_pages = default_alloc_pages, .free_pages = default_free_pages, .nr_free_pages = default_nr_free_pages, .check = default_check,&#125;; 练习 选择填空题 操作系统中可采用的内存管理方式包括() 重定位(relocation) 分段(segmentation 分页(paging) 段页式（segmentation+paging） 都有。虽然我还是很难想象重定位是内存管理方式，这难道不是进程的管理方式么，虽然能够把进程在内存中搬移大概是上述几种分配策略的前提…… 在启动页机制的情况下，在CPU运行的用户进程访问的地址空间是() 物理地址空间 逻辑地址空间 外设地址空间 都不是 用户进程访问的内存地址是虚拟地址。虚拟地址加上对应的段选择子构成逻辑地址。逻辑地址经过分段翻译成线性地址。线性地址经过分页翻译成物理地址。（但是，即使没有启动页机制，用户进程访问的地址空间也应该是逻辑地址空间吧） 连续内存分配的算法中，会产生外碎片的是() 最先匹配算法 最差匹配算法 最佳匹配算法 都不会 三种算法都会有外碎片，而没有内碎片。相比之下，分页不会有外碎片，只会有内碎片。伙伴系统是可能会产生外碎片的，当然也有内碎片。 在使能分页机制的情况下，更合适的外碎片整理方法是() 紧凑(compaction) 分区对换(Swapping in/out) 都不是 分页方式不会有外碎片。虽然很对，但这道题完全毫无意义。 描述伙伴系统(Buddy System)特征正确的是() 多个小空闲空间可合并为大的空闲空间 会产生外碎片 会产生内碎片 都不对 小空闲空间在满足一定条件时可以合并。因为是一个不断二分的过程，所以外碎片是可能会产生的。因为是分配2的幂大小的内存，所以内碎片也是有的。 简答题 操作系统中存储管理的目标是什么？ 抽象 保护 共享 虚拟化 描述编译、汇编、链接和加载的过程是什么？ 编译：将程序源代码转换为汇编代码 汇编：将汇编代码转为二进制的机器码 链接：将多个二进制的机器码结合成一个可执行环境 加载：将程序从外存中加载到内存中 这几个过程并不是完全分开的，例如动态加载的库通常在加载过程中进行链接。 详细过程可参考：http://blog.csdn.net/ajianyingxiaoqinghan/article/details/70889362 什么是内碎片、外碎片？ 内碎片是指分配给任务的内存大小比任务所要求的大小所多出来的内存。外碎片指分配给任务的内存之间无法利用的内存。当然，一块内存是否为外碎片取决于需要分配的内存的大小。 最先匹配会越用越慢吗？请说明理由（可来源于猜想或具体的实验）？ 最先匹配总是先找低地址空间的内存，到后期低地址空间都是大量小的不连续的内存空间，每次都要扫描低地址空间后到达高地质空间才能得到可用的内存。所以大概是会越用越慢的。 最差匹配的外碎片会比最优适配算法少吗？请说明理由（可来源于猜想或具体的实验） 应该会的。因为每次都找到最大的内存块进行分割，因此分割剩下的内存块也很大，往往还可以再装下一个程序。 理解0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm算法中分区释放后的合并处理过程？ (optional) 它们的处理方式都是查看边上是否也有空闲块，如果有，则合并空闲块，然后将空闲块管理数据插入链表中。如果能进行合并，都需要连续合并。当然，伙伴系统的合并过程需要判断是否满足条件。 对换和紧凑都是碎片整理技术，它们的主要区别是什么？为什么在早期的操作系统中采用对换技术？ 区别是，紧凑是在内存中搬动进程占用的内存位置，以合并出大块的空闲块；对换是把内存中的进程搬到外存中，以空出更多的内存空闲块。采用对换的原因是，处理简单。不过代价也比较高，因为外存比较慢。 一个处于等待状态的进程被对换到外存（对换等待状态）后，等待事件出现了。操作系统需要如何响应？ 将进程从硬盘中读取到内存中，在这个过程中，操作系统将该进程标为等待状态并且调度其他进程。 这道题似乎大跃进到第11讲的等待进程模型了。总之，就是进程从等待挂起状态转换到就绪挂起状态，然后在优先级足够高的时候从硬盘读入到内存，进入就绪状态，然后运行。当然，这个做法在现代操作系统里已经凉了。 伙伴系统的空闲块如何组织？ 按照内存的大小由一系列链表组织。类似于哈希表，将相同大小的内存区域首地址连接起来。（因为一般来说，内存要按首地址大小排列，链表的插入删除比较简单啊） 伙伴系统的内存分配流程？ 当向内核请求分配(2i−1，2i](2^{i-1}，2^i](2i−1，2i]数目的页块时，按照2i2^i2i大小的块来请求处理。如果对应的块链表中没有空闲页块，则在更大的页块链表中找空闲块，并将大块进行切分，直到得到满足要求的块。如果切出了多余的块，伙伴系统会将这些块插入到对应的空闲页块链表中。 伙伴系统的内存回收流程？ 当释放多页的块时，内核首先计算出该内存块的伙伴的地址。内核将满足以下条件的三个块称为伙伴： 两个块具有相同的大小，记作b。 它们的物理地址是连续的。 第一块的第一个页的物理地址是2∗(2b)2 * (2^b)2∗(2b)的倍数。 如果找到了该内存块的伙伴，确保该伙伴的所有页都是空闲的，以便进行合并。内存继续检查合并后页块的“伙伴”并检查是否可以合并，依次类推。 （所以才叫伙伴系统，了解了） 实践题 动态链接如何使用？尝试在Linux平台上使用LD_DEBUG查看一个C语言Hello world的启动流程。 编译链接和加载 LD_DEBUG 是Linux平台查看程序运行加载库的重要工具，其可以详细的列出程序执行时如何加载相应符号的。 通过LD_DEBUG =help查看如何使用, LD_DEBUG=all ./hello 完成题目 显然这道题我没有做。 观察最先匹配、最佳匹配和最差匹配这几种动态分区分配算法的工作过程，并选择一个例子进行分析分析整个工作过程中的分配和释放操作对维护数据结构的影响和原因。 请参考xv6（umalloc.c），ucore lab2代码，选择四种（0:最优匹配，1:最差匹配，2:最先匹配，3:buddy systemm）分配算法中的一种或多种，在Linux应用程序/库层面，用C、C++或python来实现malloc/free，给出你的设计思路，并给出可以在Linux上运行的malloc/free实现和测试用例。 可参考：https://github.com/shellphish/how2heap 阅读slab分配算法，尝试在应用程序中实现slab分配算法，给出设计方案和测试用例。 可参考： https://github.com/bbu/userland-slab-allocator","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第4讲：“实验1-系统软件启动过程”总结","slug":"2018-04-12-《操作系统》第4讲：“实验1-系统软件启动过程”","date":"2018-04-12T15:45:23.000Z","updated":"2018-04-12T15:45:23.000Z","comments":true,"path":"post/os-mooc-lecture-4-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-4-summary/","excerpt":"","text":"课程内容概述 这节课主要介绍了一些和Lab1相关的内容。 系统启动过程 BIOS bootloader 段机制 操作系统的加载 C语言的一些相关知识 函数调用的实现 GCC内联汇编 x86架构下的中断处理过程 系统启动过程 BIOS BIOS的工作过程已经在《操作系统》第3讲：“启动、中断、异常和系统调用”总结中详细说过了，在此不再重复。唯一值得注意的是，虽然实模式下的寻址方式是Base（16位寄存器CS）* 16 + Offset（16位寄存器IP）=线性地址（20位），但是这并不是段机制。 bootloader BIOS将控制权转交给bootloader（见lab1/boot文件夹下的内容）。它的工作内容主要包括： 使能保护模式（protection mode）和段机制（segment level protection），切换到32位4G的寻址空间，对段机制进行初始化 从硬盘上读取ELF格式的ucore kernel（位于MBR后面的扇区）并放到内存中固定位置 跳转到ucore OS的入口点（entry point），将控制权转交给ucore OS 使能保护模式 将系统寄存器CR0的第0个bit置为1，说明进入保护模式。当然，在此之前要开A20，并准备好GDT表，将基址加载到GDT基址寄存器中。 段机制 保护模式下必须开启段机制。所以讲一下段机制的原理。具体可以参见Intel80X86架构：保护模式下的内存管理。 总的来说，段机制其实是一种映射关系。一个段指向的是线性地址空间中一段连续的内存，有基址和limit。段与段之间是可以重叠的。 设置段机制的方法是，建立一个数组来存储段描述符表，称为全局描述符表GDT（也称为段表，在ucore中是由bootloader建立的，因为开启保护模式之前就需要设置好GDT），其中包括段描述符表的位置、大小等信息；这样CPU就可以找到段表了（用GDTR寄存器保存段表信息）。除了设置GDT之外，还要为CS、DS等段寄存器设置好对应的Index，使它们能够指向全局描述符表GDT对应的项，这可以在切换到保护模式之后进行。 硬件提供了一些段寄存器。这些段寄存器指向段描述符，比较重要的几个段寄存器包括： CS：代码段寄存器 DS：数据段寄存器 SS：堆栈段寄存器 段寄存器的结构是这样的： 高13位：GDT index 1位：TI，一般设置为0，因为没有用到LDT（本地描述符表） 2位：RP，表明段优先级，有4个特权级，一般应用程序放在3，操作系统放在0 每个段寄存器指向一个GDT或LDT中的段描述符。段描述符描述了一个段的起始地址和它的大小。（一个段描述符的大小是8字节，具体内容比较复杂，不过知道这两点差不多就够了） uCore中采用的应该是Intel手册中提到的扁平保护模型。 在设置完所需的表和寄存器之后，段机制就可以完成从逻辑地址到线性地址（在页机制没有开启的时候，线性地址=物理地址）的翻译了。具体的翻译过程如下图： 通过逻辑地址中的段选择子查找段描述符表项 从表项中读出段基址和段的大小 检查逻辑地址中的offset是否合法 安全性检查（这里还没有讲到） 段基址（Base Address）+段内偏移量（offset）=线性地址（linear address） 操作系统的加载 操作系统的加载过程其实就是把ELF文件中的内容填到合适的位置。ELF文件的开头是一个ELF Header，结构如下： 123456789101112131415161718/* file header */struct elfhdr &#123; uint32_t e_magic; // must equal ELF_MAGIC uint8_t e_elf[12]; uint16_t e_type; // 1=relocatable, 2=executable, 3=shared object, 4=core image uint16_t e_machine; // 3=x86, 4=68K, etc. uint32_t e_version; // file version, always 1 uint32_t e_entry; // entry point if executable uint32_t e_phoff; // file position of program header or 0 uint32_t e_shoff; // file position of section header or 0 uint32_t e_flags; // architecture-specific flags, usually 0 uint16_t e_ehsize; // size of this elf header uint16_t e_phentsize; // size of an entry in program header uint16_t e_phnum; // number of entries in program header or 0 uint16_t e_shentsize; // size of an entry in section header uint16_t e_shnum; // number of entries in section header or 0 uint16_t e_shstrndx; // section number that contains section name strings&#125;; 其中比较重要的变量是e_phoff（第一个Program Header的地址），e_phnum（文件中共有几个Program Header）和e_magic（用来检验该Header是否合法）。bootmain.c中的代码首先读一页（主引导扇区之后的8个扇区），得到ELF Header；然后，通过上述变量，可以依次访问各个Program Header。 1234567891011/* program section header */struct proghdr &#123; uint32_t p_type; // loadable code or data, dynamic linking info,etc. uint32_t p_offset; // file offset of segment uint32_t p_va; // virtual address to map segment uint32_t p_pa; // physical address, not used uint32_t p_filesz; // size of segment in file uint32_t p_memsz; // size of segment in memory (bigger if contains bss） uint32_t p_flags; // read/write/execute bits uint32_t p_align; // required alignment, invariably hardware page size&#125;; 然后通过每个Progeam Header中的ph-&gt;p_memsz（一个代码段的大小）和ph-&gt;p_offset（一个代码段的虚地址），可以从磁盘中读出对应内容，并存储到内存的对应位置（虚地址处）。 C语言的一些相关知识 函数调用的实现 将需要保存的寄存器入栈，调用函数，然后将需要保存的寄存器出栈 EBP指向的是栈底，其中保存的是调用者的EBP；ESP指向的是栈顶； 调用时会把返回地址也入栈，在EBP下面，再下面是参数 其他注意事项： 参数和函数返回值可以通过寄存器或位于内存中的栈来传递 不需要保存/恢复（save/restore）所有寄存器（因为寄存器按传统分为caller save和callee save两类） GCC内联汇编 内联汇编的完整格式如下： 12345asm (assembler template // 字符串 : output operands (optional) // 约束：把某个变量用某个寄存器来表示 : input operands (optional) : clobbers (optional)); 例1：不带任何约束的简单内联汇编 内联汇编： 1asm(&quot;movl $0xffff, %%eax\\n&quot;) 生成的汇编： 1movl $0xffff, %eax 例2：使用特定寄存器和约束的内联汇编 内联汇编代码： 1234uint32_t cr0;asm volatile(&quot;movl %%cr0, %0\\n&quot; : &quot;=r&quot;(cr0)); // %0寄存器对应的变量是cr0cr0 |= 0x80000000;asm volatile(&quot;movl %0, %%cr0\\n&quot; :: &quot;r&quot;(cr0)); // 把cr0变量中的值赋给cr0寄存器 生成的汇编代码： 12345movl %cr0, %ebxmovl %ebx, 12(%esp)ori $-2147483648, 12(%esp)movl 12(%esp), %eaxmovl %eax, %cr0 其中关键字的含义如下： volatile：不需要做进一步优化和调整顺序 %0：第一个约束 r：约束：GCC可以使用任意寄存器 例3：使用内联汇编触发系统中断 内联汇编代码： 1234long __res, arg1=2, arg2=22, arg3=222, arg4=233;__asm__ volatile(&quot;int $0x80&quot; : &quot;=a&quot; (__res) : &quot;0&quot;(11), &quot;b&quot;(arg1), &quot;c&quot;(arg2), &quot;d&quot;(arg3), &quot;S&quot;(arg4)); 生成的汇编代码： 1234567movl $11, %eaxmovl -28(%ebp), %ebxmovl -24(%ebp), %ecxmovl -20(%ebp), %edxmovl -16(%ebp), %esiint $0x80 ## 产生软中断movl %edi, -12(%ebp) 其中约束条件的含义如下： a=%eax b=%ebx c=%ecx d=%edx S=%esi D=%edi 0=和第一个寄存器相同 x86架构下的中断处理过程 此处的“中断”包括两类： 中断（Interrupts） 外部中断（External (hardware generated) interrupts）：串口、硬盘、网卡、时钟 软件产生的中断（Software generated interrupts）：INT n指令，通常用于系统调用 异常（Exceptions） 程序错误 软件产生的异常（Software generated exception）：INTO，INT 3和BOUND 机器检查出的异常 通过中断号确定中断服务例程（ISR） IDT是由操作系统分配的（Lab1的其中一个练习），在分配完空间并填充好IDT之后，需要用特权指令填充中断描述符表寄存器IDTR。 一般来说，每个中断或异常都有一个中断号，每个中断号与一个中断服务例程（Interrupt Service Routine，ISR）关联，其关联关系存储在中断描述符表（Interrupt Descriptor Table，IDT）中。IDT的每一项称为“中断门”或“陷阱门”。IDT的起始地址和大小保存在中断描述符表寄存器IDTR中，地址的表示也需要用到GDT（地址与段相关）。 IDT表中一般可能会含有三种门：中断门、陷阱门和任务门（目前没有用到），每一种门的格式如下： 可以看出，中断门和陷阱门的格式类似，其中的核心内容包括： 段选择子：16位，表示ISR所在的段 段内偏移量：32位，表示ISR地址在段内的偏移量 DPL：用于进行安全性检查（现在还没用到） 可以看出，IDT表项实质上就是存储了很多ISR的逻辑地址。通过IDT和GDT（或LDT）访问ISR的过程如下图： 调用ISR和从ISR返回的过程 中断服务例程的调用和返回这个过程是非常重要的。因为它是用户态进程获得（或者强制进入）OS服务的唯一途径，所以需要进行现场的保存和特权级的切换。这个是非常重要的。 Intel手册6.12.1节“Exception- or Interrupt-Handler Procedures”中说，处理器调用中断服务例程的过程是这样的： 如果该中断服务例程将运行在一个更高的特权级下，则会发生栈切换，过程如下： 从当前执行任务的TSS中获得ISR将会使用的段选择子和栈指针，将被打断的程序的堆栈段选择子和栈指针压入新栈中 处理器随后将EFLAGS、CS和EIP寄存器的当前值也压入新栈中 如果异常有错误码，则将错误码也压入栈中，位于EIP寄存器的值之后 如果该中断服务例程的特权级不变： 处理器直接将EFLAGS、CS和EIP寄存器的当前值压入当前栈中 如果异常有错误码，则将错误码也压入栈中，位于EIP寄存器的值之后 下图展示了这一过程（注意栈是向下增长的）： 从中断服务例程返回时，必须使用IRET（或IRETD）指令。IRET指令类似于RET指令，但是它会对保存的寄存器和EFLAGS进行恢复（EFLAGS可能会进行一些修改）。如果调用中断服务例程时发生了栈切换，则IRET指令会在返回时切换回被打断的程序的栈。 系统调用 系统调用的实现方法是： 指定中断号 使用Trap 或使用特殊指令（SYSENTER/SYSEXIT） 练习 选择填空题 80386机器加电启动后，CPU立刻跳转到()执行 ucore第一条指令 bootloader第一条指令 BIOS的第一条指令 GRUB的第一条指令 加电后的第一条指令是长跳转指令，跳到BIOS去执行。 应用程序中的C函数调用中不需要用到()指令 push ret iret call iret用于中断服务例程返回。应用程序编写不需要用到IRET。 GCC内联汇编 asm(“movl %ecx, %eax”); 的含义是() 把 ecx 内容移动到 eax 把 eax 内容移动到 ecx 答案是把 ecx 内容移动到 eax。这是显然的AT&amp;T汇编语法。 为了让系统正确完成80386的中断处理过程，操作系统需要正确设置() 全局描述符表 中断描述符表 中断服务例程 内核堆栈 在ucore处理中，上述几个都是要设置好的。显然ISR是必须准备好的。因为中断服务例程会使用内核栈，所以内核堆栈也要设置。发生中断时，硬件通过IDT找到中断号对应的中断描述符，再根据其中的ISR的逻辑地址，通过GDT或LDT得到ISR的线性地址。 简答题 段寄存器的字段含义和功能有哪些？ 代码段寄存器 CS（Code Segment）存放当前正在运行的程序代码所在段的段基址，表示当前使用的指令代码可以从该段寄存器指定的存储器段中取得，相应的偏移量则由IP提供 数据段寄存器 DS（Data Segment）指出当前程序使用的数据所存放段的最低地址，即存放数据段的段基址 堆栈段寄存器 SS（Stack Segment）指出当前堆栈的底部地址，即存放堆栈段的段基址 附加段寄存器 ES（Extra Segment）指出当前程序使用附加数据段的段基址，该段是串操作指令中目的串所在的段 附加段寄存器 FS 附加段寄存器 GS 常用的就是CS、DS和SS。 描述符特权级DPL、当前特权级CPL和请求特权级RPL的含义是什么？在哪些寄存器中存在这些字段？对应的访问条件是什么？ 参见DPL,RPL,CPL 之间的联系和区别一文中对特权级的表述。 CPL是当前进程的权限级别(Current Privilege Level)，是当前正在执行的代码所在的段的特权级，存在于cs寄存器的低两位。 RPL说明的是进程对段访问的请求权限(Request Privilege Level)，是对于段选择子而言的，每个段选择子有自己的RPL，它说明的是进程对段访问的请求权限，有点像函数参数。而且RPL对每个段来说不是固定的，两次访问同一段时的RPL可以不同。RPL可能会削弱CPL的作用，例如当前CPL=0的进程要访问一个数据段，它把段选择符中的RPL设为3，这样虽然它的CPL=0对该段仍然只有特权为3的访问权限。 DPL存储在段描述符中，规定访问该段的权限级别(Descriptor Privilege Level)，每个段的DPL固定。 对数据段和堆栈段访问时的特权级控制：要求访问数据段或堆栈段的程序的CPL≤待访问的数据段或堆栈段的DPL，同时选择子的RPL≤待访问的数据段或堆栈段的DPL，即程序访问数据段或堆栈段要遵循一个准则：只有相同或更高特权级的代码才能访问相应的数据段。这里，RPL可能会削弱CPL的作用，访问数据段或堆栈段时，默认用CPU和RPL中的最小特权级去访问数据段，所以要求max{CPL, RPL} ≤ DPL，否则访问失败。 分析可执行文件格式elf的格式（无需回答） ELF header的格式 文档：Header 代码 proghdr的格式分析 文档：Program header 代码 中断处理中硬件压栈内容？用户态中断和内核态中断的硬件压栈有什么不同？ 参见实验指导书中断与异常部分。当然，上面已经讲得非常详细了。 为什么在用户态的中断响应要使用内核堆栈？ 保护中断服务例程代码的安全。 粗略地思考一下，虽然ISR需要在内核态下执行，使用用户态堆栈也不是不可以。代码安全这个我现在是想不清楚了。 trap类型的中断门与interrupt类型的中断门有啥设置上的差别？如果在设置中断门上不做区分，会有什么可能的后果? 调用Interrupt Gate时，Interrupt会被CPU自动禁止 调用Trap Gate时，CPU则不会去禁止或打开中断，而是保留它原来的样子 如果在设置上不做区分，会导致重复触发中断。 硬件中断是可以嵌套的，但指的并不是在处理一个硬件中断的过程中把这个过程打断，而是先关掉中断，处理完当前中断之后再顺序处理下一个。 在kdebug.c文件中用到的函数read_ebp是内联的，而函数read_eip不是内联的。为什么要设计成这样？ ebp可以直接获得，若不内联，则会因为函数调用对栈的修改而得到错误的ebp值。而由于没有直接获取eip值的指令，我们需要利用call指令将eip压栈的特性，通过调用read_eip函数来读出压在栈上的eip的值。若将read_eip内联，则不会有函数调用存在，无法获得eip的值。 123456static __noinline uint32_tread_eip(void) &#123; uint32_t eip; asm volatile(&quot;movl 4(%%ebp), %0&quot; : &quot;=r&quot; (eip)); return eip;&#125; CPU加电初始化后中断是使能的吗？为什么？ 不是。CPU启动后，BIOS会在POST自检完成后在内存中建立中断向量表和中断服务程序。 主要还是因为这个时候还在实模式下，根本没有处理普通中断的能力。不过，在实模式下，需要通过某些中断的手段来实现输入输出，这些方法都不能在保护模式下使用。 如何修改lab1, 实现在出现除零异常时显示一个字符串的异常服务例程？ 在lab1/bin目录下，通过objcopy -O binary kernel kernel.bin可以把elf格式的ucore kernel转变成体积更小巧的binary格式的ucore kernel。为此，需要如何修改lab1的bootloader, 能够实现正确加载binary格式的ucore OS？ (hard) GRUB是一个通用的bootloader，被用于加载多种操作系统。如果放弃lab1的bootloader，采用GRUB来加载ucore OS，请问需要如何修改lab1, 能够实现此需求？ (hard) – 如果没有中断，操作系统设计会有哪些问题或困难？在这种情况下，能否完成对外设驱动和对进程的切换等操作系统核心功能？ 课堂实践 在Linux系统的应用程序中写一个函数print_stackframe()，用于获取当前位置的函数调用栈信息。实现如下一种或多种功能：函数入口地址、函数名信息、参数调用参数信息、返回值信息。 在ucore内核中写一个函数print_stackframe()，用于获取当前位置的函数调用栈信息。实现如下一种或多种功能：函数入口地址、函数名信息、参数调用参数信息、返回值信息。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第3讲：“启动、中断、异常和系统调用”总结","slug":"2018-04-12-《操作系统》第3讲：“启动、中断、异常和系统调用”总结","date":"2018-04-12T11:15:12.000Z","updated":"2018-04-12T11:15:12.000Z","comments":true,"path":"post/os-mooc-lecture-3-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-3-summary/","excerpt":"","text":"课程内容概述 这节课的主要内容包括： 系统启动过程 BIOS的原理 BIOS的一些具体工作 系统启动规范 中断，异常和系统调用 中断 系统调用 系统启动过程 BIOS的基本功能 计算机刚刚启动时的内存布局如图： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM 1MB ~ (4GB - 64KB) 空闲空间 640KB ~ 1MB 视频内存，BIOS启动固件（映射） 0 ~ 640KB 空闲空间 （这是一个非常简略的示意图，具体请见Memory Map (x86)） 这一复杂的映射机制是为了保证向后兼容而设计的。在8086时代，内存只有1MB大小，此时，BIOS的代码固化在EPROM中，且EPROM被编址在1MB内存地址空间的最高64KB中。PC加电后，CS寄存器初始化为0xF000，IP寄存器初始化为0xFFF0，所以CPU要执行的第一条指令的地址为CS:IP=0xF000:0XFFF0（ Segment:Offset表示） =0xFFFF0（ Linear表示） 。这个地址位于被固化的EPROM中，该地址存储了一条指令，它是一个长跳转指令JMP F000:E05B。这样就开启了BIOS的执行过程。 到了32位的80386 CPU时代，内存空间扩大到了4G，多了段机制和页机制。如果仍然把BIOS启动固件编址在0xF0000起始的64KB内存地址空间内，就会把整个物理内存地址空间隔离成不连续的两段，一段是0xF0000以前的地址，一段是1MB以后的地址，这很不协调。为此，intel采用了一个折中的方案：默认将执行BIOS ROM编址在32位内存地址空间的最高端，即位于4GB地址的最后一个64KB内。在PC系统开机复位时，CPU进入实模式，并将CS寄存器设置成0xF000，将它的shadow register的Base值初始化设置为0xFFFF0000，EIP寄存器初始化设置为0x0000FFF0。所以机器执行的第一条指令的物理地址是0xFFFFFFF0。80386的BIOS代码也要和以前8086的BIOS代码兼容，故地址0xFFFFFFF0处的指令还是一条长跳转指令jmp F000:E05B。注意，这个长跳转指令会更新CS寄存器和它的shadowregister，即执行jmp F000:E05B后，CS将被更新成0xF000。表面上看CS其实没有变化，但CS的shadow register被更新为另外一个值了，它的Base域被更新成0x000F0000，此时形成的物理地址为Base+EIP=0x000FE05B，这就是CPU执行的第二条指令的地址。此时这条指令的地址已经是1M以内了，且此地址不再位于BIOS ROM中，而是位于RAM空间中。由于Intel设计了一种映射机制，将内存高端的BIOS ROM映射到1MB以内的RAM空间里，并且可以使这一段被映射的RAM空间具有与ROM类似的只读属性。所以PC机启动时将开启这种映射机制，让4GB地址空间的最高一个64KB的内容等同于1MB地址空间的最高一个64K的内容，从而使得执行了长跳转指令后，其实是回到了早期的8086 CPU初始化控制流，保证了向下兼容。 上述说明指出，在CPU启动之后，它处于实模式之下，执行的第一条指令是jmp F000:E05B，跳转到BIOS程序中。此时，PC = 16*CS + IP，系统地址空间只有20位（1MB）。 • 20位地址空间：1MB 这之后BIOS会进行以下工作： 在实模式下提供基本输入输出方法 通过中断调用实现 只能在实模式下使用，操作系统不能使用 运行自检程序 用户选择引导设备（从什么介质启动） 将bootloader从磁盘的引导扇区加载到内存中0x7c00开始的位置 跳转到bootloader的位置：CS:IP=0000:7c00 • 系统设置信息： • 开机后自检程序 • 系统自启动程序等 这之后，控制权就交给bootloader： 切换到保护模式 将操作系统的代码和数据从硬盘加载到内存中（因为BIOS无法处理硬盘的文件系统） 跳转到操作系统的起始地址 加载之后的内存布局如下表： 地址 用途 (4GB - 64KB) ~ 4GB 实际BIOS ROM ? ~ (4GB - 64KB) 空闲空间 1MB ~ ? 操作系统 640KB ~ 1MB 视频内存，BIOS启动固件（映射） ? ~ 640KB 空闲空间 0x7c00 ~ ? bootloader 0 ~ 0x7c00 BIOS数据 最后，bootloader把控制权转交给操作系统。 BIOS的一些具体工作 上面这些听起来都很不错，但是课程中还涉及了很多烦人的细节。姑且摘录如下： BIOS本身的初始化内容 包括： 硬件自检POST 检测系统中内存和显卡等关键部件的存在和工作状态 查找并执行显卡等接口卡BIOS，进行设备初始化 执行系统BIOS，进行系统检测：检测和配置系统中安装的即插即用设备 更新CMOS中的扩展系统配置数据ESCD 按指定启动顺序从硬盘、软盘等设备启动 BIOS如何读取bootloader Wiki上是这么说的： 系统开机或者重启。 BIOS加电（台湾用语：开机）自检（Power On Self Test – POST）。BIOS执行内存地址为FFFF:0000H处的跳转指令，跳转到固化在ROM中的自检程序处，对系统硬件（包括内存）进行检查。 读取主引导记录（MBR）。当BIOS检查到硬件正常并与CMOS中的设置相符后，按照CMOS中对启动设备的设置顺序检测可用的启动设备。BIOS将相应启动设备的第一个扇区（也就是MBR扇区）读入内存地址为0000:7C00H处。 检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，若不等于则转去尝试其他启动设备，如果没有启动设备满足要求则显示&quot;NO ROM BASIC&quot;然后死机。 当检测到有启动设备满足要求后，BIOS将控制权交给相应启动设备。启动设备的MBR将自己复制到0000:0600H处，然后继续执行。 根据MBR中的引导代码启动引导程序。 事实上，BIOS不仅检查0000:7DFEH-0000:7DFFH（MBR的结束标志位）是否等于55AAH，往往还对磁盘是否有写保护、主引导扇区中是否存在活动分区等进行检查。如果发现磁盘有写保护，则显示磁盘写保护出错信息；如果发现磁盘中不存在活动分区，则显示类似如下的信息“Remove disk or other media Press any key to restart”。 我觉得这个wiki讲得十分清楚，所以就不摘录课件内容了。 标准MBR的结构如下： 地址（十进制） 描述 长度（字节） 0 代码区 440（最大446） 440 选用磁盘标志 4 444 一般为空值; 0x0000 2 446 标准MBR分区表规划（四个16 byte的主分区表入口） 64 510 MBR有效标志：0x55AA 2 系统启动规范 课程中还讲到了BIOS-MBR、BIOS-GPT、PXE和UEFI等系统启动规范，其中UEFI似乎还更重要一点。这似乎是通用的现代BIOS标准。 中断、异常和系统调用 首先下个定义： 系统调用（system call）：应用程序主动向操作系统发出的服务请求 异常（exception）：非法指令或其他原因导致当前指令执行失败（如：内存出错）后的处理请求 中断（hardware interrupt）：来自硬件设备的处理请求 它们的相同之处是，采用的处理方式大致相同。无论是发生异常、中断，还是系统调用，都需要由硬件保存现场和中断号，转到内核态，进入中断向量表，查找对应的设备驱动程序地址（异常）、异常服务例程地址（异常），或找到系统调用表，并在其中查找对应的系统调用实现的起始地址。处理完毕之后，再进行现场的切换，回到用户态继续执行程序（如果可以继续的话）。 它们的区别如下表： 源头 响应方式 处理机制 中断 外设 异步 持续，对用户应用程序是透明的 异常 应用程序或内核意想不到的行为 同步 杀死或重新执行意想不到的应用程序指令 系统调用 应用程序请求操作提供服务 异步或同步 等待和持续 这三者的处理有时可以嵌套，有时不可以。Intel手册中把中断、异常和系统调用分为Benign、Contributry和Page Fault三类： 其中8号异常没有列在分类中，因为它是就是Double Fault的中断号。当嵌套中断/异常发生时，根据种类的不同，处理方式也有所不同： 从中可以了解很多有趣的事实。比如，硬件中断“Device Not Available”和系统调用都属于Benign类，因此它们可以和任何其他中断/异常进行嵌套；而Page Fault就不可嵌套（很有道理；如果连缺页服务例程自己都缺页了，那根本就没法解决）。 （以上内容也参考了Double Fault &amp; Triple Fault一文） 相比于用户态的函数调用，中断和异常的开销是比较大的，因为它们需要进行： 特权级的切换 建立内核堆栈 验证参数的合法性（防止对内核的恶意攻击） 内核态需要映射到用户态的地址空间（因为需要访问用户程序的一些内容），因此需要更新页面映射权限 内核态也拥有独立的地址空间，因此TLB会失效 中断的具体处理机制 中断处理的过程需要软件和硬件的配合（虽然系统调用和异常也是……） 硬件处理内容包括： 在CPU初始化时设置中断使能标志 依据内部或外部事件设置中断标志 依据中断向量调用对应的中断服务例程 软件处理内容包括： 现场保存（编译器） 中断服务处理（服务例程） 清除中断标记（服务例程）（系统调用只占用一个中断向量，另有系统调用表） 现场恢复（编译器） 系统调用 系统调用的特点 系统调用是操作系统服务的编程接口 通常由高级语言编写（C或C++） 程序访问系统调用通常是通过高层次的API接口（比如封装到标准C库—）而不是直接进行系统调用 3种最常用的应用程序编程接口（API）： Win32 API：Windows POSIX API：UNIX、LINUX、Mac OS X Java API：用于JAVA虚拟机（JVM），是对实际系统调用的进一步抽象 系统调用的实现 每个系统调用对应一个系统调用号 系统调用接口根据系统调用号来维护表的索引 系统调用接口调用内核态中的系统调用功能实现，并返回系统调用的状态和结果 用户不需要知道系统调用的实现 需要设置调用参数和获取返回结果 操作系统接口的细节大部分都隐藏在应用编程接口后 通过运行程序支持的库来管理 注意，系统调用时，堆栈需要切换（内核和用户程序使用的是不同的堆栈），特权级需要进行转换。 uCore中系统调用的具体实现 以read(fd, buffer, length)的实现为例： 用vectors.S中的内容填充IDT表 发生系统调用时，硬件访问IDT表后，跳转到中断服务例程，对中断进行具体处理 kern/trap/trapentry.S:alltraps()：中断服务例程 kern/trap/trap.c:trap()：针对中断类型进行具体处理 tf-&gt;trapno == T_SYSCALL：中断类型为系统调用，调用具体的系统调用处理函数 kern/syscall/syscall.c:syscall()：进行系统调用 tf-&gt;tf_regs.reg_eax == SYS_read：读eax（系统调用编号），得到具体是哪个系统调用 kern/syscall/syscall.c:sys_read()：处理SYS_READ系统调用，从tf-&gt;sp获取堆栈中的参数（fd, buf, length） kern/fs/sysfile.c:sysfile_read()：SYS_READ系统调用的更具体实现，读取文件，直接操纵驱动程序 kern/trap/trapentry.S:trapret()：中断处理返回，将所需内容返回给用户态 习题 来自lec 3 SPOC Discussion。 简答题 BIOS从磁盘读入的第一个扇区是是什么内容？为什么没有直接读入操作系统内核映像？ BIOS完成硬件初始化和自检后，会根据CMOS中设置的启动顺序启动相应的设备，这里假定按顺序系统要启动硬盘。但此时，文件系统并没有建立，BIOS也不知道硬盘里存放的是什么，所以BIOS是无法直接启动操作系统。另外一个硬盘可以有多个分区，每个分区都有可能包括一个不同的操作系统，BIOS也无从判断应该从哪个分区启动，所以对待硬盘，所有的BIOS都是读取硬盘的0磁头、0柱面、1扇区的内容，然后把控制权交给这里面的MBR (Main Boot Record）。 我认为上述答案并不十分确切。比如，在uCore中，虽然BIOS没有建立文件系统，bootloader也没有建立文件系统啊。但是，加载操作系统是个很复杂的过程：就比如uCore，我们需要完成对ELF文件格式的解析和文件本身的读入。BIOS工作在实模式，本身访存范围只有1MB（能使用的数据只有0 ~ 0x7c00的范围），而且代码长度被限制在64KB。为了将OS读入到高地址的内存中，需要BIOS进行模式的切换。但是，如果BIOS进行了实模式到保护模式的切换，就不能实现向后兼容了。而且不同的OS的文件格式和处理方法也有差异，这会导致BIOS十分复杂。因此，让OS提供自己的启动程序是最好的选择。 比较UEFI和BIOS的区别。 统一可扩展固件接口 (Unified Extensible Firmware Interface, UEFI) 是一种个人电脑系统规格，用来定义操作系统与系统固件之间的软件界面，作为BIOS的替代方案。 UEFI启动对比BIOS启动的优势有三点： 安全性更强：UEFI启动需要一个独立的分区，它将系统启动文件和操作系统本身隔离，可以更好的保护系统的启动； 启动配置更灵活：EFI启动和GRUB启动类似，在启动的时候可以调用EFIShell，在此可以加载指定硬件驱动，选择启动文件。比如默认启动失败，在EFIShell加载U盘上的启动文件继续启动系统； 支持容量更大：传统的BIOS启动由于MBR的限制，默认是无法引导超过2TB以上的硬盘的。随着硬盘价格的不断走低，2TB以上的硬盘会逐渐普及，因此UEFI启动也是今后主流的启动方式。 分区引导扇区的结束标志是什么？ 0X55AA。当然，上面也说到了，BIOS除此之外还会检查别的内容。 在UEFI中的可信启动有什么作用？ 通过启动前的数字签名检查来保证启动介质的安全性。 什么是中断、异常和系统调用？ 中断：外部意外的响应； 异常：指令执行意外的响应； 系统调用：系统调用指令的响应。 这个回答真是十分简洁明了。 中断、异常和系统调用的处理流程有什么异同？ 相同点：都会进入异常服务例程，切换为内核态。 不同点： 源头不同，中断源是外部设备，异常和系统调用源是应用程序； 响应方式不同，中断是异步的，异常是同步的，系统调用异步和同步都可以。 处理机制不同，中断对用户程序是透明的，异常会重新执行用户指令或杀死用户进程，系统调用一般是用户程序调用的 以ucore lab8的answer为例，uCore的系统调用有哪些？大致的功能分类有哪些？ 打开kern/syscall/syscall.c，其中定义了如下内容： 123456789101112131415161718192021222324static int (*syscalls[])(uint32_t arg[]) = &#123; [SYS_exit] sys_exit, [SYS_fork] sys_fork, [SYS_wait] sys_wait, [SYS_exec] sys_exec, [SYS_yield] sys_yield, [SYS_kill] sys_kill, [SYS_getpid] sys_getpid, [SYS_putc] sys_putc, [SYS_pgdir] sys_pgdir, [SYS_gettime] sys_gettime, [SYS_lab6_set_priority] sys_lab6_set_priority, [SYS_sleep] sys_sleep, [SYS_open] sys_open, [SYS_close] sys_close, [SYS_read] sys_read, [SYS_write] sys_write, [SYS_seek] sys_seek, [SYS_fstat] sys_fstat, [SYS_fsync] sys_fsync, [SYS_getcwd] sys_getcwd, [SYS_getdirentry] sys_getdirentry, [SYS_dup] sys_dup,&#125;; 大致可以分为如下4类： 进程管理：包括 fork/exit/wait/exec/yield/kill/getpid/sleep 文件操作：包括 open/close/read/write/seek/fstat/fsync/getcwd/getdirentry/dup 内存管理：pgdir命令 外设输出：putc命令 通过分析lab1_ex0了解Linux应用的系统调用编写和含义。(仅实践，不用回答) 按说是应该做一下的，但现在没有时间了…… 通过调试lab1_ex1了解Linux应用的系统调用执行过程。(仅实践，不用回答) 按说是应该做一下的，但现在没有时间了……+1 基于实验八的代码分析ucore的系统调用实现，说明指定系统调用的参数和返回值的传递方式和存放位置信息，以及内核中的系统调用功能实现函数。 在ucore中，执行系统调用前，需要将系统调用的参数储存在寄存器中。 eax表示系统调用类型，其余参数依次存在 edx, ecx, ebx, edi, esi 中。 123456789...int num = tf-&gt;tf_regs.reg_eax;...arg[0] = tf-&gt;tf_regs.reg_edx;arg[1] = tf-&gt;tf_regs.reg_ecx;arg[2] = tf-&gt;tf_regs.reg_ebx;arg[3] = tf-&gt;tf_regs.reg_edi;arg[4] = tf-&gt;tf_regs.reg_esi;... 说实话，我不知道这个题目在问什么。姑且把lab5 report中的说法粘贴过来： fork/wait/exit系统调用的执行过程，以fork为例： 应用态进程调用user/libs/ulib.c:fork函数 user/libs/ulib.c:fork调用user/libs/syscall.c:sys_fork函数 user/libs/syscall.c:sys_fork函数调用user/libs/syscall.c:syscall函数，保存好相应的中断号和参数，引发系统调用中断 vectors.S:vector128：系统调用对应的中断向量 trapentry.S:__alltraps：进入中断处理例程 trap.c:trap trap.c:trap_dispatch：进入系统中断的具体处理例程 kern/syscall/syscall.c:syscall：根据%eax寄存器中保存的值，进入sys_fork函数处理SYS_fork这一具体系统调用 kern/syscall/syscall.c:sys_fork：调用do_fork函数 proc.c:do_fork 以ucore lab8的answer为例，分析ucore应用的系统调用编写和含义。 1234567891011121314151617181920212223syscall(int num, ...) &#123; va_list ap; va_start(ap, num); uint32_t a[MAX_ARGS]; int i, ret; for (i = 0; i &lt; MAX_ARGS; i ++) &#123; a[i] = va_arg(ap, uint32_t); &#125; va_end(ap); asm volatile ( &quot;int %1;&quot; : &quot;=a&quot; (ret) : &quot;i&quot; (T_SYSCALL), &quot;a&quot; (num), &quot;d&quot; (a[0]), &quot;c&quot; (a[1]), &quot;b&quot; (a[2]), &quot;D&quot; (a[3]), &quot;S&quot; (a[4]) : &quot;cc&quot;, &quot;memory&quot;); return ret;&#125; 这段代码是用户态的syscall函数，其中num参数为系统调用号，该函数将参数准备好后，通过SYSCALL汇编指令进行系统调用，进入内核态，返回值放在eax寄存器，传入参数通过eax~esi依次传递进去。在内核态中，首先进入trap()函数，然后调用 trap_dispatch()进入中断分发，当系统得知该中断为系统调用后，OS调用如下的syscall函数： 1234567891011121314151617181920voidsyscall(void) &#123; struct trapframe *tf = current-&gt;tf; uint32_t arg[5]; int num = tf-&gt;tf_regs.reg_eax; if (num &gt;= 0 &amp;&amp; num &lt; NUM_SYSCALLS) &#123; if (syscalls[num] != NULL) &#123; arg[0] = tf-&gt;tf_regs.reg_edx; arg[1] = tf-&gt;tf_regs.reg_ecx; arg[2] = tf-&gt;tf_regs.reg_ebx; arg[3] = tf-&gt;tf_regs.reg_edi; arg[4] = tf-&gt;tf_regs.reg_esi; tf-&gt;tf_regs.reg_eax = syscalls[num](arg); return ; &#125; &#125; print_trapframe(tf); panic(&quot;undefined syscall %d, pid = %d, name = %s.\\n&quot;, num, current-&gt;pid, current-&gt;name);&#125; 该函数得到系统调用号num = tf-&gt;tf_regs.reg_eax;，通过计算快速跳转到相应的sys_开头的函数，最终在内核态中，完成系统调用所需要的功能。 以ucore lab8的answer为例，尝试修改并运行ucore OS kernel代码，使其具有类似Linux应用工具strace的功能，即能够显示出应用程序发出的系统调用，从而可以分析ucore应用的系统调用执行过程。 利用trap.c的trap_in_kernel()函数判断是否是用户态的系统调用，调用syscall()时传入此参数 123case T_SYSCALL: syscall(trap_in_kernel(tf)); break; 更改syscall()的函数原型为void syscall(bool);； 之后在syscall(bool)中加入输出即可： 12345678910111213141516int num = tf-&gt;tf_regs.reg_eax;if (num &gt;= 0 &amp;&amp; num &lt; NUM_SYSCALLS) &#123; if (syscalls[num] != NULL) &#123; arg[0] = tf-&gt;tf_regs.reg_edx; arg[1] = tf-&gt;tf_regs.reg_ecx; arg[2] = tf-&gt;tf_regs.reg_ebx; arg[3] = tf-&gt;tf_regs.reg_edi; arg[4] = tf-&gt;tf_regs.reg_esi; if (!in_kernel) &#123; cprintf(&quot;SYSCALL: %d\\n&quot;, num); &#125; tf-&gt;tf_regs.reg_eax = syscalls[num](arg); return ; &#125;&#125; 下面是qemu运行的输出结果片段，可以看出在用户程序输出前调用了SYS_open，输出sh is running的过程中调用了SYS_write。 123456Iter 1, No.0 philosopher_sema is thinkingkernel_execve: pid = 2, name = &quot;sh&quot;.SYSCALL: 100SYSCALL: 100SYSCALL: 103.... 系统调用与函数调用的区别是什么？ 汇编指令的区别 系统调用：使用INT和IRET指令 函数调用：使用CALL和RET指令 安全性的区别 系统调用有堆栈和特权级的转换过程，函数调用没有这样的过程，系统调用相对更为安全 性能的区别 时间角度：系统调用比函数调用要做更多和特权级切换的工作，所以需要更多的时间开销 空间角度：在一些情况下，如果函数调用采用静态编译，往往需要大量的空间开销，此时系统调用更具有优势 通过分析int、iret、call和ret的指令准确功能和调用代码，比较函数调用与系统调用的堆栈操作有什么不同？ int指令压栈的内容请参考Interrupt and Exception Handling on the x86第10页。 实践练习 看不完了==","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第2讲：“实验0-操作系统实验环境准备”总结","slug":"2018-04-08-《操作系统》第2讲：“实验0-操作系统实验环境准备”总结","date":"2018-04-08T11:01:37.000Z","updated":"2018-04-08T11:01:37.000Z","comments":true,"path":"post/os-mooc-lecture-2-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-2-summary/","excerpt":"","text":"课程内容概述 这节课的主要内容包括： 对8个实验内容的更详细的介绍 对X86-32硬件的介绍 uCore的部分编程技巧和数据结构 如何使用工具编写和调试实验 实验具体内容 我认为在此处把实验具体内容再列举一遍毫无意义。所以我给出了我自己对这些实验的意义的一个总结： 0：实验环境准备 配置环境：安装适当的库、应用或直接下载虚拟机 我认为此时应该尝试编译一下答案，避免出现QEMU no output的情况 环境出问题时，不外乎就是make clean和重装两种解决方式 1：系统启动及中断 这个实验主要是了解操作系统加载到内存，开始运行和处理中断的过程 大部分都是看和总结 有少量编程，但与硬件相关性极强，很难独立做出来 2：物理内存管理 实现了一个管理空闲内存的算法，就是把一大块内存分页，然后按需求进行分配和释放 3：虚拟内存管理 实现了虚拟内存管理，也就是PDE-&gt;PTE-&gt;Page的映射 实现了页替换算法，需要进行换入和换出 代码开始变得非常复杂 4：内核线程管理 建立了一些新的内核线程 除了每个线程新建了一个内核栈之外，其实没有怎么用到虚拟内存管理，因为内核线程共用OS本身的内存管理结构 初步涉及了进程调度的概念 进程的切换是难点，不同特权级之间进程的切换是超难点（虽然此时还不需要） 细节很复杂 5：用户进程管理 建立了用户线程，终于用到了特权级切换和虚拟内存管理 把用户进程的程序内容加载到虚拟空间中是一个难点；此时由于还没有文件系统，程序内容的位置是链接时生成的变量，在程序中直接使用 系统调用的实现过程与特权级很相关 程序的状态开始有了更多的意义；僵尸态、等待态、就绪态、执行态都出现了 仍然只是初步涉及了进程调度的概念 测试时有一些很坑爹的细节，比如需要修改lab1中的一些代码 6：CPU调度 终于开始写调度算法了 过于水的一次lab，除了调度算法之外似乎什么都没有 7：同步与互斥 难度突然上升的一次lab 需要先了解信号量和条件变量 利用信号量实现一个没有什么用处的哲学家就餐问题 利用信号量实现条件变量 利用管程机制再把完全没有什么用处的哲学家就餐问题实现一遍 总之这是一次注重理解的lab 8：文件系统 代码量和难度再次直线上升！ 首先理解uCore中文件系统的实现方法（细节十分多！特别多！巨多！代码巨多！） 然后尝试填写文件系统中某个层次的读文件的代码（反正我写不出来） 修正用户进程加载程序内容的方法，改为从文件系统加载 代码全都写不出来！！ X86-32硬件简单介绍 这个时候就应该参见之前认真写的那篇文章了（Intel80X86架构概述）。这一讲中并未讲得太细，大致概括如下： 运行模式 80386共有四种运行模式，我们只用到了其中两种 实模式：加电后的默认模式，在bootloader中就会切换为保护模式 保护模式：一般的模式 寻址方法（参见Intel80X86架构：保护模式下的内存管理） 逻辑地址：由16位的段选择子和32位的偏移量组成，是应用程序直接使用的地址空间（大概就是程序运行时访问的地址吧） 线性地址：由逻辑地址的偏移量+段基址得到，是虚存管理下每个运行的应用程序能访问的地址空间 物理地址：处理器提交到总线上用于访问计算机系统中内存和外设的最终地址。如果未开启页机制，则物理地址=线性地址；否则通过页表和线性地址可得到物理地址 寄存器 通用寄存器 EAX：累加器 EBX：基址寄存器 ECX：计数器 EDX：数据寄存器 ESI：源地址指针寄存器 EDI：目的地址指针寄存器 EBP：基址指针寄存器 ESP：堆栈指针寄存器 段寄存器 CS：代码段（Code Segment） DS：数据段（Data Segment） ES：附加数据段（Extra Segment） SS：堆栈段（Stack Segment） FS：附加段 GS：附加段 指令寄存器EIP：指令的段内偏移地址 标志寄存器EFLAGS： TF：开启单步调试 IF：开启硬件中断 IOPL：I/O特权级，CPL&lt;=IOPL时才能进行I/O操作 uCore的部分编程技巧和数据结构 主要就讲了两个东西：函数指针和链表。 函数指针 大家都知道，uCore是用C写的。但是C也是可以写出面向对象代码的。就比如说swap_manager，我们只定义了一个swap_manager类型的结构体变量，它的成员变量全是函数指针。然后，我们可以定义各种各样的成员函数，比如__fifo_swap_out_victim，把函数的值赋给成员变量。需要进行换入换出的时候，就调用这个函数指针。正因为如此，把__fifo_swap_out_victim换成__clock_swap_out_victim之类也是可以的。 链表 uCore中有大量的东西都是用双向链表实现的，比如空闲内存块链表、内存中页面链表、状态队列…… uCore的双向链表的定义是这样的： 123struct list_entry &#123; struct list_entry *prev, *next;&#125;; 对于每个数据结构，每有一种它需要连接到里面的链表（后期struct Page结构就有至少两个list_entry类型的成员变量，一个用来进行空闲页管理，一个用来辅助页替换算法），就在里面多加一个list_entry项，然后把这些list_entry连接起来。一般来说，每个有实际用途的双向链表的逻辑都是，有一个不是其他变量的成员变量的head指针，每次可以从它开始访问，直到绕了一圈回来为止（因为是双向链表）。 uCore提供了用于管理链表的宏，不需要自己手动管理，总的来说挺好用的： list_init：初始化一个双向链表 list_add和list_add_before：在某链表项前或后插入一个新的项 list_next和list_prev：向前或后移动一个链表项 list_del：从链表中删除某个项 另一个关键问题是如何通过链表项指针访问对应的结构体变量（从结构体变量访问成员链表项的方法是显然的）。uCore提供了le2page宏，可以通过计算结构体变量开头的地址访问这个变量。总的来说特别好用。 编写和调试工具 全部都用文本编辑器来写代码、看代码当然没有什么问题。用eclipse-CDT建立Makefile项目再看的话，在函数之间跳转比较方便。在eclipse中配置调试是可以的，不过我一般都直接用命令行调试了。 至于从之前的实验中移植代码到后面的实验中这个问题……由于有的时候代码还需要修改，所以所有的代码我都是手动粘的。当然这也是因为我用不惯diff和meld工具。 习题 来自lab0 SPOC思考题和lab0在线练习。 选择填空题 清华大学目前的操作系统实验中采用的OS对象是() Linux ucore xv6 Nachos 是参考了xv6, OS161, Linux的教学操作系统ucore OS。 在ucore lab的实验环境搭建中，使用的非开源软件是() eclipse CDT Scitools Understand gcc qemu Scitools Understand是非开源软件，主要可以用于分析代码，可免费试用一段时间。 在ucore lab的实验环境搭建中，用来模拟一台PC机（即基于Intel 80386 CPU的计算机）的软件是() apt git meld qemu qemu是一个支持模拟多种CPU的模拟软件。apt是Unix系统的软件包管理器，git是版本管理工具，meld是文本比较工具。 ucore lab实验中8个实验是否可以不按顺序完成？ 是 否 每个实验i依赖前面所有的实验(0～i-1)，即完成了lab i，才能完成lab i+1。 ucore lab实验中在C语言中采用了面向对象的编程思想，包括函指针表和通用链表结构。是否正确？ 是 否 是的，这使得可编出更加灵活的操作系统功能模块和数据结构。当然，这也不是严格的面向对象，不过至少是模块化的，而且能用。 x86-32 CPU（即80386）有多种运行模式，ucore lab中碰到和需要处理哪些模式？ 实模式 保护模式 SMM模式 虚拟8086模式 ucore需要碰到和处理16位的实模式和32位的保护模式。其中保护模式的重要性大得多。 简答题 你理解的对于类似ucore这样需要进程/虚存/文件系统的操作系统，在硬件设计上至少需要有哪些直接的支持？至少应该提供哪些功能的特权指令？ 进程的切换需要硬件支持时钟中断；虚存管理需要地址映射机制，从而需要MMU等硬件；对于文件系统，需要硬件有稳定的存储介质来保证操作系统的持久性。 对应的，应当提供中断使能，触发软中断等中断相关的，设置内存寻址模式，设置页表等内存管理相关的，执行I/O操作等文件系统相关的特权指令。 对于现代操作系统（每个进程占一个时间片）时钟中断是非常需要的。存储介质当然也是非常必要的。当然，事实上，MMU没有也行，可以用用户态函数库来实现地址转换，但这样可能就保证不了安全性了。 Intel手册第3卷2.8节“System Instruction Summary”中给出了一个系统指令列表。“系统指令完成的是系统级的功能，包括加载系统寄存器、管理Cache、管理中断和设置调试寄存器。其中的大部分指令都必须由操作系统或特权级为0的进程执行；另一部分可以由任何特权级的进程执行。” 其中我们直接用到的不多。LGDT在建立段映射机制的时候用过，INVLPG在切换页表的时候大概用过，其他的就不知道了。 你理解的x86的实模式和保护模式有什么区别？物理地址、线性地址、逻辑地址的含义分别是什么？ 保护模式和实模式的根本区别是进程内存是否受保护。（我的意见是，实模式既是一个历史包袱，又有一定的实际用途。在实模式下，BIOS自检和加载bootloader的程序可以尽可能简单，因为不需要建立复杂的段映射。但是段机制必须开启这一点也是历史包袱。总之，bootloader一开始就开了A20，设置了GDT然后长跳转切换到保护模式了。）实模式将整个物理内存看成分段的区域，程序代码和数据位于不同区域，系统程序和用户程序没有区别对待，而且每一个指针都是指向“实在”的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并改变了值，那么对于这个被修改的系统程序或用户程序，其后果就很可能是灾难性的。为了克服这种低劣的内存管理方式，处理器厂商开发出保护模式。这样，物理内存地址不能直接被程序访问，程序内部的地址（虚拟地址）要由操作系统转化为物理地址去访问，程序对此一无所知。 物理地址：是处理器提交到总线上用于访问计算机系统中的内存和外设的最终地址。 逻辑地址：在有地址变换功能的计算机中，访问指令给出的地址叫逻辑地址。（一般的定义是段选择子+段内偏移量是逻辑地址。大概） 线性地址：线性地址是逻辑地址到物理地址变换之间的中间层，是处理器通过段(Segment)机制控制下的形成的地址空间。 虚拟地址（不得不补上）：对这个名称的定义总是模糊不清。不过，在这门课中，似乎虚拟地址就是程序内存的地址，不知道我的理解是不是错了。 理解list_entry双向链表数据结构及其4个基本操作函数和ucore中一些基于它的代码实现（此题不用填写内容） 我感觉刚才已经说得很多了。uCore中没有多么复杂的数据结构，也就只有数组和链表了。list_entry的确可以当做一个对象来看待，它可以作为其他对象的一部分，并且进行自己独立的操作。 对于如下的代码段，请说明&quot;:&quot;后面的数字是什么含义。 123456789101112/* Gate descriptors for interrupts and traps */struct gatedesc &#123; unsigned gd_off_15_0 : 16; // low 16 bits of offset in segment unsigned gd_ss : 16; // segment selector unsigned gd_args : 5; // # args, 0 for interrupt/trap gates unsigned gd_rsv1 : 3; // reserved(should be zero I guess) unsigned gd_type : 4; // type(STS_&#123;TG,IG32,TG32&#125;) unsigned gd_s : 1; // must be 0 (system) unsigned gd_dpl : 2; // descriptor(meaning new) privilege level unsigned gd_p : 1; // Present unsigned gd_off_31_16 : 16; // high bits of offset in segment&#125;; “:”后的数字表示每一个域在结构体中所占的位数，详细说明见Bit field。总的来说就是把struct的变量定义精确到了bit的程度。这个结构体是IDT中的门描述符，一个门描述符的大小为8字节。 对于如下的代码段， 1234567891011#define SETGATE(gate, istrap, sel, off, dpl) &#123; \\ (gate).gd_off_15_0 = (uint32_t)(off) &amp; 0xffff; \\ (gate).gd_ss = (sel); \\ (gate).gd_args = 0; \\ (gate).gd_rsv1 = 0; \\ (gate).gd_type = (istrap) ? STS_TG32 : STS_IG32; \\ (gate).gd_s = 0; \\ (gate).gd_dpl = (dpl); \\ (gate).gd_p = 1; \\ (gate).gd_off_31_16 = (uint32_t)(off) &gt;&gt; 16; \\&#125; 如果在其他代码段中有如下语句， 123unsigned intr;intr=8;SETGATE(intr, 1,2,3,0); 请问执行上述指令后， intr的值是多少？ 在实验1中这个宏在填充IDT表中还是挺好用的。显然可以逐步计算出intr。事实上，这个填充过程应该是直接把intr的地址当成了一个gatedesc的地址，从代码中也可以看出来。之后事实上又把这个gatedesccast成了unsigned类型，也就是输出了它的前半部分（因为unsigned的长度为4个字节）。 gd_off_15_0 = 3 &amp; 0xffff = 0x0003 gd_ss = sel = 0x0002 gd_args = b00000 gd_rsv1 = b000 gd_type = STS_TG32 = 0xf gd_s = b0 gd_dpl = b00 gd_p = b1 gd_off_31_16 = 0x0000 可以得到这个内存中的gatedesc为：0x0003000200f10000。我也不知道为什么输出就变成了0x20003。这之中肯定有大小端的问题。 参考答案中给出了一个可以直接输出的参考代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;typedef unsigned uint32_t;#define STS_IG32 0xE // 32-bit Interrupt Gate#define STS_TG32 0xF // 32-bit Trap Gate#define SETGATE(gate, istrap, sel, off, dpl) \\ &#123; \\ (gate).gd_off_15_0 = (uint32_t)(off)&amp;0xffff; \\ (gate).gd_ss = (sel); \\ (gate).gd_args = 0; \\ (gate).gd_rsv1 = 0; \\ (gate).gd_type = (istrap) ? STS_TG32 : STS_IG32; \\ (gate).gd_s = 0; \\ (gate).gd_dpl = (dpl); \\ (gate).gd_p = 1; \\ (gate).gd_off_31_16 = (uint32_t)(off) &gt;&gt; 16; \\ &#125;/* Gate descriptors for interrupts and traps */struct gatedesc &#123; unsigned gd_off_15_0 : 16; // low 16 bits of offset in segment unsigned gd_ss : 16; // segment selector unsigned gd_args : 5; // # args, 0 for interrupt/trap gates unsigned gd_rsv1 : 3; // reserved(should be zero I guess) unsigned gd_type : 4; // type(STS_&#123;TG,IG32,TG32&#125;) unsigned gd_s : 1; // must be 0 (system) unsigned gd_dpl : 2; // descriptor(meaning new) privilege level unsigned gd_p : 1; // Present unsigned gd_off_31_16 : 16; // high bits of offset in segment&#125;;int main(int argc, char const* argv[]) &#123; unsigned intr = 8; gatedesc gate = *(gatedesc*)&amp;intr; SETGATE(gate, 1, 2, 3, 0); intr = *(unsigned*)&amp;gate; printf(&quot;0x%x\\n&quot;, intr); return 0;&#125; 输出结果为0x20003，若将SETGATE(gate, 1, 2, 3, 0)改为SETGATE(gate, 0, 1, 2, 3)，则结果为0x10002。 实践练习 请在ucore中找一段你认为难度适当的AT&amp;T格式X86汇编代码，尝试解释其含义。 那就找一下后期的用于切换上下文的switch.S。把当前寄存器保存在struct context from中，再从struct context to中恢复寄存器。 12345678910struct context &#123; uint32_t eip; uint32_t esp; uint32_t ebx; uint32_t ecx; uint32_t edx; uint32_t esi; uint32_t edi; uint32_t ebp;&#125;; 这段代码其实很简单。核心问题是栈如何被操纵。开始时，栈顶是返回地址，下面（esp-4）是from（因为参数是从右往左压栈的），再下面是to。系统先从栈中取出from，然后把该函数的返回地址弹出，保存到from-&gt;eip中。然后依次保存各个通用寄存器（段寄存器不需要保存，因为内核线程之间这些寄存器都一样）。因为eax中保存的总是返回值，所以可以不保存它，简化代码。之后就是从栈中再取出to，恢复通用寄存器，最后把to-&gt;eip入栈，保证返回之后能跳转到正确地址。 1234567891011121314151617181920212223242526272829.text.globl switch_toswitch_to: # switch_to(from, to) # save from&apos;s registers movl 4(%esp), %eax # eax points to from popl 0(%eax) # save eip !popl movl %esp, 4(%eax) movl %ebx, 8(%eax) movl %ecx, 12(%eax) movl %edx, 16(%eax) movl %esi, 20(%eax) movl %edi, 24(%eax) movl %ebp, 28(%eax) # restore to&apos;s registers movl 4(%esp), %eax # not 8(%esp): popped return address already # eax now points to to movl 28(%eax), %ebp movl 24(%eax), %edi movl 20(%eax), %esi movl 16(%eax), %edx movl 12(%eax), %ecx movl 8(%eax), %ebx movl 4(%eax), %esp pushl 0(%eax) # push eip ret 宏定义和引用在内核代码中很常用。请枚举ucore中宏定义的用途，并举例描述其含义。 参考答案给出了3点： 利用宏进行复杂数据结构中的数据访问； 利用宏进行数据类型转换；如 to_struct 常用功能的代码片段优化；如 ROUNDDOWN, SetPageDirty 我觉得很有道理。因为现在手边没有代码，所以就不粘贴了，反正不是重点。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《操作系统》第1讲：“操作系统概述”总结","slug":"2018-04-08-《操作系统》第1讲：“操作系统概述”总结","date":"2018-04-08T00:00:55.000Z","updated":"2018-04-08T00:00:55.000Z","comments":true,"path":"post/os-mooc-lecture-1-summary/","link":"","permalink":"https://zhanghuimeng.github.io/post/os-mooc-lecture-1-summary/","excerpt":"","text":"课程内容概述 这一讲对课程内容和操作系统做了一个概括性的介绍，主要包括以下几块内容： 教学安排 什么是操作系统 操作系统的演变 操作系统结构的分类 教学安排 本课程将讲述的内容包括： 操作系统结构 中断和系统调用 内存管理 进程和线程 处理机调度 同步互斥 文件系统 I/O子系统 实验共有8个，包括： 0：实验环境准备 1：系统启动及中断 2：物理内存管理 3：虚拟内存管理 4：内核线程管理 5：用户进程管理 6：CPU调度 7：同步与互斥 8：文件系统 实验安排与教学安排是基本匹配的。 什么是操作系统 操作系统可以是： 一个控制程序 一个资源管理器 一套标准库 操作系统通常由内核、命令行和GUI组成。我们研究的主要是内核。以uCore为例，可以分成以下4个层次： 应用程序 命令行程序、编译器、解释器、系统库 内核 内核向上提供系统调用接口 同时调用下层提供的硬件抽象 硬件设备 操作系统内核的特征： 并发：OS需要管理和调度多个同时运行的程序 共享：对资源的互斥共享 虚拟：对CPU和内存资源的虚拟化 异步：程序的运行是时常会停止的，OS需要保证程序暂停之后状态不变 操作系统的演变 单用户系统：1945-1955 OS=装载器+通用子程序库 问题是，任务完全为串行执行，由于读卡时间过长，执行时间比例降低 批处理系统：1955-1965 每个任务在每个组件中串行执行，总体看来是并行执行的 解决了利用率问题 多道程序系统：1965-1980 将多个程序存储在内存中，复用CPU 在程序进行I/O操作时将其阻塞，切换到别的程序 分时系统：1970- 定时中断当前程序，实现对CPU的复用 个人电脑操作系统 分布式操作系统 …… 操作系统结构的分类 操作系统的结构可以分为以下几种： 简单结构：没有拆分为模块，没有很好地分离接口和功能 应用程序可以直接访问最底层的服务，也可以使用操作系统的服务 例：MS-DOS 分层结构：将操作系统分为多层，每层建立在底层上 优点：可移植性强 缺点：层次过多会导致效率降低 例：UNIX 微内核结构：将一些内核服务移动到用户态，内核只保留进程通信和硬件支持功能 优点：灵活，安全 缺点：性能差 例：目前的系统结构是微内核结构和分层结构的混合体 外核结构：内核只起到资源的保护和隔离功能，操作系统原有功能由用户态操作系统库支持 虚拟机结构：操作系统与虚拟机管理器交互，虚拟机管理器负责和硬件交互 习题 来自操作系统概述。 选择填空题 当前常见的操作系统主要用C，C++，ASM编程语言编写。 &quot;Operating system&quot;这个单词起源于Operator。 指的是原来的系统操作员。 在计算机系统中，控制和管理各种资源、有效地组织多道程序运行的系统软件称作操作系统。 对操作系统定义的考察。当然我觉得这个答案并不全面，加上“提供了一套标准库”（也就是系统调用）会更好。 允许多用户将若干个作业提交给计算机系统集中处理的操作系统称为批处理操作系统。 这说明单用户系统是每个任务手动提交上去的。 你了解的当前世界上使用最多的32bit CPU是ARM，其上运行最多的操作系统是Android。 答案如此，没有找到信源。不过知道这个也没什么意义。 应用程序通过系统调用接口获得操作系统的服务。 系统调用是非常重要的。这是应用程序主动进入内核态的方式。 现代操作系统的特征包括并发性，共享性，虚拟性，异步性，持久性。 特征到底应该包括哪些也是见仁见智。OSTEP中总结出的三点是虚拟，并发和持久性。异步性和共享性大概可以归入并发性。同时我也觉得持久性未必是操作系统的特点，而是存储设备的特点。当然这也可能是我的理解不够。 UPD：操作系统本身也是需要从持久性存储设备中读入的。文件系统也是OS的重要组成成分。所以我想得可能太片面了。 操作系统内核的架构包括宏内核，微内核，外核。 这个答案和上面讲的并不相符。那么，当然应该填简单结构、分层结构、微内核结构、外核结构和虚拟机结构了。 简答题 请总结你认为操作系统应该具有的特征有什么？并对其特征进行简要阐述。 操作系统应该具有的特征有：虚拟性、并发性、异步性、共享性和持久性。 虚拟性：虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备。 并发性：并发是指两个或多个事件在同一时间间隔内发生，在多道程序环境下，一段时间内宏观上有多个程序在同时执行，而在同一时刻，单处理器环境下实际上只有一个程序在执行，故微观上这些程序还是在分时的交替进行。操作系统的并发是通过分时得以实现的。操作系统的并发性是指计算机系统中同时存在多个运行着的程序，因此它具有处理和调度多个程序同时执行的能力。 异步性：在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。异步性使得操作系统运行在一种随机的环境下，可能导致进程产生于时间有关的错误。但是只要运行环境相同，操作系统必须保证多次运行进程，都获得相同的结果。 共享性：系统中的资源可供内存中多个并发执行的进程共同使用。（事实上，只能做到互斥共享，或者说同时。） 持久性：通过实现文件系统，操作系统可以将程序以及数据存储在磁盘等存储介质中。 详细解释可以参考操作系统的特征。 为什么现在的操作系统基本上用C语言来实现？为什么没有人用python，java来实现操作系统？ C语言是编译型语言，有良好的性能，能够直接嵌入汇编，可以方便地操作硬件；Python，Java无法保证性能，不能直接操作硬件。 不过，仍然是有人用这些语言来编写操作系统的，比如： 用Java实现的操作系统：JavaOS 用Python实现的操作系统：pycorn，pythonix 用Rust实现的操作系统：Redox 实践题 此次的实践题全部与V9-computer相关，和本课程关系不大，所以先不做了。","categories":[],"tags":[{"name":"OS","slug":"OS","permalink":"https://zhanghuimeng.github.io/tags/OS/"}]},{"title":"《英诗金库》I-34：The Nightingale, by R. Barnfield","slug":"2018-04-04-《英诗金库》I-34：The-Nightingale-by-R-Barnfield","date":"2018-04-04T01:25:00.000Z","updated":"2018-04-04T01:25:00.000Z","comments":true,"path":"post/the-nightingale-by-r-barnfield/","link":"","permalink":"https://zhanghuimeng.github.io/post/the-nightingale-by-r-barnfield/","excerpt":"","text":"作品基本信息 作品名称：The Nightingale（夜莺） 作者：Richard Barnfield（理查德·巴恩菲尔德） 出版年代：1598 编注：理查德·巴恩菲尔德（Richard Barnfield，1574-1627），英国学者及诗人，主要作品有《钟情的牧羊人》等。 作品原文 As it fell upon a day In the merry month of May, Sitting1 in a pleasant shade Which a grove2 of myrtles made, Beasts did leap and plants did spring, Every thing did banish moan Save the Nightingale alone. She, poor bird, as all forlorn, Lean’d her breast up-till3 a thorn, And there sung the dolefull’st ditty That4 to hear it was great pity. Fie, fie, fie, now would she cry; Teru, Tereu, by and by: That to hear her so complain Scarce I could from tears refrain; For her griefs so lively5 shown Made me think upon mine own. —Ah, thought I, thou mourn’st in vain, None takes pity on thy pain: Senseless trees, they cannot hear thee, Ruthless beasts, they will not cheer thee; King Pandion, he is dead, All thy friends are lapp’d in lead6: All thy fellow birds do sing Careless of thy sorrowing: Even so, poor bird, like thee None alive will pity me. 译文 付勇林 译 在欢乐的五月里 恰逢有一天， 我坐在舒适的荫凉处 头顶上有一丛长春藤攀援， 处处野兽奔逐，鸟儿啼啭， 万木葱茏、百草吐艳。 世间的万物都已忘掉了忧愁 唯独那只夜莺郁郁寡欢。 她呀，可怜的鸟儿，神色凄苦， 胸脯靠着蒺藜， 低吟着一支小曲悲楚哀怨 让人听着实在可怜。 啾、啾、啾，这时她在哭诉； 嘟噜、嘟噜，一会儿又愁肠欲断； 听着她满腹冤屈 我止不住泪流满面； 她的痛苦是这样历历在目， 让我也想起自己的苦难。 ——唉，我思量，你忧伤也是枉然， 谁也不会把你可怜： 没心肝的树啊，它们充耳不闻， 残忍的野兽，也不把你鼓舞、慰勉； 潘狄翁国王已魂归九天， 你的挚友也都进了铅造的墓棺： 所有的小鸟还在婉转歌唱， 毫不理睬你正遭受着苦难： 正是这样，可怜的鸟儿，我象你 活着的谁也不把我可怜。 我的感想 我知道这个故事。 菲洛墨拉（希腊语：Φιλομήλα，字面意思是“爱歌者”）希腊神话中阿提刻（雅典及其附近地区）国王潘狄翁与妻子宙克西珀所生之女，是普罗克涅、厄瑞克透斯和部忒斯的妹妹。 菲洛墨拉的姐夫色雷斯国王忒柔斯凶暴好色，企图霸占菲洛墨拉，遂将妻子普罗克涅藏于密林，谎称已死，要潘狄翁把另一个女儿送来。菲洛墨拉到达后即遭其强奸，又被割掉舌头。普罗克涅得知后气极，为报复竟杀死与忒柔斯的孩子，并将孩子的肉做成饭给忒柔斯吃，然后带菲洛墨拉逃跑。忒柔斯发觉真相后暴怒，拼命追赶两人。两姐妹在绝望中向神祈祷，天神把他们三人都变成了鸟：普罗克涅变成夜莺，菲洛墨拉变成燕子，忒柔斯变成戴胜。晚期的罗马作家不知出于什么原因改动了神话，把无舌的菲洛墨拉说成是夜莺，普罗克涅则说成燕子。[1] 因此大概可以看出，诗句中的“Tereu”大概不完全是拟声词。读了读英文维基，也没有什么令人震惊的重要发现。按我这个现代人的想法，忒柔斯显然没有得到应有的惩罚，为何他们三人都变成鸟了呢？忒柔斯的行径当然是糟糕至极，普罗克涅一时冲动也犯下大错，可是菲洛墨拉是无辜的啊。或许神认为忒柔斯不知不觉地吃下了自己孩子的肉，他已经付出了足够的代价。当然，以现代人的价值观去评价这些古希腊人也是不太合适的。总之，冲动是魔鬼。 回到这首诗。哦不……我们先回到这个诗人。原注中对他的介绍实在是不太够。理查德·巴恩菲尔德（1574 – 1620），英国诗人，由于和莎士比亚的密切却不为人所知的关系，成为了研究者们感兴趣的对象。在1598年，巴恩菲尔德发表了第三本书《The Encomion of Lady Pecunia》，这是一首赞颂钱财的诗歌（pecunia是拉丁语“钱”的意思）。这本书的附录中出现了一些非常有趣的事情：这可能是对莎士比亚的第一次赞美。在一篇名为《A Remembrance of some English Poets》的文章中，当时默默无名的莎士比亚被作为《维纳斯与阿童尼》的作者，与斯宾塞、丹尼尔（Samuel，1562-1619，英国诗人及历史家，于1599-1619年荣获桂冠诗人；因为我也没听说过这个人所以记一下）、杜雷顿等人并列。其中同时包含了十四行诗《If Music and sweet Poetrie agree》，以及这首美丽的颂歌《As it fell upon a day》，这首诗曾经一度被认为是莎士比亚所作。 在1599年，《热情的朝圣者》（The Passionate Pilgrim）出版，标题页上写着“By W. Shakespeare”。人们在很长一段时间内认为这一署名是正确的，然而，至少有两首诗是巴恩菲尔德所作（就是刚才提到的两首），他在1598年和1605年都强调了这一点。事实上，莎士比亚实际所作的诗可能只有五首。 巴恩菲尔德的诗很久以来都被人忽视。他的诗歌纯净、甜美、悦耳，尽管缺乏广度和原创性。他的诗歌天才由这首被误认为是莎士比亚的诗毫无疑问地证明了，虽然只有一首。[2]有人认为他就是莎士比亚的第78-86首十四行诗中提到的“Rival Poet”。[3]（我对这一概念还没有很深刻的了解，不能再讲太多了，真可惜。） 下面开启吐槽模式。老实说，我真没觉得这首诗“纯净、甜美、悦耳”；恰恰相反，我觉得它矫揉造作。然而，看了这些介绍之后，我对巴恩菲尔德其人和这首诗的观感都完全不一样了。我觉得他可能是个不幸的人，活在莎士比亚的阴影下。可是他自己未必是这么想的，也许他是因为崇拜莎士比亚才这么做的。总之这种事实在是难说。此处选择的版本似乎是《热情的朝圣者》中的缩减版，原版似乎还有以下这些行： Whilst as fickle Fortune smiled, Thou and I were both beguiled. Every one that flatters thee Is no friend in misery. Words are easy, like the wind; Faithful friends are hard to find. Every man will be thy friend Whilst thou hast wherewith to spend; But if store of crowns be scant, No man will supply thy want. If that one be prodigal, Bountiful they will him call, And with suchlike flattering, “Pity but he were a king.” If he be addict to vice, Quickly him they will entice. If to women he be bent, They have at commandment; But if Fortune once do frown, Then farewell his great renown: They that fawned on him before Use his company no more. He that is thy friend indeed, He will help thee in thy need; If thou sorrow, he will weep; If thou wake, he cannot sleep; Thus of every grief in heart He with thee doth bear a part. These are certain signs to know Faithful friend from flattering foe.[4] 再回头看的时候，感受到了一丝清澈的忧伤，也体会到了音乐性。（但是这首诗的前半段和后半段根本不是一个画风吧！） 参考文献 [1] 菲洛墨拉. https://zh.wikipedia.org/wiki/菲洛墨拉 [2] Richard Barnfield. https://en.wikipedia.org/wiki/Richard_Barnfield [3] Rival Poet. https://en.wikipedia.org/wiki/Rival_Poet [4] XX. As it fell upon a day. https://en.wikisource.org/wiki/The_Passionate_Pilgrim#XX._As_it_fell_upon_a_day 脚注 1Sitting: ‘as I was sitting.’ 2grove: so in the original and in the Passionate Pilgrim, England’s Helicon has ‘group.’ 3up-till: ‘up to’. 4That is the conjunction, = ‘so that.’ 5lively: ‘vividly.’ 6lapp’d in lead: ‘enclosed in leaden coffins.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"},{"name":"R.Barnfield","slug":"R-Barnfield","permalink":"https://zhanghuimeng.github.io/tags/R-Barnfield/"}]},{"title":"《英诗金库》I-32：They that have power to hurt and will do none, by W. Shakespeare","slug":"2018-04-02-《英诗金库》I-32：They-that-have-power-to-hurt-and-will-do-none-by-W-Shakespeare","date":"2018-04-02T00:00:00.000Z","updated":"2018-06-28T21:53:36.000Z","comments":true,"path":"post/they-that-have-power-to-hurt-and-will-do-none-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/they-that-have-power-to-hurt-and-will-do-none-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：The Life without Passion（无激情的人生） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第九四首。诗人说，只有忠贞不渝，能抗拒诱惑的人才配得上天赐的美貌。 作品原文 They that have power to hurt and will do none, That do not do the thing they most do show1, Who, moving others, are themselves as stone, Unmoved, cold, and to temptation slow, — They rightly do inherit2 Heaven’s graces, And husband nature’s riches from expense3; They are the lords and owners of their faces, Others, but stewards of their excellence. The summer’s flower is to the summer sweet, Though to itself4 it only live and die; But if that flower with base infection meet5, The basest weed outbraves his dignity: For sweetest things turn sourest by their deeds; Lilies that fester smell far worse than weeds. 译文 梁宗岱 译 谁有力量损害人而不这样干， 谁不做人以为他们爱做的事， 谁使人动情，自己却石头一般， 冰冷、无动于衷、对诱惑能抗拒—— 谁就恰当地承受上天的恩宠， 善于贮藏和保管造化的财富； 他们才是自己美貌的主人翁， 而别人只是自己姿色的家奴。 夏天的花把夏天熏得多芳馥， 虽然对自己它只自开又自落， 但是那花若染上卑劣的病毒， 最贱的野草也比它高贵得多： 极香的东西一腐烂就成极臭， 烂百合花比野草更臭得难受。 我的感想 这首诗给人的感觉就远不止是爱情了。人的好名声的毁损也是同样的。 好吧，没时间翻译解析了[1]……但是这一篇还挺有意思的。 TODO 参考文献 [1] Sonnet 94. http://www.sparknotes.com/shakespeare/shakesonnets/section5/ 脚注 1do the thing they most do show: i.e. devote themselves to the service of love, for which their appearance has so amply qualified them. 2rightly do inherit, etc.: ‘it is right that they should be endowed with supreme beauty.’ 3from expense: ‘from being expended.’ 4Though to itself, etc.: i.e. that which is sel-contained and self-centred will yet give pleasure if it be beautiful. The ‘only’ is misplaced, as so often in English; it goes with ‘to itself.’ 5with base infection meet: ‘become tainted with decay.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-28：That time of year thou mayst in me behold, by W. Shakespeare","slug":"2018-02-06-《英诗金库》I-28：That-time-of-year-thou-mayst-in-me-behold-by-W-Shakespeare","date":"2018-02-06T00:00:00.000Z","updated":"2018-06-29T02:22:12.000Z","comments":true,"path":"post/that-time-of-year-thou-mayst-in-me-behold-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/that-time-of-year-thou-mayst-in-me-behold-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：That time of year thou mayst in me behold 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第七三首。 作品原文 That time of year thou may’st in me be behold When yellow leaves, or none, or few, do hang Upon those boughs which shake against the cold Bare ruin’d choirs, where late the sweet birds sang. In me thou see’st the twilight of such day As after sunset fadeth in the west, Which by and by black night doth take away, Death’s second self, that seals up all in rest. In me thou see’st the glowing of such fire1, That on the ashes of his youth doth lie As the death-bed whereon it must expire, Consumed with2 that which it was nourish’d by: —This thou perceiv’st, which makes thy love more strong, To love that well which thou must leave ere long. 译文 屠岸 译 你从我身上能看到这个时令： 黄叶落光了，或者还剩下几片 没脱离那乱打冷颤的一簇簇枝梗—— 不再有好鸟歌唱的荒凉唱诗坛。 你从我身上能看到这样的傍晚： 夕阳的回光沉入了西方的天际， 死神的化身——黑夜，慢慢出现， 挤走黄昏，把一切封进了安息。 你从我身上能看到这张火焰： 它躺在自己青春的灰烬上燃烧， 象躺在临终的床上，一息奄奄， 跟供它养料的燃料一同毁灭掉。 看出了这个，你的爱会更加坚贞， 好好地爱着你快要失去的爱人！ 我的感想 我又想不动了……[1] TODO 参考文献 [1] Sonnet 73: That time of year thou mayst in me behold. https://www.poetryfoundation.org/poems/45099/sonnet-73-that-time-of-year-thou-mayst-in-me-behold 脚注 1such fire That, etc. : in strict grammar ‘that’ should be ‘as.’ his=its, referring to ‘fire.’ 2Consumed with: i.e. ‘together with’; fire and fuel disappear together.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"《英诗金库》I-29：When to the sessions of sweet silent thought, by W. Shakespeare","slug":"2018-02-06-《英诗金库》I-29：When-to-the-sessions-of-sweet-silent-thought-by-W-Shakespeare","date":"2018-02-06T00:00:00.000Z","updated":"2018-06-29T02:31:32.000Z","comments":true,"path":"post/when-to-the-sessions-of-sweet-silent-thought-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/when-to-the-sessions-of-sweet-silent-thought-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Remembrance（记忆） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第三十首，主题与第二九首（参见本卷第一二首）大致相同。 作品原文 When to the sessions1 of sweet silent thought I summon up remembrance of things past, I sigh the lack of many things I thought, And with old woes2 new wail my dear time’s waste; Then can I drown an eye, unused to flow, For precious friends hid in death’s dateless3 night, And weep afresh love’s long-since-cancell’d woe, And moan the expense4 of many a vanish’d sight. Then can I grieve at grievances foregone5, And heavily from woe to woe tell o’ver The sad account of fore-bemoanéd moan, Which I new pay as if not paid before: —But if the while6 I think on thee, dear friend, All losses are restored, and sorrows end. 译文 梁宗岱 译 当我传唤对以往事物的记忆 出庭于那馨香的默想的公堂， 我不禁为命中许多缺陷叹息， 带着旧恨，重新哭蹉跎的时光： 于是我可以淹没那枯涸的眼， 为了那些长埋在夜台7的亲朋， 哀悼着许多音容俱渺的美艳， 痛哭那情爱久已勾销的哀痛： 于是我为过去的惆怅而惆怅， 并且一一细算，从痛苦到痛苦， 那许多呜咽过的呜咽的旧账， 仿佛还未付过，现在又来偿付。 但是只要那刻我想起你，挚友， 损失全收回，悲哀也化为乌有。 我的感想 我记得“Remembrance of Things Past”是《追忆逝水年华》英文版书名的旧译，后来因为普鲁斯特本人的强烈抗议换成了“In Search of Lost Time”。经查，普鲁斯特本人的意见没有查到，不过名字确实是换过的。[1] 不知为何，觉得注释里的“and utter afresh my old lamentations for the waste of my past life”非常传神，我又一次为自己过去所浪费的生命而重复起那些曾经的悲泣。 我开了一个脑洞：以现代流行的价值观来说，爱情绝不是一个人生命中最重要的部分，爱侣也不是时时刻刻能够依赖的人，最重要的还是要寻找自我，自立自强。因此莎士比亚的诗歌的价值观在现代看来就很不合适了，甚至说是“直男癌”。但我觉得这并不能说明这种爱情观就是落后的。把自我的解放和人生的意义寄托在爱情，或者上帝，或者两者都有（比如但丁和彼特拉克……）上大概是当时的价值观。在这种前提下，爱情的作用和上帝是类似的，只不过缺少一些宗教性。 在现代，爱情好像比宗教失落得更快。（只是个人感觉，虽然在中国两者几乎都失落了）但是显然人们并不习惯这种把全部意义都收归于自己的生活。 参考文献 [1] In Search of Lost Time. https://en.wikipedia.org/wiki/In_Search_of_Lost_Time#Publication_in_English 脚注 1sessions… summon: he calls memory to bear witness as in a court of law. 2with old woes, etc: ‘and utter afresh my old lamentations for the waste of my past life.’ 3dateless: ‘marked by no fixed limits.’ 4expense: ‘loss.’ 5foregone: ‘gone-before,’ ‘past.’ The verb to forgo (= go without) is often spelt ‘forego’, and its past principle then is identical in form with this word. 6the while: ‘at such a time.’ 7夜台，意为坟墓。","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-24：My true-love hath my heart, by P. Sidney","slug":"2018-01-24-《英诗金库》I-24：My-true-love-hath-my-heart-by-P-Sidney","date":"2018-01-24T00:00:00.000Z","updated":"2018-06-29T01:23:04.000Z","comments":true,"path":"post/my-true-love-hath-my-heart-by-p-sidney/","link":"","permalink":"https://zhanghuimeng.github.io/post/my-true-love-hath-my-heart-by-p-sidney/","excerpt":"","text":"作品基本信息 作品名称：A Ditty（交换） 作者：Philip Sidney（菲利普·锡德尼） 出版年代：1589 编注：锡德尼（Philip Sidney，1554-1586），英国诗人，学者。他曾在伊丽莎白女王宫廷任朝臣，后触怒女王，退隐乡间。他的主要作品有牧歌传奇《阿卡迪亚》（The Countess of Pembroke’s Arcadia）、《诗辩》（An Apology for Poetry）和十四行组诗《爱星者和星星》（Astrophel and Stella）。 作品原文 My true-love hath my heart, and I have his, By just exchange one for another given: I hold his dear, and mine he cannot miss, There never was a better bargain driven: My true-love hath my heart, and I have his. His heart in me keeps him and me in one, My heart in him his thoughts and senses guides: He loves my heart, for once it was his own, I cherish his because in me it bides: My true-love hath my heart, and I have his. 译文 李霁野 译 我的真实情人占有我的心， 我也占有他的心， 我们两人公公平平 彼此以你心换我心， 我和他的心亲密无间， 他不会因失去我的心 再没有比这更好的交换。 我的真实情人占有我的心 我也占有他的心。 他的心在我体内 使他和我成为一体， 我的心在他体内 引导他的思想感官， 他爱我的心，因为以前原是他的， 我爱他的心，因为它在我体内安眠； 我的真实情人占有我的心， 我也占有他的心。 我的感想 本来很累了，但是看了维基百科上的介绍[1]，突然又对这位西德尼产生了一定的兴趣，而且感觉他的Astrophel and Stella可能很好。这本诗集也是最早的英文十四行组诗之一，和H. Constable的Diana一样，详情可见《英诗金库》I-15：Diaphenia, by H. Constable。不过我其实只是被这首诗的名字所吸引了，爱（philein）星（aster）者和星星（stella）[2]…… 而且这位诗人在31岁的时候就死了，事实上是战死的。斯宾塞为他写了一首悼诗，Astrophel[3]，据说是一首很好的诗，不过现在没时间看了。 以及，我很不能理解的一点是，这首诗明明是十四行诗，据说是比莎士比亚还早的十四行诗，这里怎么就变成10行了，说都不说一声……总之原文是这样的： My true love hath my heart, and I have his, By just exchange one for the other given: I hold his dear, and mine he cannot miss; There never was a bargain better driven. His heart in me keeps me and him in one; My heart in him his thoughts and senses guides: He loves my heart, for once it was his own; I cherish his because in me it bides. His heart his wound received from my sight; My heart was wounded with his wounded heart; For as from me on him his hurt did light, So still, methought, in me his hurt did smart: Both equal hurt, in this change sought our bliss, My true love hath my heart, and I have his.[4] 刚才的引用里其实有很多有趣的解析，但我翻译不动了…… 参考文献 [1] Philip Sidney. https://en.wikipedia.org/wiki/Philip_Sidney [2] Astrophel and Stella. https://en.wikipedia.org/wiki/Astrophel_and_Stella [3] Astrophel. https://www.bartleby.com/153/108.html [4] A Short Analysis of Sir Philip Sidney’s ‘My True Love Hath My Heart’. https://interestingliterature.com/2016/11/25/a-short-analysis-of-sir-philip-sidneys-my-true-love-hath-my-heart/ 脚注","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"李霁野","slug":"李霁野","permalink":"https://zhanghuimeng.github.io/tags/李霁野/"},{"name":"P.Sidney","slug":"P-Sidney","permalink":"https://zhanghuimeng.github.io/tags/P-Sidney/"}]},{"title":"《英诗金库》I-27：When icicles hang by the wall, by W. Shakespeare","slug":"2018-01-20-《英诗金库》I-27：When-icicles-hang-by-the-wall-by-W-Shakespeare","date":"2018-01-20T00:00:00.000Z","updated":"2018-06-29T02:08:12.000Z","comments":true,"path":"post/when-icicles-hang-by-the-wall-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/when-icicles-hang-by-the-wall-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Winter（冬之歌） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1594 编注：此诗选自《爱的徒劳》第五幕第二场。 作品原文 When icicles hang by the wall And Dick the shepherd blows his nail1, And Tom bears logs into the hall, And milk comes frozen home in pail; When blood is nipt, and ways be foul, Then nightly sings the staring owl Tuwhoo! Tuwhit! towhoo! A merry note! While greasy Joan doth keel the pot2. When all aloud the wind doth blow, And coughing drowns the parson’s saw3, And birds sit brooding4 in the snow, And Marian’s nose looks red and raw; When roasted crabs5 hiss in the bowl— Then nightly sings the staring owl Tuwhoo! Tuwhit! tuwhoo! A merry note! While greasy Joan doth keel the pot. 译文 朱生豪 译 当一条条冰柱檐前悬吊， 汤姆把木块向屋内搬送， 牧童狄克呵着他的指爪， 挤来的牛乳凝结了一桶， 刺骨的寒气，泥泞的路途， 大眼睛的鸱鸮夜夜高呼： 哆呵！ 哆喴6，哆呵！它歌唱着欢喜， 当油垢的琼转她的锅子。 当怒号的北风漫天吹响， 咳嗽打断了牧师的箴言， 鸟雀们在雪里缩住颈项， 玛利恩冻得红肿了笔尖， 炙烤的螃蟹7在锅内吱喳， 大眼睛的鸱鸮夜夜喧哗： 哆呵！ 哆喴，哆呵！它歌唱着欢喜， 当油垢的琼转她的锅子。 我的感想 咦，这又是一首选自《爱的徒劳》的诗，上一首是《英诗金库》I-20：On a day, alack the day, by W. Shakespeare。据说这是《爱的徒劳》的结尾处的两首诗之一，这两首诗中，一首是赞颂春天的，一首是赞颂冬天的（就是这首），但是这首诗的赞扬表现得很微妙。它承认了冬天的冷和不舒适，却没有用到“cold”和“unpleasant”之类的词汇。总的来说，写得很生动。[1] 参考文献 [1] When Icicles Hang by the Wall: William Shakespeare - Summary and Critical Analysis. https://www.bachelorandmaster.com/britishandamericanpoetry/when-icicles-hang-by-the-wall.html#.WzUjsqczY2w 脚注 1blows his nail: breathes on his finger-tips to warm them. 2keel the pot: ‘cool the contents of the pot by stirring.’ 3saw: ‘trite maxim.’ 4brooding: the first meaning is to sit on eggs, and so to sit still as if one were trying to hatch out a scheme. 5crabs: heated ale with spice or sugar and a roast crab-apple or a slice of toast added was a favourite drink for winter evenings. 6哆（duō ）喴（wēi），大概是语气词。 7就注释而言，这里大概译错了或者译得不好，“crab”指的并不是真的螃蟹，而是一种热饮料。","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-26：O Mistress mine, where are you roaming, by W. Shakespeare","slug":"2018-01-15-《英诗金库》I-26：O-Mistress-mine-where-are-you-roaming-by-W-Shakespeare","date":"2018-01-15T00:00:00.000Z","updated":"2018-06-29T02:00:58.000Z","comments":true,"path":"post/o-mistress-mine-where-are-you-roaming-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/o-mistress-mine-where-are-you-roaming-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Carpe Diem（活在当下） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1600 编注：此诗选自《第十二夜》第二幕第三场。标题系原编者所加。 作品原文 O Mistress mine, where are you roaming? O stay and hear! your true-love’s coming That can sing both high and low; Trip no further, pretty sweeting1, Journeys end in lovers’ meeting— Every wise man’s son doth know. What is love? 'tis not hereafter; Present mirth hath present laughter; What’s to come is still unsure: In delay there lies no plenty, — Then come kiss me, Sweet-and-twenty, Youth’s a stuff will not endure. 译文 朱生豪 译 你到哪儿去，啊我的姑娘？ 听呀，那边来了你的情郎， 嘴里吟着抑扬的曲调。 不要再走了，美貌的亲亲； 恋人的相遇终结了行程， 每个聪明人全都知晓。 什么是爱情？它不在明天； 欢笑嬉游莫放过了眼前， 将来的事有谁能猜料？ 不要蹉跎了大好的年华； 来吻着我吧，你双十娇娃， 转眼青春早化成衰老。 我的感想 想不动了……[1] 参考文献 [1] Song: “O Mistress mine where are you roaming?”. https://www.poetryfoundation.org/poems/47420/song-o-mistress-mine-where-are-you-roaming 脚注 1sweeting: properly a sweet apple, and hence a term of affection.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-25：Were I as base as is the lowly plain, by J. Sylvester","slug":"2018-01-14-《英诗金库》I-25：Were-I-as-base-as-is-the-lowly-plain-by-J-Sylvester","date":"2018-01-14T00:00:00.000Z","updated":"2018-06-29T01:48:40.000Z","comments":true,"path":"post/were-i-as-base-as-is-the-lowly-plain-by-j-sylvester/","link":"","permalink":"https://zhanghuimeng.github.io/post/were-i-as-base-as-is-the-lowly-plain-by-j-sylvester/","excerpt":"","text":"作品基本信息 作品名称：Love’s Omnipresence（爱情无处不在） 作者：Joshua Sylvester（乔舒亚·西尔维斯特） 出版年代：1602 编注：乔舒亚·西尔维斯特（Joshua Sylvester，1563-1618）是一个不很出名的英国诗人。作为诗歌翻译家，他翻译了法国诗人杜巴尔塔斯的《创世周》；作为诗人，这首十四行诗是他留传后世不多的作品之一。 作品原文 Were I as base as is the lowly plain, And you, my Love, as high as heaven above, Yet should the thoughts of me your humble swain Ascend to heaven, in honour of my Love. Were I as high as heaven above the plain, And you, my Love, as humble and as low As are the deepest bottoms of the main, Whereso’er you were, with you my love should go. Were you the earth, dear Love, and I the skies, My love should shine on you like to the sun, And look upon you with ten thousand eyes Till heaven wax’d blind, and till the world were done. Whereso’er I am, below, or else above you, Whereso’er you are, my heart shall truly love you. 译文 李霁野 译 假如我像低低的平原一样卑下， 而你，我的爱人，象天空一样高悬， 你的卑微仆人为尊崇你的身价， 他的思念也会高升上天。 假如我象平原上的天空一样高， 而你，我的爱人，象最深的海底 一样的卑下，一样的渺渺， 我的爱也追随你，无论你在哪里。 假如你是大地，我是天空，亲爱的， 我的爱象太阳一般对你照耀， 并用万只眼睛看望着你， 直到天变浑噩，世界云散烟消。 无论我在你之下，在你之上， 无论你在哪，我都爱你赤胆忠肠。 我的感想 想不动了……总之这位诗人确实不怎么出名，他的维基百科[1]都巨短…… TODO 参考文献 [1] Josuah Sylvester. https://en.wikipedia.org/wiki/Josuah_Sylvester 脚注","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"J.Sylvester","slug":"J-Sylvester","permalink":"https://zhanghuimeng.github.io/tags/J-Sylvester/"},{"name":"李霁野","slug":"李霁野","permalink":"https://zhanghuimeng.github.io/tags/李霁野/"}]},{"title":"《英诗金库》I-23：Let me not to the marriage of true minds, by W. Shakespeare","slug":"2018-01-12-《英诗金库》I-23：Let-me-not-to-the-marriage-of-true-minds-by-W-Shakespeare","date":"2018-01-12T00:00:00.000Z","updated":"2018-06-29T00:44:07.000Z","comments":true,"path":"post/let-me-not-to-the-marriage-of-true-minds-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/let-me-not-to-the-marriage-of-true-minds-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：True Love（真正的爱） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第一一六首，诗人宣称真正的爱可以征服时间。 作品原文 Let me not to the marriage of true minds Admit1 impediments. Love is not love Which alters when it alteration finds, Or bends with the remover2 to remove:— O no! it is an ever-fixéd mark That looks on tempests, and is never shaken; It is the star to every wandering bark, Whose worth’s unknown, although his height be taken3. Love’s not Time’s fool4, though rosy lips and cheeks Within his bending sickle’s5 compass come; Love alters not with his brief hours and weeks, But bears it out6 ev’n to the edge of doom:— If this be error, and upon me proved, I never writ, nor no man7 ever loved. 译文 屠岸 译 让我承认，两颗真心的结合 是阻止不了的。爱算不得爱， 要是人家变心了，它也变得， 或者人家改道了，它也快改：—— 不呵！爱是永远固定的标志， 它正视风暴，永远也不会动摇； 爱是一颗星，一切迷途的船只 都靠它引路，把它当无价之宝。 爱不是时间的玩偶，虽然红颜 到头来总不被时间的镰刀遗漏； 爱绝不跟随短促的韶光改变， 就到灭亡的边缘，也不低头：—— 假如我这话真错了，真不可信赖， 算我没写过，算爱从来不存在！ 我的感想 “算我没写过”什么鬼啦……再次放个quotation在这……[1] TODO 参考文献 [1] Shakespeare, William. Sonnet 116. Ed. Amanda Mabillard. Shakespeare Online. 8 Dec. 2012. http://www.shakespeare-online.com/sonnets/116detail.html. 脚注 1Let me not … Admit: ‘May I never own that there are.’ 2bends with the remover, etc. : ‘is disposed to draw back from one who is himself drawing back.’ 3although his height be taken: the position of the star in the sky when accurately taken may serve as a guide to the mariner, who however knows nothing of the astrological significance of the star. 4Time’s fool: ‘the dupe of Time.’ 5bending sickle: Time is generally represented as a mower with a curved scythe. 6bears it out: ‘endures without giving way.’ 7nor no man: in 16th and 17th century English the double negative did not produce an affirmative.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"《英诗金库》I-21：Forget not yet the tried intent, by T. Wyatt","slug":"2018-01-07-《英诗金库》I-21：Forget-not-yet-the-tried-intent-by-T-Wyatt","date":"2018-01-07T00:00:00.000Z","updated":"2018-06-28T23:38:46.000Z","comments":true,"path":"post/forget-not-yet-the-tried-intent-by-t-wyatt/","link":"","permalink":"https://zhanghuimeng.github.io/post/forget-not-yet-the-tried-intent-by-t-wyatt/","excerpt":"","text":"作品基本信息 作品名称：A Supplication（祈求） 作者：托马斯·怀亚特（Thomas Wyatt，1503-1542） 出版年代：1529 编注：Sir Thomas Wyatt（托马斯·怀亚特，1503?-1542），亦译为魏阿特或华埃特，英国文艺复兴时期新诗歌的第一位代表。主要作品有与萨里等人合作的《托特尔杂集》和用三韵体写成的讽刺诗《论贫穷与富有》。他曾与宫廷女官安娜·波琳相恋，后来波琳做了亨利八世的继室，他为此写了许多以爱情为题材的诗歌，《祈求》便是其中一首。 作品原文 Forget not yet the tried intent1 of such a truth as I have meant; My great travail2 so gladly spent, Forget not yet! Forget not yet when first began The weary life ye know, since whan The suit3, the service4 none tell can; Forget not yet! Forget not yet the great assays5, The cruel wrong, the scornful ways, The painful patience in delays, Forget not yet! Forget not! O, forget not this, How long ago hath been, and is The mind that never meant amiss—6 Forget not yet! Forget not then thine own approved7 The which so long has thee so loved, Whose steadfast faith yet never moved— Forget not this! 译文 林天斗 译 可别忘记我所表示的 如此一片忠诚的真切意愿； 我莫大的痛苦已那么愉快地完成， 可别忘记！ 可别忘记当初开始 你知道的那厌倦的生活，从此 那种乞求，那种服务真是难以述说； 可别忘记！ 可别忘记那些严重的考验， 那残酷的屈辱，藐视的方式， 几次拖延了的痛苦的忍耐， 可别忘记！ 别忘记！咳，不要把这忘记， 多久以前已经是，现在也是 这决不能被误解的心意—— 可别忘记！ 别忘记还有你自己赞许的 那个你曾如此长久爱过的人， 他的坚贞信念可永不动摇—— 不要把这忘记！ 我的感想 我本来不想写什么东西，但是看到了一个让我差点笑死的八卦，不妨摘录如下（据说以下内容是怀亚特写给亨利八世的信）： “Your Majesty knows that before marrying Queen Anne you said to me, Wyatt, I am going to marry Anne Boleyn, what do you think of it? I told your Majesty the that you had better not do so, and you asked me why; to which I replied that she was a bad woman, and your Majesty angrily ordered me to quit your presence for two years. Your majesty did not deign on that occasion to ask my reasons for saying what I did, and since I could not then give them by word of mouth, I will do so now in writing. One day, whilst Mistress Anne’s father and mother were at the Court eight miles from Greenwich, where, as all world knows, they were stationed, I took horse and went thither, arriving when Anne was already in bed. I mounted to her chamber and as soon as she saw me she said, “Good God! Master Wyatt, what are you doing here at this hour?’ I answered her, ‘Lady, a heart tormented as mine has been by yours for long past has urged me hither to ask for some consolation from one who has caused it so much pain.’ I approached her and kissed her, and she remained quiet and silent, and even to still greater familiarities she made no objection, when suddenly I heard a great stamping over the bed in which she slept, and the lady at once rose, slipped on a skirt, and went out by a staircase which led up behind the bed; I waited for her more than an hour but when she came down she would not allow me to approach her. “I cannot but believe that I was treated in the same way as a gentleman once was in Italy, who was as madly in love with a lady as I was, and was, by his good luck, brought to the same point, when he heard a stamping overhead and the lady rose and went out; but the gentleman in question was wiser than I, for he very soon followed the lady upstairs, and found her in the arms of a groom, and I have no doubt I should have seen the same thing if I had been wise enough to follow her. A week after she was quite at my service, and if your Majesty had deigned to hear me when you banished me, I would have told you then what I write you now.” 关于这件八卦更多的内容我参见的是[1]。简单来说，安妮·博林在和怀亚特交往的时候脚踏两条船被发现了，怀亚特非常气愤，以至于在亨利八世咨询他“娶安妮·博林这件事怎么样”的时候，直言“安妮·博林是个坏女人”。亨利八世一怒之下没让他再多说话就决定驱逐他两年（似乎是关进了伦敦塔）；怀亚特在塔里写了这封信，讲了他被戴绿帽子的故事；亨利八世看了之后，立刻把他从塔里放了出来，并且更爱他了。（但是我怎么觉得这剧情有点不对，最后他不是仍然娶了安妮么） 这个八卦故事的主要依据是一部自称记述了亨利八世和爱德华一世时期发生的史实的西班牙语作品[2]。一位历史学家把它翻译成了英语，但是也有人认为，这部作品并不真实[3]。哎呀，我现在没时间去考据这个故事的真实性了，不过还真是有趣呢…… 参考文献 [1] Forget not Yet: Anne Boleyn &amp; Thomas Wyatt. http://www.tudorsdynasty.com/forget-not-yet-thomas-wyatt/ [2] Chronicle of King Henry VIII. of England. Being a Contemporary Record of Some of the Principal Events of the Reigns of Henry VIII. and Edward VI. Written in Spanish by an Unknown Hand. https://archive.org/details/chroniclekinghe00humegoog [3] Spanish Chronicle. https://en.wikipedia.org/wiki/Spanish_Chronicle 脚注 1the tried intent, etc. : ‘the proved purpose of the devotion which I have endeavoured to show.’ 2travail: ‘toil.’ 3since whan The suit: 'for how long I have been your suitor., whan is an earlier form of ‘when.’ 4the service: i.e. [and] the service [which] none can tell. 5assays: ‘trials,’ to which you have subjected me. 6I.e.: Remember how long I have been wishing you well, as I do now. 7thine own approved: ‘one whom you have tested.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"T.Wyatt","slug":"T-Wyatt","permalink":"https://zhanghuimeng.github.io/tags/T-Wyatt/"},{"name":"林天斗","slug":"林天斗","permalink":"https://zhanghuimeng.github.io/tags/林天斗/"}]},{"title":"《英诗金库》I-22：To Aurora, by W. Alexander","slug":"2018-01-07-《英诗金库》I-22：To-Aurora-by-W-Alexander","date":"2018-01-07T00:00:00.000Z","updated":"2018-06-29T00:12:22.000Z","comments":true,"path":"post/to-aurora-by-w-alexander/","link":"","permalink":"https://zhanghuimeng.github.io/post/to-aurora-by-w-alexander/","excerpt":"","text":"作品基本信息 作品名称：To Aurora（致奥罗娜） 作者：William Alexander（威廉·亚历山大） 出版年代：1604 编注：威廉·亚历山大（William Alexander，1567?-1640），英国诗人。《致奥罗娜》系他的十四行诗集《奥罗娜》（Aurora，1604）第三三首。 作品原文 O if thou knew’st how thou thyself dost harm, And dost prejudge thy bliss1, and spoil my rest; Then thou would’st melt the ice out of thy breast And thy relenting heart would kindly warm. O if thy pride did not our joys controul, What world of loving wonders should’st thou see! For if I saw thee once transform’d in me2, Then in thy bosom I would pour my soul; Then all my thoughts should in thy visage shine, And if that3 aught mischanced thou should’st not moan Nor bear the burthen of thy griefs alone; No, I would have my share in what were4 thine; And whilst we thus should make our sorrows one, This happy harmony would make them none. 译文 付勇林 译 哦，倘若你知道怎样把自己伤害， 竟预知你的幸福，扰乱我的平静： 那末你胸中的冰块将消融殆尽 你温柔的心肠就会春光一派。 哦，倘若你的清高未把欢乐阻碍， 世上什么爱的奇迹你不收获！ 如果你把全部身心交付与我， 我将把灵魂倾注于你的心怀； 于是我一腔思恋将闪在你脸上， 如果你遭受不幸，不要自艾自怨 也不要独自把忧伤的重负承担； 不，我愿与你一起把甘苦分享： 当我们这样把痛苦融为一体， 幸福的和声将把它全然荡涤。 我的感想 首先，这诗感觉不错啊。 其次，我查了一下这位威廉·亚历山大，第一位斯特林伯爵的生平，感觉真是十足有趣[1]。他是查尔斯一世还是王子时期的Gentleman Usher（不知道怎么翻译），之后也一直受到这位国王的宠幸。总之，在1621年，詹姆斯一世给了他在新苏格兰地区的特许权（相当于现在加拿大的滨海诸省和美国北方的一些地区）。他本人经营得并不好，但是为后来的人留下了一些遗产（虽然好像不是实体的）。在1630年，查尔斯授予他Lord Alexander of Tullibody（仍然不知道怎么翻译比较好）和斯特林子爵（Viscount of Stirling）的称号。1633年，他升级为斯特林伯爵（Earl of Stirling）和加拿大子爵（Viscount Canada）。（哇……加拿大？好厉害……）1636年，他获得了长岛作为领地。至于他的诗歌成就……在十七世纪早期，他是英格兰和苏格兰名气最高的苏格兰诗人之一，但现在好像不太时兴了。 参考文献 [1] William Alexander, 1st Earl of Stirling. https://en.wikipedia.org/wiki/William_Alexander,_1st_Earl_of_Stirling 脚注 1thou: i.e. the reader; the second and fourth lines are exclamations, not addresses.（“你”指的是读者；第二行和第四行是感叹，不是对读者说的话。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"},{"name":"W.Alexander","slug":"W-Alexander","permalink":"https://zhanghuimeng.github.io/tags/W-Alexander/"}]},{"title":"《英诗金库》I-19：When in the chronicle of wasted time, by W. Shakespeare","slug":"2017-12-27-《英诗金库》I-19：When-in-the-chronicle-of-wasted-time-by-W-Shakespeare","date":"2017-12-27T00:00:00.000Z","updated":"2018-06-28T17:51:17.000Z","comments":true,"path":"post/when-in-the-chronicle-of-wasted-time-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/when-in-the-chronicle-of-wasted-time-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：To His Love（致爱人） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第一〇六首。 作品原文 When in the chronicle of wasted1 time I see descriptions of the fairest wights2, And beauty making beautiful old rhyme In praise of ladies dead, and lovely knights; Then in the blazon3 of sweet beauty’s best Of hand, of foot, of lip, of eye, of brow, I see their antique pen would have exprest Ev’n such a beauty as you master4 now. So all their praises are but prophecies Of this our time, all you prefiguring; And, for they look’d but with divining eyes5, They had not skill enough your worth to sing: For we, which now behold these present days, Have eyes to wonder, but lack tongues to praise. 译文 梁宗岱 译 当我从那湮远的古代的纪年， 发见那绝代风流人物的写真， 艳色使得古老的歌咏也香艳， 颂赞着多情骑士和绝命佳人， 于是，从那些国色天姿的描画， 无论手脚、嘴唇、或眼睛或眉额， 我发觉那些古拙的笔所表达 恰好是你现在所占领的姿色。 所以他们的赞美无非是预言 我们这时代，一切都预告着你； 只不过他们观察只用想象的眼， 还不够才华把你歌颂得尽致： 而我们，幸而得亲眼看见今天， 只有眼惊羡，却没有舌头咏叹。 我的感想 TODO[1] 参考文献 [1] A Short Analysis of Shakespeare’s Sonnet 106: ‘When in the chronicle of wasted time’. https://interestingliterature.com/2017/11/27/a-short-analysis-of-shakespeares-sonnet-106-when-in-the-chronicle-of-wasted-time/ 脚注 1wasted: not ‘misused,’ but simply ‘spent,’ ‘past.’ 2wights: ‘persons,’ almost obsolete except in a few phrases like ‘luckless wight.’ 3blazon: ‘description,’ properly a description of armorial bearings. 4you master: ‘have as your own.’ 5but with divining eyes: i.e. not having seen you, they could but guess at your beauty.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-20：On a day, alack the day, by W. Shakespeare","slug":"2017-12-27-《英诗金库》I-20：On-a-day-alack-the-day-by-W-Shakespeare","date":"2017-12-27T00:00:00.000Z","updated":"2018-06-28T18:55:33.000Z","comments":true,"path":"post/on-a-day-alack-the-day-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/on-a-day-alack-the-day-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Love’s Perjuries（爱的谎言） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1594 编注：此诗选自《爱的徒劳》第四幕第三场。 作品原文 On a day, alack the day! Love, whose month is ever May, Spied a blossom passing fair1 Playing in the wanton2 air: Through the velvet leaves the wind, All unseen 'gan3 passage find; That the lover, sick to death, Wish’d himself the heaven’s breath. Air, quoth he, thy cheeks my blow;4 Air, would I might triumph so! But, alack, my hand is sworn Ne’er to pluck thee from thy thorn: Vow, alack, for youth unmeet; Youth so qpt to pluck a sweet. Do not call it sin in me That I am forsworn5 for thee: Thou for whom Jove would swear Juno but an Ethiope6 were, And deny himself for Jove,7 Turning mortal for thy love. 译文 朱生豪 译 有一天，唉，那一天！ 爱永远是五月天， 见一朵好花娇媚， 在款款风前游戏； 穿过柔嫩的叶网， 风儿悄悄地来往。 憔悴将死的恋人， 羡慕天风的轻灵： 风能吹上你面颊， 我只能对花掩泣！ 我已向神前许愿， 不攀折鲜花嫩瓣； 少年谁不爱春红？ 这种誓情理难通。 今日我为你叛誓， 请不要把我讥刺； 你曾经迷惑乔武8， 使朱诺9变成黑人， 放弃天上的威尊， 来作尘世的凡人。 我的感想 总之，《爱的徒劳》并不是一部很有名的作品，它的情节大概是这样的…… 《爱的徒劳》是莎士比亚早期格调最为明快的喜剧之一。故事梗概是：那瓦国国王和三个贵族朝臣，发誓三年不近色，不料法国国王派公主带三名侍女前来谈判某地归属问题，四名男子很快放弃初衷，各自堕入情网。于是四对男女演出了一系列风流滑稽戏，最后法国使者忽然来报法国国王去世，公主必须立即回去，公主代表女方规定。男方必须等待一年，以观是否变心，四位女士飘然离去，尽管剧名为“爱的徒劳”，但从剧情来看，该剧所表现的是爱能成战胜一切。 莎翁在剧中以巧妙的情节创造出许多使观众捧腹的笑料，嘲笑了摒弃爱情的禁欲主义，也嘲笑了爱情的盲目性。全剧到处都是文字游戏和双关语，剧中所包容的社会各个阶层，从国王、大臣到农业、小丑，其语言无不各具特色，符合人物各自的身份，此剧还穿插了不少清新、优美的歌曲和民歌，这些民歌都富有诗意，散发着英国乡间泥土的清香，充分表现了莎士比亚的语言天才。[1] TODO 参考文献 [1] 爱的徒劳. https://book.douban.com/subject/1116395/ 脚注 1passing fair: ‘surpassingly beautiful.’ 2wanton: ‘sportive.’ 3’gan: i.e. began. 4He addresses his lady: — ‘The air may touch thy cheeks-would that I might do the same’! 5To be forsworn is to break an oath. 6Ethiope: ‘a blackamoor.’ 7deny himself for Jove: ‘assert that he was Jove no longer.’ 8乔武（Jove）通译作约芙，即罗马神话中的主神朱庇特（Jupiter）。——编注者 9朱诺（Juno），天后，主神朱庇特之妻。——编注者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-18：Shall I compare thee to a summer's day, by W. Shakespeare","slug":"2017-12-26-《英诗金库》I-18：Shall-I-compare-thee-to-a-summer-s-day-by-W-Shakespeare","date":"2017-12-26T00:00:00.000Z","updated":"2018-06-28T17:38:08.000Z","comments":true,"path":"post/shall-i-compare-thee-to-a-summer-s-day-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/shall-i-compare-thee-to-a-summer-s-day-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：To His Love（致爱人） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎士比亚十四行诗第一八首，诗人在这首诗里表达了“唯有文字可以同时间抗衡”的思想。 作品原文 Shall I compare thee to a summer’s day? Thou art more lovely and more temperate: Rough winds do shake the darling buds of May; And summer’s lease hath all too short a date; Sometimes too hot the eye of heaven shines. And often is his gold complexion dimm’d; And every fair from fair1 sometime declines, By chance, or nature’s changing course, untrimm’d2. But thy eternal summer shall not fade Nor lose possession of that fair thou owest3; Nor shall death brag thou wanderest in his shade, When in eternal line to time4 thou growest; So long as men can breathe, or eyes can see, So long lives this, and this gives life to thee. 译文 戴镏龄 译 我怎样能把你比作夏天？ 你比它更可爱也更温和； 五月的娇蕾有暴风震颠， 夏季的寿命很短就度过。 有时候当空照耀着烈日， 又往往它的光采转阴淡； 每件美艳终把美艳消失， 遭受运数和时序的摧残。 你永恒的夏季却永不凋零， 而且长把你的美艳保存； 死神难夸你踏它的倩影， 只因永恒的诗和你同春。 天地间能有人鉴赏文采， 这首诗就流传教你永在。 我的感想 啊，这首诗大概是莎士比亚最有名的十四行诗之一了。然后我一时也没有什么好说的……[1] TODO 参考文献 [1] Sonnet 18. https://en.wikipedia.org/wiki/Sonnet_18 脚注 1from fair: ‘from fairness.’ 2untrimm’d: the prefix un- is either negative, as in ‘unmoved,’ or privative, signifying the reversal of an action, as in ‘unfold.’ Here it has the latter force; to trim is to make neat, so to untrim is to disarrange. 3owest: this was the originally the same word as to ‘own’ and meant to ‘have.’ 4to time: i.e. to all time.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"戴镏龄","slug":"戴镏龄","permalink":"https://zhanghuimeng.github.io/tags/戴镏龄/"}]},{"title":"《英诗金库》I-17：Beauty sat bathing by a spring, by A. Munday","slug":"2017-12-25-《英诗金库》I-17：Beauty-sat-bathing-by-a-spring-by-A-Munday","date":"2017-12-25T00:00:00.000Z","updated":"2018-06-28T17:17:18.000Z","comments":true,"path":"post/beauty-sat-bathing-by-a-spring-by-a-munday/","link":"","permalink":"https://zhanghuimeng.github.io/post/beauty-sat-bathing-by-a-spring-by-a-munday/","excerpt":"","text":"作品基本信息 作品名称：Colin（科林） 作者：The Shepherd Tony（牧羊人托尼） 出版年代：1599 编注：牧羊人托尼（The Shepherd Tony），生平不详，也许就是安东尼·马迪（Anthony Munday, 1553-1633）。 作品原文 Beauty sat bathing by a spring Where fairest shades did hide her; The winds blew calm, the birds did sing, The cool streams ran beside her. My wanton thoughts enticed mine eye To see what was forbidden: But better memory said, fie! So vain desire was chidden: — Hey nonny nonny O! Hey nonny nonny! Into a slumber then I fell, When fond1 imagination Seem’d to see, but could not tell Her feature or her fashion2. But ev’n as babes in dreams do smile, And sometimes fall a-weeping, So I awaked, as wise this while3 As when I fell a-sleeping; — Hey nonny nonny O! Hey nonny nonny! 译文 付勇林 译 丽人沐浴在清泉的近旁 葱郁的树荫把她的倩影掩藏； 微风吹拂，百鸟儿欢唱， 冰凉的小溪淌过她身旁。 轻飘的思绪怂恿我 把她的玉体探望、观赏： 可美好的记忆说，不要脸！ 应该唾弃这般虚浮的欲望：— 嗨，啰哩啰哩哦！ 嗨，啰哩啰哩！ 于是我渐渐地沉入梦想， 这时痴情的想象 恍惚中看见，却描绘不清 那美人的花容，袅娜的体状。 就像熟睡的婴儿时而酣笑 时而又泪水流淌， 我不觉醒来，这时神清气爽 就和梦中一样：— 嗨，啰哩啰哩哦！ 嗨，啰哩啰哩！ 我的感想 那个“nonny nonny O”神似这首诗啊…… 这里[1]有关于这首诗的一些说明。 TODO 参考文献 [1] Beauty Sat Bathing by a Spring. https://rpo.library.utoronto.ca/poems/beauty-sat-bathing-spring-0 脚注 1fond: from ‘foolish,’ its original meaning, this word came to mean ‘foolishly affectionate,’ and then— its only modern meaning— 'tender, ’ 'loving, ’ without any idea of disagreement. 2her fashion: ‘her shape.’ 3this while: ‘this time.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"},{"name":"A.Munday","slug":"A-Munday","permalink":"https://zhanghuimeng.github.io/tags/A-Munday/"}]},{"title":"《英诗金库》I-13：O never say that I was false of heart, by W. Shakespeare","slug":"2017-12-24-《英诗金库》I-13：O-never-say-that-I-was-false-of-heart-by-W-Shakespeare","date":"2017-12-24T21:39:29.000Z","updated":"2018-06-27T21:39:29.000Z","comments":true,"path":"post/o-never-say-that-i-was-false-of-heart-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/o-never-say-that-i-was-false-of-heart-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：The Unchangeable（永不变心） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第一〇九首，表现了诗人对他的爱友忠贞不渝的爱。 作品原文 O never say that I was false of heart, Though absence seem’d my flame to qualify: As easy might I from myself depart As from my soul, which in thy breast doth lie; That is my home of love; if I have ranged, Like him that travels, I return again, Just1 to the time, not with the time exchanged2, So that myself bring water for my stain. Never believe, though in my nature reign’d All frailties that besiege all kinds of blood,3 That it could so preposterously be stain’d4 To leave for nothing all thy sum of good: For nothing this wide universe I call, Save thou, my rose: in it thou art my all. 译文 屠岸 译 啊！请无论如何别说我负心， 虽然我好象被离别减少了热力。 我不能离开你胸中的我的灵魂， 正如我也离不了自己的肉体： 你的胸膛是我的爱的家：我已经 旅人般流浪过，现在是重回家园； 准时而到，也没有随时光而移情，—— 我自己带水来洗涤自己的污点。 虽然我的性情中含有一切人 都有的弱点，可千万别相信我会 如此荒谬地玷污自己的性情， 竟为了空虚而抛弃你全部优美； 我说，广大的世界是空空如也， 其中只有你，玫瑰呵！是我的一切。 我的感想 还是翻译一点东西吧。 我们可以感受到语调中的自信和独立——这种语调只出现在少数几首十四行诗中。诗人表明，他对自己朋友的感情在自己离开伦敦的时候变冷了，很可能是在和他的表演公司（the Chamberlain’s Men）在1594年的巡演期间。在第9-10行中，诗人承认，“reign’d/All frailties that besiege all kinds of blood”，表明有其他的人激起了他的热情。如果读一下第110首十四行诗，这一点会更加明显，因为诗人在里面承认，他的不重视使得他需要重新获得年轻人的依赖：“These blenches gave my heart another youth”（第7行）。这一主题延续到了第111-120首十四行诗，诗人用许多词汇描述了自己的不当行为：“stain”和“frailties”（109），“offences”（110），“harmful deeds”和“infection”（111），“shames”（112），“diseased”（118），“transgression”（120），等等。 很多学者相信，莎士比亚和他的亲爱的朋友（很可能是南安普顿伯爵）的关系超出了柏拉图式的范畴，很少有其他的十四行诗能像第109-120首那样为这一论调提供证据。虽然诗人爽快地承认了自己的“stain”，他坚持认为，通过自己犯过的错误，他对自己的“rose”的爱情被增强了。虽然第109首诗算是一篇道歉，但诗人并不是在气球原谅。我们找到的实际上是一篇“矫揉造作的温和赞扬，也许是一篇告别演说”。[1] 研究者真厉害，我感觉他们都能发掘出莎士比亚和他的朋友的打情骂俏的细节了。 参考文献 [1] SONNET 109. http://www.shakespeare-online.com/sonnets/109detail.html 脚注 1Just: ‘punctually’. 2exchanged: ‘changed,’ ‘altered’—an obsolete sense. 3all kinds of blood: ‘people of different temperaments.’ 4so stain’d To leave, etc. : i.e. ‘as to leave.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"《英诗金库》I-15：Diaphenia, by H. Constable","slug":"2017-12-24-《英诗金库》I-15：Diaphenia-by-H-Constable","date":"2017-12-24T16:26:54.000Z","updated":"2018-06-28T16:26:54.000Z","comments":true,"path":"post/diaphenia-by-h-constable/","link":"","permalink":"https://zhanghuimeng.github.io/post/diaphenia-by-h-constable/","excerpt":"","text":"作品基本信息 作品名称：Diaphenia（黛尔菲妮娅） 作者：Henry Constable（亨利·康斯特布尔） 出版年代：1599 编注：亨利·康斯特布尔（Henry Constable，1502-1613），英国诗人，作品不多，主要作品有诗集《狄安娜》1（1592）等。 作品原文 Diaphenia like the daffadowndilly, White as the sun, fair as the lily, Heigh ho, how I do love thee! I do love thee as my lambs Are belovèd of their dams; How blest were I if thou would’st prove me. Diaphenia like the spreading roses, That in thy sweets all sweets encloses, Fair sweet, how I do love thee! I do love thee as each flower Loves the sun’s life-giving power; For dead2, thy breath to life might move me. Diaphenia like to all things blessèd When all thy praises are expressèd, Dear joy, how I do love thee! As the birds do love the spring, Or the bees their careful king: Then in requite, sweet virgin, love me! 译文 付勇林 译 黛尔菲妮娅象朵水仙花， 如骄阳般纯洁，似百合般光华， 哎呀呀，我多么地爱您啊！ 我真诚地爱您，就象小羊 亲昵可爱的妈妈； 我该何等地幸运，倘您把我嘉纳。 黛尔菲妮娅象盛开的玫瑰花， 您的馨香凝聚了所有的芳华， 心爱的人儿，我多么地爱您啊！ 我真心地爱您，就像每一朵鲜花 倾慕太阳生机的强大； 假如我离别人世，您唤春的气息也使我 精神焕发。 黛尔菲妮娅如万物般洪福广大， 当您全部的赞语已尽情表达， 亲爱的娇娃，我多么地爱您啊！ 就像百鸟喜爱三月阳春， 或如蜜蜂崇拜蜂王豁达： 那末，倾心相许，可爱的人儿，爱我吧！ 我的感想 把H. Constable的维基百科[1]放在这里，然后遁走……咳，这首诗真是让人没眼看，果然这位作者以热情洋溢著称。 TODO 参考文献 [1] Henry Constable. https://en.wikipedia.org/wiki/Henry_Constable 脚注 1Diana，最早的英文十四行组诗（Sonnet sequence）之一。 2For dead: i.e. For, Were I dead.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"H.Constable","slug":"H-Constable","permalink":"https://zhanghuimeng.github.io/tags/H-Constable/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"}]},{"title":"《英诗金库》I-14：To me, fair friend, you never can be old, by W. Shakespeare","slug":"2017-12-24-《英诗金库》I-14：To-me-fair-friend-you-never-can-be-old-by-W-Shakespeare","date":"2017-12-24T00:00:00.000Z","updated":"2018-06-28T16:15:31.000Z","comments":true,"path":"post/to-me-fair-friend-you-never-can-be-old-b-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/to-me-fair-friend-you-never-can-be-old-b-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：To me, fair Friend, you never can be old 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第一〇四首，诗中的情调不同于他的其他一些诗。诗人在有些诗中想用诗来使他所爱的人的美永生，但在这首诗中却哀叹美终将会消逝。 作品原文 To me, fair friend, you never can be old, For as you were when first your eyes I eyed Such seems your beauty still. Three winters cold Have from the forests shook1 three summers’ pride; Three beauteous springs to yellow autumn turn’d In process of the seasons have I seen, Three April perfumes in three hot Junes burn’d, Since first I saw you fresh, which2 yet are green. Ah! yet doth beauty, like a dial-hand, Steal3 from his figure, and no pace perceived; So your sweet hue, which methinks still4 doth stand, Hath motion, and mine eye may be deceived: For dear of which, hear this, thou age unbred,— Ere you5 were born, was beauty’s summer dead. 译文 梁宗岱 译 我的感想 总的来说这首诗超棒。 感想写不完，只好TODO了。[1] 参考文献 [1] Sonnet 104. https://en.wikipedia.org/wiki/Sonnet_104 脚注 1hook: for ‘shaken’ is not common in the 17th century, which often used the past tense of strong verbs in place of the past participle. 2which: for ‘who’ is often found in Shakespeare and his contemporaries; it occurs frequently in the Authorised Version of the Bible (1611), notably in the Lord’s Prayer. （在莎士比亚及其同时代人中，用“which”来代替“who”是常见用法，比如在钦定版圣经里就很常见，特别是在主祷文里。） 3Steal: I take to be intransitive, and his to be put for 'its, 'i.e. beauty’s, beauty slowly vanishes from the figure it adorns, as the hand steals imperceptibly round the clock. 4still: is the adjective, going with ‘stand.’ 5Posterity is addressed collectively in the former line, individually in the latter, where ‘you’ = ‘any of you.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-16：Rosalynde, by T. Lodge","slug":"2017-12-24-《英诗金库》I-16：Rosalynde-by-T-Lodge","date":"2017-12-24T00:00:00.000Z","updated":"2018-06-28T16:42:29.000Z","comments":true,"path":"post/rosalynde-by-t-lodge/","link":"","permalink":"https://zhanghuimeng.github.io/post/rosalynde-by-t-lodge/","excerpt":"","text":"作品基本信息 作品名称：Rosalynde（罗莎琳达） 作者：Thomas Lodge（托马斯·洛吉） 出版年代：1590 编注：托马斯·洛吉（Thomas Lodge，1558?-1625），英国诗人、小说家及戏剧家。《罗莎琳达》选自他1590年写成的传奇故事《罗莎琳达、尤菲绮斯黄金遗产》（Rosalynde: Euphues Golden Legacy），这个故事为莎士比亚的喜剧《皆大欢喜》提供了基本情节和大量细节。 作品原文 Like to the clear1 in highest sphere Where all imperial glory shines, Of selfsame2 colour is her hair Whether unfolded, or in twines: Heigh ho, fair Rosalynde! Her eyes are sapphires set in snow, Resembling heaven by every wink; The Gods do fear whenas they glow3, And I do tremble when I think Heigh ho, would she were mine! Her cheeks are like the blushing cloud That beautifies Aurora’s face, Or like the silver crimson shroud4 That Phoebus’ smiling looks doth grace; Heigh ho, fair Rosalynde! Her lips are like two budded roses Whom5 ranks of lilies neighbour nigh, Within which bounds she balm encloses Apt to entice a deity: Heigh ho, would she were mine! Her neck is like a stately flower Where Love himself imprison’d lies, To watch for glances every hour From her divine and sacred eyes: Heigh ho, for Rosalynde! Her paps are centres of delight, Her breasts are orbs of heavenly frame, Where Nature moulds the dew of light6 To feed perfection with the same: Heigh ho, would she were mine! With orient7 pearl, With ruby red, With marble white, with sapphire bue Her body every way is fed, Yet soft in touch and sweet in view: Heiho, fair Rosalynde! Nature herself shape admires; The Gods are wounded in her sight; And Love firsakes his heavenly fires And at her eyes his brand doth light: Heigh ho, would she were mine! Then muse not, Nymphs, though I bemoan The absence of fair Rosalynde, Since for a fair there’s fairer none, Nor for her virtues so divine8: Heigh ho, fair Rosalynde; Heigh ho, my heart! would God that she were mine! 译文 付勇林 译 晶莹透亮，似在那高高的天上 那里金光灿烂，壮丽辉煌， 她的秀发闪着纯净的光泽 不论是飘曳婆娑，还是挽髻摇荡： 多美啊，罗莎琳达！ 那双明眸犹如宝石湛蓝，嵌在雪地之上， 眨巴着研究，与天空辉映闪光； 它们光芒四射，众神也汗颜、恐慌， 当我春心萌动，不免战栗摇晃 多美啊，但愿她是我的娇娘！ 她双颊红晕，犹如绚丽的云霞 映得奥罗娜9也娇艳非常， 那双颊又象深红色的盖布 是太阳神的笑颜使它更为荣光； 多美啊，罗莎琳达！ 她双唇鲜嫩，有如玫瑰初放 就开在那行行百合的近旁， 在这片天地里，她饱蕴芳香 诱使神灵也心花怒放： 多美啊，但愿她是我的娇娘！ 她的脖颈与庄严的塔楼一样 囚住了爱神，他就此安躺， 希冀她非凡圣明的慧眼 时时投来深情的目光 多美啊，罗莎琳达！ 她的乳房是快乐的中央， 她的酥胸是苍穹的太阳， 造物主在那儿造就晶莹的光亮 又用它把完美哺养： 多美啊，但愿她是我的娇娘！ 珍珠的色彩，红宝石的透亮 大理石的洁白，蓝宝石的幽光 她的身体处处都是这样， 那么风姿柔美，甜润芬芳： 多美啊，罗莎琳达！ 造物主艳羡她的身段， 她秀目流盼使众神遍体鳞伤； 爱神也丢弃掉神圣的火炬 因为她的眼里，爱火在升腾向上： 多美啊，但愿她是我的娇娘！ 别惊讶，仙女们10，虽然我爱上 美丽的罗莎琳达不在我的身旁， 因为美人难再有美人的媲美， 也再没人有她那样贞洁、高尚； 多美啊，罗莎琳达； 多美，我的心肝！上帝，但愿她是我的娇娘！ 我的感想 总之列一点参考文献在这里，然后…… [1]：T. Lodge的维基 [2]：似乎是剧本的古本照片 [3]：Gutenberg上的剧本原文 [4]：Rosalynde和《皆大欢喜》的对比，以及这部剧本的剧情概述 TODO 参考文献 [1] Thomas Lodge. https://en.wikipedia.org/wiki/Thomas_Lodge [2] Thomas Lodge’s Rosalynde. http://medievalromance.bodleian.ox.ac.uk/Thomas_Lodges_Rosalynde [3] Rosalynde by Thomas Lodge. https://www.gutenberg.org/ebooks/17181 [4] Summary of Thomas Lodge’s “Rosalynde” by Evan Thomas. https://osuasyoulikeit.wordpress.com/2014/01/29/summary-of-thomas-lodges-rosalynde-by-evan-thomas/ 脚注 1the clear: ‘the brightness.’ 2我一直觉得“selfsame”这个词特别高级。我总觉得那是“自己和自己很相像，永远不变的意思”。哈，显然不是，其实就是特别相像。——我 3whenas they glow: ‘when her eyes sparkle.’ 4shroud: ‘covering,’ in this sense it is obsolete, though we still use the expression ‘shrouded in mystery.’ 5Whom: ‘who’ in the sixteenth centry was not restricted to persons. 6Nature moulds the dew of light, etc. : Rosalynde’s breast is conceived as giving out a soft radiance (‘the dew of light’), which goes to complete the sum of her perfections. 7orient, from meaning ‘eastern,’ came, as applied so pearls, to mean ‘brilliant,’ the pearls of the Indian teas being superior to those of the mussels of Europe. 8so divine: i.e. is there anyone so divine. 9奥罗娜（Aurora），罗马神话中的曙光女神。——译者 10此处原文作Nymphs，指希腊神话中属于山林水泽的仙女。——译者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"付勇林","slug":"付勇林","permalink":"https://zhanghuimeng.github.io/tags/付勇林/"},{"name":"T.Lodge","slug":"T-Lodge","permalink":"https://zhanghuimeng.github.io/tags/T-Lodge/"}]},{"title":"《英诗金库》I-12：When in disgrace with fortune and men's eyes, by W. Shakespeare","slug":"2017-12-22-《英诗金库》I-12：When-in-disgrace-with-fortune-and-men-s-eyes-by-W-Shakespeare","date":"2017-12-22T00:00:00.000Z","updated":"2018-06-27T21:05:53.000Z","comments":true,"path":"post/when-in-disgrace-with-fortune-and-men-s-eyes-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/when-in-disgrace-with-fortune-and-men-s-eyes-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：A Consolation（安慰） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第二九首，歌颂了爱的伟大力量。诗人一想到他所爱的人，满腹的愤懑和怀旧的哀思都消失了。 作品原文 When in disgrace with fortune and men’s eyes I all alone beweep my outcast state, And trouble deaf heaven with my bootless cries, And look upon myself, and curse my fate; Wishing me like to one more rich in hope, Featured1 like him, like him with friend possest, Desiring this man’s art, and that man’s scope, With what I most enjoy contented least;2 Yet in these thoughts myself almost despising, Haply I think on Thee—and then my state, Like to the lark at break of day arising From sullen earth, sings hymns at heaven’s gate; For thy sweet love remember’s such wealth brings, That then I scorn to change my state with kings. 译文 屠岸 译 我一旦失去了幸福，又遭人白眼， 就独自哭泣，怨人家把我抛弃， 白白地用哭喊来麻烦聋耳的苍天， 又看看自己，只痛恨时运不济， 愿自己象人家那样：或前程远大， 或一表人才，或胜友如云广交谊， 想有这人的权威，这人的才华， 于自己平素最得意的，倒最不满意； 但在这几乎是看轻自己的思想里， 我偶尔想到了你呵，——我的心怀 顿时象破晓的云雀从阴郁的大地 冲上了天门，歌唱起赞美诗来； 我记着你的甜爱，就是珍宝， 教我不屑把处境跟帝王对调。 我的感想 哎呀，我感觉我都想不动了，只能读一读别人的分析…… 比较值得一读的是一些我没有注意到的用典。据说第3-4行引用的是圣经旧约里的《约伯记》，约伯向上帝祈祷，却没有回应。诗人发现自己也处在相同的境遇中：人格化的天堂就是上帝，而他现在聋了，使得诗人的哭喊毫无用处。约伯也在失去上帝的恩宠之后诅咒自己，这和诅咒自己命运的诗人也很类似。[1] 不过我最想吐槽的一点是，请问您想有的是谁的才华哇，我立刻去读他的诗…… 参考文献 [1] Shakespeare’s Sonnets Summary and Analysis of Sonnet 29 - “When in disgrace with fortune and men’s eyes”. https://www.gradesaver.com/shakespeares-sonnets/study-guide/summary-sonnet-29-when-in-disgrace-with-fortune-and-mens-eyes 脚注 1Featured: ‘formed,’ ‘shaped,’ with reference to life rather than the face. （此处指的与其说是面容，不如说是人生。） 2I. e.: those occupations which generally give him pleasure are least able to satisfy him now. （这些平时会给他带来乐趣的场合不那么能令他满足了。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"学堂在线《汇编语言程序设计》题解及答案","slug":"2017-09-21-学堂在线《汇编语言程序设计》题解及答案","date":"2017-09-21T00:00:00.000Z","updated":"2019-02-14T00:06:39.000Z","comments":true,"path":"post/xuetangx-assembly-language-programming-question-and-answer/","link":"","permalink":"https://zhanghuimeng.github.io/post/xuetangx-assembly-language-programming-question-and-answer/","excerpt":"","text":"这是一篇从简书上转载的博客，原文地址：学堂在线《汇编语言程序设计》题解及答案 《汇编语言程序设计》是鄙系的张悠慧老师开的一门自主进度的课程，它以计算机系小学期《汇编语言程序设计》为蓝本，但是课程的设计并不太好，结构有些杂乱，而且，习题没有答案，很多地方都非常坑爹。所以我决定来写个题解啦…… 课程内容 在清华计算机系，汇编语言程序设计通常作为本科生接触到的第一门计算机系统课程，被定位为该系列的入门课，起到“承上启下”的作用。主要的授课内容包括：（1）汇编语言与计算机系统结构、指令集初步、数制与整数表示、浮点数表示；（2）80x86计算机组织与保护模式、X86指令系统与寻址方式、C与X86汇编、X86汇编编程；（3）MIPS汇编。课程强调汇编语言的软硬件分界与桥梁作用，使得学习者能把程序的执行与计算机的工作过程紧密联系起来，以便深入地感知、理解和体会计算机的逻辑功能以及各种软件系统的原理，逐步形成软件系统功能构筑在其上，硬件系统功能运行于其下的计算机系统思维能力。与以往的讲法不同，本课程突出了“承上启下”这一理念，在内容编排上进一步突出了与相关课程的衔接，尤其是与C语言编程、编译原理、组成原理的衔接。比如说，（1）强化与高级语言的联系，从典型的C语言代码段入手，通过编译成汇编代码来详细解释程序员角度的X86结构运行模型。掌握这两种语言的对应可以将程序的执行与计算机的工作过程紧密联系起来，直接体现汇编语言本身固有的特点，即它是最易于将“程序”和“机器”统一起来的一个结合点。（2）进一步的通过对不同汇编代码的解释来给出微体系结构方面的差异。比如，同一段C代码通过不同的编译器/编译器开关所生成的代码是不一样的，为什么不一样？这就可以通过处理器微体系结构的差异来简单解释。这种做法可以为后续课程，如编译原理、计算机组成原理等提供一些先导知识，并有利于学生从整个系统构成的角度来理解各个课程的作用与位置。（3）加入MIPS汇编（包括部分体系结构的内容），为后续的以MIPS为核心的计算机组成原理、编译原理、操作系统等专业课程奠定MIPS汇编语言的基础。 课程内容与目标 题解 文字填空题 请写出ISA这个缩写的全名（单词首字母大写，单词间以&quot;/&quot;间隔） 答案：= Instruction/Set/Architecture 指令集简介 题解 单选题 只有LOAD和STORE指令可以访问存储器的指令系统属于RISC还是CISC? RISC（√） CISC 分析：这是RISC和CISC指令集的重要区别。 单选题 X86指令系统属于RISC还是CISC? CISC（√） RISC 单选题 X86指令至多只有一个操作数在()中。 内存（√） 寄存器 分析：而MIPS32指令的操作数必须都在寄存器中。 整数的机器表示 题解 单选题 X86处理器的存储字节序是（）。 小端（√） 大端 分析：小端表示即所谓“低对低，高对高”（高位有效数字存在内存的高位中）。X86的字节序为小端，ARM、MIPS和IA64的字节序可配置，网络传输一般采取大端序。详见https://en.wikipedia.org/wiki/Endianness。 无符号整数与带符号整数 题解 文字填空题 已知某32位整数X，其值为-101（十进制），则其16进制补码为（），另一32位整数Y的补码为0xFFFFFF6A，则X+Y的16进制补码(32位)为（），X-Y的16进制补码为（）。（本题一共三个空，十六进制表示示例：0xFFFFFFFF 注意开头与字母大小写。答案之间以‘/‘符号隔开） 答案：0xFFFFFF9B/0xFFFFFF05/0x00000031 分析：正数的补码与原码相等，负数的补码等于原码取反+1。 （其实我这道题一直没有通过，但我觉得计算结果是对的） 判断题 以下几道判断题都与本题条件相同。已知x、y为int类型； unsigned int ux = x; unsigned int uy = y.判断以下等式是否成立？(x&gt;y)==(-x&lt;-y) 正确 错误（√） 分析：若y=-2147483648，则-y=-2147483648，等式不成立。 判断题 (x|-x)&gt;&gt;31 == -1 正确 错误（√） 分析：取x=0，显然原式是错的。不过，当x不等于0时，原式是正确的，因为x和-x中至少有一个是负数，则(x|-x)的最高位必然为1，算术右移31位后，就全是1了。 判断题 ¬x+¬y == ¬(x+y) 正确 错误（√） 分析：随便举个例子就会发现这是错的。 判断题 (int)(ux-uy) == -(y-x) 正确（√） 错误 分析：可以这样思考：无符号整数和带符号整数的内部表示形式和运算规则都是一样的，区别只在于解释的方法。 浮点数的机器表示 题解 数值填空题 单精度浮点数的exp域的位宽是（）位？ 答案：8 数值填空题 单精度浮点数的frac域位宽是（）位。 答案：23 判断题 已知 int x = …; float f = …; double d = …;且d 与 f 都不是 NaN。判断以下关系式是否成立？x == (int)(float) x 正确 错误（√） 分析：float的frac域宽度不够，可能会有精度损失。 判断题 条件同上题 x == (int)(double) x 正确（√） 错误 分析：double的frac域足够放下int，不会有精度损失。 判断题 f == (float)(double) f 正确（√） 错误 分析：float转换成double不会有精度损失。 判断题 d == (float) d 正确 错误（√） 分析：double转换成float可能会有精度损失。 判断题 f == -(-f) 正确（√） 错误 分析：浮点数取负只改变符号位，不会溢出。 判断题 2/3 == 2/3.0 正确 错误（√） 分析：2/3的结果是整数，但2/3.0的结果是浮点数。 判断题 (d &lt; 0.0) == ((d*2) &lt; 0.0) 正确（√） 错误 分析：浮点数的下溢是逐步下溢，不像整数会从负数变成正数。 判断题 (d &gt; f) == (-f &gt; -d) 正确（√） 错误 分析：浮点数取负不会溢出。 判断题 (d+f)-d == f 正确 错误（√） 分析：d+f可能会溢出，损失精度。 80x80汇编与C语言-2 题解 文字填空题 已知寄存器edx内的数值为0x8000，ecx内的则为0x10；请给出地址表达式0x4 (%edx,%ecx,4)所表示的地址值。 答案：0x8044 分析：D(Rb, Ri, S) = Rb + S*Ri +Ｄ 数值填空题 x86-64体系结构具有（）个通用寄存器，而x86-32只有（）个。 答案：16；8 判断题 leal (%edx,%eax),%ecx这条指令在执行过程中需要访问内存数据。 正确 错误（√） 分析：leal指令只计算地址，不访存。因此leal指令也可以用于整数运算。 单选题 请问哪个条件码可用于检测无符号整数运算的溢出？ CF（√） SF ZF OF 分析：CF（Carry Flag），无符号整数运算溢出时置位；SF（Sign Flag），计算结果&lt;0时置位；ZF（Zero Flag），计算结果=0时置位；OF（Overflow Flag），带符号整数运算溢出时置位。 单选题 seta、setb指令适用于无符号还是带符号整数的条件码读取？ 无符号（√） 带符号 分析：seta和setb中的a、b分别指的是above和below。带符号整数对应的是setg和setl（greater和less）。 文字填空题 请补充与下图中C语言对应的汇编代码中的遗漏部分（x86-32结构下编译生成）。 1234567891011121314pushl %ebpmovl %esp, %ebppushl %ebxmovl 8(%ebp), %ecxmovl 12(%ebp), %edxmovl %ecx, %ebxsubl %edx, %ebxmovl %edx, %eaxsubl %ecx, %eaxcmpl %edx, %ecx_____ %ebx, %eaxpopl %ebxpopl %ebpret 答案：cmovg 分析：将汇编代码“翻译”如下： 123456789ecx = xedx = yebx = xebx = x - yeax = yeax = y - xCompare x to yif (?) (eax = x - y)return eax 由分析可知，此处应该填写条件移动指令cmovg（若x&gt;y则传送）。 80x80汇编与C语言-2（续） 题解 文字填空题 左侧的C语言程序段编译为右侧的汇编代码（x86-32体系结构），请填空 答案：.L8；.L3；.L4；.L9；.L8；.L6；.L6 分析：由switch的特性可知，7个空分别对应的是x=0到x=6时的跳转结果。经过分析可知，.L8对应的是默认情况（x=0及其他）；.L6对应的是x=5或6；.L9对应的是x=3；.L4对应的是x=2；.L3对应的是x=1；.L12对应的是返回。 80x80汇编与C语言-3 题解 文字填空题 下图给出了一个C函数，并由gcc编译成相应的汇编代码（AT&amp;T语法格式），请补全这段代码里头被省去的部分。（X86-32结构） 答案：%esp；8；12；%ecx；%ecx；%edx；%ebx 分析：下面用表格给出每行汇编代码的解释。 汇编 解释 pushl %ebp setup, save old ebp movl %esp, %ebp setup movl 8(%ebp), %edx edx = x movl 12(%ebp), %ecx ecx = y pushl %ebx save old ebx movl 12(%ebp), %eax eax = z movl %edx, %ebx ebx = edx = x addl $40, %edx edx += 40 (edx = x + 40 = t3) imull %ecx, %ebx ebx *= y (ebx = x * y = t1) addl %ecx, %ecx ecx += y (ecx = 2*y = t4) sarl %cl, %edx edx &gt;&gt;= cl (cl = t4, edx = t5) subl %ebx, %eax eax -= ebx (eax = z - t1 = t2) imull %edx, %eax eax *= edx (eax = t2 * t5 = rval) popl %ebx reset ebx popl %ebp reset ebp ret return eax (rval) 文字填空题 在X86-32位体系结构中，当前运行函数的帧（Frame）基址寄存器所指向的栈地址的“上方”（高地址）由低到高存放的是函数返回地址、____；“下方”存放的是____、____（此处无需考虑顺序）。 答案：输入参数；局部变量；临时存储分析：其实有很多填法（比如，把临时存储换成“保存的寄存器值”），不过这是标准答案了。 80x80汇编与C语言-4 题解 文字填空题 请按顺序填写图左侧汇编代码对应的C代码（e.g. 右3） 答案：右3；右5；右1 分析：值得注意的是右5和对应的汇编代码。众所周知，算术右移指令对应的除法的取整模式是向下取整，而C语言要求的除法的取整模式是向0取整，因此负数除法的取整会出问题，正确的计算方法是：a&lt;0时，a/2^b = (a+2^b−1)&gt;&gt;b 。这就解释了汇编代码中testl %eax, %eax和jge .L4的意义。jge .L4的意义是：当条件码满足SF=OF时，跳到.L4（即不是负数，不用加上15）。testl做的事是，取后面两个操作数的与，根据运算结果置条件码。当%eax&gt;=0时，运算结果仍为%eax，SF为0，OF也为0，满足条件，跳转；当%eax&lt;0时，SF为1，不符合条件，不跳转。 文字填空题 已知三个二维矩阵的定义如下，并已初始化。 1234#define n 10int a[n][n] ;int b[n][n] ;int c[n][n] ; 需要进行矩阵乘，即矩阵a x b结果置于c。下面这段C代码是一个矩阵乘函数。 12345678910111213void column()&#123; int j, k , i; int r; for (j=0; j&lt;n; j++) &#123; for (k=0; k&lt;n; k++) &#123; r = b[k][j]; for (i=0; i&lt;n; i++) c[i][j] += a[i][k] * r; &#125; &#125;&#125; 答案：%esp；%ebp；%edi；%eax；%eax；-20；%edx；%esi；$9；$9；$8 分析：下面以表格形式给出汇编代码和解释。 汇编 解释 _matrix: pushl %ebp setup, save old ebp movl %esp, %ebp setup pushl %edi save edi pushl %esi save esi pushl %ebx save ebx subl $8, %esp esp -= 8 movl $0, -16(%ebp) j = 0 (-16(%ebp) = j) L13: the start of j loop movl -16(%ebp), %eax eax = j xorl %edi, %edi edi = 0 (edi = k) leal b_start_addr(, %eax, 4), %eax eax = &amp;b[4*j] movl %eax, -20(%ebp) -20(%ebp) = &amp;b[4\\*j + (40*k)] L12: the start of k loop movl -20(%ebp), %edx edx = &amp;b[4\\*j + (40*k)] xorl %ecx, %ecx ecx = 0 (ecx = i * 10) movl $9, %ebx ebx = 9 // as &quot;i&quot; movl (%edx), %esi esi = b[k][j], or r = b[k][j] (esi = r) L11: the start of i loop movl -16(%ebp), %edx edx = j leal (%ecx, %edx), %eax eax = ecx + edx = 10 * i + j leal (%ecx, %edi), %edx edx = ecx + edi = 10 * i + k movl a_start_addr(,%edx, 4), %edx edx = a[4*edx] (edx = a[i][k]) addl $10, %ecx ecx += 10 (ecx = i * 10) imull %esi, %edx edx *= r (edx = a[i][k] * r) addl %edx, c_start_addr(, %eax, 4) c[4*eax] += edx (c[i][j] += a[i][k] * r) decl %ebx ebx-- // as &quot;i&quot; jns L11 if (ebx &gt; 0) goto L11 the end of i loop addl $40, -20(%ebp) -20(%ebp) += 40 (-20(%ebp) = 40\\*k+4*j) incl %edi edi++ (k++) cmpl $9, %edi compare k : 9 jle L12 if (k &lt;= 9) goto L12 the end of k loop incl -16(%ebp) -16(%ebp)++ (-16(%ebp)=j) (j++) cmpl $9, -16(%ebp) compare j : 9 jle L13 if (j &lt;= 9) goto L13 the end of j loop addl $8, %esp esp += 8 popl %ebx finish, reset ebx popl %esi finish, reset esi popl %edi finish, reset edi popl %ebp finish, reset ebp ret return 80x80汇编编程-1 题解 文字填空题 在X86-32位编程中有一种简单的获得所运行的指令地址的方法（X86-32位结构下eip寄存器是无法直接访问的）。比如说我们要获得下面程序中XXXX这条指令的地址并置于eax寄存器中，那么可以采用如下代码段。请补充完函数GetAddress的第一条语句(AT&amp;T语法)。 12movl ____, ____ret 12call GetAddressxxxx 答案：(%esp)；%eax 分析：在call之后，GetAddress的返回地址，也就是xxxx的地址被压栈。此时，只需将栈顶所指向位置的内容（(%esp))，注意括号代表访存）存入eax中再返回。 （其实第二空我没过，但老师告诉我填%eax是对的。） 数值填空题 已知一个c语言结构类型的定义如下图所示，请问在X86 32位Linux系统下变量p所占的空间大小是多少字节，对齐的要求为多少字节对齐？ 答案：24；4 分析： TagStruct的内存分布： k[0] (4 bytes) k[1] (4 bytes) c2 (1 byte) padding (3 bytes) 大小为12字节，4对齐。 S1的内存分布： c (1 byte) padding(3 bytes) i[0] (4 bytes) i[1] (4 bytes) v (12 bytes) 大小为24字节，4对齐。 80x86汇编编程-2（程序链接） 题解 文字填空题 有如下的C代码以及对应的反汇编出来的汇编代码（x86-32体系结构）：当strcpy调用完成返回到foo过程时，buf[0]、buf[1]、buf[2]的值分别是多少?在执行0x0804850d的ret指令前（popl后），ebp的值是多少？上述ret指令执行后，eip的值是多少？用32位16进制表示，注意大小端。e.g. 0x00000000 字符的十六进制转换表已给出 答案：0x64636261；0x68676665；0x08040069；0x68676665；0x08040069 分析： 通过分析可以画出调用strcpy之前完整的栈（具体分析过程略）如下表（每个格子代表4个字节，address向下递减） 内容 指向该位置的指针 callfoo过程保存的%ebp empty empty empty empty empty string address (0x0804859c) foo过程的返回地址 (0x08048523) foo过程保存的%ebp %ebp buf empty empty empty empty empty empty empty string address (strcpy的第二个参数) %ebp - 4 (buf) 可以看出，传递给strcpy的buf指针就是%ebp-4，在复制了字符串&quot;abcdefghi&quot;之后，会发生溢出，破坏栈中保存的%ebp和返回地址。但现在的问题是，在考虑大小端之后，栈中的实际内容到底应该是什么样子的呢？ 由于X86的字节序为小端（“低对低，高对高”），可以画出从buf指针开始向上到string address位置中实际的保存内容（一个格子代表一个字节，地址从上往下递减）： 描述 内容 string address (高) 08 04 85 string address (低) 9c foo的返回地址 (高) 08 04 85 foo的返回地址 (低) 23 保存的%ebp (高) ?? ?? ?? 保存的%ebp (低) ?? buf[0] (高) ?? ?? ?? buf[0] (低) ?? 在向以buf开头的地址中写入字符串&quot;abcdefghi\\0&quot;（转换成16进制，就是0x61626364656667686900）时，由于char类型的大小只有一个字节，大小端对它来说是无所谓的，只要从低地址向高地址覆写就可以。于是，我们得到了修改过的栈帧： 描述 内容 string address (高) 08 04 85 string address (低) 9c foo的返回地址 (buf[2]) (高) 08 04 85 00 foo的返回地址 (buf[2]) (低) 23 69 保存的%ebp (buf[1]) (高) ?? 68 ?? 67 ?? 66 保存的%ebp (buf[1]) (低) ?? 65 buf[0] (高) ?? 64 ?? 63 ?? 62 buf[0] (低) ?? 61 而寄存器会以小端模式来解释内存中的内容，因此可得，buf[0] = 0x64636261，buf[1] = 0x68676665，buf[2] = 0x08040069；popl后得到的%ebp为0x68676665，执行ret后%eip的值（也就是要返回到什么地址）为0x08040069。 MIPS32指令集与编程 题解 文字填空题 异常（exception）可以分类为 ____ 和____两类，其中系统调用属于____异常、时钟中断属于____异常、Page Fault是 ____异常、机器cold reset是 ____异常。 答案：同步；异步；同步；异步；同步；异步 分析：同步异常一般是指令引起的，异步异常一般是硬件引起的。 文字填空题 位于某个跳转指令的Branch Delay Slot中的指令（这一slot中的指令地址为A）发生了异常，那么异常处理完成后，恢复执行的指令地址是 ____；如果该跳转指令是JAL，那么该跳转指令执行完成后31号寄存器的内容是 ____。 答案：A-4；A+4 分析：精确异常处理要求，延迟槽中的指令如果发生异常，恢复执行的指令是跳转指令；函数返回到下一条指令。 期末考试\\ 期末考试中有许多题是重复的，不再一一列出。因为考试不给具体的题目对错，我至今也没有刷到100分，因此也请大家帮忙纠正一下我是不是有题目做错了…… 文字填空题\\ X、Y的数据宽度均为16位，计算结果也用16进制表示）已知[X]补＝0019H，[Y]补＝FE6AH，则[X+Y]补＝____，[X-Y]补＝____。 答案：FE83H；00AFH 分析：显然，X是正数，Y是负数。 [X+Y]补=X补+Y补=0x0019+0xFE6A=0xFE83 −Y原=(Y补−1)反=0x0096 [X−Y]补=X补−Y原=0x0019+0x0096=0x00AF 文字填空题 在X86-32位体系结构中，C语言过程调用的默认传参规则是将过程参数从____至____压入栈，过程返回值（32位）通过____寄存器传出。 答案：右；左；%eax 文字填空题 给出13/8这一数字的32位浮点数（符合IEEE 754标准）表示，即exp= ____；frac= ____ 答案：01111111；10100000000000000000000 分析：13/8=(1101)2/2^3=(1.101)2 因此E=0，exp=E+bias=0+(2^(E_length−1)−1)=0+(01111111)2=(01111111)2 省略掉有效数字开头的1，frac=10100000000000000000000 。（后面一共20个0） 文字填空题 寄存器EAX,EBX内存储的为带符号32位整数，若%EAX &gt;%EBX，则指令cmpl %EAX,%EBX执行后 SF=____，OF= ____。（若不确定，可以填“不确定”） 答案：不确定；不确定 分析：cmpl指令根据%ebx - %eax的值设置条件码。因为补码加法可能溢出也可能不溢出，带符号数的减法结果可能溢出到正数也可能不溢出，所以两空均为不确定。 文字填空题 X86 32位linux系统下的float类型的数据对齐要求是____字节对齐，double类型的是____字节对齐；X86 32位Windows系统下的double类型数据是____字节对齐。 答案：4；4；8 文字填空题 lw $t6, 65536($sp)经过MIPS 32汇编器处理后，产生的代码如下，请补全。 123lui $1,____ addu $1, $1,____ lw $t6, 0($1) 答案：1；$sp 分析：lui将立即数装载到寄存器的高16位，低16位清零，而65536=(10000000000000000)2，因此，执行lui指令后，$1=65536。 文字填空题 li $6, 0x345678 经过MIPS 32汇编器处理后，产生的代码如下，请补全 12lui $1, ________ $6, $1, ____ 答案：0x34；ori/addiu；0x5678 分析：lui的作用同上题；ori作用的是寄存器的低16位。","categories":[],"tags":[{"name":"OldBlog","slug":"OldBlog","permalink":"https://zhanghuimeng.github.io/tags/OldBlog/"}]},{"title":"《英诗金库》I-10：Being your slave, what should I do but tend, by W. Shakespeare","slug":"2017-07-08-《英诗金库》I-10：Being-your-slave-what-should-I-do-but-tend-by-W-Shakespeare","date":"2017-07-08T16:09:10.000Z","updated":"2018-06-27T16:09:10.000Z","comments":true,"path":"post/being-your-slave-what-should-i-do-but-tend-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/being-your-slave-what-should-i-do-but-tend-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Absence（别离） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第五七首。诗人在此宣称他心甘情愿作他爱友的奴仆。 作品原文 Being your slave, what should I do but tend1 Upon the hours and times of your desire? I have no precious time at all to spend Nor services to do, till you require. Nor dare I chide the world-without-end hour Whilst I, my sovereign, watch the colck for you, Nor think the bitterness of absence sour When you have bid your servant once adieu: Nor dare I question with my jealous thought Where you may be, or your affairs suppose2, But like a sad slave, stay and think of nought Save, where you are, how happy you make those; — So true a fool is love, that in your will, Though you do anything, he thinks no ill.3 译文 梁宗岱 译 既然是你奴隶，我有什么可做， 除了时时刻刻伺候你的心愿？ 我毫无宝贵的时间可消磨， 也无事可做，直到你有所驱遣。 我不敢骂那绵绵无尽的时刻， 当我为你，主人，把时辰来看守； 也不敢埋怨别离是多么残酷， 在你已经把你的仆人辞退后； 也不敢用妒忌的念头去探索， 你究竟在哪里，或者为什么忙碌， 只是，像个可怜的奴隶，呆想着 你所在的地方，人们会多幸福。 爱这呆子是那么无救药的带 凭你为所欲为，他都不觉得坏。 我的感想 我之前曾经随便bb了如下内容： 这首诗可以记下来，留作嘲讽之用； 莎士比亚的怨言真多。而且这是默认他的俊友已经出去胡搞了……是么 bid adieu怎么翻译成辞退的？要是真辞退，这首诗就不是这个感觉了，那就应该是…… alas, my love, you do me wrong, to cast off discourteously…. （误） 总之，据说这首诗也应该和下一首（第58首；不过似乎这里并没有选）连起来读，而且还和第26首有点关系[1]，但在这里懒得再去看了。 参考文献 [1] Sonnet 57. https://en.wikipedia.org/wiki/Sonnet_57 脚注 1tend: ‘attend.’ 2your affairs suppose: ‘conjecture what is your business.’ 3in your will…he thinks no ill: ‘he believes that your intentions are always good.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-11：How like a winter hath my absence been, by W. Shakespeare","slug":"2017-07-08-《英诗金库》I-11：How-like-a-winter-hath-my-absence-been-by-W-Shakespeare","date":"2017-07-08T00:00:00.000Z","updated":"2018-06-27T20:40:29.000Z","comments":true,"path":"post/how-like-a-winter-hath-my-absence-been-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/how-like-a-winter-hath-my-absence-been-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：How like a winter has my absence been 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第九七首，表现了诗人别离爱友后的悲哀心情。 作品原文 How like a winter hath my absence been From Thee, the pleasure of the fleeting year! What freezings have I felt, what dark days seen, What old December’s bareness everywhere! And yet this time removed1 was summer’s time; The teeming autumn2, big3 with rich increase, Bearing the wanton burden4 of the prime5 Like widow’d wombs after their lord’s decease; Yet this abundant issue seem’d to me But hope of orphans6, and unfather’d fruit; For summer and his pleasures wait on thee, And, thou away, the very birds are mute; Or if they sing, 'tis with so dull a cheer7, That leaves look pale, dreading the winter’s near. 译文 杨熙龄 译 自从别你以来，我一直象在深冬， 你象最幸福的季节，在飞逝的一年中！ 我感到多么寒冷，天色多么阴霾， 到处象是十二月的荒凉凋衰！ 然而我们俩离别是在夏季的时日， 丰盛的秋天满怀着丰饶的果实， 它负担着佳日留存下的丰硕担负， 象一个才失去夫君的寡妇的肚腹。 然而在我看来这繁茂的收获， 只能是孤儿，是没人品尝的瓜果， 因为夏天和它的幸福始终等待着你， 你不在，便是小鸟儿也把嘴闭起。 即使它们鸣啭，但那调子多么低沉， 树叶儿颜色惨白，担心着冬日将临。 我的感想 感想有点写不动了…… 总之这首诗的重点就是，虽然现在是夏天，但是你离开了我，所以我伤心得好像冬天一样。 有人说这首诗的意象类似于济慈的To Autumn。[1]以前我很喜欢这首诗。这并不是说我现在就不喜欢了，但是我还没有读到那里。 参考文献 [1] A Short Analysis of Shakespeare’s Sonnet 97: ‘How like a winter hath my absence been’. https://interestingliterature.com/2017/11/13/a-short-analysis-of-shakespeares-sonnet-97-how-like-a-winter-hath-my-absence-been/ 脚注 1this time removed: ‘time of separation.’ （分离的时刻。） 2The teeming autumn, etc. : an absolute clause equivalent to, ‘while the teeming autumn was bearing.’ （独立分句，意为：当丰饶的秋天满怀着……） 3big: ‘pregnant.’ 4wanton burden: ‘luxuriant produce’; a burden is that which is borne in the womb. 5prime: ‘spring’, as being the first season of the year. 6But hope of orphans, etc. : Autumn is the mother and Spring the father; but Spring has vanished, so that the children when born will be fatherless. 7cheer: ‘face.’ ‘expression of countenance’; this, the original meaning, is now obsolete. The second meaning ‘mood,’ ‘state of mind,’ hardly survives except in the phrases ‘of good cheer,’ ‘what cheer?’ —and perhaps the latter is now only slang. The word is used in the sense of ‘cheerfulness’ from the 14th century onwards. Cf. note on No.163, 1.3. （“cheer”在此处的语义是脸，面部表情，这是这个词最原始的意思，但现在已经废弃不用了。“cheer”的另一个意思是心情，心境，这个语义现在只存在于短语“of good cheer”（放心）和“what cheer”（你好吗）中，虽然“what cheer”现在已经只是个俗语了。从14世纪开始，“cheer”就开始被作为“cheerfulness”的同义词来使用了。）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"杨熙龄","slug":"杨熙龄","permalink":"https://zhanghuimeng.github.io/tags/杨熙龄/"}]},{"title":"《英诗金库》I-9：Present in Absence, by J. Donne","slug":"2017-07-07-《英诗金库》I-9：Present-in-Absence-by-J-Donne","date":"2017-07-07T00:00:00.000Z","updated":"2018-06-27T15:20:06.000Z","comments":true,"path":"post/present-in-absence-by-j-donne/","link":"","permalink":"https://zhanghuimeng.github.io/post/present-in-absence-by-j-donne/","excerpt":"","text":"作品基本信息 作品名称：Present in Absence（逢在离别中） 作者：无名氏1 出版年代：1602 编注：无 作品原文 Absence, hear thou my protestation Against thy strength2, Distance, and length; Do what thou canst3 for alteration: For hearts of truest mettle Absence doth join, and Time doth settle. Who loves a mistress of such quality, He soon hath found Affection’s ground Beyond time, place, and all mortality. To hearts that cannot vary Absence is present, Time doth tarry. By absence this good means I gain, That I can catch her, Where none can watch her, In some close corner of my brain: There I embrace and kiss her; And so enjoy her and none miss her. 译文 黄新渠 译 呵，离别，听我在抗议 抗议你的完全， 时间和距离； 尽你所能来将我改变吧， 面对真诚坚强的心灵， 离别犹相逢，时光也停息。 谁爱上这种品格的情侣， 他不久就会发现 爱的天地 超越了时间、空间和生死。 对于忠贞不渝的心灵， 离别乃相逢，时光也停滞。 正是用离别这种美妙的方式， 在谁也看不见她的地方 我能与她相遇， 在我隐秘的心灵深处： 我和她拥抱亲吻； 把她赞赏，将她铭记。 我的感想 John Donne简介 没啥可简介的了，都考据出来不是他写的了，那还简介个啥…… 呃，我不记得后面有选他的其他诗歌了，鉴于这位诗人在二十世纪又重新复兴了，还是重新随便讲讲吧。简单来说，他是17世纪的一位玄学派诗人，当时并不出名，但在20世纪的叶芝和T. S. 艾略特等人的大力推崇下，他又出名了。据说是因为他的诗很有现代性和感受力。所以他的很多事迹并不著名，很需要考证。[1] 本诗作者考据 我在网上找到了一篇文章（事实上是The Modern Language Review, Vol. 6, No. 3 (Jul., 1911), pp. 383-386的文章，The Authorship of “Absence, Hear Thou My Protestation”，第一次有机会写正式的参考文献==）[2]，专门考据这首诗的作者。我以前感觉这种事挺有趣的，看了之后，却感觉这种活计的趣味不大…… 简单来说，之前的分析者从风格出发，大多认为这首诗的作者确实是John Donne；而作者提出了一些新的证据用于反驳这种观点。这首诗出现在德拉蒙德的一份手稿中，署名为J. H.；这份手稿中署名为J. H.的除了这首诗之外，还有一首名为Love is a follish melancholy的诗，而这首诗在别的手稿中被标明是John Hoskins的作品。因此，德拉蒙德手稿中的J. H.很有可能就是John Hoskins，这首诗的作者也很可能是John Hoskins。 刚才发现Hoskins的维基[3]也将这首诗归到他的名下，声称Grierson的这篇论述文章是有力的证据。好的，那我就信了吧……John Donne再见…… 参考文献 [1] Featured Poem: Present in Absence by John Donne. https://blog.thereader.org.uk/2015/06/15/featured-poem-present-in-absence-by-john-donne/ [2] The Authorship of “Absence, Hear Thou My Protestation”, H. J. C. Grierson, The Modern Language Review Vol. 6, No. 3 (Jul., 1911), pp. 383-386. https://www.jstor.org/stable/3712719 [3] John Hoskins. https://en.wikipedia.org/wiki/John_Hoskins_(poet) 脚注 1事实上很多信源（如https://www.bartleby.com/40/176.html）认为这首诗的作者是John Donne。亦有人认为是John Hoskins。 2strength: ‘completeness.’ 3thou canst: ‘you can, ’ in Poet.Rhap.（在Davison出版的Poetical Rhapsody中的版本写作’you can’。） for alteration: ‘to make me change.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"J.Donne","slug":"J-Donne","permalink":"https://zhanghuimeng.github.io/tags/J-Donne/"},{"name":"黄新渠","slug":"黄新渠","permalink":"https://zhanghuimeng.github.io/tags/黄新渠/"}]},{"title":"《英诗金库》I-5：The Passionate Shepherd to His Love, by C. Marlowe","slug":"2017-07-03-《英诗金库》I-5：The-Passionate-Shepherd-to-His-Love-by-C-Marlowe","date":"2017-07-03T00:00:00.000Z","updated":"2018-06-27T00:36:03.000Z","comments":true,"path":"post/the-passionate-shepherd-to-his-love-by-c-marlowe/","link":"","permalink":"https://zhanghuimeng.github.io/post/the-passionate-shepherd-to-his-love-by-c-marlowe/","excerpt":"","text":"作品基本信息 作品名称：The Passionate1 Shepherd to His Love（牧羊人的恋歌） 作者：Christopher Marlowe（克里斯托弗·马洛） 出版年代：1599 编注：克·马洛（Christopher Marlowe，1564-1593），英国戏剧家，诗人。他从事文学创作的时间只有短促的五年，但却留下了极为可观的戏剧创作的遗产。他最出名的剧作是《浮士德博士的悲剧》。短诗《牧羊人的恋歌》歌颂理想的爱情，是一首有代表性的优秀抒情诗。 作品原文 Come live with me and be my Love, And we will all the pleasures prove That hills and valleys, dale and field, And all the craggy mountains yield. There we will sit upon the rocks, And see the shepherds feed their flocks, By shallow rivers, to whose falls Melodious birds sing madrigals2. There will I make thee beds of roses And a thousand fragrant posies, A cap of flowers, and a kirtle3 Embroider’d all with leaves of myrtle. A gown made of the finest wool, Which from our pretty Lambs we pull, Fair linéd slippers for the cold, With buckles of the purest gold. A belt of straw and ivy buds, With coral clasps and amber studs: And if these pleasures may thee move, Come live with me and be my Love. Thy silver dishes for thy meat As precious as the gods do eat, Shall on an ivory table be Prepared each day for thee and me. The shepherd swains shall dance and sing For thy delight each May-morning: If these delights thy mind may move, Then live with me and be my love. 译文 袁广达 梁葆成 译 来吧，和我生活在一起，做我的爱人， 在这里将使我们快乐无边： 这里有峻峭秀丽的山峦， 还有风光明媚的山谷田园。 在那边，我俩坐在山岩上， 看牧羊人喂养可爱的羔羊； 在浅浅的小溪旁， 鸟儿随着潺潺流水把爱情歌唱。 在那边，我将用玫瑰编一顶花冠， 用成千的花束做床， 用爱神木的叶子织成长裙； 一切都献给你，绚丽与芬芳！ 从羔羊身上剪下最好的羊毛， 为你做防寒的鞋衬和长袍； 用纯金为你制作鞋扣， 该是多么珍贵，多么荣耀！ 长春藤和芳草做的腰带， 珊瑚带扣点缀着琥珀水晶。 假如这些享受能打动你的心， 来吧，和我生活在一起，做我的爱人！ 银碟里盛着你吃的美味儿， 如同天上众神所用的意义， 丰盛的佳肴将为我俩 摆在象牙制的桌面上。 牧羊少年们在每个五月的早晨， 将为你纵情舞蹈，高歌入云； 假如这些欢乐能打动你的心， 来吧，和我生活在一起，做我的爱人！ 我的感想 我肯定是不懂田园牧歌也不懂马洛的，不过我在网上找到了一篇不错的分析[1]，不妨翻译一下。 关于马洛的简介 克里斯托弗·马洛的成年生活包围在迷雾中。很多人猜测他在剑桥期间被招募称为了一名政府间谍。确实，他从大学未经解释地离开了很久，而且他的生活方式超过了一名背景相当低的学生的一般水平。 生于英国坎特伯雷市（肯特郡），父亲是鞋匠，父母名字分别是“John”和“Katherine” 在坎特伯雷市上了国王学院（Kings School）（现在这所学校里的一栋房子以他命名） 1584年于剑桥大学圣体学院（Corpus Christi College）获得文学士学位（Bachelor of Arts Degree） 在1587年，虽然马洛的宗教倾向（religious leanings）导致了女王枢密院（Privy Council）的干涉，在一些犹豫之后，学院还是按时授予了他文学硕士学位（Master of Arts Degree）（其实这里我也不太明白马洛干了什么，他是想皈依天主教么，以及是他已经有名到需要枢密院来管，还是枢密院太闲，还是他干的事情太严重？） 马洛是一位戏剧家、诗人和翻译家。他是伊丽莎白时期一位非常杰出的悲剧作者。他的作品对同时代的剧作家威廉·莎士比亚产生了很大的影响。 1593年5月18日，由于马洛在同事John Fry的帮助下退出教会（我不知道怎么正式的说……但好像就是叛教了），一张以异端罪指控他的逮捕令被签发 1593年5月30日，马洛在德特福德（Deptford）的一所房子里被Ingram Frizer捅死 关于这首诗本身的介绍 这首诗的格式是六个四行诗节，节奏为抑扬格四音步（iambic tetrameter）（四步，每步两个音节，重音在第二个音节上） 韵脚格式（在第1、2、23和24行的结尾允许尾韵的出现）是AABB CCDD EEFF GGHH IIJJ KKAA 你可能会感觉这首诗的语调是很有诱惑性的（虽然在Walter Raleigh对这首诗的回复作品《The Nymph’s Reply to the Shepherd》中，他认为马洛的作品是纯洁的，这些只是天真幼稚而已） 这首诗中最好的地方是意象。马洛在读者脑中创造了一幅欢快多变的乡村风景画，充满了小溪和许多鸟鸣声；还有成千上万的可以用来装饰恋人的花朵——长裙、腰带…… 注意重复的句子——不断重复的肯定句式，“we will”，“I will”，以及对开头的“Come live with me and be my love”在第20行和24行的重复。以及1、2行和结尾的20、24行的韵脚是相同的。 这首诗中用到了很多头韵——比如“live”和“love”，“we will”，“pleasures prove”，“seeing the shepherds”，“pretty lambs we pull”和“Coral clasps” 参考文献 [1] An Analysis of &quot; The Passionate Shepherd to His Love&quot; by Christopher Marlowe. https://owlcation.com/humanities/Come-Live-With-Me-And-Be-My-Love-The-Passionate-Shepherd-to-His-Love-by-Christopher-Marlowe 脚注 1Passionate: ‘in love’, which state is sometimes called ‘the tender Passion’. 2madrigals: here used loosely for ‘songs.’ A madrigal is strictly a five- or six- Part song written according to elaborate rules. 3kirtle: ‘Petticoat.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"C.Marlowe","slug":"C-Marlowe","permalink":"https://zhanghuimeng.github.io/tags/C-Marlowe/"},{"name":"袁广达","slug":"袁广达","permalink":"https://zhanghuimeng.github.io/tags/袁广达/"},{"name":"梁葆成","slug":"梁葆成","permalink":"https://zhanghuimeng.github.io/tags/梁葆成/"}]},{"title":"《英诗金库》I-7：Under the greenwood tree, by W. Shakespeare","slug":"2017-07-01-《英诗金库》I-7：Under-the-greenwood-tree-by-W-Shakespeare","date":"2017-07-01T13:51:13.000Z","updated":"2018-06-27T13:51:13.000Z","comments":true,"path":"post/under-the-greenwood-tree-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/under-the-greenwood-tree-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Under the Greenwood Tree 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1599 编注：此诗选自《皆大欢喜》第二幕第五场。 作品原文 Under the greenwood tree Who loves to lie with me, And turn his merry note Unto the sweet bird’s throat— Come hither, come hither, come hither! Here shall he see No enemy But winter and rough weather. Who doth ambition shun And loves to live i’ the sun, Seeking the food he eats And pleased with what he gets— Come hither, come hither, come hither! Here shall he see No enemy But winter and rough weather. 译文 朱生豪 译 绿树高张翠幕， 谁来谐我偃卧， 翻将欢乐心声， 学唱枝头鸟鸣： 盍来此？盍来此？盍来此？ 目之所接， 精神契一， 唯忧雨雪之将至。 孰能敝屣尊荣， 来沐丽日光风， 觅食自求果腹， 一饱欣然意足： 盍来此？盍来此？盍来此？ 目之所接， 精神契一， 唯忧雨雪之将至。 我的感想 啊，我感觉朱生豪译得超棒的，我甚至都想把译文背下来（而不是原文） 《皆大欢喜》这部剧本的音乐性不错，后面似乎有很多诗都来自于这部作品。 由于《皆大欢喜》里有许多歌曲，它被称为一部音乐喜剧。的确，这部剧本里的歌曲数量比莎士比亚的其他任何一部剧本都要多。这些音乐包含在阿尔丁森林中发生的故事里，如下所述： Under the Greenwood Tree：这首歌总结了老公爵对乡村生活相比于宫廷生活的舒适性的看法。这首歌是阿米恩斯（Amiens）唱的。 Blow, Blow, Thou Winter Wind：这首歌也是阿米恩斯唱的。它认为，和忘恩负义者给人带来的心理伤害相比，冰霜和冬日寒风造成的肉体痛苦反而是较易忍受的。 What Shall He Have That Killed the Deer：这首歌与相邻几幕里的情话形成了鲜明的对比，为剧本增添了一丝活泼的气息和森林色彩。它强调了田园生活的色彩。 It Was a Lover and his Lass：这是婚礼仪式的序曲。它赞颂了春天，宣布了自然界的新生和人类生活中道德的复兴。[1] 网易云音乐上有这首歌的诸多版本。[2] 参考文献 [1] As You Like It. https://en.wikipedia.org/wiki/As_You_Like_It [2] Under The Greenwood Tree. http://music.163.com/song?id=405998575 脚注","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"《英诗金库》I-1：Spring, the sweet spring, by T. Nashe","slug":"2017-07-01-《英诗金库》I-1：Spring-the-sweet-spring-by-T-Nashe","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-26T17:58:49.000Z","comments":true,"path":"post/spring-the-sweet-spring-by-t-nashe/","link":"","permalink":"https://zhanghuimeng.github.io/post/spring-the-sweet-spring-by-t-nashe/","excerpt":"","text":"作品基本信息 作品名称：Spring（春） 作者：Thomas Nashe（妥默斯·讷徐/托马斯·纳什） 出版年代：1600 编注：妥默斯·讷徐（Thomas Nash，1567-1601），现通译为托马斯·纳什，英国剧作家及诗人。《春》选自他1593年创作的喜剧《夏天的最后的遗嘱》。 作品原文 Spring, the sweet spring, is the year’s pleasant king; Then blooms each thing, then maids dance in a ring, Cold doth not sting, the pretty birds do sing: Cuckoo, jug-jug, pu-we, to-witta-woo!1 The palm and may make country houses gay, Lambs frisk and play, the shepherds pipe all day, And we hear aye birds tune this merry lay: Cuckoo, jug-jug, pu-we, to-witta-woo! The fields breathe sweet, the daisies kiss our feet, Young lovers meet, old wives a-sunning sit, In every street these tunes our ears do greet, Cuckoo, jug-jug, pu-we, to witta-woo! Spring, the sweet spring! 译文 郭沫若 译 春，甘美之春，一年之中的尧舜， 处处都有花树，都有女儿环舞， 微寒但觉清和，佳禽争着唱歌， 啁啁，啾啾2，哥哥，割麦，插—禾！ 榆柳呀山楂，打扮着田舍人家， 羊羔嬉游，牧笛儿整日价吹奏， 百鸟总在和鸣，一片悠扬声韵， 啁啁，啾啾，哥哥，割麦，插—禾！ 郊原荡漾香风，雏菊吻人脚踵， 情侣作对成双，老妪坐晒阳光， 走向任何通衢3，都有歌声悦耳， 啁啁，啾啾，哥哥，割麦，插—禾！ 春！甘美之春！ 我的感想 我本来一直觉得郭沫若译得特别烂，但当我真的手打一遍翻译的时候，反倒觉得他翻译得不错。原文就是那种戏剧夸张式的傻白甜风格，翻译出来再不激情洋溢简直是见鬼了。而且译者肯定比我更有文学素养对吧…… 刚才在百度上搜到了一首以这首诗填词的清唱剧（我不懂音乐，看歌手介绍是这么说的？）风格的歌[1]，惊了。（虽然真是不怎么好听，我不爱这种唱法，感觉一句拐了好多的弯） 参考文献 [1] Spring (Thomas Nash). http://www.xiami.com/song/1773178762 脚注 1jug-jug: the conventional representation of the nightingale’s song; pu-we is perhaps intended for the cry of the peewit or plover; to-witta-woo, more commonly ‘to-wit-to-woo’, is supposed to represent the hoot of the owl. 2啁啾（zhōu jiū），形容鸟叫的声音。 3通衢（tōng qú），指四通八达、宽敞平坦的道路。（学习了一个新词）","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"T.Nashe","slug":"T-Nashe","permalink":"https://zhanghuimeng.github.io/tags/T-Nashe/"},{"name":"郭沫若","slug":"郭沫若","permalink":"https://zhanghuimeng.github.io/tags/郭沫若/"}]},{"title":"《英诗金库》I-2：Summons to Love, by W. Drummond","slug":"2017-07-01-《英诗金库》I-2：Summons-to-Love-by-W-Drummond","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-26T21:10:07.000Z","comments":true,"path":"post/summons-to-love-by-w-drummond/","link":"","permalink":"https://zhanghuimeng.github.io/post/summons-to-love-by-w-drummond/","excerpt":"","text":"作品基本信息 作品名称：Summons To Love（对爱的呼唤） 作者：William Drummond（威廉·德拉蒙德） 出版年代：1616 编注：威廉·德拉蒙德（William Drummond，1585-1649），苏格兰诗人，他在文学上的最高造诣是他那些精妙绝伦的十四行诗，这些诗为他赢得了一个光荣称号——苏格兰的彼特拉克（Francesco de Petrarch, 1304-1374. 意大利诗人，首创十四行诗）。德拉蒙德的主要作品有诗集《天国之花》（The Flowers of Sion）、散文集《柏树林》（Cypresse Grove）等。他还撰写了《苏格兰史》。 作品原文 Phoebus, arise! And paint the sable skies With azure, white, and red: Rouse Memnon’s mother from her Tithon’s bed That she thy career may with roses spread: The nightingales thy coming each-where sing: Make an eternal spring, Give life to this dark world which lieth dead; Spread forth thy golden hair In larger locks than thou wast wont before, And emperor-like decore1 With diadem of pearl thy temples fair: Chase hence the ugly night Which serves but to make dear thy glorious light. —This is that happy morn, That day, long-wished day, Of all my life so dark, (If cruel stars have not my ruin sworn And fates my hopes betray),2 Which, purely white, deserves An everlasting diamond should it mark. This is the morn should bring unto this grove My Love, to hear and recompense my love. Fair King, who all preserves3, But show thy blushing beams And thou two sweeter eyes Shalt see than those which by Peneüs’ streams Did once thy heart surprise. Now, Flora, deck thyself in fairest guise: If that ye, winds, would hear A voice surpassing far Amphion’s lyre, Your furious chiding stay; Let Zephyr only breathe, And with her tresses play. —The winds all silent are,4 And Phoebus in his chair5 Ensaffroning sea and air Makes vanish every star: Night like a drunkard reels Beyond the hills, to shun his flaming wheels: The fields with flowers are deck’d in every hue, The clouds with orient gold spangle their blue; Here is the pleasant place— And nothing wanting is, save She6, alas! 译文 曹明伦 译 太阳哟，升起来吧！ 用碧蓝、雪白和鲜红 涂抹这黑暗的天空； 将门农之母从提托诺斯7卧榻上唤醒 让她用玫瑰花铺开你一天的行程： 处处夜莺啼，歌唱你的来临： 创造出一个永恒之春， 为这僵死的黑暗世界带来生命； 撒开你的一绺绺金发， 撒得更宽更广，浩渺无垠； 用那珍珠镶成的王冠 来装饰你那美丽的额顶： 然后再去驱赶那丑陋的黑夜 它只能使你的金光更珍贵十分。 ——哦，这就是那个快乐的黎明， 那一天哟，是我黑暗生涯中 渴望已久的十分， （假如无情的星宿还未断言我的灭亡， 倘若命运女神还未出卖我的希望）， 这纯洁的一天就理所当然 值得用一颗不朽的钻石来将它标明。 在此良晨应当携我的情侣到这林中来 倾听，来酬答我的爱情。 哦，保护万物的太阳神哟， 你就放射出通红的光芒吧， 你将看见一双甜蜜的眸子 胜过你在珀涅俄斯溪畔见过的眼睛， 而那双眼睛曾惊扰你的心灵。8 哦，弗罗拉9，用最美的衣裳将你打扮： 那么，风儿哟，你们会听见一个声音 远远胜过安菲翁10的竖琴， 停息你们狂暴的怒号； 只让微风儿吹拂飘萦， 轻轻地拨弄她的头发， 温柔地亲吻她的红唇。11 ——所有的风儿都屏住了声息， 福波斯驾驶着他的马车12 用金辉染饰天空与海洋， 使每一颗星星都失去踪影； 黑夜象蹒跚的醉汉躲到山那边， 远远地避开他那喷火的车轮： 鲜花点缀的原野五彩缤纷， 蓝天上布满金光灿烂的彩云； 这儿就是那快乐的地方—— 一切都有了，唉，就是她没来临！ 我的感想 额，我发现我竟然没写啥想法，只好补点东西……后来我发现（因为之后还有更多德拉蒙德的诗），德拉蒙德[1]这人其实丧的很，特别是自从他的初恋死掉之后。这首诗反而显得格外快活了。 参考文献 [1] William Drummond of Hawthornden. https://en.wikipedia.org/wiki/William_Drummond_of_Hawthornden 脚注 1decore: ‘decorate’.（装饰。） 2And fates my hopes betray: the ‘not’ must be understood from the previous line. 3preserves: in modern grammar this would be ‘preservest’. But in 14th-century English, -s was the regular ending of the second person singular. 4After this line Palgrave has omitted the line, ‘Kissing sometimes those purple ports of death’, which apparently means her lips, from which issue words that alay her lovers. 5Phoebus in his chair: i.e. the Sun-god’s chariot. 6save She: the nominative of the pronoun is normally used after ‘save’, a relic of the time when the phrase was a nominative absolute, ‘She being safe.’ 7门农（Memnon）之母即黎明女神厄俄斯（Eos），提托诺斯（Tithonus）是门农之父，埃塞俄比亚王。——译者 8太阳神阿波罗曾在珀涅俄斯溪畔遇见并爱上女神达佛涅（Daphne），古罗马诗人奥维德（Ovid，公元前43年—公元17年）曾写诗赞颂达佛涅美丽的眼睛。——译者 9弗罗拉（Flora），罗马神话传说中的花神。——译者 10安菲翁（Amphion）系主神宙斯之子，以竖琴的魔力筑成忒拜城。——译者 11《金库》原编者删去了这行原诗，为译文节奏和谐起见，故将这句译出。——译者 12在希腊神话中，太阳神既称阿波罗（Apollo），又称福玻斯（Phoebus）。他每天架三匹马拉的载着太阳的金马车由东向西驶过天空。——译者","categories":[],"tags":[{"name":"W.Drummond","slug":"W-Drummond","permalink":"https://zhanghuimeng.github.io/tags/W-Drummond/"},{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"曹明伦","slug":"曹明伦","permalink":"https://zhanghuimeng.github.io/tags/曹明伦/"}]},{"title":"《英诗金库》I-3：When I have seen by Time's fell hand defaced, by W. Shakespeare","slug":"2017-07-01-《英诗金库》I-3：When-I-have-seen-by-Time-s-fell-hand-defaced-by-W-Shakespeare","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-26T21:31:38.000Z","comments":true,"path":"post/when-i-have-seen-by-time-s-fell-hand-defaced-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/when-i-have-seen-by-time-s-fell-hand-defaced-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Time and Love（时间与爱） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：威廉·莎士比亚（William Shakespeare，1564-1616）是英国文艺复兴时期伟大的戏剧家、诗人，生于富裕市民家庭，当过剧场杂役、演员。他一生作品浩繁，著有剧本37部、长诗2首，十四行诗154首。《时间与爱》系他的十四行诗第六四首。莎氏的十四行诗均无标题，《时间与爱》以及本书中莎氏十四行诗前的标题都由原编者所加。 作品原文 When I have seen by Time’s fell1 hand defaced The rich proud cost2 of out-worn buried age; When sometime lofty3 towers I see down-razed, And brass eternal4 slave to mortal rage; When I have seen the hungry ocean gain Advantage on the kingdom of the shore, And the firm soil win of the watery main,5 Increasing store with loss, and loss with store; When I have seen such interchange of state, Or state itself confounded to decay,6 Ruin hath taught me thus to ruminate— That Time will come and take my Love away: —This thought is as a death, which cannot choose But weep to have that which it fears to lose. 译文 屠岸 译 我曾经看见：时间的残酷的手 捣毁了往古年代的异宝奇珍； 无常刈7倒了一度巍峨的高楼， 死的暴力甚至教赤铜化灰尘； 我又见到：贪婪的海洋不断 进占着大陆王国滨海的领地， 坚实的陆地也进占大海的地盘， 盈和亏，得和失相互代谢交替； 我见到这些循环变化的情况， 见到庄严的景象向寂灭沉沦； 断垣残壁就教我这样思量—— 时间总会来夺去我的爱人。8 这念头真象“死”呀，没办法，只好 哭着把唯恐失掉的人儿抓牢。 我的感想 这首诗的比喻写的很不错——或者说是很沉重。 第一段将时间进行了人格化：时间会摧毁人类的造物，是人类无法企及的力量。第二段描述了海洋和陆地之间一场不分胜负的争斗。第三段中，描述者将这些观察结果应用于自己的状况，意识到死亡是不可避免的，时间最终会带走他的爱人。最后两句中，和莎士比亚通常的做法不同，没有提供解决方案，没有机敏的转折，只有不可避免的眼泪。[1] 好吧，即使是诗圣也有这么惨的时候…… 参考文献 [1] Sonnet 64. https://en.wikipedia.org/wiki/Sonnet_64 脚注 1fell: ‘cruel.’ 2cost: ‘costly object’: an obsolete use found in 2 Hen. IV, I. iii. 60, ‘leaves his part-created cost/A naked object to the weeping clouds.’ 3sometime lofty: i.e. which once were lofty. 4eternal as the epithet of ‘brass’ is often found in the Roman poets. 5the firm soil win of the watery main: ‘the land encroaching on the sea.’ In some parts of the coast the sea is gaining on the land, in others the land is gaining on the sea; thus the ‘store’ is balanced by the ‘loss.’ 6state itself confounded to decay: i.e. not merely gained by another element, but wholly disappearing. 7刈，yì，割草。 8莎士比亚学者一般认为莎氏的十四行诗分类如下：第一至一七首是劝说诗人的青年朋友结婚，借以把美的典型在后代身上保存下来；第一八至一二六首继续着诗人对那位青年的倾诉；第一二七至一五二是献给一位女人的；第一五三至一五四则是希腊诗歌的仿作。故此行中的“爱人”有人译为“爱友”。——编注者","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"屠岸","slug":"屠岸","permalink":"https://zhanghuimeng.github.io/tags/屠岸/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"}]},{"title":"《英诗金库》I-4：Since brass, nor stone, nor earth, nor boundless sea, by W. Shakespeare","slug":"2017-07-01-《英诗金库》I-4：Since-brass-nor-stone-nor-earth-nor-boundless-sea-by-W-Shakespeare","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-26T21:47:02.000Z","comments":true,"path":"post/since-brass-nor-stone-nor-earth-nor-boundless-sea-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/since-brass-nor-stone-nor-earth-nor-boundless-sea-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：Since brass, nor stone, nor earth, nor boundless sea 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1609 编注：此诗系莎氏十四行诗第六五首。诗人在诗中表达了这样一种思想：时间能摧毁一切，柔脆的美却能与它对抗，文学是永恒的。 作品原文 Since brass, nor stone, nor earth, nor boundless sea,1 But sad mortality o’erways their power, How with this rage shall beauty hold a plea2, Whose action is no stronger than a flower? O how shall summer’s honey breath hold out Against the wreckful siege of battering days, When rocks impregnable are not so stout Nor gates of steel so strong, but time decays? O fearful meditation! where, alack! Shall Time’s best jewel3 from Time’s chest lie hid? Or what strong hand can hold his swift foot back, Or who his spoil of beauty can forbid? O! none, unless this miracle have might,4 That in black ink my love may still shine bright. 译文 梁宗岱 译 既然铜、石、或大地、或无边的海， 没有不屈服于那阴惨的无常， 美，她的活力比一朵花还柔脆， 怎能和他那肃杀的严威抵抗？ 哦，夏天温馨的呼息怎能支持 残暴的日子刻刻猛烈的轰炸， 当岩石，无论多么险固，或钢扉， 无论多坚强，都要被时光熔化？ 哦，骇人的思想！时光的珍饰，唉， 怎能够不被收进时光的宝箱？ 什么劲手能挽他的捷足回来， 或者谁能禁止他把美丽夺抢？ 哦，没有谁，除非这奇迹有力量： 我的爱在翰墨里永久放光芒。 我的感想 呃，这首诗是第65首，紧接在64首后面，而且显然是和它有一定关系的。[1]其实这两首诗完全可以连起来看——前一首诗的结尾不是恰好没有那种“解决方法”么，我们这里设法接着解决这个问题好了。下面随便翻译一点赏析。 这首十四行诗实际上是第六四首的延续，而且是两首诗中更为感人的。这两首诗讲的都是时间对爱和生命的蹂躏，以及诗人如何设法通过他不朽的诗行克服死亡。此处被人格化的是代表着生命力的夏天，用更多的隐喻描述了它和时间的斗争，比如这些短语：“wreckful siege”，“battering days”，“impregnable”和“gates of steel”。 莎士比亚被时间永远不息的毁灭性深深困扰着。为了描述时间的破坏力到底有多大，莎士比亚列出了自然界中那些对时间最不敏感的物体，比如石头、铜、铁和海洋，而不是那些最脆弱的自然造物，比如玫瑰和郁金香。但最后的对句为我们带来了一些希望：人性中有一些能够战胜时间并永存下去的东西。对于诗人来说，他将通过诗句获胜——他的诗将会永远流传下去。[2] 参考文献 [1] Sonnet 65. https://en.wikipedia.org/wiki/Sonnet_65 [2] SONNET 65. http://www.shakespeare-online.com/sonnets/65detail.html 脚注 1Since brass, nor stone, etc.: 'Since there is neither brass, nor stone, 'etc. 2hold a plea: ‘plead.’ The usual meaning of the phrase is to try an action. 3Time’s best jewel: the poet’s mistress, whom Time will one day gather to the chest where he stores his spoils. 4none, unless, etc.: his lady’s reign will not be over when she is dead, but only when she is forgotten, and that she will not be so long as her poet’s verses are read.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"Sonnet","slug":"Sonnet","permalink":"https://zhanghuimeng.github.io/tags/Sonnet/"},{"name":"梁宗岱","slug":"梁宗岱","permalink":"https://zhanghuimeng.github.io/tags/梁宗岱/"}]},{"title":"《英诗金库》I-6：Crabbed Age and Youth, by W. Shakespeare","slug":"2017-07-01-《英诗金库》I-6：Crabbed-Age-and-Youth-by-W-Shakespeare","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-27T12:03:52.000Z","comments":true,"path":"post/crabbed-age-and-youth-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/crabbed-age-and-youth-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：A Madrigal（小曲） 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1599 编注：此诗选自1599年出版的诗集《爱的礼赞》（The Passionate Pilgrim），据说是莎氏在该诗集中唯一的诗作。 作品原文 Crabbed Age and Youth Cannot live together; Youth is full of pleasance1, Age is full of care; Youth like summer brave2, Age like winter bare; Youth is full of sport, Age’s breath is short, Youth is nimble, Age is lame: Youth is hot and bold, Age is weak and cold, Youth is wild, and Age is tame:— Age, I do abhor thee, Youth, I do adore thee; O! my Love, my Love is young! Age, I do defy thee— O sweet shepherd, hie thee3, For methinks thou stay’st4 too long. 译文 曹明伦 译 乖戾的老年与青春 不能在一起生存： 青春充满了欢乐， 老年却充满忧心。 青春似夏日朝霞， 老年像严寒冬令； 青春如夏天华美， 老年象冬日凋零： 青春生机勃勃， 老年气喘不匀， 青春敏捷，老年跛行： 青春热情无畏， 老年虚弱惧冷， 青春激昂，老年恭顺：—— 我憎恨你，老年， 我崇拜你，青春； 爱人哟，我的爱人正年轻！ 哦，心爱的牧羊人，快去吧， 我看你呆了太多时辰。 我的感想 这首诗写得不错。不过据说[1]，它并不是莎士比亚写的…… 以及这首诗也有音乐改编版（Madeleine Dring），我在Youtube上找到了演唱[2]，虽然录音效果好像不太好。 参考文献 [1] Crabbed Age and Youth. http://www.oxfordreference.com/view/10.1093/oi/authority.20110803095645118 [2] ‘Crabbed Age and Youth’ - Amarantha. https://www.youtube.com/watch?v=yYvUdA30Z0g 脚注 1Pleasance: ‘enjoyment.’ 2brave: ‘fair to see,’ generally referring to clothes. 3hie thee: ‘hasten.’ 4stay’st: ‘delayest.’","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"曹明伦","slug":"曹明伦","permalink":"https://zhanghuimeng.github.io/tags/曹明伦/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"}]},{"title":"《英诗金库》I-8：It was a lover and his lass, by W. Shakespeare","slug":"2017-07-01-《英诗金库》I-8：It-was-a-lover-and-his-lass-by-W-Shakespeare","date":"2017-07-01T00:00:00.000Z","updated":"2018-06-27T14:12:15.000Z","comments":true,"path":"post/it-was-a-lover-and-his-lass-by-w-shakespeare/","link":"","permalink":"https://zhanghuimeng.github.io/post/it-was-a-lover-and-his-lass-by-w-shakespeare/","excerpt":"","text":"作品基本信息 作品名称：It was a Lover and his Lass 作者：William Shakespeare（威廉·莎士比亚） 出版年代：1599 编注：此诗选自《皆大欢喜》第五幕第三场。 作品原文 It was a lover and his lass With a hey and a ho, and a hey-nonino! That o’er the green cornfield did pass In the spring time, the only pretty ring time1, When birds do sing hey ding a ding ding: Sweet lovers love the Spring. Between the acres of the rye These pretty country folks would lie: This carol they began that hour, How that a life was but a flower: And therefore take the present time With a hey and a ho, and a hey-nonino! For love is crowned with the prime In spring time, the only pretty ring time, When birds do sing hey ding a ding ding: Sweet lovers love the Spring. 译文 朱生豪 译 一对情人并着肩， 嗳唷嗳唷嗳嗳唷， 走过了青青稻麦田， 春天是最好的结婚天， 听嘤嘤歌唱枝头鸟， 姐郎们最爱春光好。 小麦青青大麦鲜， 乡女村男交颈儿眠， 新歌一曲意缠绵， 人生美满象好花妍， 劝君莫负艳阳天， 嗳唷嗳唷嗳嗳唷， 恩爱欢娱要趁少年， 春天是最好的结婚天， 听嘤嘤歌唱枝头鸟， 姐郎们最爱春光好。 我的感想 关于《皆大欢喜》的音乐，前一篇里面已经讲过了。我感觉这首歌的改编更多，随便在网易云上找了一个[1]，出乎意料，还挺好听的，伴奏有种《春之歌》的感觉……？ 参考文献 [1] It Was A Lover And His Lass. http://music.163.com/song?id=568099339 脚注 1ring time: i.e. the season for giving a wedding-ring.","categories":[],"tags":[{"name":"GoldenTreasury","slug":"GoldenTreasury","permalink":"https://zhanghuimeng.github.io/tags/GoldenTreasury/"},{"name":"W.Shakespeare","slug":"W-Shakespeare","permalink":"https://zhanghuimeng.github.io/tags/W-Shakespeare/"},{"name":"朱生豪","slug":"朱生豪","permalink":"https://zhanghuimeng.github.io/tags/朱生豪/"}]},{"title":"大学物理实验（2）：压电元件导纳圆的测量，及互感耦合电路特性研究","slug":"2017-04-17-大学物理实验（2）：压电元件导纳圆的测量，及互感耦合电路特性研究","date":"2017-04-17T00:00:00.000Z","updated":"2018-07-18T01:11:00.000Z","comments":true,"path":"post/physics-experiment-b-2-piezoelectric-element/","link":"","permalink":"https://zhanghuimeng.github.io/post/physics-experiment-b-2-piezoelectric-element/","excerpt":"","text":"这是关于《物理实验B（2）》中的压电元件导纳圆实验的总结。我记得一共要求做6次实验，我好像写了3次总结，现在只能找到2篇了。这是一篇搬运过来的旧博客，进行了一定的修改。 压电元件导纳圆测起来不难。 互感耦合电路测起来也不是很难。 实验地点：6A503 实验时间：3小时4分钟 实验难度：中等（要测的数据比较多，需要掌握一点关于示波器使用的技巧；有一个自己设计的内容，但是不难） 实验装置 下图是示波器和函数信号发生器。 下图是函数信号发生器说明书。 下图是示波器说明书。 说明书里面只有标黄的那些才需要看，其中函数信号发生器的“扫频”也不用管。不过我设置的时候遇到了衰减的问题，需要从*10改成*1。 下图是压电元件。 下图是电阻箱。 下图是互感耦合电路装置。 实验步骤 压电元件导纳圆的测量 连接电路（非常简明易懂），把示波器插到正确的位置（注意共地）。 在90kHz附近寻找共振频率（两个电压同相）。 调整频率（这回也要从一边调到另一边，不要回调），找到所需的相位差，用示波器的光标测量相位差和最大值。 Autoset很好用，我还适当调了一下采样率。 电路有一定的延迟，测的时候不要手太快了。 示波器可以自动测量相位差（以角度表示）、峰峰值和最大值，可以作为参考。 我在测量时发现调了半天，U1U_1U1​都不怎么变化，感觉非常恐慌，但是计算出来并没有出太大的问题；不过示波器能测出来的有效位数确实比较少。 将数据输入到实验室电脑的程序中，计算ggg和bbb，打印。 下图是运行中的信号发生器（左）和示波器（右）。 下图是实验室电脑上用于计算ggg和bbb的程序（我的实验数据已经马赛克掉了）。 用示波器研究互感耦合电路的特性 这个实验是选做的，不过就像助教说的那样，别人都做了，你没有做，你的分就低了，所以还是要做。（2018.7.18 UPDATE：I don’t really care now.） 连接电路 按指导书上的图示，改变电阻，进行测量（对于测量ΔR1\\Delta R_1ΔR1​，可以直接按图索骥） 计算 （选做的选做）测量ΔL1\\Delta L_1ΔL1​随R2R_2R2​的变化关系。（我在下面把这个推导了一下。） 这是互感耦合实验电路的样子。 示波器的显示大概是这样的： 实验计算 导纳圆 压电元件导纳圆的推导过程很长，但是测起来并不是很难，只要照着实验指导书上的要求搭电路并且在共振频率附近测量相应的频率fff、UUU、U1U_1U1​和ttt即可。 互感 u1=(R1+ΔR1)I1msin⁡ωt+ω(L1−ΔL1)I1mcos⁡ωtu_1 = (R_1 + \\Delta R_1) I_{1m} \\sin{\\omega t} + \\omega (L_1 - \\Delta L_1) I_{1m} \\cos{\\omega t} u1​=(R1​+ΔR1​)I1m​sinωt+ω(L1​−ΔL1​)I1m​cosωt 从上式可以推导出： ΔR1=M2ω2R2R22+ω2L22\\Delta R_1 = \\frac{M^2 \\omega^2 R_2}{R_2^2 + \\omega^2 L_2^2} ΔR1​=R22​+ω2L22​M2ω2R2​​ ΔL1=M2ω2L2R22+ω2L22\\Delta L_1 = \\frac{M^2 \\omega^2 L_2}{R_2^2 + \\omega^2 L_2^2} ΔL1​=R22​+ω2L22​M2ω2L2​​ 测试方法可以直接参见实验指导书。 当sin⁡ωt=1\\sin{\\omega t} = 1sinωt=1时，测ΔR1\\Delta R_1ΔR1​随R2R_2R2​的变化关系，用 (R1+ΔR1)=u1tI1m=u1tuRmR=ut−uRmuRmR=(utuRm−1)R(R_1 + \\Delta R_1) = \\frac{u_{1t}}{I_{1m}} = \\frac{u_{1t}}{u_{R_m}} R = \\frac{u_t - u_{R_m}}{u_{R_m}}R = (\\frac{u_t}{u_{R_m}} - 1) R (R1​+ΔR1​)=I1m​u1t​​=uRm​​u1t​​R=uRm​​ut​−uRm​​​R=(uRm​​ut​​−1)R 计算ΔR1\\Delta R_1ΔR1​。 当cos⁡ωt=1\\cos{\\omega t} = 1cosωt=1时，测ΔL1\\Delta L_1ΔL1​随R2R_2R2​的变化关系，用 (L1−ΔL1)=1ωu1tI1m=1ωu1tuRmR=1ωut−uRmuRmR=1ω(utuRm−1)R(L_1 - \\Delta L_1) = \\frac{1}{\\omega} \\frac{u_{1t}}{I_{1m}} = \\frac{1}{\\omega} \\frac{u_{1t}}{u_{R_m}} R = \\frac{1}{\\omega} \\frac{u_t - u_{R_m}}{u_{R_m}}R = \\frac{1}{\\omega}(\\frac{u_t}{u_{R_m}} - 1) R (L1​−ΔL1​)=ω1​I1m​u1t​​=ω1​uRm​​u1t​​R=ω1​uRm​​ut​−uRm​​​R=ω1​(uRm​​ut​​−1)R 计算ΔL1\\Delta L_1ΔL1​。 其他 这次的助教格外友善。","categories":[],"tags":[{"name":"PhysicsExperiment","slug":"PhysicsExperiment","permalink":"https://zhanghuimeng.github.io/tags/PhysicsExperiment/"},{"name":"OldBlog","slug":"OldBlog","permalink":"https://zhanghuimeng.github.io/tags/OldBlog/"}]},{"title":"大学物理实验B（1）：塞曼效应","slug":"2017-03-24-大学物理实验（1）：塞曼效应","date":"2017-03-24T00:00:00.000Z","updated":"2018-07-14T18:29:00.000Z","comments":true,"path":"post/physics-experiment-b-1-zeeman-effect/","link":"","permalink":"https://zhanghuimeng.github.io/post/physics-experiment-b-1-zeeman-effect/","excerpt":"","text":"这是关于《物理实验B（2）》中的塞曼效应实验的总结。我记得一共要求做6次实验，我好像写了3次总结，现在只能找到2篇了。这是一篇搬运过来的旧博客，进行了一定的修改。 简单来说，塞曼效应就是原子在外磁场中获得能量，谱线分裂。具体原理大家都知道，什么汞原子546.1nm谱线在磁场中分裂成9条，这里就不写了。这个实验是用F-P标准具观察谱线的分裂，然后用测量望远镜去测干涉圆环的直径。 实验地点：6B605 实验时间：2小时57分钟 实验难度：中等偏简单（毕竟光学实验还要调光路，但不难调，而且老师挺友善的会帮你调。要测的数据也不多。之所以时间长了，是因为我脑抽测错数据了，又重来了一遍） 实验装置 因为是光学实验，所以屋里（和照片）比较暗。 下图是实验装置，从左到右依次是电磁铁、聚光透镜（上面可安装偏振片）、干涉滤光片、F-P标准具和测量望远镜。后面那个带显示屏的白箱子是励磁稳压稳流电源。 下图左上是测量望远镜（和它可以拧的那个部分），右下是电源特写。 下图仍然是F-P标准具和测量望远镜。 下图中的线圈是还没关灯的时候拍下来的电磁铁和汞灯。汞灯发出的光是蓝色的，通过滤光片之后是绿色的。 实验步骤 1. 点燃汞灯 就直接打开开关就行。汞灯是蓝的。 2. 调节光路 在这一步应该先把偏振片和滤光片拿下来，用白纸挡在F-P标准具前看一下，光是不是差不多都进入镜头中了。如果不行，就需要调节高度。然后调节望远镜的高度、消视差、消空程，使得望远镜里能看到比较清晰的几圈亮环；不行的话可以找老师问一下，没准还能看到几个老师热烈地讨论光学问题。此处没图，忘了拍没分裂的谱线状态了，总之是好多圈绿线。我上一个做实验的人大概挺靠谱的，调都没调就大概是准的。 然后把滤光片装上（因为实验室的滤光片不是特别精确，所以可能需要旋转一下，找一个从望远镜里看起来最亮的方向）。 然后把偏振片也装上。 3. 观察零场花样 旋转偏振片，从望远镜里观察谱线的状况（6或3条），记录偏振片读数方向和方位。偏振片上有个小白纸片指示方位。 这一条只是我照着实验指导书随便写出来的，因为我忘了测了。准确的说，因为我不知道应该看到什么，所以觉得偏振片转了一圈都没什么变化…… 4. 加磁场 取下偏振片。 先把稳流电源的电压调到最大（不然会带不动电流），电流调到0，然后再打开开关，电流调到3.50A。（调到2.50A、3.00A、4.50A显然原理相同） 5. 测量Dk2(λ2)D^2_{k}(\\lambda_{2})Dk2​(λ2​)、Dk2(λ1)D^2_{k}(\\lambda_{1})Dk2​(λ1​)和Dk−12(λ1)D^2_{k-1}(\\lambda_{1})Dk−12​(λ1​) 测量方法如下图（这些圈当然应该是绿的）。 而在测量过程中，实际上会看到的是下图。 可以看到上图中刻度4、亮斑中心和叉丝中心对齐了。 要测的直径如图。（最后将用到的波数计算公式是Δv~=12dDk2(λ2)−Dk−12(λ1)Dk−12(λ1)−Dk2(λ1)\\Delta\\tilde{v} = \\frac{1}{2d} \\frac{D^2_{k}(\\lambda_{2}) - D^2_{k-1}(\\lambda_{1})}{D^2_{k-1}(\\lambda_{1}) - D^2_{k}(\\lambda_{1})}Δv~=2d1​Dk−12​(λ1​)−Dk2​(λ1​)Dk2​(λ2​)−Dk−12​(λ1​)​） 公式中的第kkk级表明了谱线环距中心的远近，λ2λ_2λ2​指波长，它反映了它是一套圆环（我说的“套”是指相距比较近的9个谱线环……看上图应该能意会是什么意思，它们是从一条谱线分裂来的）里的第几个环，靠里的编号小。任选两种中间有间隔的不同波长的光形成的谱线环，测编号大的谱线环的第kkk级直径，和编号小的谱线环的第kkk级、第k−1k-1k−1级直径。 如果搞不清楚，那就直接测相邻的两套圆环里从左往右数第3条和第7条的直径，都测完了回去再算（x）。从上图可以看出来，第3、5、7条线最亮，所以这么选择也有一定的道理。 具体的测量直径的方法是，先调整中心亮斑对准十字叉丝（可能需要上下调整，如果看不清叉丝，可以用小台灯补一点光），然后就可以去读待测圆环的左右位置并计算出直径了。机械误差好像很大，所以要测3-5次时直接从一边打轮到另一边（中间尽量不要向回转）测一次，再从这一边转到这一边再测就行（就会有相当的误差）。 除此之外，我得到了一些这样的经验教训： 转螺旋测微器（我不知道学名是什么……大概意会一下）时扶着镜筒，不然镜头可能会晃动甚至移位 尽量使镜头最中间的刻度（应该是4）、叉丝和亮斑中心对齐。不调到4也一样能测，但问题是，粗测的范围只有0-8，如果不使刻度在两边均匀分布，可能测到比较大的圆环刻度就没了。 电流可能会有微小的变化。建议勤加观察，微调一下。 6. 收拾东西 关闭稳流电源时先把电流调到0再关闭电源，因为有大电感。 不要乱摸F-P标准具。虽然它长得很好看。 实验计算 数据处理的公式书上已经给了。 计算波数差： Δv~=12dDk2(λ2)−Dk−12(λ1)Dk−12(λ1)−Dk2(λ1)\\Delta\\tilde{v} = \\frac{1}{2d} \\frac{D^2_{k}(\\lambda_{2}) - D^2_{k-1}(\\lambda_{1})}{D^2_{k-1}(\\lambda_{1}) - D^2_{k}(\\lambda_{1})} Δv~=2d1​Dk−12​(λ1​)−Dk2​(λ1​)Dk2​(λ2​)−Dk−12​(λ1​)​ 计算LLL（7和3当然是根据你测的是哪些谱线决定的）： L=Δv~M2g2−M1g1=2Δv~7−3L = \\frac{\\Delta\\tilde{v}}{M_2g_2-M_1g_1} = 2\\frac{\\Delta\\tilde{v}}{7 - 3} L=M2​g2​−M1​g1​Δv~​=27−3Δv~​ 计算BBB： B=L/0.467cm−1B = L / 0.467cm^{-1} B=L/0.467cm−1 一些说明： 波数差公式里的ddd是F-P标准具的间距，本实验中是2mm。 我也没搞懂为什么LLL是这么算，量子物理没学好。嗯，有没有人愿意告诉我……（2018.7.14 UPDATE：至今也没人告诉我） 算BBB的时候注意单位。 其他 还有几张没太拍好的实验过程图，不过手机能拍下来我已经很感动了。 2018.7.14 UPDATE：回头看这篇文章的时候，虽然感觉写得很详细，但我完全想不起来实验到底应该怎么做，为什么要这么做了。一部分原因是当时我也没搞懂原理……这样的话，总结简直毫无意义，以后我尽量以自己过一年还能看懂自己写的是什么为目标写总结好了。","categories":[],"tags":[{"name":"PhysicsExperiment","slug":"PhysicsExperiment","permalink":"https://zhanghuimeng.github.io/tags/PhysicsExperiment/"},{"name":"OldBlog","slug":"OldBlog","permalink":"https://zhanghuimeng.github.io/tags/OldBlog/"}]},{"title":"数电实验（1）：点亮数字人生","slug":"2017-03-24-数电实验（1）：点亮数字人生","date":"2017-03-24T00:00:00.000Z","updated":"2018-07-14T17:41:00.000Z","comments":true,"path":"post/light-up-your-digital-life/","link":"","permalink":"https://zhanghuimeng.github.io/post/light-up-your-digital-life/","excerpt":"","text":"这是关于《数字逻辑实验》的第一次正式实验，“点亮数字人生”的总结。这是一篇搬运过来的旧博客，进行了一定的修改。 实验指导书截图 实验步骤 1. 在老师处获取一个实验箱 没错，就是刚才你们看到的那个箱子。里面肯定还配芯片、电源、连接线、等等，请收好。以后作业就靠它了。今年有两个班改版了（包括我们班），收到的应该是积木形状的。 2. 安装必要的软件 2.1 在电脑上下载Quartus II 一位善良的同学提供了官网下载链接。 linux: http://download.altera.com/akdlm/software/acdsinst/16.1/196/ib_tar/Quartus-lite-16.1.0.196-linux.tar windows: http://download.altera.com/akdlm/software/acdsinst/16.1/196/ib_tar/Quartus-lite-16.1.0.196-windows.tar 因为他登录之后发现下载只不过是普通的网址，于是便记录下来，这样便可避免登录，还可使用下载软件提速、断点续下。 我把Quartus-lite-16.1.0.196-windows.tar的资源放在百度网盘上了： 链接：http://pan.baidu.com/s/1pLHdq6R 密码：cyy4 至于其他版本呢……有同学是在北邮人上下载了9.0版和13版。13版同样没有什么问题，但9.0版需要破解，否则会缺少.pof文件。在虚拟机上安装的同学还会遇到驱动问题，此事待会再谈。 2.2 开始安装Quartus II 我在Windows10上安装了Quartus-lite-16.1.0.196-windows。在安装过程中，我遇到了这样的问题： 面临这种情况，其实只需要选中原本的软件和MAX II/V两个版本就行，盘不会满的。模拟需要安装那个免费版的ModelSim，但是单纯的烧录不需要。以后如果你发现自己装的少了，还可以用那个安装包去更新。 如果使用的是破解软件或者在虚拟机上安装，还可能会出很多其他的问题，不过我这里差不多这样就装好了。 3. 开始建项目、写程序、绑引脚 具体项目建立过程书上都有，不再赘述。 这次的程序代码也是从书上抄的。 12345678910111213141516171819202122232425262728293031323334353637383940LIBRARY IEEE;USE IEEE.STD_LOGIC_1164.ALL;USE IEEE.STD_LOGIC_ARITH.ALL;USE IEEE.STD_LOGIC_UNSIGNED.ALL;entity digital_7 is port( key:in std_logic_vector(3 downto 0); display:out std_logic_vector(6 downto 0); display_4:out std_logic_vector(3 downto 0) );end digital_7;architecture bhv of digital_7 isbegin display_4&lt;=key; process(key) begin case key is when &quot;0000&quot; =&gt; display &lt;= &quot;1111110&quot;; --0 when &quot;0001&quot; =&gt; display &lt;= &quot;0110000&quot;; --1 when &quot;0010&quot; =&gt; display &lt;= &quot;1101101&quot;; --2 when &quot;0011&quot; =&gt; display &lt;= &quot;1111001&quot;; --3 when &quot;0100&quot; =&gt; display &lt;= &quot;0110011&quot;; --4 when &quot;0101&quot; =&gt; display &lt;= &quot;1011011&quot;; --5 when &quot;0110&quot; =&gt; display &lt;= &quot;0011111&quot;; --6 when &quot;0111&quot; =&gt; display &lt;= &quot;1110000&quot;; --7 when &quot;1000&quot; =&gt; display &lt;= &quot;1111111&quot;; --8 when &quot;1001&quot; =&gt; display &lt;= &quot;1110011&quot;; --9 when &quot;1010&quot; =&gt; display &lt;= &quot;1110111&quot;; --10 when &quot;1011&quot; =&gt; display &lt;= &quot;0011111&quot;; --11 when &quot;1100&quot; =&gt; display &lt;= &quot;1001110&quot;; --12 when &quot;1101&quot; =&gt; display &lt;= &quot;0111101&quot;; --13 when &quot;1110&quot; =&gt; display &lt;= &quot;1001111&quot;; --14 when &quot;1111&quot; =&gt; display &lt;= &quot;1000111&quot;; --15 when others =&gt; display &lt;= &quot;0000000&quot;; --others end case; end process;end bhv; 下面是代码截图。（下图的程序是干什么的，我已经想不起来了。） 写完代码之后，绑定引脚，编译。 这之后可以把USB线插到电脑上，进行设置，准备下载。 有时候在硬件连接那一步会出问题。如果插电以后显示驱动未安装，就需要到Altera的安装目录里找到driver里面的驱动安装之。在虚拟机Windows10，Quartus 9.0环境下，有时候可能会安装不了驱动（安全警报），可以尝试进入Win10调试模式后再安装。 4. 下载 而在这一切都做完之后，我迫不及待地点击了Programmer，想把程序下载到硬件。 结果我发现找不到.pof文件，尝试烧录，也毫无效果。而且，9.0版本软件如果不能破解，好像就没法编译出.pof文件，无法输出程序。 我在这个网站上找到了相关的建议（虽然既没图，又和我们用的器件不一样）： Quartus Prime Lite » Tools » Programmer (or double-click Program Device in the task list) Click Hardware Setup, and select USB-Blaster [USB-0] Click Add File, and select your SRAM object file (.sof) in the output_files directory Click Start Save as example1.cdf, so it opens with these settings next time Great! We did it, the design is now on the FPGA (until we remove the power) 于是，我在工程目录下的output_files文件夹找到了这个vhd1.pof，加载进去，就能下载了。 我猜测，如果没有指定正确的pof文件，编译只会把空的那个文件烧上去，所以无效。 5. 运行 之后的事情就真的很简单了。我的机器必须在烧好之后重开一次电源键，否则程序无法正常显示。下面两张图是我的电路完成图。 下面两张图是从同学的朋友圈里找到的普通箱子的完成图，因为时间过去太久，很难考证到底是谁的图了，非常感谢他们的图，侵删。 如果在下载的时候没开电源，可能会在Quartus主窗口中报错&quot;can’t access JTAG chain&quot;（上课时就有同学遇到这种故障），报这种错误的原因可能包括： 下载有时受环境影响很大。比如，在嘈杂的环境下就可能下载不进去。 电源按钮没有打开或者是工作模式没有跳到&quot;RUN” 电路板问题（电源，负载，虚焊等） FPGA器件上的JTAG相关引脚出现故障 USB-Blaster坏了 10针JTAG线缆没有压制好 JTAG的PCB不正确 …… 大多时候原因就是没开电源，打开电源就可以往上烧了。 实验总结 最后还是很开心的。看到自己按了开关之后数字就能变化，开心。但是紧接下来就又要有加法器的实验了，希望自己仍能存活下来。（2018.7.14 UPDATE：我还活着。）","categories":[],"tags":[{"name":"OldBlog","slug":"OldBlog","permalink":"https://zhanghuimeng.github.io/tags/OldBlog/"},{"name":"DigitCircuit","slug":"DigitCircuit","permalink":"https://zhanghuimeng.github.io/tags/DigitCircuit/"}]},{"title":"IMF预测称，今明两年全球经济增速将略有上升","slug":"2017-01-18-IMF预测称，今明两年全球经济增速将略有上升","date":"2017-01-18T00:00:00.000Z","updated":"2018-07-21T15:15:32.000Z","comments":true,"path":"post/imf-fredicts-global-growth-speed-up-translation/","link":"","permalink":"https://zhanghuimeng.github.io/post/imf-fredicts-global-growth-speed-up-translation/","excerpt":"","text":"这是一篇搬运过来的旧博客，进行了一定的修改。 图为2017年1月16日，中国辽宁省沈阳市停车场里的新车。 国际货币基金组织（International Monetary Fund，简称IMF）称，经历了2016年的停滞不前之后，全球经济增速将在今明两年有所上升。 IMF周一发布的报告显示，全球经济今年可能将增长3.4%，明年可能达到3.6%。 但其官员也称，前景并不明朗，因为它不确定特朗普政府将在美国采取怎样的经济措施。 IMF称，特朗普保证会加大政府在基础建设和军事方面的投入，这将刺激经济增长。但如果经济发展过快，美国中央银行可能会提高利率，旨在将通胀保持在较低水平。 基于对刺激经济增长措施的期望，IMF也提高了对中国的增长预估，同时下调了对其他大型新兴经济体的增长预测，比如印度、巴西和墨西哥。 这一全球借贷方（IMF）称，如果世界趋势转向贸易保护主义，这将伤害国际贸易，并导致经济增速比预测更慢。 词汇总结： Trump administration：特朗普政府 economic action：经济措施 overheat：过热，增长过快 US central bank：美国中央银行 in an effort to：努力，试图（实际上这里不是试图的意思，而是表目的） large emerging economies：大型新兴经济体 原文链接","categories":[],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://zhanghuimeng.github.io/tags/Translation/"}]}]}